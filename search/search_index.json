{"config":{"lang":["fr"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"hash-tool","text":"<p>Outil CLI de v\u00e9rification d'int\u00e9grit\u00e9 de fichiers par hachage BLAKE3. Calcule des empreintes cryptographiques sur un dossier, d\u00e9tecte toute modification ult\u00e9rieure, et compare deux \u00e9tats pour identifier pr\u00e9cis\u00e9ment ce qui a chang\u00e9.</p>"},{"location":"#cas-dusage","title":"Cas d'usage","text":"<ul> <li> <p>Audit avant archivage \u2014 photographier l'\u00e9tat d'un dossier avant de l'archiver,   pour pouvoir prouver plus tard qu'il n'a pas \u00e9t\u00e9 alt\u00e9r\u00e9</p> </li> <li> <p>Contr\u00f4le apr\u00e8s migration \u2014 v\u00e9rifier qu'une copie ou migration de donn\u00e9es est   parfaite, sans perte ni corruption</p> </li> <li> <p>Surveillance p\u00e9riodique \u2014 d\u00e9tecter toute modification non autoris\u00e9e sur un   volume chiffr\u00e9 (VeraCrypt, LUKS) ou un NAS</p> </li> <li> <p>Automatisation CI/CD \u2014 int\u00e9grer un contr\u00f4le d'int\u00e9grit\u00e9 dans un pipeline   via un fichier JSON</p> </li> </ul>"},{"location":"#commandes-disponibles","title":"Commandes disponibles","text":"Commande Description Cas d'usage principal <code>compute</code> Calcule les empreintes BLAKE3 d'un dossier Cr\u00e9er une base de r\u00e9f\u00e9rence <code>verify</code> V\u00e9rifie l'int\u00e9grit\u00e9 d'un dossier contre une base Contr\u00f4le p\u00e9riodique <code>compare</code> Compare deux bases d'empreintes Audit apr\u00e8s migration <code>list</code> Liste les bases disponibles dans un dossier Inventaire rapide <code>diff</code> D\u00e9tecte les fichiers ajout\u00e9s ou supprim\u00e9s (sans recalcul) Diagnostic rapide <code>stats</code> Affiche des statistiques sur une base V\u00e9rification avant verify <code>runner</code> Ex\u00e9cute un pipeline JSON (compute + verify + compare) Automatisation"},{"location":"#modes-dexecution","title":"Modes d'ex\u00e9cution","text":"<p>hash-tool fonctionne dans deux modes \u2014 la d\u00e9tection est automatique :</p> <p>Mode natif (recommand\u00e9) : <code>b3sum</code> et <code>jq</code> sont install\u00e9s sur la machine. hash-tool appelle directement <code>src/integrity.sh</code>. Plus rapide, pas de d\u00e9pendance Docker.</p> <p>Mode Docker (fallback) : <code>b3sum</code> ou <code>jq</code> sont absents, mais l'image <code>hash-tool</code> est disponible. hash-tool construit les volumes et lance <code>docker run</code> automatiquement. L'interface CLI reste identique dans les deux modes.</p> <pre><code># V\u00e9rifier le mode actif\nbash hash-tool check-env\n</code></pre>"},{"location":"#installation-en-3-commandes","title":"Installation en 3 commandes","text":"<pre><code>git clone https://github.com/Alan45678/hash-tool\ncd hash-tool\nchmod +x hash-tool runner.sh src/integrity.sh\n</code></pre> <p>Voir Pr\u00e9requis et Installation pour les d\u00e9tails.</p>"},{"location":"#exemple-rapide","title":"Exemple rapide","text":"<pre><code># 1. Calculer les empreintes d'un dossier\nbash hash-tool compute -data ./mes-documents -save ./bases -meta \"Avant archivage\"\n\n# 2. Plus tard, v\u00e9rifier que rien n'a chang\u00e9\nbash hash-tool verify -base ./bases/hashes_mes-documents.b3 -data ./mes-documents\n\n# 3. Apr\u00e8s une migration, comparer deux \u00e9tats\nbash hash-tool compare -old ./bases/hashes_avant.b3 -new ./bases/hashes_apres.b3\n\n# 4. Automatiser avec un pipeline JSON : pipeline = compute + compute + compare \nbash hash-tool runner -pipeline ./pipelines/pipeline.json\n</code></pre>"},{"location":"#navigation","title":"Navigation","text":"Je veux... Par ici Installer et lancer ma premi\u00e8re commande D\u00e9marrage rapide Apprendre par la pratique Tutoriels Consulter la r\u00e9f\u00e9rence d'une commande Utilisation Utiliser Docker ou Docker Compose Docker R\u00e9soudre un probl\u00e8me Troubleshooting Contribuer ou comprendre le code D\u00e9veloppement"},{"location":"development/architecture/","title":"Architecture","text":""},{"location":"development/architecture/#structure-du-code","title":"Structure du code","text":"<pre><code>hash-tool                  -&gt; wrapper CLI (point d'entr\u00e9e utilisateur)\nrunner.sh                  -&gt; ex\u00e9cuteur de pipelines JSON\nsrc/\n  integrity.sh             -&gt; moteur principal (compute, verify, compare)\n  lib/\n    core.sh                -&gt; fonctions de calcul et v\u00e9rification BLAKE3\n    results.sh             -&gt; \u00e9criture des fichiers de r\u00e9sultats\n    report.sh              -&gt; g\u00e9n\u00e9ration du rapport HTML\n    ui.sh                  -&gt; affichage terminal (couleurs, formatage, quiet mode)\ndocker/\n  entrypoint.sh            -&gt; point d'entr\u00e9e du conteneur Docker\nreports/\n  template.html            -&gt; template HTML pour les rapports compare\npipelines/\n  pipeline.json            -&gt; exemple de pipeline JSON\nexamples/\n  workspace/               -&gt; donn\u00e9es de test et bases de r\u00e9f\u00e9rence\n</code></pre>"},{"location":"development/architecture/#role-de-chaque-module","title":"R\u00f4le de chaque module","text":""},{"location":"development/architecture/#hash-tool","title":"<code>hash-tool</code>","text":"<p>Point d'entr\u00e9e utilisateur. Responsabilit\u00e9s :</p> <ul> <li> <p>D\u00e9tection automatique du mode d'ex\u00e9cution (natif ou Docker)</p> </li> <li> <p>Parsing des arguments CLI (<code>-data</code>, <code>-base</code>, <code>-old</code>, <code>-new</code>, <code>-save</code>, <code>-meta</code>, <code>-quiet</code>)</p> </li> <li> <p>Construction des volumes Docker et dispatch vers <code>_run_docker_integrity()</code></p> </li> <li> <p>\u00c9criture du sidecar <code>.meta.json</code> en mode natif</p> </li> <li> <p>Dispatch vers <code>integrity.sh</code> ou <code>runner.sh</code></p> </li> </ul>"},{"location":"development/architecture/#srcintegritysh","title":"<code>src/integrity.sh</code>","text":"<p>Orchestrateur principal. Responsabilit\u00e9s :</p> <ul> <li> <p>Parsing des arguments positionnels (syntaxe directe sans tirets)</p> </li> <li> <p>Validation des entr\u00e9es (<code>core_assert_b3_valid</code>, <code>core_assert_target_valid</code>)</p> </li> <li> <p>Orchestration du flux : appel des fonctions <code>core.*</code>, <code>results.*</code>, <code>ui.*</code></p> </li> <li> <p>Gestion du r\u00e9pertoire de travail (r\u00e9solution des chemins absolus avant <code>cd</code>)</p> </li> </ul>"},{"location":"development/architecture/#srclibcoresh","title":"<code>src/lib/core.sh</code>","text":"<p>Couche de calcul pur. Responsabilit\u00e9s :</p> <ul> <li> <p><code>core_compute</code> : appel <code>b3sum</code> fichier par fichier, callback de progression</p> </li> <li> <p><code>core_verify</code> : appel <code>b3sum --check</code>, parsing des r\u00e9sultats OK/FAILED/ERREUR</p> </li> <li> <p><code>core_compare</code> : diff entre deux bases <code>.b3</code> (modifi\u00e9s, disparus, nouveaux)</p> </li> <li> <p><code>core_sidecar_write</code> / <code>core_sidecar_read</code> : gestion des m\u00e9tadonn\u00e9es JSON</p> </li> <li> <p><code>core_make_result_dir</code> : cr\u00e9ation du dossier de r\u00e9sultats horodat\u00e9</p> </li> </ul>"},{"location":"development/architecture/#srclibresultssh","title":"<code>src/lib/results.sh</code>","text":"<p>\u00c9criture des fichiers de r\u00e9sultats. Responsabilit\u00e9s :</p> <ul> <li> <p><code>results_write_verify</code> : <code>recap.txt</code> et <code>failed.txt</code></p> </li> <li> <p><code>results_write_compare</code> : <code>recap.txt</code>, <code>modifies.b3</code>, <code>disparus.txt</code>, <code>nouveaux.txt</code></p> </li> </ul>"},{"location":"development/architecture/#srclibreportsh","title":"<code>src/lib/report.sh</code>","text":"<p>G\u00e9n\u00e9ration du rapport HTML. Responsabilit\u00e9s :</p> <ul> <li> <p><code>generate_compare_html</code> : injection des donn\u00e9es dans <code>reports/template.html</code> via <code>awk</code></p> </li> <li> <p><code>_render_html_file_list</code> : rendu des listes de fichiers en HTML</p> </li> </ul>"},{"location":"development/architecture/#srclibuish","title":"<code>src/lib/ui.sh</code>","text":"<p>Affichage terminal. Responsabilit\u00e9s :</p> <ul> <li> <p><code>say</code> : affichage conditionnel (respecte <code>QUIET</code>)</p> </li> <li> <p><code>ui_progress_callback</code> : barre de progression avec ETA</p> </li> <li> <p><code>ui_show_verify_result</code> : affichage du r\u00e9sultat de v\u00e9rification</p> </li> <li> <p><code>ui_show_compare_result</code> : affichage du r\u00e9sum\u00e9 de comparaison</p> </li> <li> <p>D\u00e9tection <code>/dev/tty</code> pour la progression (compatible CI sans TTY)</p> </li> </ul>"},{"location":"development/architecture/#dockerentrypointsh","title":"<code>docker/entrypoint.sh</code>","text":"<p>Point d'entr\u00e9e du conteneur. Responsabilit\u00e9s :</p> <ul> <li> <p>Dispatch des commandes (<code>compute</code>, <code>verify</code>, <code>compare</code>, <code>runner</code>, <code>shell</code>, <code>help</code>)</p> </li> <li> <p>V\u00e9rification des d\u00e9pendances (<code>b3sum</code>, <code>jq</code>, <code>integrity.sh</code>, <code>runner.sh</code>)</p> </li> <li> <p>Mode debug interactif (<code>shell</code>)</p> </li> </ul>"},{"location":"development/architecture/#flux-dexecution-natif","title":"Flux d'ex\u00e9cution natif","text":"<pre><code>hash-tool compute -data ./data -save ./bases\n  \u2514\u2500\u2500 cmd_compute()\n        \u251c\u2500\u2500 _parse_args()\n        \u251c\u2500\u2500 mkdir -p \"$save_dir\"\n        \u251c\u2500\u2500 (sous-shell) cd \"$OPT_DATA\"\n        \u2502     \u2514\u2500\u2500 _run_integrity compute \"$data_abs\" \"$b3_file\"\n        \u2502           \u2514\u2500\u2500 bash integrity.sh compute \"$data_abs\" \"$b3_file\"\n        \u2502                 \u2514\u2500\u2500 core_compute()\n        \u2502                       \u2514\u2500\u2500 b3sum fichier par fichier -&gt; hashes.b3\n        \u2514\u2500\u2500 _sidecar_write() -&gt; hashes.b3.meta.json\n</code></pre>"},{"location":"development/architecture/#flux-dexecution-docker","title":"Flux d'ex\u00e9cution Docker","text":"<pre><code>hash-tool compute -data ./data -save ./bases\n  \u2514\u2500\u2500 cmd_compute()\n        \u251c\u2500\u2500 _parse_args()\n        \u251c\u2500\u2500 mkdir -p \"$save_dir\"\n        \u251c\u2500\u2500 (sous-shell) cd \"$data_abs\"\n        \u2502     \u2514\u2500\u2500 _run_integrity compute \"$data_abs\" \"$b3_file\"\n        \u2502           \u2514\u2500\u2500 _run_docker_integrity compute \"$data_abs\" \"$b3_file\"\n        \u2502                 \u251c\u2500\u2500 volumes+=(-v \"$data_abs\":/data:ro)\n        \u2502                 \u251c\u2500\u2500 volumes+=(-v \"$(dirname $b3_file)\":/bases)\n        \u2502                 \u2514\u2500\u2500 docker run --rm \"${volumes[@]}\" hash_tool compute /data /bases/hashes.b3\n        \u2502                       \u2514\u2500\u2500 entrypoint.sh -&gt; integrity.sh compute /data /bases/hashes.b3\n        \u2502                             \u2514\u2500\u2500 core_compute() -&gt; b3sum -&gt; /bases/hashes.b3\n        \u2514\u2500\u2500 (mode Docker : sidecar d\u00e9j\u00e0 \u00e9crit par integrity.sh dans le conteneur)\n</code></pre>"},{"location":"development/architecture/#conventions-de-code","title":"Conventions de code","text":"<p>Bash strict mode - tous les scripts commencent par <code>set -euo pipefail</code>.</p> <p>Arithm\u00e9tique sous set -e</p> <p><code>(( expression ))</code> retourne exit code 1 quand l'expression vaut z\u00e9ro. Sous <code>set -e</code>, cela tue le script. Toujours utiliser <code>[ \"$var\" -gt 0 ]</code> pour les comparaisons enti\u00e8res en dehors d'un <code>if</code> explicite.</p> <p>Nommage :</p> <ul> <li> <p>Fonctions internes : pr\u00e9fixe <code>_</code> (ex. <code>_run_integrity</code>, <code>_sidecar_write</code>)</p> </li> <li> <p>Commandes CLI : pr\u00e9fixe <code>cmd_</code> (ex. <code>cmd_compute</code>, <code>cmd_verify</code>)</p> </li> <li> <p>Fonctions de biblioth\u00e8que : pr\u00e9fixe du module (ex. <code>core_compute</code>, <code>ui_say</code>)</p> </li> <li> <p>Variables globales export\u00e9es : <code>MAJUSCULES</code> (ex. <code>CORE_VERIFY_STATUS</code>, <code>QUIET</code>)</p> </li> </ul> <p>Contrats de fonction - chaque fonction dans <code>src/lib/</code> documente en t\u00eate :</p> <ul> <li> <p>Contrat d'entr\u00e9e (arguments, pr\u00e9conditions)</p> </li> <li> <p>Contrat de sortie (exit code, stdout, variables positionn\u00e9es)</p> </li> <li> <p>Effets de bord (fichiers \u00e9crits, variables modifi\u00e9es dans le scope appelant)</p> </li> </ul> <p>R\u00e9pertoire de travail - les chemins dans les <code>.b3</code> sont relatifs au r\u00e9pertoire</p> <p>de travail au moment du <code>compute</code>. <code>integrity.sh</code> r\u00e9sout les chemins en absolu avant tout <code>cd</code> pour \u00e9viter les invalidations.</p>"},{"location":"development/architecture/#dependances-externes","title":"D\u00e9pendances externes","text":"Outil Usage Requis <code>bash</code> &gt;= 4 Interpr\u00e9teur Oui <code>b3sum</code> Calcul BLAKE3 Oui (mode natif) <code>jq</code> Sidecars JSON Oui (mode natif) <code>find</code> D\u00e9couverte des fichiers Oui (fourni par coreutils) <code>awk</code> Injection template HTML Oui (fourni par syst\u00e8me) <code>docker</code> Mode conteneur Oui (mode Docker uniquement) <code>shellcheck</code> Lint (d\u00e9veloppement) Non (CI uniquement) <code>mkdocs</code> Documentation (d\u00e9veloppement) Non (CI uniquement)"},{"location":"development/ci/","title":"CI/CD","text":"<p>Le pipeline CI est d\u00e9fini dans <code>.github/workflows/ci.yml</code>. Il se d\u00e9clenche sur chaque push et pull request, toutes branches confondues.</p>"},{"location":"development/ci/#vue-densemble","title":"Vue d'ensemble","text":"<pre><code>push / pull_request\n        \u2502\n        \u251c\u2500\u2500 tests (ubuntu-22.04)  \u2500\u2510\n        \u251c\u2500\u2500 tests (ubuntu-24.04)  \u2500\u253c\u2500\u2500 en parall\u00e8le\n        \u251c\u2500\u2500 docker                \u2500\u2518\n        \u2502\n        \u2514\u2500\u2500 docs (master uniquement, apr\u00e8s tests + docker)\n</code></pre>"},{"location":"development/ci/#job-tests","title":"Job : <code>tests</code>","text":"<p>Tourne en parall\u00e8le sur ubuntu-22.04 et ubuntu-24.04 (<code>fail-fast: false</code> - les deux contextes vont jusqu'au bout ind\u00e9pendamment).</p>"},{"location":"development/ci/#steps","title":"Steps","text":"<p>1. Installer les d\u00e9pendances <pre><code>sudo apt-get install -y b3sum jq shellcheck\n</code></pre></p> <p>2. V\u00e9rifier les pr\u00e9requis <pre><code>b3sum --version &amp;&amp; jq --version &amp;&amp; shellcheck --version &amp;&amp; bash --version\n</code></pre></p> <p>3. Debug T01 - smoke test minimal hors suite de tests : <pre><code>cd /tmp &amp;&amp; mkdir -p integrity-debug/data\necho \"test\" &gt; integrity-debug/data/f.txt\ncd integrity-debug\nbash .../src/integrity.sh compute ./data base.b3\n</code></pre> Permet d'identifier les erreurs d'environnement avant de lancer les suites compl\u00e8tes.</p> <p>4. T00-T20 - <code>run_tests.sh</code></p> <p>Tests fonctionnels de <code>integrity.sh</code> : compute, verify, compare, options CLI, gestion d'erreurs. Lanc\u00e9 avec <code>bash -x</code> et <code>head -200</code> pour limiter la sortie.</p> <p>5. TP01-TP12 - <code>run_tests_pipeline.sh</code></p> <p>Tests du pipeline JSON via <code>runner.sh</code> : JSON invalide, champs manquants, op\u00e9rations inconnues, compute/verify/compare en pipeline, champ <code>resultats</code> personnalis\u00e9.</p> <p>6. CU01-CU53 - <code>run_tests_core.sh</code></p> <p>Tests unitaires de <code>src/lib/core.sh</code> : <code>core_compute</code>, <code>core_verify</code>, <code>core_compare</code>, gestion des variables <code>CORE_VERIFY_*</code>, cas limites.</p> <p>7. ShellCheck</p> <p><pre><code>shellcheck src/integrity.sh runner.sh src/lib/core.sh src/lib/ui.sh \\\n           src/lib/report.sh src/lib/results.sh docker/entrypoint.sh \\\n           tests/run_tests.sh tests/run_tests_pipeline.sh tests/run_tests_core.sh\n</code></pre> Tout warning ShellCheck est trait\u00e9 comme une erreur bloquante.</p> <p>8. Upload artefacts (<code>if: always()</code>)</p> <p>Les r\u00e9sultats dans <code>/tmp/integrity-test*/</code> sont upload\u00e9s m\u00eame en cas d'\u00e9chec, avec une r\u00e9tention de 7 jours. Permet d'inspecter les fichiers produits par les tests.</p>"},{"location":"development/ci/#job-docker","title":"Job : <code>docker</code>","text":"<p>Tourne sur <code>ubuntu-latest</code>. Valide que l'image se construit et que les commandes fondamentales fonctionnent en mode conteneur.</p>"},{"location":"development/ci/#steps_1","title":"Steps","text":"<p>Build</p> <pre><code>docker build -t hash_tool .\n</code></pre> <p>Smoke test - version</p> <pre><code>docker run --rm hash_tool version\n</code></pre> <p>Smoke test - help</p> <pre><code>docker run --rm hash_tool help\n</code></pre> <p>Smoke test - compute via volume</p> <pre><code>mkdir -p /tmp/testdata /tmp/testbases\necho \"contenu alpha\" &gt; /tmp/testdata/alpha.txt\necho \"contenu beta\"  &gt; /tmp/testdata/beta.txt\ndocker run --rm \\\n  -v /tmp/testdata:/data:ro \\\n  -v /tmp/testbases:/bases \\\n  hash_tool compute /data /bases/test.b3\n[ -s /tmp/testbases/test.b3 ] || exit 1\n</code></pre> <p>V\u00e9rifie que le fichier <code>.b3</code> est produit et non vide sur l'h\u00f4te.</p> <p>Smoke test - verify via volume</p> <pre><code>docker run --rm \\\n  -v /tmp/testdata:/data:ro \\\n  -v /tmp/testbases:/bases:ro \\\n  -v /tmp/testresultats:/resultats \\\n  -e RESULTATS_DIR=/resultats \\\n  hash_tool verify /bases/test.b3 /data\n</code></pre> <p>Commande inconnue -&gt; exit non-z\u00e9ro</p> <pre><code>docker run --rm hash_tool commande_inexistante &amp;&amp; exit 1 || true\n</code></pre> <p>V\u00e9rifie que l'entrypoint rejette les commandes non reconnues.</p>"},{"location":"development/ci/#job-docs","title":"Job : <code>docs</code>","text":"<p>Se d\u00e9clenche uniquement sur push sur <code>master</code>, apr\u00e8s que <code>tests</code> et <code>docker</code> aient tous les deux r\u00e9ussi (<code>needs: [tests, docker]</code>).</p> <pre><code>pip install mkdocs mkdocs-material\nmkdocs gh-deploy --force\n</code></pre> <p>D\u00e9ploie la documentation sur la branche <code>gh-pages</code> -&gt; GitHub Pages. Ne se d\u00e9clenche pas sur les branches de feature ni les pull requests.</p>"},{"location":"development/ci/#reproduire-la-ci-en-local","title":"Reproduire la CI en local","text":"<p>Les jobs CI reproduisent exactement <code>make test</code> et <code>make lint</code> :</p> <pre><code>make lint    # reproduit le job ShellCheck\nmake test    # reproduit les trois suites de tests\n</code></pre> <p>Pour reproduire le job Docker :</p> <pre><code>docker build -t hash_tool .\ndocker run --rm hash_tool version\ndocker run --rm hash_tool help\n</code></pre>"},{"location":"development/ci/#causes-frequentes-dechec-ci","title":"Causes fr\u00e9quentes d'\u00e9chec CI","text":"Sympt\u00f4me Cause Solution <code>integrity.sh non ex\u00e9cutable</code> (exit 126) Bit ex\u00e9cutable perdu lors d'un commit <code>git add --chmod=+x src/integrity.sh</code> <code>(( )) : retourne exit 1</code> Expression arithm\u00e9tique sous <code>set -e</code> Remplacer <code>(( expr ))</code> par <code>[ -gt ]</code> <code>/dev/tty: No such device</code> Test <code>/dev/tty</code> sans TTY en CI Tester via subshell <code>( exec &gt;/dev/tty )</code> <code>template.html introuvable</code> Fichier exclu par <code>.gitignore</code> V\u00e9rifier les r\u00e8gles glob (<code>*temp*</code>) ShellCheck SC2034 Variable inter-module non vue par ShellCheck Ajouter <code># shellcheck disable=SC2034</code>"},{"location":"development/ci/#ajouter-un-test","title":"Ajouter un test","text":"<ol> <li>Ajouter le cas dans la suite concern\u00e9e (<code>run_tests.sh</code>, <code>run_tests_pipeline.sh</code> ou <code>run_tests_core.sh</code>)</li> <li>V\u00e9rifier localement avec <code>make test</code></li> <li>Pusher - la CI valide sur les deux OS</li> </ol> <p>Pour un nouveau script de test ind\u00e9pendant, ajouter un step dans <code>ci.yml</code> en suivant la convention existante (<code>chmod +x</code> -&gt; <code>cd tests &amp;&amp; ./mon_script.sh</code>).</p>"},{"location":"development/testing/","title":"Tests","text":""},{"location":"development/testing/#structure","title":"Structure","text":"<pre><code>tests/\n  run_tests.sh           -&gt; tests fonctionnels integrity.sh       (T00-T20)\n  run_tests_core.sh      -&gt; tests unitaires src/lib/core.sh       (CU01-CU53)\n  run_tests_pipeline.sh  -&gt; tests d'int\u00e9gration runner.sh         (TP00-TP12)\n</code></pre>"},{"location":"development/testing/#execution","title":"Ex\u00e9cution","text":""},{"location":"development/testing/#tous-les-tests-recommande","title":"Tous les tests (recommand\u00e9)","text":"<pre><code>make test\n</code></pre> <p>\u00c9quivalent \u00e0 :</p> <pre><code>cd tests &amp;&amp; bash run_tests.sh\ncd tests &amp;&amp; bash run_tests_core.sh\ncd tests &amp;&amp; bash run_tests_pipeline.sh\n</code></pre>"},{"location":"development/testing/#suite-individuelle","title":"Suite individuelle","text":"<pre><code>cd tests &amp;&amp; bash run_tests.sh\ncd tests &amp;&amp; bash run_tests_core.sh\ncd tests &amp;&amp; bash run_tests_pipeline.sh\n</code></pre>"},{"location":"development/testing/#lint-shellcheck","title":"Lint ShellCheck","text":"<pre><code>make lint\n</code></pre> <p>Lance ShellCheck sur tous les scripts. Aucun avertissement tol\u00e9r\u00e9 - tout warning est trait\u00e9 comme une erreur bloquante.</p>"},{"location":"development/testing/#suites-de-tests","title":"Suites de tests","text":""},{"location":"development/testing/#run_testssh-tests-fonctionnels-t00-t20","title":"<code>run_tests.sh</code> - Tests fonctionnels (T00-T20)","text":"<p>Tests de <code>integrity.sh</code> en ex\u00e9cution directe. Couvre :</p> <ul> <li> <p><code>T00</code> - Permissions : <code>integrity.sh</code> est ex\u00e9cutable</p> </li> <li> <p><code>T01</code> - <code>compute</code> : base cr\u00e9\u00e9e, chemins relatifs corrects, nb fichiers correct</p> </li> <li> <p><code>T02</code> - <code>compute</code> : dossier cible inexistant -&gt; erreur</p> </li> <li> <p><code>T03</code> - <code>compute</code> : dossier vide -&gt; erreur</p> </li> <li> <p><code>T04</code> - <code>verify</code> : v\u00e9rification OK, exit 0</p> </li> <li> <p><code>T05</code> - <code>verify</code> : corruption d\u00e9tect\u00e9e, exit 1</p> </li> <li> <p><code>T06</code> - <code>verify</code> : base absente -&gt; erreur</p> </li> <li> <p><code>T07</code> - <code>compare</code> : fichiers de r\u00e9sultats produits</p> </li> <li> <p><code>T08</code> - <code>compare</code> : bases identiques -&gt; 0 diff\u00e9rences</p> </li> <li> <p><code>T09</code> - <code>compare</code> : base absente -&gt; erreur</p> </li> <li> <p><code>T10</code> - <code>verify</code> : argument <code>[dossier]</code> explicite</p> </li> <li> <p><code>T11</code> - Sidecar : \u00e9crit lors du compute, relu lors du verify</p> </li> <li> <p><code>T12</code> - Mode <code>--quiet</code> : aucune sortie terminal</p> </li> </ul>"},{"location":"development/testing/#run_tests_coresh-tests-unitaires-cu01-cu53","title":"<code>run_tests_core.sh</code> - Tests unitaires (CU01-CU53)","text":"<p>Tests des fonctions de <code>src/lib/core.sh</code> en isolation. Couvre :</p> <ul> <li> <p><code>CU01-CU10</code> - <code>core_compute</code> : hachage correct, ordre d\u00e9terministe, chemins relatifs</p> </li> <li> <p><code>CU11-CU20</code> - <code>core_verify</code> : variables <code>CORE_VERIFY_*</code> positionn\u00e9es correctement</p> </li> <li> <p><code>CU21-CU30</code> - <code>core_verify</code> : compteurs OK/FAIL, statuts OK/ECHEC/ERREUR</p> </li> <li> <p><code>CU31-CU40</code> - <code>core_compare</code> : d\u00e9tection modifi\u00e9s/disparus/nouveaux</p> </li> <li> <p><code>CU41-CU50</code> - <code>core_sidecar_write</code> / <code>core_sidecar_read</code> : JSON correct</p> </li> <li> <p><code>CU51-CU53</code> - <code>core_make_result_dir</code> : horodatage si conflit de nom</p> </li> </ul>"},{"location":"development/testing/#run_tests_pipelinesh-tests-dintegration-tp00-tp12","title":"<code>run_tests_pipeline.sh</code> - Tests d'int\u00e9gration (TP00-TP12)","text":"<p>Tests de <code>runner.sh</code> avec des pipelines JSON construits \u00e0 la vol\u00e9e. Couvre :</p> <ul> <li> <p><code>TP00</code> - Permissions : <code>integrity.sh</code> est ex\u00e9cutable</p> </li> <li> <p><code>TP01</code> - JSON invalide -&gt; erreur propre sans stacktrace jq</p> </li> <li> <p><code>TP02</code> - Fichier <code>.pipeline</code> absent -&gt; erreur</p> </li> <li> <p><code>TP03</code> - Champ <code>nom</code> manquant dans compute -&gt; erreur avec mention du champ</p> </li> <li> <p><code>TP04</code> - Op\u00e9ration inconnue -&gt; erreur avec nom de l'op\u00e9ration</p> </li> <li> <p><code>TP05</code> - <code>compute</code> : r\u00e9pertoire de travail correct, chemins relatifs dans la base</p> </li> <li> <p><code>TP06</code> - <code>compute</code> : source absente -&gt; erreur, pas de base cr\u00e9\u00e9e</p> </li> <li> <p><code>TP07</code> - <code>verify</code> : r\u00e9pertoire de travail correct, v\u00e9rification OK</p> </li> <li> <p><code>TP08</code> - <code>verify</code> : corruption d\u00e9tect\u00e9e</p> </li> <li> <p><code>TP09</code> - <code>verify</code> : base <code>.b3</code> absente -&gt; erreur</p> </li> <li> <p><code>TP10</code> - <code>compare</code> : fichiers de r\u00e9sultats produits (sans champ <code>resultats</code>)</p> </li> <li> <p><code>TP10b</code> - <code>compare</code> : champ <code>resultats</code> personnalis\u00e9 dans <code>pipeline.json</code></p> </li> <li> <p><code>TP11</code> - <code>compare</code> : <code>base_a</code> absente -&gt; erreur</p> </li> <li> <p><code>TP12</code> - Pipeline complet : <code>compute \u00d7 2</code> + <code>verify</code> + <code>compare</code></p> </li> </ul>"},{"location":"development/testing/#donnees-de-test","title":"Donn\u00e9es de test","text":"<pre><code>examples/workspace/\n  _data-source/           -&gt; 4 fichiers lorem-ipsum (source de r\u00e9f\u00e9rence)\n  _data-destination/      -&gt; 4 fichiers (1 modifi\u00e9 : lorem-ipsum-01-modif.txt)\n  bases/                  -&gt; bases .b3 pr\u00e9-calcul\u00e9es\n  result/                 -&gt; r\u00e9sultats de compare de r\u00e9f\u00e9rence\n</code></pre> <p>Ne pas modifier ces fichiers</p> <p>Les assertions des suites d\u00e9pendent de l'\u00e9tat exact de ces fichiers. En particulier : <code>_data-destination/lorem-ipsum-01-modif.txt</code> doit \u00eatre diff\u00e9rent de <code>_data-source/lorem-ipsum-01.txt</code> pour que les tests de d\u00e9tection de corruption passent.</p> <p>Pour r\u00e9initialiser apr\u00e8s une modification accidentelle : <pre><code>git checkout examples/\n</code></pre></p>"},{"location":"development/testing/#ajouter-un-test","title":"Ajouter un test","text":""},{"location":"development/testing/#dans-run_testssh-ou-run_tests_pipelinesh","title":"Dans <code>run_tests.sh</code> ou <code>run_tests_pipeline.sh</code>","text":"<p>Les tests utilisent les fonctions <code>assert_*</code> d\u00e9finies en t\u00eate de chaque script :</p> <pre><code># Exemple d'assertion\nassert_file_exists \"base cr\u00e9\u00e9e\" \"$outdir/hashes.b3\"\nassert_contains \"ERREUR signal\u00e9e\" \"$output\" \"ERREUR\"\nassert_not_contains \"pas de stacktrace\" \"$output\" \"parse error\"\nassert_exit_zero \"exit 0\" \"$exit_code\"\nassert_exit_nonzero \"exit non-z\u00e9ro\" \"$exit_code\"\n</code></pre> <p>Ajouter la fonction de test dans le fichier concern\u00e9, puis l'appeler dans la section d'orchestration en bas du script.</p>"},{"location":"development/testing/#dans-run_tests_coresh","title":"Dans <code>run_tests_core.sh</code>","text":"<pre><code># Exemple de test unitaire\n_cu99_dir=$(mktemp -d)\necho \"test\" &gt; \"$_cu99_dir/f.txt\"\ncore_compute \"$_cu99_dir\" \"$_cu99_dir/out.b3\"\nif [ -f \"$_cu99_dir/out.b3\" ]; then\n  pass \"CU99 base cr\u00e9\u00e9e\"\nelse\n  fail \"CU99 base absente\"\nfi\n</code></pre>"},{"location":"development/testing/#bonnes-pratiques","title":"Bonnes pratiques","text":"<ul> <li> <p>Chaque test cr\u00e9e ses donn\u00e9es dans un dossier temporaire (<code>mktemp -d</code>) - pas dans <code>examples/</code></p> </li> <li> <p>Nettoyer avec <code>trap \"rm -rf $tmpdir\" EXIT</code></p> </li> <li> <p>Tester le code de sortie ET le contenu des fichiers produits</p> </li> <li> <p>Pr\u00e9fixer le nom du test avec son identifiant (<code>TP13</code>, <code>CU54</code>, etc.)</p> </li> </ul>"},{"location":"development/testing/#pieges-connus","title":"Pi\u00e8ges connus","text":"<p><code>(( ))</code> sous <code>set -e</code></p> <p>Les expressions arithm\u00e9tiques <code>(( expr ))</code> retournent exit 1 quand elles valent z\u00e9ro. Dans les tests lanc\u00e9s avec <code>set -euo pipefail</code>, cela peut tuer le script de test. Utiliser <code>[ \"$var\" -gt 0 ]</code> \u00e0 la place.</p> <p><code>bash \"$RUNNER\" \"$cfg\"</code> sans <code>|| true</code></p> <p>Si <code>runner.sh</code> retourne exit 1 (m\u00eame attendu), le script de test s'arr\u00eate. Toujours capturer le code de sortie explicitement :</p> <pre><code>bash \"$RUNNER\" \"$cfg\" &gt; \"$output_file\" 2&gt;&amp;1 || true\nexit_code=$?\n</code></pre> <p>Permissions</p> <p><code>integrity.sh</code> doit \u00eatre ex\u00e9cutable. Si un commit a perdu le bit ex\u00e9cutable :</p> <pre><code>git add --chmod=+x src/integrity.sh\ngit commit -m \"fix: restaurer bit ex\u00e9cutable integrity.sh\"\n</code></pre>"},{"location":"docker/compose/","title":"Docker Compose","text":"<p><code>docker-compose.yml</code> d\u00e9finit trois services pr\u00e9configur\u00e9s pour les cas d'usage courants. L'objectif est d'\u00e9viter de retaper les options <code>-v</code> et <code>-e</code> \u00e0 chaque commande.</p>"},{"location":"docker/compose/#configuration-initiale","title":"Configuration initiale","text":"<p>Avant tout usage, adapter la section <code>x-volumes</code> en t\u00eate du fichier :</p> <pre><code>x-volumes:\n  data:      &amp;vol-data      /chemin/vers/donnees     # donn\u00e9es \u00e0 hacher (lecture seule)\n  bases:     &amp;vol-bases     /chemin/vers/bases        # fichiers .b3\n  pipelines: &amp;vol-pipelines /chemin/vers/pipelines   # fichiers pipeline.json\n  resultats: &amp;vol-resultats /chemin/vers/resultats   # r\u00e9sultats compare/verify\n</code></pre> <p>C'est le seul endroit \u00e0 modifier - tous les services r\u00e9f\u00e9rencent ces chemins via les ancres YAML (<code>*vol-data</code>, <code>*vol-bases</code>, etc.).</p>"},{"location":"docker/compose/#exemples-de-chemins-selon-lenvironnement","title":"Exemples de chemins selon l'environnement","text":"Environnement Exemple Linux / serveur <code>/srv/hash-tool/donn\u00e9es</code> macOS <code>/Users/moi/Documents/donn\u00e9es</code> WSL2 <code>/home/wsl-acer/donn\u00e9es</code> (pas <code>/mnt/c/...</code>) NAS Synology <code>/volume1/donn\u00e9es</code> <p>WSL2</p> <p>Ne pas utiliser les chemins <code>/mnt/c/...</code> - Docker Desktop ne monte pas correctement les chemins Windows comme volumes. Utiliser le filesystem Linux natif (<code>/home/...</code>).</p>"},{"location":"docker/compose/#services","title":"Services","text":""},{"location":"docker/compose/#integrity-commandes-unitaires","title":"<code>integrity</code> - commandes unitaires","text":"<p>Service principal pour <code>compute</code>, <code>verify</code> et <code>compare</code>.</p> <pre><code># Calculer les empreintes\ndocker compose run --rm integrity compute /data /bases/hashes.b3\n\n# V\u00e9rifier l'int\u00e9grit\u00e9\ndocker compose run --rm integrity verify /bases/hashes.b3 /data\n\n# Comparer deux bases\ndocker compose run --rm integrity compare /bases/old.b3 /bases/new.b3\n</code></pre> <p>Volumes mont\u00e9s : <code>/data</code> (<code>:ro</code>), <code>/bases</code>, <code>/resultats</code>.</p>"},{"location":"docker/compose/#pipeline-execution-runnersh","title":"<code>pipeline</code> - ex\u00e9cution runner.sh","text":"<p>Service d\u00e9di\u00e9 \u00e0 l'ex\u00e9cution d'un pipeline JSON complet.</p> <pre><code>docker compose run --rm pipeline\n</code></pre> <p>Lance <code>runner.sh /pipelines/pipeline.json</code> automatiquement. Le fichier <code>pipeline.json</code> doit \u00eatre plac\u00e9 dans le dossier mapp\u00e9 sur <code>/pipelines</code>.</p> <p>Volumes mont\u00e9s : <code>/data</code> (<code>:ro</code>), <code>/bases</code>, <code>/pipelines</code>, <code>/resultats</code>.</p>"},{"location":"docker/compose/#cron-verification-periodique","title":"<code>cron</code> - v\u00e9rification p\u00e9riodique","text":"<p>Service optionnel, d\u00e9sactiv\u00e9 par d\u00e9faut (profil <code>cron</code>).</p> <pre><code># D\u00e9marrer le service cron en arri\u00e8re-plan\ndocker compose --profile cron up -d cron\n\n# Arr\u00eater\ndocker compose --profile cron down\n</code></pre> <p>Variables de configuration :</p> Variable D\u00e9faut Description <code>CRON_SCHEDULE</code> <code>0 3 * * *</code> Expression cron (03h00 chaque nuit) <code>CRON_BASE</code> <code>/bases/hashes.b3</code> Base \u00e0 v\u00e9rifier <p>Image \u00e9tendue requise</p> <p>Le service <code>cron</code> utilise l'image <code>hash_tool</code> standard qui ne contient pas <code>crond</code>. Pour un usage en production, cr\u00e9er une image d\u00e9riv\u00e9e avec <code>crond</code> install\u00e9. Voir Automatisation pour le setup complet.</p>"},{"location":"docker/compose/#build-de-limage","title":"Build de l'image","text":"<p>Si l'image n'est pas encore build\u00e9e :</p> <pre><code>docker compose build\n# ou\ndocker build -t hash_tool .\n</code></pre> <p>Les deux sont \u00e9quivalents - <code>docker-compose.yml</code> r\u00e9f\u00e9rence le m\u00eame <code>Dockerfile</code>.</p>"},{"location":"docker/compose/#comparaison-docker-compose-run-vs-docker-run","title":"Comparaison <code>docker compose run</code> vs <code>docker run</code>","text":"<code>docker compose run</code> <code>docker run</code> Volumes Pr\u00e9configur\u00e9s dans <code>docker-compose.yml</code> \u00c0 sp\u00e9cifier \u00e0 chaque commande Image R\u00e9f\u00e9renc\u00e9e dans <code>docker-compose.yml</code> \u00c0 sp\u00e9cifier \u00e0 chaque commande Cas d'usage Usage r\u00e9gulier sur un poste fixe Usage ponctuel, CI, scripts <p>En CI, <code>docker run</code> avec les volumes explicites est pr\u00e9f\u00e9rable - pas de d\u00e9pendance \u00e0 <code>docker-compose.yml</code> ni aux chemins locaux.</p>"},{"location":"docker/compose/#exemple-complet-workflow-audit","title":"Exemple complet - workflow audit","text":"<pre><code># 1. Configurer les chemins dans docker-compose.yml (une seule fois)\n# data:      /srv/archives\n# bases:     /srv/bases\n# resultats: /srv/resultats\n\n# 2. Calculer les empreintes initiales\ndocker compose run --rm integrity compute /data /bases/hashes_archives.b3\n\n# 3. Plus tard, v\u00e9rifier l'int\u00e9grit\u00e9\ndocker compose run --rm integrity verify /bases/hashes_archives.b3 /data\n\n# 4. Apr\u00e8s une migration, comparer deux \u00e9tats\ndocker compose run --rm integrity compare \\\n  /bases/hashes_avant.b3 \\\n  /bases/hashes_apres.b3\n</code></pre>"},{"location":"docker/setup/","title":"Setup Docker","text":""},{"location":"docker/setup/#build-de-limage","title":"Build de l'image","text":"<p>Commande standard : <code>docker build -t hash_tool .</code>. Build multi-arch ARM64 : <code>docker build --platform linux/arm64 -t hash_tool:arm64 .</code>. Le build doit \u00eatre lanc\u00e9 depuis la racine du d\u00e9p\u00f4t (pr\u00e9sence du <code>Dockerfile</code>). Taille de l'image produite : ~15 Mo (base Alpine 3.19).</p>"},{"location":"docker/setup/#dependances-installees","title":"D\u00e9pendances install\u00e9es","text":"<p>Liste des packages Alpine install\u00e9s : bash, jq, b3sum (depuis community), coreutils, findutils. Aucun binaire t\u00e9l\u00e9charg\u00e9 depuis GitHub - tout depuis <code>apk</code>. Justification de ce choix (fiabilit\u00e9, reproductibilit\u00e9).</p>"},{"location":"docker/setup/#entrypoint","title":"Entrypoint","text":"<p>R\u00f4le de <code>docker/entrypoint.sh</code> : dispatch des commandes vers <code>integrity.sh</code> ou <code>runner.sh</code>. Commandes support\u00e9es : <code>compute</code>, <code>verify</code>, <code>compare</code>, <code>runner</code>, <code>shell</code> (debug interactif), <code>help</code>. Commande inconnue -&gt; exit non-z\u00e9ro.</p>"},{"location":"docker/setup/#variables-denvironnement","title":"Variables d'environnement","text":"<p><code>RESULTATS_DIR</code> : dossier de sortie dans le conteneur (d\u00e9faut : <code>/resultats</code>). Doit correspondre \u00e0 un volume mont\u00e9. <code>HASH_TOOL_DOCKER_IMAGE</code> : non applicable dans le conteneur, utilis\u00e9e par <code>hash-tool</code> c\u00f4t\u00e9 h\u00f4te.</p>"},{"location":"docker/volumes/","title":"Volumes Docker","text":""},{"location":"docker/volumes/#volumes-definis","title":"Volumes d\u00e9finis","text":"<p>Quatre volumes utilis\u00e9s par le conteneur : <code>/data</code> (donn\u00e9es \u00e0 hacher), <code>/bases</code> (fichiers <code>.b3</code>), <code>/pipelines</code> (fichiers <code>pipeline.json</code>), <code>/resultats</code> (sorties).</p>"},{"location":"docker/volumes/#regles-de-montage","title":"R\u00e8gles de montage","text":"<p><code>/data</code> : monter en lecture seule (<code>:ro</code>) - le conteneur ne doit jamais modifier les donn\u00e9es source. <code>/bases</code> : lecture/\u00e9criture - les <code>.b3</code> et sidecars sont \u00e9crits ici. <code>/resultats</code> : lecture/\u00e9criture - r\u00e9sultats <code>verify</code> et <code>compare</code> \u00e9crits ici. <code>/pipelines</code> : lecture seule suffisante.</p>"},{"location":"docker/volumes/#mapping-par-commande","title":"Mapping par commande","text":"<p>Tableau : pour chaque commande (<code>compute</code>, <code>verify</code>, <code>compare</code>, <code>runner</code>), quels volumes sont requis et avec quel mode d'acc\u00e8s. Erreur fr\u00e9quente : tenter d'\u00e9crire la base dans <code>/data</code> mont\u00e9 en <code>:ro</code>.</p>"},{"location":"docker/volumes/#exemples-de-montage","title":"Exemples de montage","text":"<p>Commandes <code>docker run</code> compl\u00e8tes avec tous les <code>-v</code> pour chaque cas d'usage. Convention de nommage des chemins h\u00f4te selon l'OS : Linux (<code>/srv/...</code>), macOS (<code>/Users/...</code>), WSL (<code>/mnt/c/...</code>), NAS (<code>/volume1/...</code>).</p>"},{"location":"getting-started/installation/","title":"Installation","text":""},{"location":"getting-started/installation/#installation-native","title":"Installation native","text":"<p>\u00c9tapes : clonage du d\u00e9p\u00f4t, application des permissions (<code>chmod +x</code> sur <code>hash-tool</code>, <code>runner.sh</code>, <code>src/integrity.sh</code>), v\u00e9rification avec <code>hash-tool check-env</code>. Sortie attendue de <code>check-env</code> ligne par ligne comment\u00e9e.</p>"},{"location":"getting-started/installation/#build-docker","title":"Build Docker","text":"<p>Commande de build standard : <code>docker build -t hash_tool .</code>. Build multi-arch pour ARM64 : <code>docker build --platform linux/arm64 -t hash_tool:arm64 .</code>. V\u00e9rification que l'image est disponible : <code>docker image inspect hash_tool</code>.</p>"},{"location":"getting-started/installation/#verification-de-linstallation","title":"V\u00e9rification de l'installation","text":"<p>Commande de validation finale : <code>hash-tool version</code> puis <code>hash-tool check-env</code>. Sortie compl\u00e8te attendue dans les deux cas. Indicateurs visuels OK/KO expliqu\u00e9s. Mode d'ex\u00e9cution s\u00e9lectionn\u00e9 affich\u00e9 en fin de <code>check-env</code>.</p>"},{"location":"getting-started/prerequisites/","title":"Pr\u00e9requis","text":""},{"location":"getting-started/prerequisites/#mode-natif","title":"Mode natif","text":"<p>Le mode natif est recommand\u00e9 pour tous les usages r\u00e9guliers. Il est plus rapide et ne n\u00e9cessite pas Docker.</p> D\u00e9pendance Version minimale R\u00f4le <code>bash</code> 4.0 Interpr\u00e9teur - bash 3.x (macOS syst\u00e8me) est incompatible <code>b3sum</code> toute version r\u00e9cente Calcul des empreintes BLAKE3 <code>jq</code> 1.6 Lecture et \u00e9criture des sidecars <code>.meta.json</code>"},{"location":"getting-started/prerequisites/#verification","title":"V\u00e9rification","text":"<pre><code>bash --version   # doit afficher \"version 4.\" ou sup\u00e9rieur\nb3sum --version\njq --version\n</code></pre>"},{"location":"getting-started/prerequisites/#installation-par-os","title":"Installation par OS","text":"<p>Debian / Ubuntu</p> <pre><code>sudo apt-get update\nsudo apt-get install -y jq\n\n# b3sum : absent des d\u00e9p\u00f4ts par d\u00e9faut, installer le binaire statique\nsudo wget https://github.com/BLAKE3-team/BLAKE3/releases/latest/download/b3sum_linux_x64_musl \\\n  -O /usr/local/bin/b3sum\nsudo chmod +x /usr/local/bin/b3sum\n</code></pre> <p>Alpine Linux</p> <pre><code>apk add --no-cache jq\napk add --no-cache b3sum   # d\u00e9p\u00f4t community requis\n</code></pre> <p>macOS</p> <pre><code>brew install jq b3sum bash\n</code></pre> <p>bash sur macOS</p> <p>Le bash syst\u00e8me macOS (<code>/bin/bash</code>) est en version 3.2 pour des raisons de licence. Il est incompatible avec hash_tool. Apr\u00e8s <code>brew install bash</code>, utiliser <code>/opt/homebrew/bin/bash</code> ou ajouter <code>/opt/homebrew/bin</code> en t\u00eate de <code>PATH</code>. Ne pas remplacer <code>/bin/bash</code> syst\u00e8me.</p> <p>WSL2 (Windows)</p> <pre><code>sudo apt-get update\nsudo apt-get install -y jq\nsudo wget https://github.com/BLAKE3-team/BLAKE3/releases/latest/download/b3sum_linux_x64_musl \\\n  -O /usr/local/bin/b3sum\nsudo chmod +x /usr/local/bin/b3sum\n</code></pre> <p>WSL2 : privil\u00e9gier le mode natif</p> <p>Le mode Docker sur WSL2 est fonctionnel mais lent (overhead conteneur + pont r\u00e9seau). Installer <code>b3sum</code> et <code>jq</code> nativement - <code>hash-tool</code> bascule automatiquement en mode natif.</p>"},{"location":"getting-started/prerequisites/#mode-docker","title":"Mode Docker","text":"<p>Le mode Docker est utile quand l'installation native n'est pas possible : NAS Synology, environnement restrictif, ou machine sans droits d'installation.</p> D\u00e9pendance Version minimale R\u00f4le <code>docker</code> 20.10 Moteur de conteneurs image <code>hash_tool</code> - Image build\u00e9e localement (non publi\u00e9e sur Docker Hub)"},{"location":"getting-started/prerequisites/#verification_1","title":"V\u00e9rification","text":"<pre><code>docker --version\ndocker image inspect hash_tool   # doit retourner des infos sur l'image\n</code></pre>"},{"location":"getting-started/prerequisites/#build-de-limage","title":"Build de l'image","text":"<p>L'image n'est pas publi\u00e9e sur Docker Hub - elle doit \u00eatre build\u00e9e depuis les sources :</p> <pre><code>cd /chemin/vers/hash-tool\ndocker build -t hash_tool .\n</code></pre> <p>Build multi-architecture (ARM64 pour NAS Synology) :</p> <pre><code>docker build --platform linux/arm64 -t hash_tool:arm64 .\n</code></pre> <p>Performance Docker sur WSL2</p> <p>Sur WSL2, Docker acc\u00e8de aux volumes via un pont r\u00e9seau. Combin\u00e9 au fait que <code>b3sum</code> est appel\u00e9 une fois par fichier, les performances sont tr\u00e8s d\u00e9grad\u00e9es sur de grands volumes de fichiers. Voir Troubleshooting Docker pour la solution.</p> <p>Emplacement du projet sur WSL2</p> <p>Le projet doit \u00eatre clon\u00e9 dans le filesystem Linux natif (<code>/home/...</code>), pas sur le disque Windows (<code>/mnt/c/...</code>). Docker Desktop ne monte pas correctement les chemins <code>/mnt/c/</code> comme volumes.</p> <pre><code># Correct\ncd ~\ngit clone &lt;url&gt; hash-tool\n\n# Incorrect - volumes non mont\u00e9s\ncd /mnt/c/Users/moi/Desktop\ngit clone &lt;url&gt; hash-tool\n</code></pre>"},{"location":"getting-started/prerequisites/#compatibilite-os","title":"Compatibilit\u00e9 OS","text":"Environnement Mode natif Mode Docker Notes Ubuntu 22.04 / 24.04 \u2713 \u2713 Environnement de r\u00e9f\u00e9rence CI Debian 11+ \u2713 \u2713 Alpine Linux 3.18+ \u2713 \u2713 b3sum via d\u00e9p\u00f4t community macOS 13+ \u2713 \u2713 bash via brew obligatoire Windows WSL2 \u2713 \u2713 (lent) Projet dans <code>/home/</code>, pas <code>/mnt/c/</code> NAS Synology (ARM64) - \u2713 Build <code>--platform linux/arm64</code> Raspberry Pi (ARM64) \u2713 \u2713 b3sum binaire ARM64 requis"},{"location":"getting-started/prerequisites/#detection-automatique-du-mode-dexecution","title":"D\u00e9tection automatique du mode d'ex\u00e9cution","text":"<p><code>hash-tool</code> d\u00e9tecte automatiquement le mode au d\u00e9marrage :</p> <ol> <li>Natif : si <code>b3sum</code>, <code>jq</code> et <code>src/integrity.sh</code> sont disponibles -&gt; mode natif</li> <li>Docker : si l'image <code>hash_tool</code> est pr\u00e9sente -&gt; mode Docker</li> <li>Erreur : aucun mode disponible -&gt; message d'erreur explicite</li> </ol> <pre><code># V\u00e9rifier le mode s\u00e9lectionn\u00e9\nbash hash-tool check-env\n</code></pre> <p>La derni\u00e8re ligne de <code>check-env</code> indique le mode actif : <pre><code>-&gt; Ex\u00e9cution native active\n</code></pre> ou <pre><code>-&gt; Ex\u00e9cution Docker active (fallback)\n</code></pre></p>"},{"location":"getting-started/quickstart/","title":"D\u00e9marrage rapide","text":"<p>Ce guide couvre les trois op\u00e9rations fondamentales de hash_tool en moins de 10 minutes : calculer des empreintes, v\u00e9rifier l'int\u00e9grit\u00e9, comparer deux \u00e9tats.</p>"},{"location":"getting-started/quickstart/#prerequis","title":"Pr\u00e9requis","text":"<p>bash &gt;= 4, <code>b3sum</code>, <code>jq</code> install\u00e9s, et <code>src/integrity.sh</code> ex\u00e9cutable. Voir Pr\u00e9requis et Installation si ce n'est pas le cas.</p>"},{"location":"getting-started/quickstart/#1-premier-compute","title":"1. Premier compute","text":"<p>Le <code>compute</code> calcule les empreintes BLAKE3 de tous les fichiers d'un dossier et les enregistre dans un fichier <code>.b3</code>.</p> <pre><code>bash src/integrity.sh compute ./mes-documents hashes.b3\n</code></pre> <p>Sortie attendue :</p> <pre><code>Base enregistr\u00e9e : hashes.b3 (147 fichiers)\nSidecar : hashes.b3.meta.json\n</code></pre> <p>Deux fichiers sont produits :</p> <ul> <li><code>hashes.b3</code> - une ligne par fichier, au format <code>&lt;hash_blake3&gt;  &lt;chemin_relatif&gt;</code> :   <pre><code>3b2e4f... ./rapport-2024.pdf\na91c7d... ./donn\u00e9es/export.csv\n</code></pre></li> <li><code>hashes.b3.meta.json</code> - m\u00e9tadonn\u00e9es de contexte (date, dossier, nombre de fichiers) :   <pre><code>{\n  \"created_by\": \"2.0.0\",\n  \"date\": \"2026-02-28T14:00:00Z\",\n  \"comment\": \"\",\n  \"parameters\": {\n    \"directory\": \"./mes-documents\",\n    \"hash_algo\": \"blake3\",\n    \"nb_files\": 147\n  }\n}\n</code></pre></li> </ul> <p>R\u00e9pertoire de travail</p> <p>Les chemins dans <code>hashes.b3</code> sont relatifs au r\u00e9pertoire courant au moment du <code>compute</code>. Le <code>verify</code> doit \u00eatre lanc\u00e9 depuis le m\u00eame r\u00e9pertoire. C'est la source d'erreur la plus fr\u00e9quente - voir Troubleshooting.</p> <p>Ajouter un commentaire</p> <p>Un commentaire libre peut \u00eatre stock\u00e9 dans le sidecar pour documenter le contexte : <pre><code>bash src/integrity.sh compute ./mes-documents hashes.b3 \"Snapshot avant archivage\"\n</code></pre></p>"},{"location":"getting-started/quickstart/#2-premier-verify","title":"2. Premier verify","text":"<p>Le <code>verify</code> relit le fichier <code>.b3</code> et recalcule les empreintes pour d\u00e9tecter toute modification.</p> <pre><code>bash src/integrity.sh verify hashes.b3\n</code></pre> <p>Sortie nominale (tout OK) :</p> <pre><code>--- M\u00e9tadonn\u00e9es (sidecar) ---\n{\n  \"created_by\": \"2.0.0\",\n  \"date\": \"2026-02-28T14:00:00Z\",\n  ...\n}\n-----------------------------\nV\u00e9rification OK - 147 fichiers int\u00e8gres.\nR\u00e9sultats dans : ~/integrity_resultats/resultats_hashes\n  recap.txt\n</code></pre> <p>Le code de sortie <code>0</code> confirme l'int\u00e9grit\u00e9. Exploitable en script :</p> <pre><code>bash src/integrity.sh verify hashes.b3\nif [ $? -eq 0 ]; then\n    echo \"Int\u00e9grit\u00e9 confirm\u00e9e\"\nelse\n    echo \"ANOMALIE D\u00c9TECT\u00c9E\" &gt;&amp;2\nfi\n</code></pre> <p>Sortie en cas d'anomalie :</p> <pre><code>\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\n  ECHEC : 2 fichier(s) corrompu(s) ou manquant(s)\n\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\n\n./donn\u00e9es/export.csv: FAILED\n./rapport-2024.pdf: FAILED (No such file or directory)\n\nR\u00e9sultats dans : ~/integrity_resultats/resultats_hashes\n  recap.txt\n  failed.txt\n</code></pre> <p>Le code de sortie est <code>1</code>. Le d\u00e9tail est dans <code>failed.txt</code>.</p>"},{"location":"getting-started/quickstart/#3-premier-compare","title":"3. Premier compare","text":"<p>Le <code>compare</code> confronte deux bases <code>.b3</code> pour identifier ce qui a chang\u00e9 entre deux \u00e9tats.</p> <p>Cas d'usage typique : v\u00e9rifier qu'une migration n'a rien alt\u00e9r\u00e9.</p> <pre><code># \u00c9tape 1 : compute avant migration\nbash src/integrity.sh compute ./source hashes_avant.b3\n\n# \u00c9tape 2 : ex\u00e9cuter la migration\n# ...\n\n# \u00c9tape 3 : compute apr\u00e8s migration\nbash src/integrity.sh compute ./destination hashes_apres.b3\n\n# \u00c9tape 4 : compare\nbash src/integrity.sh compare hashes_avant.b3 hashes_apres.b3\n</code></pre> <p>Sortie nominale (migration parfaite) :</p> <pre><code>R\u00e9sultats enregistr\u00e9s dans : ~/integrity_resultats/resultats_hashes_avant\n  recap.txt     - modifi\u00e9s: 0, disparus: 0, nouveaux: 0\n  modifies.b3   - 0 fichiers\n  disparus.txt  - 0 fichiers\n  nouveaux.txt  - 0 fichiers\n  report.html   - rapport visuel\n</code></pre> <p>Cinq fichiers sont produits dans le dossier de r\u00e9sultats :</p> Fichier Contenu <code>recap.txt</code> Synth\u00e8se chiffr\u00e9e : modifi\u00e9s, disparus, nouveaux <code>modifies.b3</code> Fichiers pr\u00e9sents dans les deux bases avec un hash diff\u00e9rent <code>disparus.txt</code> Fichiers pr\u00e9sents dans la base de r\u00e9f\u00e9rence, absents dans la nouvelle <code>nouveaux.txt</code> Fichiers absents de la base de r\u00e9f\u00e9rence, pr\u00e9sents dans la nouvelle <code>report.html</code> Rapport visuel complet, ouvrir dans un navigateur <p>Ouvrir le rapport HTML :</p> <pre><code>xdg-open ~/integrity_resultats/resultats_hashes_avant/report.html   # Linux\nopen ~/integrity_resultats/resultats_hashes_avant/report.html        # macOS\n</code></pre>"},{"location":"getting-started/quickstart/#recapitulatif-des-commandes","title":"R\u00e9capitulatif des commandes","text":"<pre><code># Calculer les empreintes d'un dossier\nbash src/integrity.sh compute &lt;dossier&gt; &lt;base.b3&gt; [commentaire]\n\n# V\u00e9rifier l'int\u00e9grit\u00e9 d'un dossier contre une base\nbash src/integrity.sh verify &lt;base.b3&gt; [dossier]\n\n# Comparer deux bases\nbash src/integrity.sh compare &lt;ancienne.b3&gt; &lt;nouvelle.b3&gt;\n</code></pre>"},{"location":"getting-started/quickstart/#etapes-suivantes","title":"\u00c9tapes suivantes","text":"<ul> <li>Tutoriel : Premier audit complet</li> <li>Tutoriel : V\u00e9rification d'une migration</li> <li>R\u00e9f\u00e9rence des commandes</li> <li>Automatisation et cron</li> </ul>"},{"location":"guides/automation/","title":"Guide - Automatisation et planification","text":""},{"location":"guides/automation/#verification-planifiee-en-cron-linux","title":"V\u00e9rification planifi\u00e9e en cron Linux","text":"<p>Exemple de crontab pour lancer <code>hash-tool verify</code> chaque nuit \u00e0 3h. Redirection stdout/stderr vers un fichier log. Exploitation du code de sortie non-z\u00e9ro pour envoyer une alerte (mail, notification). <pre><code>0 3 * * * /chemin/hash-tool verify -base /bases/hashes.b3 -data /donnees -quiet &gt;&gt; /var/log/hash_tool.log 2&gt;&amp;1\n</code></pre></p>"},{"location":"guides/automation/#service-docker-cron","title":"Service Docker cron","text":"<p>Activation du profil <code>cron</code> dans <code>docker-compose.yml</code> : <code>docker compose --profile cron up -d cron</code>. Configuration via variables d'environnement <code>CRON_SCHEDULE</code> et <code>CRON_BASE</code>. Note : le service <code>cron</code> utilise l'image standard - crond doit \u00eatre ajout\u00e9 (Dockerfile \u00e9tendu ou image d\u00e9riv\u00e9e). Instructions de build de l'image \u00e9tendue.</p>"},{"location":"guides/automation/#integration-cicd","title":"Int\u00e9gration CI/CD","text":"<p>Utilisation de hash_tool dans un pipeline GitHub Actions : build de l'image Docker, smoke tests (version, help, check-env, compute via volume, verify). R\u00e9f\u00e9rence au workflow <code>.github/workflows/ci.yml</code> livr\u00e9 avec le projet. Extension possible : ajouter un job de v\u00e9rification d'int\u00e9grit\u00e9 sur les artefacts de build.</p>"},{"location":"guides/automation/#alertes-et-monitoring","title":"Alertes et monitoring","text":"<p>Exploitation du code de sortie <code>1</code> pour d\u00e9clencher une alerte : script wrapper avec envoi d'email, int\u00e9gration Slack webhook, notification syst\u00e8me. Exemple de script wrapper minimaliste.</p>"},{"location":"guides/migration/","title":"Guide - V\u00e9rification d'une migration","text":""},{"location":"guides/migration/#cas-dusage","title":"Cas d'usage","text":"<p>Copie de disque, migration serveur, transfert NAS, duplication d'archive. Objectif : certifier que chaque fichier de la source est pr\u00e9sent et identique dans la destination apr\u00e8s l'op\u00e9ration.</p>"},{"location":"guides/migration/#workflow-complet","title":"Workflow complet","text":"<ol> <li><code>compute</code> sur la source avant migration (avec <code>-meta</code> documentant la date)</li> <li>Ex\u00e9cuter la migration</li> <li><code>compute</code> sur la destination apr\u00e8s migration</li> <li><code>compare</code> entre les deux bases</li> <li>Lecture du rapport : 0 modifi\u00e9 + 0 disparu + 0 nouveau = migration valid\u00e9e</li> </ol>"},{"location":"guides/migration/#interpreter-les-ecarts","title":"Interpr\u00e9ter les \u00e9carts","text":"<p>Fichiers modifi\u00e9s : erreur de copie, corruption en transit - \u00e0 recopier. Fichiers disparus : non transf\u00e9r\u00e9s - \u00e0 identifier et recopier. Fichiers nouveaux : ajout\u00e9s c\u00f4t\u00e9 destination pendant la migration (fichiers syst\u00e8me, logs) - \u00e0 qualifier et d\u00e9cider de leur l\u00e9gitimit\u00e9.</p>"},{"location":"guides/migration/#pipeline-recommande","title":"Pipeline recommand\u00e9","text":"<p>R\u00e9f\u00e9rence \u00e0 <code>pipeline-amelioree.json</code> qui encha\u00eene compute source, verify imm\u00e9diat, compute destination, compare - en une seule ex\u00e9cution. Avantage : le verify interm\u00e9diaire d\u00e9tecte un probl\u00e8me de compute avant de lancer la migration.</p>"},{"location":"guides/migration/#cas-particulier-deux-chemins-non-relatifs","title":"Cas particulier - deux chemins non relatifs","text":"<p>Quand source et destination sont sur des disques ou machines diff\u00e9rentes, utiliser <code>pipeline-debug-deux-adresses.json</code> comme base avec chemins absolus.</p>"},{"location":"guides/veracrypt/","title":"Guide - Volumes VeraCrypt","text":""},{"location":"guides/veracrypt/#contexte","title":"Contexte","text":"<p>V\u00e9rification d'int\u00e9grit\u00e9 sur des volumes chiffr\u00e9s VeraCrypt mont\u00e9s sous Windows/WSL. Les volumes apparaissent comme des lecteurs (<code>/mnt/a/</code>, <code>/mnt/i/</code>, <code>/mnt/h/</code>). hash_tool fonctionne dessus comme sur n'importe quel dossier.</p>"},{"location":"guides/veracrypt/#prerequis","title":"Pr\u00e9requis","text":"<p>Volumes VeraCrypt mont\u00e9s avant d'ex\u00e9cuter hash_tool. V\u00e9rification : <code>ls /mnt/a/dossier_disque_1</code> doit retourner les fichiers attendus. Les bases <code>.b3</code> doivent \u00eatre stock\u00e9es hors des volumes chiffr\u00e9s (ex : <code>Desktop/bases/</code>) pour \u00eatre accessibles sans monter les volumes.</p>"},{"location":"guides/veracrypt/#workflow","title":"Workflow","text":"<ol> <li>Monter les volumes VeraCrypt</li> <li><code>compute</code> sur chaque volume avec base sauvegard\u00e9e hors volume</li> <li><code>verify</code> pour contr\u00f4le imm\u00e9diat</li> <li><code>compare</code> entre deux volumes pour audit crois\u00e9</li> <li>D\u00e9monter les volumes</li> </ol>"},{"location":"guides/veracrypt/#pipeline-veracryptjson-commente","title":"Pipeline veracrypt.json comment\u00e9","text":"<p>D\u00e9construction de <code>pipeline-veracrypt.json</code> \u00e9tape par \u00e9tape : 3 <code>compute</code> sur 3 volumes diff\u00e9rents, 1 <code>verify</code> de contr\u00f4le, 1 <code>compare</code> entre les deux premiers volumes. Adaptation des chemins <code>/mnt/a/</code>, <code>/mnt/i/</code>, <code>/mnt/h/</code>, <code>/mnt/c/Users/TonNom/Desktop/</code>.</p>"},{"location":"guides/veracrypt/#adaptation-a-votre-configuration","title":"Adaptation \u00e0 votre configuration","text":"<p>Instructions pour modifier les lettres de lecteur et les chemins de bases selon la configuration VeraCrypt locale. Variables \u00e0 remplacer dans le JSON.</p>"},{"location":"reference/file-formats/","title":"Formats de fichiers","text":""},{"location":"reference/file-formats/#format-b3","title":"Format <code>.b3</code>","text":"<p>Structure d'une ligne : hash BLAKE3 (64 caract\u00e8res hexad\u00e9cimaux) + deux espaces + chemin relatif du fichier. Compatible avec la sortie native de <code>b3sum</code>. Encodage : UTF-8. Un fichier par ligne. Pas d'en-t\u00eate. Exemple de ligne r\u00e9elle.</p>"},{"location":"reference/file-formats/#chemins-relatifs-dans-la-base","title":"Chemins relatifs dans la base","text":"<p>Les chemins sont relatifs au r\u00e9pertoire de travail au moment du <code>compute</code>. Convention de pr\u00e9fixe <code>./</code> ou pr\u00e9fixe de sous-dossier selon la commande utilis\u00e9e. Impact direct sur <code>verify</code> : le r\u00e9pertoire de travail au moment du <code>verify</code> doit \u00eatre coh\u00e9rent avec celui du <code>compute</code>. C'est la source d'erreur la plus fr\u00e9quente - lien vers <code>troubleshooting/execution.md</code>.</p>"},{"location":"reference/file-formats/#gitignore-et-dockerignore","title":"<code>.gitignore</code> et <code>.dockerignore</code>","text":"<p>Ce qui est exclu et pourquoi : <code>.gitignore</code> exclut <code>*.b3</code>, <code>resultats/</code>, <code>integrity_resultats/</code>, <code>site/</code> (doc g\u00e9n\u00e9r\u00e9e), fichiers temporaires, OS, \u00e9diteurs. <code>.dockerignore</code> exclut <code>examples/</code>, <code>tests/</code>, <code>docs/</code>, <code>*.md</code> (sauf README). Rationalit\u00e9 : les donn\u00e9es utilisateur et r\u00e9sultats ne vont jamais dans l'image.</p>"},{"location":"reference/output-files/","title":"Fichiers de r\u00e9sultats","text":"<p>Produits dans <code>RESULTATS_DIR</code> par les commandes <code>verify</code> et <code>compare</code>.</p>"},{"location":"reference/output-files/#recaptxt","title":"<code>recap.txt</code>","text":"<p>Synth\u00e8se chiffr\u00e9e de l'op\u00e9ration : nombre de fichiers OK, modifi\u00e9s, disparus, nouveaux. Date et heure d'ex\u00e9cution. Chemin de la base utilis\u00e9e. Format texte brut, lisible par un script. Toujours produit, m\u00eame si tout est OK.</p>"},{"location":"reference/output-files/#modifiesb3","title":"<code>modifies.b3</code>","text":"<p>Fichiers pr\u00e9sents dans les deux bases avec un hash diff\u00e9rent. Format identique au <code>.b3</code> standard - peut \u00eatre relu par b3sum. Contient les deux lignes (ancienne et nouvelle) pour chaque fichier modifi\u00e9, permettant de voir les deux hashes. Absent ou vide si aucun fichier modifi\u00e9.</p>"},{"location":"reference/output-files/#disparustxt","title":"<code>disparus.txt</code>","text":"<p>Liste des fichiers pr\u00e9sents dans la base de r\u00e9f\u00e9rence (ou au moment du <code>compute</code>) et introuvables lors de la v\u00e9rification. Un chemin par ligne. Absent ou vide si aucun fichier disparu.</p>"},{"location":"reference/output-files/#nouveauxtxt","title":"<code>nouveaux.txt</code>","text":"<p>Liste des fichiers pr\u00e9sents sur disque mais absents de la base de r\u00e9f\u00e9rence. Un chemin par ligne. Absent ou vide si aucun nouveau fichier.</p>"},{"location":"reference/output-files/#reporthtml","title":"<code>report.html</code>","text":"<p>Rapport visuel g\u00e9n\u00e9r\u00e9 depuis <code>reports/template.html</code>. Sections : r\u00e9sum\u00e9 statistique, liste des fichiers modifi\u00e9s avec les deux hashes, liste des disparus, liste des nouveaux. Ouvrir dans un navigateur. Toujours produit par <code>compare</code>, produit par <code>verify</code> uniquement si des anomalies sont d\u00e9tect\u00e9es.</p>"},{"location":"reference/output-files/#failedtxt","title":"<code>failed.txt</code>","text":"<p>Produit par <code>verify</code> uniquement. Liste des fichiers en erreur : hash diff\u00e9rent ou fichier inaccessible. Format : chemin + statut (FAIL ou ERROR).</p>"},{"location":"reference/sidecar/","title":"Fichier sidecar <code>.meta.json</code>","text":""},{"location":"reference/sidecar/#role","title":"R\u00f4le","text":"<p>Fichier JSON accol\u00e9 \u00e0 chaque base <code>.b3</code> (<code>&lt;base&gt;.b3.meta.json</code>). Stocke les m\u00e9tadonn\u00e9es de contexte au moment du <code>compute</code> : qui a cr\u00e9\u00e9 la base, quand, sur quel dossier, avec quels param\u00e8tres. Affich\u00e9 automatiquement par <code>verify</code>, <code>compare</code>, <code>stats</code> et <code>list</code>.</p>"},{"location":"reference/sidecar/#schema-complet","title":"Sch\u00e9ma complet","text":"<p><pre><code>{\n  \"created_by\": \"hash-tool v2.0.0\",\n  \"date\": \"2024-01-01T03:00:00Z\",\n  \"comment\": \"Snapshot initial - avant archivage\",\n  \"parameters\": {\n    \"directory\": \"/chemin/absolu/vers/dossier\",\n    \"hash_algo\": \"blake3\",\n    \"readonly\": false,\n    \"nb_files\": 1234\n  }\n}\n</code></pre> Description de chaque champ : type, format, source de la valeur.</p>"},{"location":"reference/sidecar/#lecture-automatique","title":"Lecture automatique","text":"<p><code>verify</code> et <code>compare</code> affichent le sidecar en t\u00eate d'ex\u00e9cution avec d\u00e9limiteurs visuels. <code>stats</code> affiche le sidecar en fin de sortie. <code>list</code> affiche le commentaire et la date sur une ligne d\u00e9di\u00e9e.</p>"},{"location":"reference/sidecar/#absence-de-sidecar","title":"Absence de sidecar","text":"<p>Comportement si le sidecar est absent : les commandes fonctionnent normalement, le sidecar est simplement ignor\u00e9. Pas d'erreur. Les bases cr\u00e9\u00e9es avec la v1.x (sans sidecar) restent pleinement utilisables.</p>"},{"location":"troubleshooting/","title":"Troubleshooting","text":""},{"location":"troubleshooting/#comment-utiliser-ce-guide","title":"Comment utiliser ce guide","text":"<p>D\u00e9marche diagnostique syst\u00e9matique : lancer <code>hash-tool check-env</code> en premier. La sortie identifie imm\u00e9diatement les composants manquants ou d\u00e9faillants. Convention utilis\u00e9e dans toutes les pages : Sympt\u00f4me -&gt; Cause probable -&gt; Diagnostic (commande \u00e0 lancer) -&gt; Solution.</p>"},{"location":"troubleshooting/#tableau-symptome-page","title":"Tableau sympt\u00f4me -&gt; page","text":"Sympt\u00f4me Page <code>b3sum</code> introuvable, <code>hash-tool</code> non ex\u00e9cutable Installation <code>verify</code> \u00e9choue sur tous les fichiers Ex\u00e9cution <code>.b3</code> vide, compare retourne des r\u00e9sultats aberrants Ex\u00e9cution Erreurs de volumes, permission denied Docker Docker Pipeline JSON : erreur jq, <code>op</code> non reconnu Pipeline <code>report.html</code> vide, <code>RESULTATS_DIR</code> ignor\u00e9 R\u00e9sultats"},{"location":"troubleshooting/#diagnostic-de-premier-niveau","title":"Diagnostic de premier niveau","text":"<p>Commandes \u00e0 lancer syst\u00e9matiquement avant d'ouvrir une issue : 1. <code>hash-tool version</code> - confirme que le script est accessible et ex\u00e9cutable 2. <code>hash-tool check-env</code> - \u00e9tat de toutes les d\u00e9pendances 3. <code>head -3 &lt;fichier.b3&gt;</code> - inspecte le pr\u00e9fixe des chemins dans la base</p>"},{"location":"troubleshooting/docker/","title":"Troubleshooting - Docker","text":""},{"location":"troubleshooting/docker/#execution-docker-lente-sur-wsl2","title":"Ex\u00e9cution Docker lente sur WSL2","text":"<p>Sympt\u00f4me : hash-tool est tr\u00e8s lent sur Docker + WSL 2. </p> <p>Cause : trois facteurs cumul\u00e9s :</p> <ul> <li> <p>Overhead de d\u00e9marrage du conteneur (~1-2s par appel)</p> </li> <li> <p><code>b3sum</code> appel\u00e9 une fois par fichier (pas en batch)</p> </li> <li> <p>Acc\u00e8s aux volumes WSL2 via un pont r\u00e9seau lent</p> </li> </ul> <p>Solution recommand\u00e9e : installer les d\u00e9pendances nativement dans WSL2. <code>hash-tool</code> bascule automatiquement en mode natif si <code>b3sum</code> et <code>jq</code> sont disponibles.</p> <pre><code>sudo apt-get install -y jq\nsudo wget https://github.com/BLAKE3-team/BLAKE3/releases/latest/download/b3sum_linux_x64_musl \\\n  -O /usr/local/bin/b3sum\nsudo chmod +x /usr/local/bin/b3sum\n</code></pre>"},{"location":"troubleshooting/docker/#volumes-montes-mais-fichiers-non-trouves-dans-le-conteneur","title":"Volumes mont\u00e9s mais fichiers non trouv\u00e9s dans le conteneur","text":"<p>Sympt\u00f4me : <code>compute</code> ou <code>verify</code> retourne \"dossier introuvable\". Cause : chemin h\u00f4te relatif pass\u00e9 \u00e0 <code>-v</code> - Docker exige des chemins absolus. Diagnostic : <code>docker run --rm -v &lt;chemin&gt;:/data hash_tool shell</code> puis <code>ls /data</code>. Solution : <code>docker run -v $(pwd)/examples:/data ...</code> ou chemin absolu explicite.</p>"},{"location":"troubleshooting/docker/#permission-denied-sur-bases-ou-resultats","title":"Permission denied sur <code>/bases</code> ou <code>/resultats</code>","text":"<p>Sympt\u00f4me : erreur d'\u00e9criture lors du <code>compute</code> ou <code>compare</code>. Cause : UID du processus Alpine dans le conteneur (root = UID 0) diff\u00e9rent du propri\u00e9taire des fichiers h\u00f4te, ou dossier h\u00f4te cr\u00e9\u00e9 avec des permissions restrictives. Solution : <code>docker run --user $(id -u):$(id -g) ...</code> ou <code>chmod 777</code> sur le dossier h\u00f4te (moins recommand\u00e9).</p>"},{"location":"troubleshooting/docker/#data-monte-en-ro-mais-compute-echoue-a-ecrire-la-base","title":"<code>/data</code> mont\u00e9 en <code>:ro</code> mais <code>compute</code> \u00e9choue \u00e0 \u00e9crire la base","text":"<p>Sympt\u00f4me : <code>Permission denied</code> sur l'\u00e9criture du <code>.b3</code>. Cause : tentative d'\u00e9crire la base dans <code>/data</code> mont\u00e9 en lecture seule. Solution : s\u00e9parer les volumes - donn\u00e9es dans <code>-v .../data:/data:ro</code>, bases dans <code>-v .../bases:/bases</code> (lecture/\u00e9criture). La base s'\u00e9crit dans <code>/bases</code>.</p>"},{"location":"troubleshooting/docker/#fallback-docker-non-declenche-alors-que-b3sum-est-absent","title":"Fallback Docker non d\u00e9clench\u00e9 alors que b3sum est absent","text":"<p>Sympt\u00f4me : <code>check-env</code> signale <code>EXEC_MODE=none</code> alors que Docker est install\u00e9. Cause : <code>_docker_available()</code> v\u00e9rifie <code>docker image inspect hash_tool</code> - si l'image n'est pas build\u00e9e localement, le fallback ne s'active pas. Solution : <code>docker build -t hash_tool .</code></p>"},{"location":"troubleshooting/docker/#arm64-nas-synology-image-incompatible","title":"ARM64 / NAS Synology : image incompatible","text":"<p>Sympt\u00f4me : <code>exec format error</code> au lancement du conteneur. Cause : image build\u00e9e pour amd64, conteneur ex\u00e9cut\u00e9 sur ARM64. Solution : <code>docker build --platform linux/arm64 -t hash_tool:arm64 .</code> V\u00e9rification de l'architecture cible : <code>uname -m</code> sur le NAS.</p>"},{"location":"troubleshooting/execution/","title":"Troubleshooting - Ex\u00e9cution","text":"<p>Probl\u00e8mes rencontr\u00e9s lors de l'ex\u00e9cution de <code>compute</code>, <code>verify</code> et <code>compare</code>. Pour chaque probl\u00e8me : Sympt\u00f4me -&gt; Cause -&gt; Diagnostic -&gt; Solution.</p>"},{"location":"troubleshooting/execution/#verify-echoue-sur-tous-les-fichiers-alors-que-rien-na-change","title":"<code>verify</code> \u00e9choue sur tous les fichiers alors que rien n'a chang\u00e9","text":"<p>Sympt\u00f4me : 100% des fichiers en <code>FAILED</code>, <code>failed.txt</code> liste tous les fichiers avec <code>No such file or directory</code>, pourtant les donn\u00e9es sont intactes sur le disque.</p> <p>Cause : la base a \u00e9t\u00e9 calcul\u00e9e depuis un r\u00e9pertoire de travail diff\u00e9rent de celui utilis\u00e9 pour <code>verify</code>. Les chemins relatifs dans le <code>.b3</code> ne correspondent plus au r\u00e9pertoire courant.</p> <p>Diagnostic :</p> <pre><code># Inspecter les 3 premi\u00e8res lignes de la base\nhead -3 hashes.b3\n</code></pre> <p>Si les chemins commencent par <code>./data/fichier.txt</code> mais que tu es dans <code>/home/user/data</code>, <code>b3sum</code> cherche <code>./data/fichier.txt</code> depuis <code>/home/user/data/</code> - soit <code>/home/user/data/data/fichier.txt</code>, qui n'existe pas.</p> <pre><code># Afficher le r\u00e9pertoire de travail courant\npwd\n\n# Comparer avec le dossier enregistr\u00e9 dans le sidecar\ncat hashes.b3.meta.json | grep directory\n</code></pre> <p>Solution :</p> <pre><code># Option 1 : se positionner dans le bon r\u00e9pertoire avant verify\ncd /home/user/projet   # r\u00e9pertoire depuis lequel compute a \u00e9t\u00e9 lanc\u00e9\nbash src/integrity.sh verify hashes.b3\n\n# Option 2 : passer le dossier explicitement en second argument\nbash src/integrity.sh verify /bases/hashes.b3 /home/user/projet\n</code></pre> <p>R\u00e8gle \u00e0 retenir : le r\u00e9pertoire de travail au moment du <code>verify</code> doit \u00eatre identique \u00e0 celui du <code>compute</code>. En cas de doute, le sidecar <code>.meta.json</code> indique le dossier source enregistr\u00e9 lors du compute.</p>"},{"location":"troubleshooting/execution/#compute-produit-un-b3-vide-ou-avec-moins-de-fichiers-quattendu","title":"<code>compute</code> produit un <code>.b3</code> vide ou avec moins de fichiers qu'attendu","text":"<p>Sympt\u00f4me : le fichier <code>.b3</code> est cr\u00e9\u00e9 mais contient 0 ligne, ou un nombre anormalement bas de fichiers.</p> <p>Cause 1 - dossier vide : le dossier cible ne contient aucun fichier r\u00e9gulier (uniquement des sous-dossiers vides, ou aucun fichier).</p> <p>Cause 2 - permissions insuffisantes : certains fichiers ne sont pas lisibles par l'utilisateur courant. <code>b3sum</code> les ignore silencieusement.</p> <p>Cause 3 - fichiers cach\u00e9s : <code>find</code> inclut les fichiers cach\u00e9s (<code>.git/</code>, <code>.DS_Store</code>). Si le dossier est un d\u00e9p\u00f4t git, les objets dans <code>.git/</code> sont index\u00e9s.</p> <p>Diagnostic :</p> <pre><code># Compter les fichiers trouv\u00e9s par find (m\u00eame algorithme que compute)\nfind ./mon-dossier -type f | wc -l\n\n# V\u00e9rifier les permissions des fichiers\nfind ./mon-dossier -type f ! -readable\n\n# Voir quels fichiers sont inclus\nfind ./mon-dossier -type f | head -20\n</code></pre> <p>Solution :</p> <pre><code># Si le dossier est vide : v\u00e9rifier le chemin pass\u00e9 \u00e0 compute\nls -la ./mon-dossier\n\n# Si permissions : corriger ou lancer avec sudo (d\u00e9conseill\u00e9)\nchmod -R u+r ./mon-dossier\n\n# Si .git/ ind\u00e9sirable : exclure explicitement via un wrapper\nfind ./mon-dossier -type f -not -path '*/.git/*' | ...\n# Note : integrity.sh n'expose pas d'option d'exclusion native\n</code></pre>"},{"location":"troubleshooting/execution/#compare-retourne-des-milliers-de-modifies-inattendus","title":"<code>compare</code> retourne des milliers de \"modifi\u00e9s\" inattendus","text":"<p>Sympt\u00f4me : <code>modifies.b3</code> liste des centaines ou milliers de fichiers comme modifi\u00e9s, alors que les donn\u00e9es n'ont pas chang\u00e9. <code>nb_disparus</code> et <code>nb_nouveaux</code> sont aussi anormalement \u00e9lev\u00e9s.</p> <p>Cause : les deux bases ont \u00e9t\u00e9 calcul\u00e9es depuis des r\u00e9pertoires de travail diff\u00e9rents. Les pr\u00e9fixes de chemins diff\u00e8rent, donc <code>compare</code> ne peut pas faire correspondre les entr\u00e9es.</p> <p>Exemple : - <code>hashes_source.b3</code> : chemins du type <code>./data/fichier.txt</code> (compute depuis <code>/srv</code>) - <code>hashes_dest.b3</code> : chemins du type <code>./fichier.txt</code> (compute depuis <code>/srv/data</code>)</p> <p>Aucun chemin ne correspond - tous les fichiers apparaissent comme \"disparus\" dans l'une et \"nouveaux\" dans l'autre, et donc \"modifi\u00e9s\" si les hashes matchent par accident.</p> <p>Diagnostic :</p> <pre><code># Comparer les pr\u00e9fixes des deux bases\nhead -1 hashes_source.b3\nhead -1 hashes_dest.b3\n</code></pre> <p>Si les pr\u00e9fixes diff\u00e8rent, c'est la cause.</p> <p>Solution :</p> <pre><code># Recalculer les deux bases depuis le m\u00eame r\u00e9pertoire parent\n# avec le m\u00eame dossier cible relatif\n\ncd /srv\nbash src/integrity.sh compute ./data hashes_source.b3\n# ... migration ...\nbash src/integrity.sh compute ./data hashes_dest.b3\nbash src/integrity.sh compare hashes_source.b3 hashes_dest.b3\n</code></pre>"},{"location":"troubleshooting/execution/#verify-retourne-exit-1-alors-que-la-verification-est-ok","title":"<code>verify</code> retourne exit 1 alors que la v\u00e9rification est OK","text":"<p>Sympt\u00f4me : la sortie affiche <code>V\u00e9rification OK - N fichiers int\u00e8gres</code> mais le code de sortie est <code>1</code>.</p> <p>Cause : bug connu dans les versions ant\u00e9rieures \u00e0 <code>2.0.1</code> - l'expression arithm\u00e9tique <code>(( nb_fail &gt; 0 ))</code> dans <code>ui.sh</code> retourne exit code 1 quand <code>nb_fail=0</code> sous <code>set -e</code>, ce qui tue le processus apr\u00e8s l'affichage.</p> <p>Diagnostic :</p> <pre><code>bash src/integrity.sh verify hashes.b3\necho \"exit: $?\"\ngrep \"version\\|VERSION\" src/integrity.sh\n</code></pre> <p>Solution : mettre \u00e0 jour vers la version corrig\u00e9e. Le fix est dans <code>src/lib/ui.sh</code>, fonction <code>ui_show_verify_result</code> - remplacer :</p> <pre><code># Avant (bugu\u00e9)\n(( nb_fail &gt; 0 )) || [ -n \"$lines_err\" ] &amp;&amp; say \"  failed.txt\"\n\n# Apr\u00e8s (correct)\nif [ \"$nb_fail\" -gt 0 ] || [ -n \"$lines_err\" ]; then say \"  failed.txt\"; fi\n</code></pre>"},{"location":"troubleshooting/execution/#codes-de-sortie","title":"Codes de sortie","text":"Code Commande Signification <code>0</code> <code>compute</code> Base cr\u00e9\u00e9e avec succ\u00e8s <code>0</code> <code>verify</code> Tous les fichiers int\u00e8gres <code>0</code> <code>compare</code> Comparaison effectu\u00e9e (m\u00eame si des diff\u00e9rences existent) <code>1</code> <code>compute</code> Erreur - dossier introuvable, vide, ou b3sum en \u00e9chec <code>1</code> <code>verify</code> Anomalie d\u00e9tect\u00e9e ou erreur technique <code>1</code> <code>compare</code> Erreur technique uniquement (diff\u00e9rences = exit 0) <p>Code 1 sur verify : anomalie ou erreur ?</p> <p>Le code <code>1</code> de <code>verify</code> couvre deux cas distincts. Pour distinguer :</p> <pre><code>bash src/integrity.sh verify hashes.b3\nexit_code=$?\nif [ $exit_code -ne 0 ]; then\n    statut=$(grep \"STATUT\" ~/integrity_resultats/resultats_hashes/recap.txt)\n    echo \"Exit $exit_code - $statut\"\n    # STATUT : ECHEC  -&gt; corruption d\u00e9tect\u00e9e (comportement attendu)\n    # STATUT : ERREUR -&gt; erreur technique (base invalide, b3sum absent...)\nfi\n</code></pre>"},{"location":"troubleshooting/execution/#espaces-et-caracteres-speciaux-dans-les-chemins","title":"Espaces et caract\u00e8res sp\u00e9ciaux dans les chemins","text":"<p><code>b3sum</code> et <code>find</code> g\u00e8rent les espaces dans les noms de fichiers via <code>-print0</code> et <code>sort -z</code> (s\u00e9parateur null). Les noms de fichiers avec espaces, apostrophes ou caract\u00e8res Unicode sont support\u00e9s sans configuration particuli\u00e8re.</p> <p>En revanche, les arguments pass\u00e9s au shell doivent \u00eatre quot\u00e9s :</p> <pre><code># Correct\nbash src/integrity.sh compute \"./mon dossier\" \"ma base.b3\"\n\n# Incorrect - le shell splitte sur les espaces\nbash src/integrity.sh compute ./mon dossier ma base.b3\n</code></pre> <p>Pour les chemins contenant <code>$</code>, <code>!</code> ou des backticks, utiliser des guillemets simples :</p> <pre><code>bash src/integrity.sh compute './donn\u00e9es$2026' hashes.b3\n</code></pre>"},{"location":"troubleshooting/execution/#b3sum-lent-sur-un-grand-nombre-de-fichiers","title":"<code>b3sum</code> lent sur un grand nombre de fichiers","text":"<p>Comportement normal : <code>compute</code> appelle <code>b3sum</code> une fois par fichier. Sur 100 000 fichiers de petite taille, le temps est domin\u00e9 par le co\u00fbt de lancement de <code>b3sum</code>, pas par le hachage lui-m\u00eame.</p> <p>Indicateur : la barre de progression ETA affiche un ETA qui cro\u00eet au lieu de d\u00e9cro\u00eetre.</p> <p>Solution : pas de workaround natif dans la version actuelle. Pour les volumes tr\u00e8s importants (&gt; 100 000 fichiers), privil\u00e9gier Docker sur une machine avec un SSD NVMe.</p>"},{"location":"troubleshooting/execution/#voir-aussi","title":"Voir aussi","text":"<ul> <li>Troubleshooting - Installation</li> <li>Troubleshooting - Docker</li> <li>Troubleshooting - Pipeline</li> <li>Troubleshooting - R\u00e9sultats</li> <li>Formats de fichiers - structure du <code>.b3</code> et impact sur les chemins</li> </ul>"},{"location":"troubleshooting/installation/","title":"Troubleshooting - Installation","text":""},{"location":"troubleshooting/installation/#b3sum-introuvable-en-natif","title":"<code>b3sum</code> introuvable en natif","text":"<p>Sympt\u00f4me : <code>check-env</code> retourne <code>[KO] b3sum introuvable</code>. Cause : absent des d\u00e9p\u00f4ts par d\u00e9faut sur certaines distributions. Solution par OS : - Alpine : <code>apk add --no-cache b3sum</code> (activer le d\u00e9p\u00f4t community) - Debian/Ubuntu : installer via cargo (<code>cargo install b3sum</code>) ou t\u00e9l\u00e9charger   le binaire depuis les releases GitHub de BLAKE3 - macOS : <code>brew install b3sum</code> V\u00e9rification : <code>b3sum --version</code></p>"},{"location":"troubleshooting/installation/#bash-version-insuffisante-4","title":"<code>bash</code> version insuffisante (&lt; 4)","text":"<p>Sympt\u00f4me : erreurs de syntaxe bash au lancement, <code>check-env</code> signale la version. Cause fr\u00e9quente : macOS - bash syst\u00e8me = 3.x (Apple distribue bash 3.2 pour des raisons de licence GPLv2). Diagnostic : <code>bash --version</code> Solution : <code>brew install bash</code>, puis utiliser <code>/opt/homebrew/bin/bash</code>. Ne pas remplacer <code>/bin/bash</code> syst\u00e8me sur macOS.</p>"},{"location":"troubleshooting/installation/#hash-tool-non-executable","title":"<code>hash-tool</code> non ex\u00e9cutable","text":"<p>Sympt\u00f4me : <code>Permission denied</code> ou <code>command not found</code>. Cause : <code>chmod +x</code> non appliqu\u00e9, ou fichiers sur un syst\u00e8me de fichiers FAT32/NTFS (ignorent les bits de permission Unix). Solution : <code>chmod +x hash-tool runner.sh src/integrity.sh src/lib/*.sh</code> Cas FAT/NTFS : cloner le d\u00e9p\u00f4t sur un syst\u00e8me de fichiers natif Linux/ext4.</p>"},{"location":"troubleshooting/installation/#image-docker-absente","title":"Image Docker absente","text":"<p>Sympt\u00f4me : <code>[--] Image Docker 'hash_tool' absente</code> dans <code>check-env</code>. Cause : image non build\u00e9e - elle n'est pas publi\u00e9e sur Docker Hub. Solution : <code>docker build -t hash_tool .</code> depuis la racine du d\u00e9p\u00f4t. Erreur fr\u00e9quente : lancer le build depuis un sous-dossier (Dockerfile introuvable).</p>"},{"location":"troubleshooting/pipeline/","title":"Troubleshooting - Pipeline","text":""},{"location":"troubleshooting/pipeline/#erreur-jq-generique-au-lancement-du-runner","title":"Erreur jq g\u00e9n\u00e9rique au lancement du runner","text":"<p>Sympt\u00f4me : <code>parse error</code> ou <code>null</code> retourn\u00e9 par jq. Cause : JSON malform\u00e9 dans le fichier pipeline. Diagnostic : <code>jq . pipeline.json</code> - valide la syntaxe et affiche l'erreur avec num\u00e9ro de ligne. Erreurs fr\u00e9quentes : virgule apr\u00e8s le dernier \u00e9l\u00e9ment d'un tableau (<code>},</code> avant <code>]</code>), guillemets manquants sur les cl\u00e9s, accolades non ferm\u00e9es.</p>"},{"location":"troubleshooting/pipeline/#champ-op-non-reconnu","title":"Champ <code>op</code> non reconnu","text":"<p>Sympt\u00f4me : runner signale une op\u00e9ration inconnue. Cause : deux formats de pipeline coexistent dans le projet - <code>op</code> (format historique de <code>pipeline.json</code>) et <code>type</code> (format am\u00e9lior\u00e9 de <code>pipeline-amelioree.json</code>). Ils ne sont pas interchangeables selon la version du runner. Solution : rester coh\u00e9rent sur un seul format dans un m\u00eame fichier. V\u00e9rifier quel format est attendu par la version de <code>runner.sh</code> utilis\u00e9e.</p>"},{"location":"troubleshooting/pipeline/#pipeline-sarrete-a-mi-execution","title":"Pipeline s'arr\u00eate \u00e0 mi-ex\u00e9cution","text":"<p>Comportement attendu : <code>runner.sh</code> utilise <code>set -euo pipefail</code> - toute commande en erreur arr\u00eate imm\u00e9diatement le pipeline. Ce n'est pas un bug. Si l'arr\u00eat est non d\u00e9sir\u00e9 : identifier l'\u00e9tape qui \u00e9choue (message d'erreur dans la sortie), corriger le probl\u00e8me sous-jacent. Pas de mode <code>--continue-on-error</code> natif.</p>"},{"location":"troubleshooting/pipeline/#chemins-relatifs-dans-le-pipeline-non-resolus","title":"Chemins relatifs dans le pipeline non r\u00e9solus","text":"<p>Sympt\u00f4me : \"dossier introuvable\" malgr\u00e9 un chemin qui semble correct. Cause : les chemins relatifs dans le JSON sont r\u00e9solus depuis le r\u00e9pertoire du script <code>runner.sh</code>, pas depuis le CWD de l'utilisateur. Solution : utiliser exclusivement des chemins absolus dans les fichiers pipeline destin\u00e9s \u00e0 la production.</p>"},{"location":"troubleshooting/results/","title":"Troubleshooting - R\u00e9sultats","text":""},{"location":"troubleshooting/results/#reporthtml-vide-ou-non-genere","title":"<code>report.html</code> vide ou non g\u00e9n\u00e9r\u00e9","text":"<p>Sympt\u00f4me : fichier <code>report.html</code> absent ou de taille 0. Cause : <code>reports/template.html</code> introuvable au moment de la g\u00e9n\u00e9ration. <code>report.sh</code> cherche le template relativement \u00e0 <code>SCRIPT_DIR</code>. Diagnostic : v\u00e9rifier que <code>reports/template.html</code> est pr\u00e9sent \u00e0 la racine du d\u00e9p\u00f4t. En mode Docker, le template n'est pas copi\u00e9 dans l'image - \u00e0 v\u00e9rifier dans le Dockerfile si une version personnalis\u00e9e est utilis\u00e9e.</p>"},{"location":"troubleshooting/results/#modifiesb3-contient-des-fichiers-visiblement-non-modifies","title":"<code>modifies.b3</code> contient des fichiers visiblement non modifi\u00e9s","text":"<p>Cause : probl\u00e8me de pr\u00e9fixes de chemins entre les deux bases compar\u00e9es - m\u00eame cause que le faux positif massif dans <code>compare</code>. Lien : voir <code>troubleshooting/execution.md</code> - section \"compare retourne des milliers de modifi\u00e9s inattendus\".</p>"},{"location":"troubleshooting/results/#resultats_dir-non-respecte-resultats-ecrits-ailleurs","title":"<code>RESULTATS_DIR</code> non respect\u00e9 - r\u00e9sultats \u00e9crits ailleurs","text":"<p>Sympt\u00f4me : les r\u00e9sultats apparaissent dans un dossier inattendu. Priorit\u00e9 de la variable : argument <code>-save</code> CLI &gt; variable d'environnement <code>RESULTATS_DIR</code> &gt; valeur par d\u00e9faut du script. Diagnostic : <code>echo $RESULTATS_DIR</code> avant lancement. En Docker, v\u00e9rifier que <code>-e RESULTATS_DIR=/resultats</code> est bien pass\u00e9 \u00e0 <code>docker run</code>.</p>"},{"location":"troubleshooting/results/#dossier-de-resultats-ecrase-a-chaque-execution","title":"Dossier de r\u00e9sultats \u00e9cras\u00e9 \u00e0 chaque ex\u00e9cution","text":"<p>Comportement attendu : le dossier est recr\u00e9\u00e9 \u00e0 chaque ex\u00e9cution - les r\u00e9sultats pr\u00e9c\u00e9dents sont \u00e9cras\u00e9s. C'est intentionnel. Pour conserver l'historique : utiliser <code>-save</code> avec un chemin horodat\u00e9 : <pre><code>hash-tool verify -base ./bases/hashes.b3 -save ./resultats/$(date +%Y%m%d_%H%M%S)\n</code></pre></p>"},{"location":"tutorials/","title":"Tutoriels","text":""},{"location":"tutorials/#avant-de-commencer","title":"Avant de commencer","text":"<p>Pr\u00e9requis communs aux 3 tutoriels : <code>hash-tool check-env</code> doit retourner OK, jeu de donn\u00e9es de test disponible dans <code>examples/</code> (inclus dans le d\u00e9p\u00f4t). Aucune donn\u00e9e personnelle requise.</p>"},{"location":"tutorials/#quel-tutoriel-choisir","title":"Quel tutoriel choisir ?","text":"<p>Tableau de d\u00e9cision : - Je veux juste v\u00e9rifier un dossier -&gt; Tutoriel 1 - Je viens de copier ou migrer des donn\u00e9es -&gt; Tutoriel 2 - Je veux automatiser et ne plus retaper les commandes -&gt; Tutoriel 3</p> <p>Les tutoriels sont ind\u00e9pendants mais progressifs. T2 et T3 pr\u00e9supposent la ma\u00eetrise du cycle de base introduit en T1.</p>"},{"location":"tutorials/#ce-que-vous-allez-apprendre","title":"Ce que vous allez apprendre","text":"<p>Vue d'ensemble des 3 tutoriels et comp\u00e9tences acquises \u00e0 l'issue de chacun. Temps estim\u00e9 par tutoriel (T1 : 15 min, T2 : 20 min, T3 : 25 min).</p>"},{"location":"tutorials/01-premier-audit/","title":"Tutoriel 1 - Premier audit d'int\u00e9grit\u00e9","text":""},{"location":"tutorials/01-premier-audit/#situation-de-depart","title":"Situation de d\u00e9part","text":"<p>Description du contexte : dossier de donn\u00e9es \u00e0 prot\u00e9ger, objectif de d\u00e9tecter toute alt\u00e9ration future. Pr\u00e9sentation de <code>examples/workspace/_data-source/</code> utilis\u00e9 comme support : 4 fichiers lorem-ipsum, \u00e9tat initial connu.</p>"},{"location":"tutorials/01-premier-audit/#etape-1-calculer-les-empreintes","title":"\u00c9tape 1 - Calculer les empreintes","text":"<p>Commande compl\u00e8te avec <code>-data</code>, <code>-save</code>, <code>-meta</code>. Sortie terminal attendue montr\u00e9e ligne par ligne. Explication des deux fichiers produits : <code>hashes__data-source.b3</code> et <code>hashes__data-source.b3.meta.json</code>.</p>"},{"location":"tutorials/01-premier-audit/#etape-2-inspecter-la-base-produite","title":"\u00c9tape 2 - Inspecter la base produite","text":"<p>Commande <code>hash-tool stats</code> sur la base cr\u00e9\u00e9e. Sortie comment\u00e9e : nombre de fichiers, distribution des extensions, contenu du sidecar avec le commentaire saisi \u00e0 l'\u00e9tape pr\u00e9c\u00e9dente.</p>"},{"location":"tutorials/01-premier-audit/#etape-3-verifier-lintegrite-cas-nominal","title":"\u00c9tape 3 - V\u00e9rifier l'int\u00e9grit\u00e9 (cas nominal)","text":"<p>Commande <code>verify</code> sur le m\u00eame dossier sans modification. Sortie attendue : tous les fichiers OK. Signification du code de sortie <code>0</code>.</p>"},{"location":"tutorials/01-premier-audit/#etape-4-simuler-une-alteration","title":"\u00c9tape 4 - Simuler une alt\u00e9ration","text":"<p>Instruction explicite : ajouter un caract\u00e8re dans <code>lorem-ipsum-01-modif.txt</code>. Relancer <code>verify</code>. Sortie d'erreur compl\u00e8te montr\u00e9e. Explication de chaque ligne : fichier incrimin\u00e9, hash attendu vs hash calcul\u00e9.</p>"},{"location":"tutorials/01-premier-audit/#etape-5-lire-les-fichiers-de-resultats","title":"\u00c9tape 5 - Lire les fichiers de r\u00e9sultats","text":"<p>Contenu r\u00e9el de <code>recap.txt</code> et <code>failed.txt</code> produits dans <code>RESULTATS_DIR</code>. Chaque champ annot\u00e9. Distinction erreur d'ex\u00e9cution vs fichier corrompu.</p>"},{"location":"tutorials/01-premier-audit/#ce-que-vous-savez-maintenant-faire","title":"Ce que vous savez maintenant faire","text":"<p>R\u00e9capitulatif des commandes ma\u00eetris\u00e9es : <code>compute</code>, <code>stats</code>, <code>verify</code>. Lien vers Tutoriel 2 pour le cas migration.</p>"},{"location":"tutorials/02-migration/","title":"Tutoriel 2 - V\u00e9rifier une migration de donn\u00e9es","text":""},{"location":"tutorials/02-migration/#situation-de-depart","title":"Situation de d\u00e9part","text":"<p>Contexte : <code>_data-source/</code> copi\u00e9 vers <code>_data-destination/</code>. La copie est-elle parfaite ? <code>lorem-ipsum-01-modif.txt</code> diff\u00e8re intentionnellement entre les deux dossiers - c'est le d\u00e9faut \u00e0 d\u00e9tecter. Aucune modification manuelle requise, les donn\u00e9es de test sont d\u00e9j\u00e0 dans cet \u00e9tat.</p>"},{"location":"tutorials/02-migration/#etape-1-calculer-les-empreintes-de-la-source","title":"\u00c9tape 1 - Calculer les empreintes de la source","text":"<p>Commande <code>compute</code> sur <code>_data-source/</code> avec <code>-meta \"Source - avant migration\"</code>. R\u00e9sultat : <code>hashes__data-source.b3</code> produit.</p>"},{"location":"tutorials/02-migration/#etape-2-calculer-les-empreintes-de-la-destination","title":"\u00c9tape 2 - Calculer les empreintes de la destination","text":"<p>Commande <code>compute</code> sur <code>_data-destination/</code> avec <code>-meta \"Destination - apr\u00e8s migration\"</code>. R\u00e9sultat : <code>hashes__data-destination.b3</code> produit. Importance de sauvegarder les deux bases dans le m\u00eame dossier <code>bases/</code>.</p>"},{"location":"tutorials/02-migration/#etape-3-comparer-les-deux-bases","title":"\u00c9tape 3 - Comparer les deux bases","text":"<p>Commande <code>compare</code> avec <code>-old</code>, <code>-new</code>, <code>-save</code>. Sortie terminal compl\u00e8te montr\u00e9e avec les compteurs : 1 modifi\u00e9, 0 disparu, 0 nouveau.</p>"},{"location":"tutorials/02-migration/#etape-4-lire-les-resultats","title":"\u00c9tape 4 - Lire les r\u00e9sultats","text":"<p>Parcours de chaque fichier produit dans le dossier de r\u00e9sultats : <code>recap.txt</code> (synth\u00e8se chiffr\u00e9e), <code>modifies.b3</code> (<code>lorem-ipsum-01-modif.txt</code> appara\u00eet ici avec les deux hashes), <code>disparus.txt</code> (vide - explication), <code>nouveaux.txt</code> (vide - explication), <code>report.html</code> (description des sections).</p>"},{"location":"tutorials/02-migration/#etape-5-interpreter-et-decider","title":"\u00c9tape 5 - Interpr\u00e9ter et d\u00e9cider","text":"<p>Arbre de d\u00e9cision : modifi\u00e9s -&gt; erreur de copie \u00e0 corriger / disparus -&gt; fichier non transf\u00e9r\u00e9 / nouveaux -&gt; fichier parasite \u00e0 identifier. Crit\u00e8res de validation d'une migration : 0 modifi\u00e9, 0 disparu, 0 nouveau.</p>"},{"location":"tutorials/02-migration/#variante-deux-machines-ou-deux-disques","title":"Variante - Deux machines ou deux disques","text":"<p>R\u00e9f\u00e9rence \u00e0 <code>pipeline-debug-deux-adresses.json</code> : chemins absolus mixtes, adaptation quand source et destination sont sur des montages diff\u00e9rents (disques, WSL, NAS).</p>"},{"location":"tutorials/02-migration/#ce-que-vous-savez-maintenant-faire","title":"Ce que vous savez maintenant faire","text":"<p>R\u00e9capitulatif : cycle compute -&gt; compute -&gt; compare. Lien vers Tutoriel 3 pour automatiser ce workflow en pipeline.</p>"},{"location":"tutorials/03-automatisation/","title":"Tutoriel 3 - Automatiser avec un pipeline JSON","text":""},{"location":"tutorials/03-automatisation/#situation-de-depart","title":"Situation de d\u00e9part","text":"<p>Le workflow T2 (compute + compute + compare) est r\u00e9p\u00e9titif. Objectif : d\u00e9finir une fois les chemins et op\u00e9rations dans un fichier JSON, lancer tout en une seule commande, r\u00e9sultats reproductibles sans erreur de saisie.</p>"},{"location":"tutorials/03-automatisation/#etape-1-anatomie-dun-pipeline-json","title":"\u00c9tape 1 - Anatomie d'un pipeline JSON","text":"<p>D\u00e9construction de <code>pipelines/pipeline.json</code> champ par champ. Tableau : cl\u00e9 -&gt; r\u00f4le -&gt; valeur exemple -&gt; obligatoire/optionnel. Distinction entre les trois op\u00e9rations : <code>compute</code>, <code>verify</code>, <code>compare</code> et leurs champs sp\u00e9cifiques.</p>"},{"location":"tutorials/03-automatisation/#etape-2-ecrire-votre-premier-pipeline","title":"\u00c9tape 2 - \u00c9crire votre premier pipeline","text":"<p>Construction pas \u00e0 pas d'un pipeline \u00e0 3 op\u00e9rations sur les donn\u00e9es de <code>examples/</code>. Fichier JSON complet montr\u00e9 en fin de section. Validation pr\u00e9alable : <code>jq . pipeline.json</code> pour d\u00e9tecter les erreurs de syntaxe.</p>"},{"location":"tutorials/03-automatisation/#etape-3-lancer-le-pipeline","title":"\u00c9tape 3 - Lancer le pipeline","text":"<p>Commande <code>hash-tool runner</code> avec <code>-pipeline</code> et <code>-save</code>. Sortie terminal compl\u00e8te : chaque \u00e9tape logg\u00e9e s\u00e9quentiellement, r\u00e9sum\u00e9 final.</p>"},{"location":"tutorials/03-automatisation/#etape-4-analyser-les-resultats-produits","title":"\u00c9tape 4 - Analyser les r\u00e9sultats produits","text":"<p>M\u00eame lecture que T2 mais en soulignant que les 3 op\u00e9rations ont \u00e9t\u00e9 ex\u00e9cut\u00e9es en une seule invocation. Dossier de r\u00e9sultats produit automatiquement.</p>"},{"location":"tutorials/03-automatisation/#etape-5-pipelines-fournis-en-exemple","title":"\u00c9tape 5 - Pipelines fournis en exemple","text":"<p>Tableau des 4 pipelines livr\u00e9s avec le projet : <code>pipeline.json</code> (base, chemins relatifs), <code>pipeline-debug.json</code> (debug local), <code>pipeline-debug-deux-adresses.json</code> (chemins absolus mixtes), <code>pipeline-veracrypt.json</code> (volumes chiffr\u00e9s Windows/WSL). Ce qui diff\u00e9rencie chacun et quand l'utiliser.</p>"},{"location":"tutorials/03-automatisation/#etape-6-lancer-via-docker","title":"\u00c9tape 6 - Lancer via Docker","text":"<p>M\u00eame pipeline, ex\u00e9cution via Docker. Commande <code>docker run</code> compl\u00e8te avec montages <code>-v</code> pour chaque volume. Mapping chemin h\u00f4te -&gt; chemin conteneur expliqu\u00e9 pour chaque op\u00e9ration du pipeline.</p>"},{"location":"tutorials/03-automatisation/#aller-plus-loin-planifier-lexecution","title":"Aller plus loin - Planifier l'ex\u00e9cution","text":"<p>Extrait cron Linux pour ex\u00e9cution nocturne. R\u00e9f\u00e9rence au service <code>cron</code> dans <code>docker-compose.yml</code> (profil). Lien vers <code>guides/automation.md</code> pour le setup complet.</p>"},{"location":"tutorials/03-automatisation/#ce-que-vous-savez-maintenant-faire","title":"Ce que vous savez maintenant faire","text":"<p>R\u00e9capitulatif des 3 tutoriels encha\u00een\u00e9s. L'utilisateur ma\u00eetrise le workflow complet : audit unitaire, v\u00e9rification de migration, automatisation par pipeline.</p>"},{"location":"usage/cli/","title":"Interface CLI","text":""},{"location":"usage/cli/#interface-hash-tool","title":"Interface <code>hash-tool</code>","text":"<p>R\u00f4le du wrapper : point d'entr\u00e9e unique abstrayant la couche d'ex\u00e9cution. Syntaxe g\u00e9n\u00e9rale : <code>hash-tool &lt;commande&gt; [options]</code>. Liste compl\u00e8te des commandes disponibles avec description en une ligne. Comportement de <code>help</code> et <code>help &lt;commande&gt;</code>.</p>"},{"location":"usage/cli/#options-globales","title":"Options globales","text":"<p>Tableau des options communes \u00e0 toutes les commandes : <code>-quiet</code> (mode silencieux), <code>-verbose</code> (mode verbeux), <code>-readonly</code> (flag sidecar), <code>-meta &lt;texte&gt;</code> (commentaire sidecar), <code>-save &lt;dossier&gt;</code> (dossier de sortie, surcharge <code>RESULTATS_DIR</code>).</p>"},{"location":"usage/cli/#dispatch-et-detection-denvironnement","title":"Dispatch et d\u00e9tection d'environnement","text":"<p>Logique de s\u00e9lection du mode d'ex\u00e9cution : <code>_native_available()</code> v\u00e9rifie b3sum + jq + integrity.sh, <code>_docker_available()</code> v\u00e9rifie docker + image locale. Priorit\u00e9 : natif -&gt; Docker -&gt; erreur bloquante. Variable d'environnement <code>HASH_TOOL_DOCKER_IMAGE</code> pour surcharger le nom de l'image.</p>"},{"location":"usage/cli/#variables-denvironnement","title":"Variables d'environnement","text":"<p>Tableau des variables reconnues : <code>RESULTATS_DIR</code> (dossier de sortie par d\u00e9faut), <code>HASH_TOOL_DOCKER_IMAGE</code> (nom de l'image Docker). Priorit\u00e9 des valeurs : argument CLI &gt; variable d'environnement &gt; valeur par d\u00e9faut.</p>"},{"location":"usage/pipeline/","title":"Pipelines JSON","text":""},{"location":"usage/pipeline/#format-pipelinejson","title":"Format pipeline.json","text":"<p>Sch\u00e9ma JSON complet : objet racine <code>pipeline</code> contenant un tableau d'op\u00e9rations. Champs obligatoires par type d'op\u00e9ration. Champs optionnels (<code>options</code>, <code>meta</code>, <code>description</code>). Deux formats coexistants : champ <code>op</code> (format historique) vs champ <code>type</code> (format am\u00e9lior\u00e9) - ne pas m\u00e9langer dans un m\u00eame fichier.</p>"},{"location":"usage/pipeline/#operations-supportees","title":"Op\u00e9rations support\u00e9es","text":"<p>Description de chaque op\u00e9ration avec ses champs sp\u00e9cifiques : <code>compute</code> (source, bases, nom), <code>verify</code> (source, base), <code>compare</code> (base_a, base_b, resultats). Correspondance exacte avec les commandes CLI.</p>"},{"location":"usage/pipeline/#execution","title":"Ex\u00e9cution","text":"<p>Commande : <code>hash-tool runner -pipeline &lt;fichier.json&gt; [-save &lt;dossier&gt;]</code>. Comportement s\u00e9quentiel : les op\u00e9rations s'ex\u00e9cutent dans l'ordre du tableau. Arr\u00eat imm\u00e9diat en cas d'\u00e9chec d'une \u00e9tape (<code>set -euo pipefail</code>).</p>"},{"location":"usage/pipeline/#chemins-dans-le-pipeline","title":"Chemins dans le pipeline","text":"<p>Les chemins relatifs sont r\u00e9solus depuis le r\u00e9pertoire du script <code>runner.sh</code>, pas depuis le CWD de l'utilisateur. R\u00e8gle pratique : toujours utiliser des chemins absolus dans les pipelines en production.</p>"},{"location":"usage/pipeline/#pipelines-dexemple-fournis","title":"Pipelines d'exemple fournis","text":"<p>Description et cas d'usage de chacun des 4 pipelines livr\u00e9s : <code>pipeline.json</code>, <code>pipeline-debug.json</code>, <code>pipeline-debug-deux-adresses.json</code>, <code>pipeline-veracrypt.json</code>. Lien vers <code>guides/veracrypt.md</code> pour le d\u00e9tail du cas VeraCrypt.</p>"},{"location":"usage/commands/compare/","title":"compare","text":""},{"location":"usage/commands/compare/#syntaxe","title":"Syntaxe","text":"<p><pre><code>hash-tool compare -old &lt;ancienne.b3&gt; -new &lt;nouvelle.b3&gt; [-save &lt;dossier&gt;] [-quiet]\n</code></pre> Tableau des options. <code>-old</code> est la r\u00e9f\u00e9rence, <code>-new</code> est l'\u00e9tat \u00e0 comparer.</p>"},{"location":"usage/commands/compare/#comportement","title":"Comportement","text":"<p>Lecture et affichage des sidecars des deux bases si pr\u00e9sents. Diff entre les deux ensembles de hashes : fichiers modifi\u00e9s (pr\u00e9sents dans les deux, hash diff\u00e9rent), disparus (dans <code>-old</code>, absents de <code>-new</code>), nouveaux (absents de <code>-old</code>, pr\u00e9sents dans <code>-new</code>). Production des 5 fichiers de r\u00e9sultats.</p>"},{"location":"usage/commands/compare/#fichiers-produits","title":"Fichiers produits","text":"<p>Description de chacun des 5 fichiers dans le dossier de r\u00e9sultats : <code>disparus.txt</code>, <code>modifies.b3</code>, <code>nouveaux.txt</code>, <code>recap.txt</code>, <code>report.html</code>. Format de chaque fichier et contenu typique.</p>"},{"location":"usage/commands/compare/#codes-de-sortie","title":"Codes de sortie","text":"<p><code>0</code> : bases identiques, aucune diff\u00e9rence. <code>1</code> : diff\u00e9rences d\u00e9tect\u00e9es ou erreur d'ex\u00e9cution. Exploitable en script pour d\u00e9clencher une alerte.</p>"},{"location":"usage/commands/compare/#exemples","title":"Exemples","text":"<p>Comparaison avant/apr\u00e8s migration, avec <code>-save</code> horodat\u00e9, r\u00e9sultat z\u00e9ro diff\u00e9rence (migration parfaite).</p>"},{"location":"usage/commands/compute/","title":"compute","text":"<p>Calcule les empreintes BLAKE3 de tous les fichiers d'un dossier et les enregistre dans un fichier <code>.b3</code>. Produit \u00e9galement un fichier sidecar <code>.meta.json</code> si <code>jq</code> est disponible.</p>"},{"location":"usage/commands/compute/#syntaxe","title":"Syntaxe","text":"<pre><code>bash src/integrity.sh compute &lt;dossier&gt; &lt;base.b3&gt; [commentaire]\n</code></pre> Argument Obligatoire Description <code>&lt;dossier&gt;</code> Oui Dossier cible \u00e0 hacher (relatif ou absolu) <code>&lt;base.b3&gt;</code> Oui Fichier de sortie contenant les empreintes <code>[commentaire]</code> Non Texte libre stock\u00e9 dans le sidecar <code>.meta.json</code> <p>Option globale applicable :</p> Option Description <code>--quiet</code> Supprime toute sortie terminal. Exit code propag\u00e9 sans modification."},{"location":"usage/commands/compute/#comportement","title":"Comportement","text":"<ol> <li>Validation : v\u00e9rifie que <code>&lt;dossier&gt;</code> existe, est bien un dossier, et contient au moins    un fichier r\u00e9gulier. Erreur imm\u00e9diate sinon.</li> <li>D\u00e9couverte : <code>find &lt;dossier&gt; -type f</code> r\u00e9cursif, tri\u00e9 par chemin de mani\u00e8re d\u00e9terministe.    Les fichiers cach\u00e9s et les sous-dossiers sont inclus.</li> <li>Hachage : chaque fichier est pass\u00e9 \u00e0 <code>b3sum</code> individuellement. Les r\u00e9sultats sont    accumul\u00e9s dans <code>&lt;base.b3&gt;</code>.</li> <li>Format de sortie : une ligne par fichier, format natif <code>b3sum</code> :    <pre><code>&lt;hash_blake3_64_chars&gt;  &lt;chemin_relatif&gt;\n</code></pre>    Les chemins sont relatifs au r\u00e9pertoire de travail au moment du <code>compute</code>, pas au dossier    cible. Ce point est critique pour la coh\u00e9rence avec <code>verify</code>.</li> <li>Progression : une ligne ETA s'affiche sur le terminal en temps r\u00e9el (effac\u00e9e \u00e0 la fin).    D\u00e9sactiv\u00e9e en mode <code>--quiet</code>.</li> <li>Sidecar : si <code>jq</code> est disponible, un fichier <code>&lt;base.b3&gt;.meta.json</code> est cr\u00e9\u00e9 \u00e0 c\u00f4t\u00e9    de la base.</li> </ol>"},{"location":"usage/commands/compute/#fichiers-produits","title":"Fichiers produits","text":""},{"location":"usage/commands/compute/#baseb3","title":"<code>&lt;base.b3&gt;</code>","text":"<p>Fichier texte, une ligne par fichier index\u00e9. Compatible avec la sortie native de <code>b3sum</code> - il peut \u00eatre relu directement par <code>b3sum --check</code>.</p> <pre><code>3b2e4f8a1c...  ./rapport-2024.pdf\na91c7d22f0...  ./donn\u00e9es/export.csv\nf047b3e19d...  ./donn\u00e9es/archive.zip\n</code></pre>"},{"location":"usage/commands/compute/#baseb3metajson-sidecar","title":"<code>&lt;base.b3&gt;.meta.json</code> (sidecar)","text":"<p>Fichier JSON cr\u00e9\u00e9 automatiquement si <code>jq</code> est disponible. Stocke le contexte de cr\u00e9ation pour affichage lors des op\u00e9rations <code>verify</code>, <code>compare</code>, <code>stats</code> et <code>list</code>.</p> <pre><code>{\n  \"created_by\": \"2.0.0\",\n  \"date\": \"2026-02-28T14:00:00Z\",\n  \"comment\": \"Snapshot avant archivage Q1 2026\",\n  \"parameters\": {\n    \"directory\": \"./mes-documents\",\n    \"hash_algo\": \"blake3\",\n    \"nb_files\": 147\n  }\n}\n</code></pre> Champ Description <code>created_by</code> Version de l'outil <code>date</code> Date ISO 8601 UTC au moment du compute <code>comment</code> Valeur du troisi\u00e8me argument, vide si absent <code>parameters.directory</code> Dossier tel que pass\u00e9 en argument <code>parameters.hash_algo</code> Toujours <code>blake3</code> <code>parameters.nb_files</code> Nombre de fichiers index\u00e9s <p>Si <code>jq</code> est absent, le sidecar n'est pas cr\u00e9\u00e9. La base <code>.b3</code> est produite normalement. Les bases sans sidecar sont pleinement utilisables par toutes les commandes.</p>"},{"location":"usage/commands/compute/#codes-de-sortie","title":"Codes de sortie","text":"Code Signification <code>0</code> Succ\u00e8s - base cr\u00e9\u00e9e et sidecar g\u00e9n\u00e9r\u00e9 <code>1</code> Erreur - dossier introuvable, dossier vide, <code>&lt;base.b3&gt;</code> est un dossier, erreur <code>b3sum</code>"},{"location":"usage/commands/compute/#repertoire-de-travail","title":"R\u00e9pertoire de travail","text":"<p>Point critique</p> <p>Les chemins dans le <code>.b3</code> sont relatifs au r\u00e9pertoire de travail courant au moment du <code>compute</code>, pas au dossier cible.</p> <p>Exemple : si tu lances <code>compute ./data hashes.b3</code> depuis <code>/home/user/projet</code>, les chemins dans <code>hashes.b3</code> seront <code>./data/fichier.txt</code>.</p> <p>Le <code>verify</code> doit donc \u00eatre lanc\u00e9 depuis <code>/home/user/projet</code> pour que les chemins correspondent. C'est la source d'erreur la plus fr\u00e9quente. Voir Troubleshooting - chemins relatifs.</p>"},{"location":"usage/commands/compute/#exemples","title":"Exemples","text":""},{"location":"usage/commands/compute/#cas-nominal","title":"Cas nominal","text":"<pre><code>cd /home/user/projet\nbash src/integrity.sh compute ./data hashes.b3\n</code></pre> <pre><code>Base enregistr\u00e9e : hashes.b3 (312 fichiers)\nSidecar : hashes.b3.meta.json\n</code></pre>"},{"location":"usage/commands/compute/#avec-commentaire-dans-le-sidecar","title":"Avec commentaire dans le sidecar","text":"<pre><code>bash src/integrity.sh compute ./data hashes.b3 \"Snapshot avant migration serveur\"\n</code></pre> <p>Le commentaire est stock\u00e9 dans <code>hashes.b3.meta.json</code> et affich\u00e9 automatiquement lors des <code>verify</code> et <code>compare</code> ult\u00e9rieurs.</p>"},{"location":"usage/commands/compute/#chemin-absolu-pour-la-base","title":"Chemin absolu pour la base","text":"<p>Utile quand la base doit \u00eatre stock\u00e9e dans un dossier d\u00e9di\u00e9, s\u00e9par\u00e9 des donn\u00e9es :</p> <pre><code>bash src/integrity.sh compute ./data /srv/bases/hashes_data.b3\n</code></pre>"},{"location":"usage/commands/compute/#mode-silencieux-usage-en-script-ou-cron","title":"Mode silencieux (usage en script ou cron)","text":"<pre><code>bash src/integrity.sh --quiet compute ./data hashes.b3\necho \"exit: $?\"\n</code></pre> <p>Aucune sortie terminal. Le code de retour indique le succ\u00e8s ou l'\u00e9chec.</p>"},{"location":"usage/commands/compute/#usage-docker","title":"Usage Docker","text":"<pre><code>docker run --rm \\\n  -v /srv/data:/data:ro \\\n  -v /srv/bases:/bases \\\n  hash_tool compute /data /bases/hashes.b3 \"Audit mensuel\"\n</code></pre> <p>Le volume <code>/data</code> est mont\u00e9 en lecture seule (<code>:ro</code>) - le conteneur ne modifie jamais les donn\u00e9es source. La base est \u00e9crite dans <code>/bases</code>.</p>"},{"location":"usage/commands/compute/#erreurs-frequentes","title":"Erreurs fr\u00e9quentes","text":"<p><code>Dossier cible introuvable</code> Le chemin pass\u00e9 en premier argument n'existe pas. V\u00e9rifier le chemin et le r\u00e9pertoire de travail courant.</p> <p><code>Le dossier ne contient aucun fichier r\u00e9gulier</code> Le dossier est vide ou ne contient que des sous-dossiers vides. <code>compute</code> refuse de cr\u00e9er une base vide.</p> <p><code>&lt;base.b3&gt; est un dossier</code> Le deuxi\u00e8me argument pointe vers un dossier existant. Le fichier <code>.b3</code> de sortie doit \u00eatre un chemin de fichier, pas un dossier.</p>"},{"location":"usage/commands/compute/#voir-aussi","title":"Voir aussi","text":"<ul> <li>verify - v\u00e9rifier l'int\u00e9grit\u00e9 contre une base existante</li> <li>compare - comparer deux bases</li> <li>Formats de fichiers - structure d\u00e9taill\u00e9e du <code>.b3</code></li> <li>Fichier sidecar - sch\u00e9ma complet du <code>.meta.json</code></li> </ul>"},{"location":"usage/commands/diff/","title":"diff","text":""},{"location":"usage/commands/diff/#syntaxe","title":"Syntaxe","text":"<p><pre><code>hash-tool diff -base &lt;fichier.b3&gt; [-data &lt;dossier&gt;]\n</code></pre> <code>-base</code> : base de r\u00e9f\u00e9rence (obligatoire). <code>-data</code> : dossier courant \u00e0 comparer (d\u00e9faut : r\u00e9pertoire courant).</p>"},{"location":"usage/commands/diff/#comportement","title":"Comportement","text":"<p>Comparaison des chemins de fichiers uniquement - les hashes ne sont pas recalcul\u00e9s. D\u00e9tecte : fichiers disparus (pr\u00e9sents dans la base, absents sur disque) et nouveaux fichiers non index\u00e9s (pr\u00e9sents sur disque, absents de la base). Rapide car aucun calcul cryptographique.</p>"},{"location":"usage/commands/diff/#difference-avec-compare","title":"Diff\u00e9rence avec <code>compare</code>","text":"<p><code>diff</code> compare une base et un dossier sans recalcul : d\u00e9tecte les absences et ajouts mais pas les modifications de contenu. <code>compare</code> compare deux bases d\u00e9j\u00e0 calcul\u00e9es : d\u00e9tecte aussi les modifications. Utiliser <code>diff</code> pour un diagnostic rapide, <code>compare</code> pour une v\u00e9rification compl\u00e8te.</p>"},{"location":"usage/commands/diff/#exemples","title":"Exemples","text":"<p>Diagnostic rapide apr\u00e8s suspicion d'ajout/suppression de fichiers. Sortie comment\u00e9e : section \"disparus\", section \"nouveaux\".</p>"},{"location":"usage/commands/list/","title":"list","text":""},{"location":"usage/commands/list/#syntaxe","title":"Syntaxe","text":"<p><pre><code>hash-tool list [-data &lt;dossier&gt;]\n</code></pre> Option <code>-data</code> : dossier \u00e0 parcourir. D\u00e9faut : r\u00e9pertoire courant. Profondeur de recherche : 2 niveaux maximum.</p>"},{"location":"usage/commands/list/#affichage","title":"Affichage","text":"<p>Pour chaque base <code>.b3</code> trouv\u00e9e : nom du fichier, nombre de fichiers index\u00e9s, taille du fichier <code>.b3</code>, indicateur <code>[+meta]</code> si sidecar pr\u00e9sent. Si sidecar pr\u00e9sent : commentaire et date de cr\u00e9ation affich\u00e9s en dessous. R\u00e9sultats tri\u00e9s par nom.</p>"},{"location":"usage/commands/list/#utilite","title":"Utilit\u00e9","text":"<p>Inventaire rapide des bases disponibles avant de lancer un <code>verify</code> ou <code>compare</code>. Permet de v\u00e9rifier qu'une base existe et contient le bon nombre de fichiers sans l'ouvrir.</p>"},{"location":"usage/commands/list/#exemples","title":"Exemples","text":"<p>Listage dans le dossier courant, avec <code>-data</code> explicite sur un dossier de bases. Sortie comment\u00e9e avec et sans sidecars.</p>"},{"location":"usage/commands/stats/","title":"stats","text":""},{"location":"usage/commands/stats/#syntaxe","title":"Syntaxe","text":"<p><pre><code>hash-tool stats -base &lt;fichier.b3&gt;\n</code></pre> <code>-base</code> : fichier <code>.b3</code> \u00e0 analyser (obligatoire).</p>"},{"location":"usage/commands/stats/#affichage","title":"Affichage","text":"<p>Chemin absolu du fichier base, taille du fichier <code>.b3</code>, nombre total de fichiers index\u00e9s. Top 10 des extensions les plus fr\u00e9quentes avec leur compteur. Contenu complet du sidecar <code>.meta.json</code> si pr\u00e9sent.</p>"},{"location":"usage/commands/stats/#usage-typique","title":"Usage typique","text":"<p>Audit rapide d'une base avant de lancer un <code>verify</code> ou <code>compare</code> : s'assurer que la base contient le bon nombre de fichiers et correspond au bon dossier (via les m\u00e9tadonn\u00e9es sidecar). D\u00e9tection imm\u00e9diate d'une base vide ou tronqu\u00e9e.</p>"},{"location":"usage/commands/stats/#exemples","title":"Exemples","text":"<p>Sortie compl\u00e8te sur une base avec sidecar. Sortie sur une base sans sidecar.</p>"},{"location":"usage/commands/verify/","title":"verify","text":"<p>Relit un fichier <code>.b3</code> et recalcule les empreintes BLAKE3 pour d\u00e9tecter toute modification, disparition ou erreur d'acc\u00e8s. C'est l'op\u00e9ration de contr\u00f4le d'int\u00e9grit\u00e9 au sens strict.</p>"},{"location":"usage/commands/verify/#syntaxe","title":"Syntaxe","text":"<pre><code>bash src/integrity.sh verify &lt;base.b3&gt; [dossier]\n</code></pre> Argument Obligatoire Description <code>&lt;base.b3&gt;</code> Oui Fichier de base contenant les empreintes de r\u00e9f\u00e9rence <code>[dossier]</code> Non R\u00e9pertoire de travail \u00e0 utiliser pour r\u00e9soudre les chemins. Si absent, le r\u00e9pertoire courant est utilis\u00e9. <p>Option globale applicable :</p> Option Description <code>--quiet</code> Supprime toute sortie terminal. Les fichiers de r\u00e9sultats sont quand m\u00eame produits."},{"location":"usage/commands/verify/#comportement","title":"Comportement","text":"<ol> <li>Validation : v\u00e9rifie que <code>&lt;base.b3&gt;</code> existe et respecte le format b3sum (hash 64 chars +    deux espaces + chemin). Erreur imm\u00e9diate sinon.</li> <li>R\u00e9solution du chemin absolu : le chemin de la base est converti en absolu avant tout    <code>cd</code>, pour rester valide apr\u00e8s changement de r\u00e9pertoire.</li> <li>Affichage du sidecar : si <code>&lt;base.b3&gt;.meta.json</code> existe, son contenu est affich\u00e9 en t\u00eate    d'ex\u00e9cution (sauf <code>--quiet</code>). Permet de confirmer que l'on v\u00e9rifie la bonne base.</li> <li>Changement de r\u00e9pertoire : si <code>[dossier]</code> est fourni, <code>cd</code> vers ce dossier avant    la v\u00e9rification. Les chemins relatifs dans la base sont r\u00e9solus depuis ce dossier.</li> <li>V\u00e9rification : <code>b3sum --check &lt;base.b3&gt;</code> recalcule chaque empreinte et compare.    Trois cat\u00e9gories de r\u00e9sultats :</li> <li><code>OK</code> - hash identique, fichier int\u00e8gre</li> <li><code>FAILED</code> - hash diff\u00e9rent, contenu modifi\u00e9</li> <li>Erreur - fichier inaccessible ou disparu</li> <li>Fichiers de r\u00e9sultats : \u00e9crits dans <code>$RESULTATS_DIR/resultats_&lt;nom_base&gt;/</code>.    Si ce dossier existe d\u00e9j\u00e0 (run pr\u00e9c\u00e9dent), un horodatage est ajout\u00e9 au nom pour \u00e9viter    l'\u00e9crasement.</li> </ol>"},{"location":"usage/commands/verify/#fichiers-produits","title":"Fichiers produits","text":"<p>Les r\u00e9sultats sont toujours \u00e9crits dans le dossier de r\u00e9sultats, m\u00eame si tout est OK.</p>"},{"location":"usage/commands/verify/#recaptxt-toujours-produit","title":"<code>recap.txt</code> - toujours produit","text":"<p>Synth\u00e8se de l'op\u00e9ration :</p> <pre><code>========================================\n  STATUT : OK\n========================================\n\nCommande  : integrity.sh verify hashes.b3\nDate      : Fri Feb 28 14:00:00 UTC 2026\nBase      : /srv/bases/hashes.b3\n\nOK        : 147\n</code></pre> <p>En cas d'\u00e9chec :</p> <pre><code>========================================\n  STATUT : ECHEC\n========================================\n\nCommande  : integrity.sh verify hashes.b3\nDate      : Fri Feb 28 14:00:00 UTC 2026\nBase      : /srv/bases/hashes.b3\n\nOK        : 145\nFAILED    : 2  &lt;- voir failed.txt\n</code></pre>"},{"location":"usage/commands/verify/#failedtxt-produit-uniquement-en-cas-danomalie","title":"<code>failed.txt</code> - produit uniquement en cas d'anomalie","text":"<p>Liste des fichiers en \u00e9chec avec leur statut :</p> <pre><code>========================================\n  FICHIERS EN ECHEC\n========================================\n\n./donn\u00e9es/export.csv: FAILED\n./rapport-2024.pdf: FAILED (No such file or directory)\n</code></pre> <p><code>FAILED</code> seul signifie que le fichier existe mais que son contenu a chang\u00e9 (hash diff\u00e9rent). <code>FAILED (No such file or directory)</code> signifie que le fichier a disparu du disque.</p> <p>Si aucune anomalie n'est d\u00e9tect\u00e9e, <code>failed.txt</code> n'est pas cr\u00e9\u00e9 (ou supprim\u00e9 s'il existait d'un run pr\u00e9c\u00e9dent dans le m\u00eame dossier).</p>"},{"location":"usage/commands/verify/#codes-de-sortie","title":"Codes de sortie","text":"Code Signification <code>0</code> Int\u00e9grit\u00e9 confirm\u00e9e - tous les fichiers sont int\u00e8gres <code>1</code> Anomalie d\u00e9tect\u00e9e (fichiers modifi\u00e9s ou disparus) ou erreur d'ex\u00e9cution <p>Distinction anomalie / erreur</p> <p>Le code <code>1</code> couvre deux cas distincts : une corruption d\u00e9tect\u00e9e (comportement attendu) et une erreur technique (base introuvable, <code>b3sum</code> absent). Le <code>recap.txt</code> permet de distinguer les deux : statut <code>ECHEC</code> pour une corruption, statut <code>ERREUR</code> pour une erreur technique.</p>"},{"location":"usage/commands/verify/#repertoire-de-travail","title":"R\u00e9pertoire de travail","text":"<p>Point critique</p> <p>Les chemins dans le <code>.b3</code> sont relatifs au r\u00e9pertoire de travail au moment du <code>compute</code>. Le <code>verify</code> doit \u00eatre lanc\u00e9 depuis le m\u00eame r\u00e9pertoire, ou le dossier \u00e9quivalent doit \u00eatre pass\u00e9 en second argument.</p> <p>Exemple :</p> <pre><code># compute lanc\u00e9 depuis /home/user/projet\ncd /home/user/projet\nbash src/integrity.sh compute ./data hashes.b3\n# -&gt; chemins dans hashes.b3 : ./data/fichier.txt\n\n# verify correct : m\u00eame r\u00e9pertoire de travail\ncd /home/user/projet\nbash src/integrity.sh verify hashes.b3\n\n# verify avec dossier explicite (utile en Docker ou CI)\nbash src/integrity.sh verify /bases/hashes.b3 /home/user/projet\n</code></pre> <p>Voir Troubleshooting - chemins relatifs.</p>"},{"location":"usage/commands/verify/#dossier-de-resultats","title":"Dossier de r\u00e9sultats","text":"<p>Par d\u00e9faut : <code>~/integrity_resultats/resultats_&lt;nom_base&gt;/</code>.</p> <p>Surchargeable via la variable d'environnement <code>RESULTATS_DIR</code> :</p> <pre><code>RESULTATS_DIR=/srv/audits bash src/integrity.sh verify hashes.b3\n</code></pre> <p>Le nom du dossier est d\u00e9riv\u00e9 du nom de la base : <code>hashes.b3</code> -&gt; <code>resultats_hashes</code>. Si ce dossier existe d\u00e9j\u00e0, un horodatage est ajout\u00e9 : <code>resultats_hashes_20260228-140000</code>.</p>"},{"location":"usage/commands/verify/#exemples","title":"Exemples","text":""},{"location":"usage/commands/verify/#verification-nominale","title":"V\u00e9rification nominale","text":"<pre><code>cd /home/user/projet\nbash src/integrity.sh verify hashes.b3\n</code></pre> <pre><code>--- M\u00e9tadonn\u00e9es (sidecar) ---\n{\n  \"created_by\": \"2.0.0\",\n  \"date\": \"2026-02-28T14:00:00Z\",\n  \"comment\": \"Snapshot avant archivage\",\n  ...\n}\n-----------------------------\nV\u00e9rification OK - 147 fichiers int\u00e8gres.\nR\u00e9sultats dans : ~/integrity_resultats/resultats_hashes\n  recap.txt\n</code></pre>"},{"location":"usage/commands/verify/#avec-dossier-explicite","title":"Avec dossier explicite","text":"<p>Utile quand la base est stock\u00e9e ailleurs que dans le r\u00e9pertoire de travail :</p> <pre><code>bash src/integrity.sh verify /srv/bases/hashes.b3 /home/user/projet\n</code></pre>"},{"location":"usage/commands/verify/#en-mode-silencieux-pour-un-script","title":"En mode silencieux pour un script","text":"<pre><code>bash src/integrity.sh --quiet verify hashes.b3\nif [ $? -ne 0 ]; then\n    echo \"ANOMALIE D\u00c9TECT\u00c9E - voir $RESULTATS_DIR\" &gt;&amp;2\n    exit 1\nfi\n</code></pre>"},{"location":"usage/commands/verify/#usage-docker","title":"Usage Docker","text":"<pre><code>docker run --rm \\\n  -v /srv/data:/data:ro \\\n  -v /srv/bases:/bases:ro \\\n  -v /srv/resultats:/resultats \\\n  -e RESULTATS_DIR=/resultats \\\n  hash_tool verify /bases/hashes.b3 /data\necho \"exit: $?\"\n</code></pre>"},{"location":"usage/commands/verify/#integration-cron","title":"Int\u00e9gration cron","text":"<pre><code># /etc/cron.d/hash_tool\n0 3 * * * root bash /opt/hash_tool/src/integrity.sh --quiet verify /srv/bases/hashes.b3 \\\n  &gt;&gt; /var/log/hash_tool.log 2&gt;&amp;1 || echo \"ECHEC $(date)\" &gt;&gt; /var/log/hash_tool_alerts.log\n</code></pre>"},{"location":"usage/commands/verify/#erreurs-frequentes","title":"Erreurs fr\u00e9quentes","text":"<p><code>FAILED (No such file or directory)</code> Le fichier existait au moment du <code>compute</code> mais a disparu. V\u00e9rifier s'il a \u00e9t\u00e9 d\u00e9plac\u00e9, renomm\u00e9 ou supprim\u00e9.</p> <p>Tous les fichiers en FAILED R\u00e9pertoire de travail incorrect. Le <code>verify</code> est lanc\u00e9 depuis un dossier diff\u00e9rent de celui du <code>compute</code>. Passer le bon dossier en second argument ou se positionner dans le bon r\u00e9pertoire. Voir Troubleshooting.</p> <p><code>fichier .b3 introuvable</code> Le chemin pass\u00e9 en premier argument est incorrect ou relatif \u00e0 un mauvais r\u00e9pertoire courant. Utiliser un chemin absolu pour \u00e9viter toute ambigu\u00eft\u00e9.</p>"},{"location":"usage/commands/verify/#voir-aussi","title":"Voir aussi","text":"<ul> <li>compute - calculer une base d'empreintes</li> <li>compare - comparer deux bases</li> <li>Fichiers de r\u00e9sultats - description compl\u00e8te de <code>recap.txt</code> et <code>failed.txt</code></li> <li>Troubleshooting - ex\u00e9cution - probl\u00e8mes de chemins relatifs</li> </ul>"}]}