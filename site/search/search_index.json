{"config":{"lang":["fr"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"hash_tool","text":"<p>D\u00e9tection de corruption silencieuse et d'erreurs de transfert sur disque, par hachage BLAKE3.</p>"},{"location":"#principe","title":"Principe","text":"<p><code>integrity.sh</code> calcule une empreinte cryptographique de chaque fichier d'un dossier, stocke ces empreintes dans un fichier <code>.b3</code>, puis permet de v\u00e9rifier ult\u00e9rieurement que rien n'a chang\u00e9. <code>runner.sh</code> orchestre plusieurs op\u00e9rations via un fichier <code>pipeline.json</code>.</p> <pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    compute     \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  Dossier    \u2502 \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25ba \u2502  base.b3     \u2502\n\u2502  de donn\u00e9es \u2502                \u2502  (hashes)    \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518                \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                                      \u2502\n                     verify / compare \u2502\n                                      \u25bc\n                               \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n                               \u2502  Rapport     \u2502\n                               \u2502  recap.txt   \u2502\n                               \u2502  report.html \u2502\n                               \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518</code></pre>"},{"location":"#cas-dusage","title":"Cas d'usage","text":"<ul> <li>Archivage long terme \u2014 v\u00e9rifier qu'un disque n'a pas d\u00e9velopp\u00e9 de secteurs d\u00e9fectueux</li> <li>Transfert de donn\u00e9es \u2014 confirmer qu'une copie est bit-\u00e0-bit identique \u00e0 la source</li> <li>VeraCrypt \u2014 indexer des partitions chiffr\u00e9es avant d\u00e9montage, v\u00e9rifier apr\u00e8s remontage</li> <li>Monitoring p\u00e9riodique \u2014 cron hebdomadaire sur un NAS ou serveur</li> </ul>"},{"location":"#demarrage-rapide","title":"D\u00e9marrage rapide","text":"Script directPipeline JSONDocker <pre><code># 1. Indexer un dossier\n./src/integrity.sh compute ./mon_dossier hashes_$(date +%Y-%m-%d).b3\n\n# 2. V\u00e9rifier l'int\u00e9grit\u00e9\n./src/integrity.sh verify hashes_$(date +%Y-%m-%d).b3\n\n# 3. Comparer deux snapshots\n./src/integrity.sh compare ancien.b3 nouveau.b3</code></pre> <pre><code># \u00c9diter pipelines/pipeline.json, puis :\n./runner.sh</code></pre> <pre><code>docker run --rm \\\n  -v /mes/donnees:/data:ro \\\n  -v /mes/bases:/bases \\\n  hash_tool compute /data /bases/hashes_$(date +%Y-%m-%d).b3</code></pre>"},{"location":"#dependances","title":"D\u00e9pendances","text":"Outil Requis par Installation <code>bash &gt;= 4</code> <code>integrity.sh</code>, <code>runner.sh</code> Natif Linux/macOS <code>b3sum</code> <code>integrity.sh</code> <code>apt install b3sum</code> <code>jq</code> <code>runner.sh</code> <code>apt install jq</code> <code>find</code>, <code>sort</code>, <code>awk</code>, <code>comm</code>, <code>join</code>, <code>stat</code>, <code>du</code> <code>integrity.sh</code> Natifs (GNU coreutils) <p>macOS</p> <p><code>bash</code> est en version 3.x par d\u00e9faut sur macOS. Installer bash 5 via Homebrew : <code>brew install bash</code>.</p>"},{"location":"#structure-du-projet","title":"Structure du projet","text":"<pre><code>hash_tool/\n\u251c\u2500\u2500 src/\n\u2502   \u251c\u2500\u2500 integrity.sh           \u2190 script principal\n\u2502   \u2514\u2500\u2500 lib/\n\u2502       \u2514\u2500\u2500 report.sh          \u2190 g\u00e9n\u00e9ration HTML\n\u251c\u2500\u2500 runner.sh                  \u2190 orchestrateur pipeline\n\u251c\u2500\u2500 pipelines/\n\u2502   \u251c\u2500\u2500 pipeline.json          \u2190 exemple/test local\n\u2502   \u2514\u2500\u2500 pipeline-full.json     \u2190 exemple multi-disques VeraCrypt\n\u251c\u2500\u2500 docker/\n\u2502   \u2514\u2500\u2500 entrypoint.sh\n\u251c\u2500\u2500 tests/\n\u2502   \u251c\u2500\u2500 run_tests.sh           \u2190 T00\u2013T14\n\u2502   \u2514\u2500\u2500 run_tests_pipeline.sh  \u2190 TP01\u2013TP12\n\u251c\u2500\u2500 docs/\n\u251c\u2500\u2500 Dockerfile\n\u251c\u2500\u2500 docker-compose.yml\n\u2514\u2500\u2500 CHANGELOG.md</code></pre>"},{"location":"getting-started/","title":"D\u00e9marrage rapide","text":"<p>Installation et premier usage en moins de 5 minutes.</p>"},{"location":"getting-started/#prerequis","title":"Pr\u00e9requis","text":""},{"location":"getting-started/#linux-wsl","title":"Linux / WSL","text":"<pre><code># Debian / Ubuntu\nsudo apt install b3sum jq\n\n# V\u00e9rifier\nb3sum --version\njq --version\nbash --version   # doit \u00eatre &gt;= 4</code></pre>"},{"location":"getting-started/#macos","title":"macOS","text":"<pre><code>brew install b3sum jq bash\n\n# Ajouter bash 5 \u00e0 /etc/shells si n\u00e9cessaire\necho \"$(brew --prefix)/bin/bash\" | sudo tee -a /etc/shells</code></pre>"},{"location":"getting-started/#windows","title":"Windows","text":"<p>Utiliser WSL (Windows Subsystem for Linux) avec une distribution Debian ou Ubuntu, puis proc\u00e9der comme sous Linux.</p> <pre><code>REM Lancement depuis Windows via WSL\nwsl bash /mnt/c/Users/TonNom/Desktop/hash_tool/runner.sh</code></pre>"},{"location":"getting-started/#docker-aucune-dependance-sur-lhote","title":"Docker (aucune d\u00e9pendance sur l'h\u00f4te)","text":"<pre><code>docker build -t hash_tool .</code></pre> <p>Voir la r\u00e9f\u00e9rence Docker pour l'usage complet.</p>"},{"location":"getting-started/#installation","title":"Installation","text":"<p>Aucune installation syst\u00e8me requise. Cloner ou copier le dossier <code>hash_tool/</code> o\u00f9 vous le souhaitez.</p> <pre><code>git clone https://github.com/hash_tool/hash_tool.git\ncd hash_tool\nchmod +x src/integrity.sh runner.sh</code></pre>"},{"location":"getting-started/#premier-usage","title":"Premier usage","text":""},{"location":"getting-started/#etape-1-indexer-un-dossier","title":"\u00c9tape 1 \u2014 Indexer un dossier","text":"<pre><code>cd hash_tool\n./src/integrity.sh compute ./mon_dossier hashes_2024-01-15.b3</code></pre> <p>Sortie attendue :</p> <pre><code>Base enregistr\u00e9e : hashes_2024-01-15.b3 (142 fichiers)</code></pre> <p>Le fichier <code>hashes_2024-01-15.b3</code> contient une ligne par fichier :</p> <pre><code>a1b2c3d4...f0a1b2  ./mon_dossier/document.pdf\ne5f6a7b8...e5f6a7  ./mon_dossier/sous-dossier/image.jpg</code></pre> <p>R\u00e9pertoire de travail</p> <p>Toujours lancer <code>compute</code> depuis le dossier qui contient les donn\u00e9es, pas depuis un dossier parent. Les chemins dans le <code>.b3</code> sont relatifs au <code>pwd</code> au moment du compute.</p> <pre><code># Correct\ncd /mnt/a/mes_donnees\n/opt/hash_tool/src/integrity.sh compute . /opt/bases/hashes.b3\n\n# Incorrect \u2014 chemins absolus dans la base, non portables\n/opt/hash_tool/src/integrity.sh compute /mnt/a/mes_donnees /opt/bases/hashes.b3</code></pre>"},{"location":"getting-started/#etape-2-verifier-lintegrite","title":"\u00c9tape 2 \u2014 V\u00e9rifier l'int\u00e9grit\u00e9","text":"<pre><code># Depuis le m\u00eame r\u00e9pertoire qu'au compute\n./src/integrity.sh verify hashes_2024-01-15.b3</code></pre> <p>Sortie si tout est intact :</p> <pre><code>V\u00e9rification OK \u2014 142 fichiers int\u00e8gres.\nR\u00e9sultats dans : /home/user/integrity_resultats/resultats_hashes_2024-01-15\n  recap.txt</code></pre> <p>Sortie si corruption d\u00e9tect\u00e9e :</p> <pre><code>\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\n  ECHEC : 2 fichier(s) corrompu(s) ou manquant(s)\n\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\n\n./mon_dossier/document.pdf: FAILED\n./mon_dossier/archive.zip: FAILED\n\nR\u00e9sultats dans : /home/user/integrity_resultats/resultats_hashes_2024-01-15\n  recap.txt\n  failed.txt</code></pre>"},{"location":"getting-started/#etape-3-comparer-deux-snapshots","title":"\u00c9tape 3 \u2014 Comparer deux snapshots","text":"<pre><code># Apr\u00e8s avoir recalcul\u00e9 une nouvelle base\n./src/integrity.sh compute ./mon_dossier hashes_2024-02-01.b3\n\n# Comparer\n./src/integrity.sh compare hashes_2024-01-15.b3 hashes_2024-02-01.b3</code></pre> <p>Produit dans <code>~/integrity_resultats/resultats_hashes_2024-01-15/</code> :</p> <pre><code>recap.txt       \u2014 r\u00e9sum\u00e9 texte (modifi\u00e9s / disparus / nouveaux)\nmodifies.b3     \u2014 fichiers avec hash diff\u00e9rent\ndisparus.txt    \u2014 fichiers pr\u00e9sents dans l'ancienne base, absents de la nouvelle\nnouveaux.txt    \u2014 fichiers absents de l'ancienne base, pr\u00e9sents dans la nouvelle\nreport.html     \u2014 rapport visuel interactif</code></pre>"},{"location":"getting-started/#usage-avec-le-pipeline","title":"Usage avec le pipeline","text":"<p>Pour plusieurs dossiers ou une routine r\u00e9guli\u00e8re, <code>runner.sh</code> + <code>pipeline.json</code> est plus robuste que les appels manuels.</p> <pre><code># \u00c9diter pipelines/pipeline.json avec vos chemins\n./runner.sh\n\n# Ou avec un fichier de config explicite\n./runner.sh /chemin/vers/mon-pipeline.json</code></pre> <p>Voir la r\u00e9f\u00e9rence runner.sh pour le format complet du pipeline.</p>"},{"location":"getting-started/#ou-sont-les-resultats","title":"O\u00f9 sont les r\u00e9sultats ?","text":"<p>Par d\u00e9faut dans <code>~/integrity_resultats/</code>. Configurable via la variable d'environnement <code>RESULTATS_DIR</code> :</p> <pre><code>export RESULTATS_DIR=/srv/rapports/integrity\n./src/integrity.sh verify hashes.b3</code></pre> <p>Ou directement dans le pipeline via le champ <code>resultats</code> sur les blocs <code>compare</code>.</p>"},{"location":"getting-started/#prochaines-etapes","title":"Prochaines \u00e9tapes","text":"<ul> <li>R\u00e9f\u00e9rence compl\u00e8te integrity.sh \u2014 toutes les options, variables, exit codes</li> <li>R\u00e9f\u00e9rence runner.sh \u2014 format pipeline.json</li> <li>Guide VeraCrypt \u2014 workflow multi-disques</li> <li>Guide CI/Cron \u2014 automatisation</li> </ul>"},{"location":"ancienne%20doc/docker/","title":"Docker \u2014 hash_tool","text":"<p>Utilisation de hash_tool via Docker \u2014 aucune d\u00e9pendance \u00e0 installer sur l'h\u00f4te.</p>"},{"location":"ancienne%20doc/docker/#prerequis","title":"Pr\u00e9requis","text":"<ul> <li>Docker &gt;= 20.10 (support multi-platform)</li> <li>Optionnel : Docker Compose v2</li> </ul>"},{"location":"ancienne%20doc/docker/#build","title":"Build","text":"<pre><code># Build standard (amd64)\ndocker build -t hash_tool .\n\n# Build pour ARM64 (NAS Synology DS923+, Raspberry Pi, Apple Silicon)\ndocker build --platform linux/arm64 -t hash_tool:arm64 .\n\n# Build avec version b3sum sp\u00e9cifique\ndocker build --build-arg B3SUM_VERSION=1.5.4 -t hash_tool .</code></pre>"},{"location":"ancienne%20doc/docker/#commandes-disponibles","title":"Commandes disponibles","text":"<pre><code>docker run [--rm] [-v ...] hash_tool &lt;commande&gt; [args]\n\n  compute &lt;dossier&gt; &lt;base.b3&gt;           Calcule les hashes\n  verify  &lt;base.b3&gt; [dossier]           V\u00e9rifie l'int\u00e9grit\u00e9\n  compare &lt;ancienne.b3&gt; &lt;nouvelle.b3&gt;   Compare deux bases\n  runner  [pipeline.json]               Ex\u00e9cute un pipeline JSON\n  shell                                 Shell bash interactif (debug)\n  help                                  Aide\n  version                               Versions des outils</code></pre>"},{"location":"ancienne%20doc/docker/#exemples-dutilisation","title":"Exemples d'utilisation","text":""},{"location":"ancienne%20doc/docker/#compute-indexer-un-dossier","title":"Compute \u2014 indexer un dossier","text":"<pre><code>docker run --rm \\\n  -v /mes/donnees:/data:ro \\\n  -v /mes/bases:/bases \\\n  hash_tool compute /data /bases/hashes_$(date +%Y-%m-%d).b3</code></pre>"},{"location":"ancienne%20doc/docker/#verify-verifier-lintegrite","title":"Verify \u2014 v\u00e9rifier l'int\u00e9grit\u00e9","text":"<pre><code># Depuis le r\u00e9pertoire d'origine (m\u00eame montage /data qu'au compute)\ndocker run --rm \\\n  -v /mes/donnees:/data:ro \\\n  -v /mes/bases:/bases:ro \\\n  -v /mes/resultats:/resultats \\\n  hash_tool verify /bases/hashes_2024-01-15.b3 /data</code></pre> <p>Le r\u00e9sultat (<code>recap.txt</code>, <code>failed.txt</code> si \u00e9chec) est \u00e9crit dans <code>/resultats</code> sur l'h\u00f4te.</p>"},{"location":"ancienne%20doc/docker/#compare-deux-snapshots","title":"Compare \u2014 deux snapshots","text":"<pre><code>docker run --rm \\\n  -v /mes/bases:/bases:ro \\\n  -v /mes/resultats:/resultats \\\n  hash_tool compare /bases/hashes_2024-01-15.b3 /bases/hashes_2024-02-01.b3</code></pre> <p>Produit <code>recap.txt</code>, <code>modifies.b3</code>, <code>disparus.txt</code>, <code>nouveaux.txt</code>, <code>report.html</code>.</p>"},{"location":"ancienne%20doc/docker/#pipeline-json-complet","title":"Pipeline JSON complet","text":"<pre><code>docker run --rm \\\n  -v /mes/donnees:/data:ro \\\n  -v /mes/bases:/bases \\\n  -v /mes/resultats:/resultats \\\n  -v /chemin/vers/pipeline.json:/pipelines/pipeline.json:ro \\\n  hash_tool runner</code></pre>"},{"location":"ancienne%20doc/docker/#mode-silencieux-cicron","title":"Mode silencieux \u2014 CI/cron","text":"<pre><code># Exit code 0 si OK, non-nul si FAILED\ndocker run --rm \\\n  -v /mes/donnees:/data:ro \\\n  -v /mes/bases:/bases:ro \\\n  -v /mes/resultats:/resultats \\\n  hash_tool --quiet verify /bases/hashes.b3 /data \\\n  || echo \"ALERTE : corruption d\u00e9tect\u00e9e\"</code></pre>"},{"location":"ancienne%20doc/docker/#debug-interactif","title":"Debug interactif","text":"<pre><code>docker run --rm -it \\\n  -v /mes/donnees:/data \\\n  -v /mes/bases:/bases \\\n  hash_tool shell</code></pre>"},{"location":"ancienne%20doc/docker/#volumes","title":"Volumes","text":"Volume Usage Recommandation <code>/data</code> Donn\u00e9es \u00e0 hacher <code>:ro</code> (lecture seule) <code>/bases</code> Fichiers <code>.b3</code> Lecture/\u00e9criture pour <code>compute</code> <code>/pipelines</code> Fichiers <code>pipeline.json</code> <code>:ro</code> <code>/resultats</code> R\u00e9sultats <code>verify</code>/<code>compare</code> Lecture/\u00e9criture"},{"location":"ancienne%20doc/docker/#variable-denvironnement","title":"Variable d'environnement","text":"<p><code>RESULTATS_DIR</code> \u2014 dossier de r\u00e9sultats dans le conteneur (d\u00e9faut : <code>/resultats</code>).</p> <pre><code>docker run --rm \\\n  -v /mes/resultats:/mon_dossier_custom \\\n  -e RESULTATS_DIR=/mon_dossier_custom \\\n  hash_tool verify /bases/hashes.b3</code></pre>"},{"location":"ancienne%20doc/docker/#docker-compose","title":"Docker Compose","text":"<p>Adapter les chemins dans <code>docker-compose.yml</code> (section <code>x-volumes</code>), puis :</p> <pre><code># Commande ponctuelle\ndocker compose run --rm integrity verify /bases/hashes.b3 /data\ndocker compose run --rm integrity compute /data /bases/hashes.b3\n\n# Pipeline complet\ndocker compose run --rm pipeline\n\n# Build et run pipeline\ndocker compose build &amp;&amp; docker compose run --rm pipeline</code></pre>"},{"location":"ancienne%20doc/docker/#nas-synology","title":"NAS Synology","text":"<p>Sur DSM 7.x avec Docker Manager ou Portainer :</p> <pre><code># Chemin type sur Synology\ndocker run --rm \\\n  -v /volume1/data:/data:ro \\\n  -v /volume1/bases:/bases \\\n  -v /volume1/resultats:/resultats \\\n  hash_tool verify /bases/hashes.b3 /data</code></pre> <p>Pour ARM64 (DS220+, DS923+) : builder avec <code>--platform linux/arm64</code> ou utiliser une image pr\u00e9-build\u00e9e.</p>"},{"location":"ancienne%20doc/docker/#cron-sur-serveur-debian","title":"Cron sur serveur Debian","text":"<pre><code># /etc/cron.d/hash-integrity\n0 3 * * * root docker run --rm \\\n  -v /srv/data:/data:ro \\\n  -v /srv/bases:/bases:ro \\\n  -v /srv/resultats:/resultats \\\n  hash_tool --quiet verify /bases/hashes.b3 /data \\\n  &gt;&gt; /var/log/hash-integrity.log 2&gt;&amp;1 \\\n  || mail -s \"ALERTE int\u00e9grit\u00e9 $(hostname)\" admin@example.com</code></pre>"},{"location":"ancienne%20doc/docker/#taille-de-limage","title":"Taille de l'image","text":"Couche Taille approx. Alpine 3.19 base ~7 Mo bash + jq + coreutils + findutils ~5 Mo b3sum binaire musl ~2 Mo Scripts hash_tool &lt;100 Ko Total ~14 Mo <p>L'utilisation d'un binaire musl pr\u00e9-compil\u00e9 (stage <code>fetcher</code>) \u00e9vite d'embarquer la toolchain Rust (~700 Mo) dans l'image finale.</p>"},{"location":"ancienne%20doc/docker/#mise-a-jour-de-b3sum","title":"Mise \u00e0 jour de b3sum","text":"<p>Modifier <code>ARG B3SUM_VERSION</code> dans le <code>Dockerfile</code> et rebuilder :</p> <pre><code>docker build --build-arg B3SUM_VERSION=1.6.0 -t hash_tool .</code></pre> <p>Les URLs de release suivent le pattern : <pre><code>https://github.com/BLAKE3-team/BLAKE3/releases/download/&lt;version&gt;/b3sum_linux_amd64_musl\nhttps://github.com/BLAKE3-team/BLAKE3/releases/download/&lt;version&gt;/b3sum_linux_aarch64_musl</code></pre></p> <p>La signature <code>.b3</code> est v\u00e9rifi\u00e9e automatiquement au build (le binaire se v\u00e9rifie lui-m\u00eame).</p>"},{"location":"ancienne%20doc/explication-run-tests/","title":"Explication du code \u2014 run_tests.sh + run_tests_pipeline.sh","text":""},{"location":"ancienne%20doc/explication-run-tests/#vue-densemble","title":"Vue d'ensemble","text":"<p>Deux suites de tests ind\u00e9pendantes, bash pur, sans framework externe.</p> <pre><code>tests/\n\u251c\u2500\u2500 run_tests.sh            \u2190 integrity.sh \u2014 15 cas T00\u2013T14\n\u2514\u2500\u2500 run_tests_pipeline.sh   \u2190 runner.sh + pipeline.json \u2014 12 cas TP01\u2013TP12</code></pre> <p>Chaque suite : pr\u00e9requis \u2192 setup \u2192 tests \u2192 teardown \u2192 rapport + exit code CI.</p>"},{"location":"ancienne%20doc/explication-run-tests/#partie-1-run_testssh-integritysh","title":"PARTIE 1 \u2014 run_tests.sh (integrity.sh)","text":""},{"location":"ancienne%20doc/explication-run-tests/#11-configuration-et-chemins","title":"1.1 Configuration et chemins","text":"<pre><code>SCRIPT_DIR=\"$(cd \"$(dirname \"${BASH_SOURCE[0]}\")\" &amp;&amp; pwd)\"\nINTEGRITY=\"$SCRIPT_DIR/../integrity.sh\"\nWORKDIR=\"$(mktemp -d /tmp/integrity-test.XXXXXX)\"</code></pre> <ul> <li><code>SCRIPT_DIR</code> : r\u00e9pertoire absolu du script, ind\u00e9pendant du <code>pwd</code> appelant.</li> <li><code>INTEGRITY</code> : chemin relatif \u00e0 <code>run_tests.sh</code> \u2014 d\u00e9pla\u00e7ables ensemble sans modifier les chemins.</li> <li><code>WORKDIR</code> : r\u00e9pertoire temporaire isol\u00e9 par <code>mktemp</code>, suffix al\u00e9atoire 6 chars.</li> </ul>"},{"location":"ancienne%20doc/explication-run-tests/#12-systeme-de-comptage","title":"1.2 Syst\u00e8me de comptage","text":"<pre><code>PASS=0; FAIL=0; TOTAL=0\npass() { echo -e \"${GREEN}  PASS${NC} \u2014 $1\"; (( PASS++ )); (( TOTAL++ )); }\nfail() { echo -e \"${RED}  FAIL${NC} \u2014 $1\"; (( FAIL++ )); (( TOTAL++ )); }</code></pre> <p><code>TOTAL</code> permet de d\u00e9tecter un test saut\u00e9 silencieusement.</p>"},{"location":"ancienne%20doc/explication-run-tests/#13-fonctions-dassertion","title":"1.3 Fonctions d'assertion","text":"<p><code>assert_exit_zero</code> / <code>assert_exit_nonzero</code> : ex\u00e9cute une commande, v\u00e9rifie le code de retour. <code>&gt; /dev/null 2&gt;&amp;1</code> supprime toute sortie. <code>shift</code> consomme le label pour que <code>\"$@\"</code> ne contienne que la commande.</p> <p><code>assert_contains</code> / <code>assert_not_contains</code> : cherche un pattern dans une cha\u00eene captur\u00e9e. La capture via <code>local out=$(commande)</code> avant l'assertion permet plusieurs inspections sans relancer la commande.</p> <p><code>assert_line_count</code> : <code>wc -l &lt; fichier</code> (sans le nom) \u2014 pas d'affichage du nom par <code>wc</code>.</p> <p><code>assert_file_exists</code> / <code>assert_file_absent</code> : pr\u00e9sence ou absence d'un fichier r\u00e9gulier.</p>"},{"location":"ancienne%20doc/explication-run-tests/#14-setup-teardown","title":"1.4 Setup / Teardown","text":"<p>4 fichiers d\u00e9terministes (contenu connu \u2192 hashes reproductibles). <code>sub/delta.txt</code> valide la r\u00e9cursivit\u00e9 de <code>find</code>. <code>teardown()</code> supprime <code>WORKDIR</code> entier.</p>"},{"location":"ancienne%20doc/explication-run-tests/#15-pattern-true","title":"1.5 Pattern || true","text":"<pre><code>local out\nout=$(commande 2&gt;&amp;1 || true)</code></pre> <p>Critique : sans <code>|| true</code>, un code de retour non nul sous <code>-euo pipefail</code> interrompt le script avant que l'assertion enregistre l'\u00e9chec.</p>"},{"location":"ancienne%20doc/explication-run-tests/#16-cas-de-test-specifiques","title":"1.6 Cas de test sp\u00e9cifiques","text":"<p>T00 \u2014 ShellCheck : analyse statique sur <code>integrity.sh</code> et <code>run_tests.sh</code>. <code>SKIP</code> propre si non install\u00e9.</p> <p>T11 \u2014 Int\u00e9grit\u00e9 base avec ETA : v\u00e9rifie que <code>compute_with_progress</code> produit une base bit-\u00e0-bit identique \u00e0 <code>find | sort | xargs b3sum</code>, sans artefact <code>ETA</code> ni <code>\\r</code>.</p> <p>T12 \u2014 Mode <code>--quiet</code> : stdout vide sur verify OK, verify ECHEC, et compute. Exit code non nul propag\u00e9. Fichiers de r\u00e9sultats produits malgr\u00e9 <code>--quiet</code>.</p> <p>T13 \u2014 Horodatage : deux <code>verify</code> successifs sur la m\u00eame base \u2192 deux dossiers distincts (pas d'\u00e9crasement). <code>sleep 1</code> garantit des timestamps diff\u00e9rents.</p> <p>T14 \u2014 Argument invalide : <code>verify base.b3 /chemin/inexistant</code> \u2192 <code>ERREUR</code> explicite.</p>"},{"location":"ancienne%20doc/explication-run-tests/#17-tableau-des-cas","title":"1.7 Tableau des cas","text":"Cas Description T00 ShellCheck (analyse statique) T01 Compute de base T02 Verify sans modification T03 Verify apr\u00e8s corruption T04 Verify apr\u00e8s suppression T05 Compare sans diff\u00e9rence T06 Compare avec fichier modifi\u00e9 T07 Compare avec fichier supprim\u00e9 + ajout\u00e9 T08 Noms de fichiers avec espaces T09 Dossiers vides ignor\u00e9s T10 Chemins absolus vs relatifs T11 Int\u00e9grit\u00e9 base avec ETA T12 Mode <code>--quiet</code> T13 Horodatage anti-\u00e9crasement T14 Argument invalide pour verify"},{"location":"ancienne%20doc/explication-run-tests/#partie-2-run_tests_pipelinesh-runnersh-pipelinejson","title":"PARTIE 2 \u2014 run_tests_pipeline.sh (runner.sh + pipeline.json)","text":""},{"location":"ancienne%20doc/explication-run-tests/#21-configuration-et-chemins","title":"2.1 Configuration et chemins","text":"<pre><code>SCRIPT_DIR=\"$(cd \"$(dirname \"${BASH_SOURCE[0]}\")\" &amp;&amp; pwd)\"\nRUNNER=\"$SCRIPT_DIR/../runner.sh\"\nINTEGRITY=\"$SCRIPT_DIR/../integrity.sh\"\nWORKDIR=\"$(mktemp -d /tmp/integrity-pipeline-test.XXXXXX)\"\nexport RESULTATS_DIR=\"$WORKDIR/resultats\"</code></pre> <p><code>RESULTATS_DIR</code> est export\u00e9 pour que <code>integrity.sh</code> (appel\u00e9 par <code>runner.sh</code>) redirige ses r\u00e9sultats dans le <code>WORKDIR</code> isol\u00e9 \u2014 pas dans <code>~/integrity_resultats</code>.</p>"},{"location":"ancienne%20doc/explication-run-tests/#22-helper-write_config","title":"2.2 Helper write_config","text":"<pre><code>write_config() {\n    local path=\"$WORKDIR/pipeline.json\"\n    cat &gt; \"$path\"\n    echo \"$path\"\n}</code></pre> <p>Lit le JSON depuis stdin (heredoc), l'\u00e9crit dans <code>WORKDIR/pipeline.json</code>, retourne le chemin. Permet de g\u00e9n\u00e9rer un <code>pipeline.json</code> diff\u00e9rent par test sans fichiers temporaires nomm\u00e9s \u00e0 la main.</p> <p>Usage :</p> <pre><code>local cfg\ncfg=$(write_config &lt;&lt;EOF\n{ \"pipeline\": [ { \"op\": \"compute\", ... } ] }\nEOF\n)\nbash \"$RUNNER\" \"$cfg\"</code></pre>"},{"location":"ancienne%20doc/explication-run-tests/#23-strategie-de-test-par-cas","title":"2.3 Strat\u00e9gie de test par cas","text":"<p>TP01\u2013TP04 (parsing) : tests n\u00e9gatifs \u2014 chaque test passe un JSON ou une config invalide et v\u00e9rifie que <code>runner.sh</code> \u00e9choue avec un message <code>ERREUR</code> explicite, sans stacktrace <code>jq</code> brute ni crash silencieux.</p> <p>TP05\u2013TP06 (compute) : TP05 v\u00e9rifie trois invariants sur la base produite \u2014 existence, chemins relatifs (<code>./</code>en d\u00e9but de chemin), comptage exact de fichiers. TP06 v\u00e9rifie l'\u00e9chec propre sur source absente.</p> <p>TP07\u2013TP09 (verify) : TP07 v\u00e9rifie le bon r\u00e9pertoire de travail (v\u00e9rification OK, <code>recap.txt</code> produit). TP08 v\u00e9rifie la d\u00e9tection de corruption. TP09 v\u00e9rifie l'\u00e9chec propre sur base absente.</p> <p>TP10\u2013TP11 (compare) : TP10 v\u00e9rifie les quatre fichiers de r\u00e9sultats produits. TP11 v\u00e9rifie l'\u00e9chec propre sur <code>base_a</code> absente.</p> <p>TP12 (pipeline complet) : test d'int\u00e9gration \u2014 compute \u00d7 2 + verify + compare dans un seul <code>pipeline.json</code>. V\u00e9rifie les labels dans la sortie, les bases cr\u00e9\u00e9es, et l'absence d'erreur.</p>"},{"location":"ancienne%20doc/explication-run-tests/#24-resolution-des-dossiers-de-resultats","title":"2.4 R\u00e9solution des dossiers de r\u00e9sultats","text":"<pre><code>outdir_tp07=$(ls -d \"${RESULTATS_DIR}/resultats_hashes_a\"* 2&gt;/dev/null | tail -1)</code></pre> <p><code>tail -1</code> r\u00e9cup\u00e8re le dossier le plus r\u00e9cent \u2014 compatible avec l'horodatage automatique de <code>make_result_dir()</code>. Sans <code>tail -1</code>, si un dossier <code>resultats_hashes_a</code> existe d\u00e9j\u00e0 d'un test pr\u00e9c\u00e9dent, <code>ls</code> retourne plusieurs lignes et l'assertion porte sur la mauvaise.</p>"},{"location":"ancienne%20doc/explication-run-tests/#25-prerequis-et-execution","title":"2.5 Pr\u00e9requis et ex\u00e9cution","text":"<pre><code>cd tests\n./run_tests_pipeline.sh</code></pre> <p>Pr\u00e9requis : <code>jq</code>, <code>b3sum</code>, <code>bash &gt;= 4</code>, <code>runner.sh</code> et <code>integrity.sh</code> dans le r\u00e9pertoire parent. Exit code CI-compatible : 0 si tous passent, 1 si au moins un \u00e9chec.</p>"},{"location":"ancienne%20doc/explication-run-tests/#26-tableau-des-cas","title":"2.6 Tableau des cas","text":"Cas Description TP01 JSON invalide \u2014 erreur propre sans stacktrace jq TP02 Cl\u00e9 <code>.pipeline</code> absente TP03 Champ <code>nom</code> manquant dans compute TP04 Op\u00e9ration inconnue TP05 Compute \u2014 cd correct, chemins relatifs, comptage TP06 Compute \u2014 dossier source absent TP07 Verify \u2014 bon r\u00e9pertoire de travail, OK TP08 Verify \u2014 corruption d\u00e9tect\u00e9e TP09 Verify \u2014 base .b3 absente TP10 Compare \u2014 fichiers de r\u00e9sultats produits TP11 Compare \u2014 base_a absente TP12 Pipeline complet compute + verify + compare"},{"location":"ancienne%20doc/explication-run-tests/#prerequis-globaux","title":"Pr\u00e9requis globaux","text":"<pre><code># run_tests.sh\napt install b3sum shellcheck   # shellcheck optionnel\n\n# run_tests_pipeline.sh\napt install b3sum jq</code></pre> <p>Les deux suites sont ind\u00e9pendantes et peuvent \u00eatre lanc\u00e9es s\u00e9par\u00e9ment.</p>"},{"location":"ancienne%20doc/manuel/","title":"Manuel technique \u2014 V\u00e9rification d'int\u00e9grit\u00e9 de donn\u00e9es","text":"<p>P\u00e9rim\u00e8tre : d\u00e9tection d'erreurs de transfert et de corruption silencieuse sur disque, sans adversaire. Outils couverts : b3sum (BLAKE3) \u00b7 xxHash3 \u00b7 find \u00b7 diff \u00b7 bash \u00b7 jq</p>"},{"location":"ancienne%20doc/manuel/#table-des-matieres","title":"Table des mati\u00e8res","text":"<ol> <li>Algorithmes de hachage</li> <li>Structure du fichier .b3</li> <li>Workflow : calcul, stockage, comparaison</li> <li>Explication du script integrity.sh</li> <li>Pipeline batch : runner.sh + pipeline.json</li> <li>Performances et optimisation disque</li> <li>Limites et angles morts</li> <li>R\u00e9f\u00e9rence rapide</li> <li>Annexe \u2014 Alternatives et extensions</li> </ol>"},{"location":"ancienne%20doc/manuel/#1-algorithmes-de-hachage","title":"1. Algorithmes de hachage","text":""},{"location":"ancienne%20doc/manuel/#taxonomie","title":"Taxonomie","text":"<p>Deux familles distinctes, usages mutuellement exclusifs :</p> Propri\u00e9t\u00e9 Cryptographique (BLAKE3) Non-cryptographique (xxHash3) R\u00e9sistance collision intentionnelle Oui \u2014 infaisable calculatoirement Non \u2014 collisions construisibles R\u00e9sistance pr\u00e9image Oui Non D\u00e9bit CPU (1 c\u0153ur) ~1 Go/s ~50 Go/s D\u00e9bit sur HDD (150 Mo/s) Identique \u2014 disque impose le rythme Identique D\u00e9bit sur SATA SSD (500 Mo/s) Identique Identique D\u00e9tection corruption accidentelle Oui Oui Utilisable en s\u00e9curit\u00e9 Oui Non"},{"location":"ancienne%20doc/manuel/#pourquoi-blake3-plutot-que-xxhash3","title":"Pourquoi BLAKE3 plut\u00f4t que xxHash3","text":"<p>xxHash3 est techniquement suffisant pour d\u00e9tecter des erreurs accidentelles. BLAKE3 est recommand\u00e9 pour une seule raison : le co\u00fbt marginal sur disque est nul \u2014 les deux sont limit\u00e9s par l'I/O. BLAKE3 reste utilisable si le besoin \u00e9volue vers un contexte de s\u00e9curit\u00e9. Headroom gratuit.</p> <pre><code># Si xxHash3 est pr\u00e9f\u00e9r\u00e9 \u2014 workflow identique \u00e0 b3sum\nfind ./dossier -type f -print0 | sort -z | xargs -0 xxh128sum &gt; base.xxh</code></pre>"},{"location":"ancienne%20doc/manuel/#limitations-specifiques-a-ce-workflow","title":"Limitations sp\u00e9cifiques \u00e0 ce workflow","text":"<ul> <li>Ne hache pas les m\u00e9tadonn\u00e9es (mtime, permissions).</li> <li>Ne hache pas les dossiers vides : <code>find -type f</code> ne remonte que les fichiers r\u00e9guliers.</li> <li>Sensible aux chemins : chemin absolu vs relatif \u2192 deux bases incompatibles pour la m\u00eame donn\u00e9e.</li> </ul>"},{"location":"ancienne%20doc/manuel/#2-structure-du-fichier-b3","title":"2. Structure du fichier .b3","text":"<p>b3sum produit un format texte simple, une ligne par fichier :</p> <pre><code># Format : &lt;hash&gt;  &lt;chemin&gt;\n# Deux espaces s\u00e9parent le hash du chemin (convention b3sum/sha256sum)\n\na1b2c3d4e5f6a7b8c9d0e1f2a3b4c5d6e7f8a9b0c1d2e3f4a5b6c7d8e9f0a1b2  ./dossier/fichier.txt\ne5f6a7b8c9d0e1f2a3b4c5d6e7f8a9b0c1d2e3f4a5b6c7d8e9f0a1b2c3d4e5f6  ./dossier/sous/autre.bin</code></pre> Nombre de fichiers Taille approximative 10 000 ~2 Mo 100 000 ~20 Mo 1 000 000 ~200 Mo <p>R\u00e8gle absolue : chemins relatifs. Toujours <code>find ./dossier</code>, jamais <code>find /chemin/absolu</code>. Un chemin absolu rend la base inutilisable apr\u00e8s d\u00e9placement ou remontage.</p>"},{"location":"ancienne%20doc/manuel/#3-workflow-calcul-stockage-comparaison","title":"3. Workflow : calcul, stockage, comparaison","text":""},{"location":"ancienne%20doc/manuel/#calcul-et-enregistrement-de-la-base","title":"Calcul et enregistrement de la base","text":"<pre><code>find ./mon_dossier -type f -print0 \\\n  | sort -z \\\n  | xargs -0 b3sum \\\n  &gt; hashes_2024-01-15.b3\n\nwc -l hashes_2024-01-15.b3</code></pre> <p><code>sort -z</code> : <code>find</code> ne garantit pas un ordre d\u00e9terministe. Sans tri, <code>diff</code> entre deux bases est inutilisable.</p> <p><code>-print0</code> / <code>-0</code> : robuste aux noms de fichiers avec espaces ou caract\u00e8res sp\u00e9ciaux.</p>"},{"location":"ancienne%20doc/manuel/#verification-directe","title":"V\u00e9rification directe","text":"<pre><code>b3sum --check hashes_2024-01-15.b3\n\n# Sortie OK :\n# ./mon_dossier/fichier.txt: OK\n\n# Sortie ECHEC :\n# ./mon_dossier/sous/corrompu.bin: FAILED\n# b3sum: WARNING: 1 computed checksum did NOT match\n\nb3sum --check hashes_2024-01-15.b3 2&gt;&amp;1 | grep FAILED</code></pre> <p>Contrainte critique : r\u00e9pertoire de travail. <code>b3sum --check</code> r\u00e9sout les chemins relatifs depuis <code>pwd</code>. Toujours ex\u00e9cuter depuis le r\u00e9pertoire o\u00f9 <code>compute</code> a \u00e9t\u00e9 lanc\u00e9.</p>"},{"location":"ancienne%20doc/manuel/#comparaison-de-deux-bases-b3","title":"Comparaison de deux bases .b3","text":"<pre><code>diff &lt;(sort hashes_2024-01-15.b3) &lt;(sort hashes_2024-02-01.b3)</code></pre> <p><code>run_compare()</code> dans <code>integrity.sh</code> automatise cette comparaison avec <code>join</code>, <code>comm</code>, et un rapport structur\u00e9.</p>"},{"location":"ancienne%20doc/manuel/#4-explication-du-script-integritysh","title":"4. Explication du script integrity.sh","text":""},{"location":"ancienne%20doc/manuel/#en-tete-et-mode-strict","title":"En-t\u00eate et mode strict","text":"<pre><code>#!/usr/bin/env bash\nset -euo pipefail</code></pre> <ul> <li><code>-e</code> : arr\u00eat sur \u00e9chec de commande.</li> <li><code>-u</code> : erreur sur variable non initialis\u00e9e.</li> <li><code>-o pipefail</code> : \u00e9chec du pipeline si une commande interm\u00e9diaire \u00e9choue.</li> </ul>"},{"location":"ancienne%20doc/manuel/#parsing-des-arguments","title":"Parsing des arguments","text":"<pre><code>QUIET=0\nARGS=()\nfor arg in \"$@\"; do\n  case \"$arg\" in\n    --quiet) QUIET=1 ;;\n    *)       ARGS+=(\"$arg\") ;;\n  esac\ndone\nMODE=\"${ARGS[0]:-}\"\nARG2=\"${ARGS[1]:-}\"\nARG3=\"${ARGS[2]:-}\"</code></pre> <p><code>--quiet</code> filtr\u00e9 avant la lecture positionnelle. <code>:-</code> donne une valeur vide par d\u00e9faut en mode <code>-u</code>.</p>"},{"location":"ancienne%20doc/manuel/#mode-compute","title":"Mode compute","text":"<pre><code>compute_with_progress() {\n  local -a files\n  mapfile -d '' files &lt; &lt;(find \"$target\" -type f -print0 | sort -z)\n\n  for file in \"${files[@]}\"; do\n    b3sum \"$file\" &gt;&gt; \"$hashfile\"\n    # ETA calcul\u00e9 et affich\u00e9 sur /dev/tty \u2014 jamais dans le pipe\n    printf \"\\r[%d/%d] ETA : %dm %02ds   \" ... &gt; /dev/tty\n  done\n}</code></pre> <p><code>mapfile -d ''</code> : charge les chemins en tableau depuis flux nul-s\u00e9par\u00e9. Robuste aux espaces et caract\u00e8res sp\u00e9ciaux.</p> <p><code>&gt; /dev/tty</code> : progression \u00e9crite directement sur le terminal, ne peut pas polluer la base <code>.b3</code>.</p>"},{"location":"ancienne%20doc/manuel/#mode-verify","title":"Mode verify","text":"<pre><code>hashfile_abs=$(realpath \"$ARG2\")\n[ -n \"${ARG3:-}\" ] &amp;&amp; cd \"$ARG3\"\nrun_verify \"$hashfile_abs\"</code></pre> <p>Le chemin absolu est r\u00e9solu avant le <code>cd</code> \u2014 un chemin relatif deviendrait invalide apr\u00e8s changement de r\u00e9pertoire.</p>"},{"location":"ancienne%20doc/manuel/#mode-compare","title":"Mode compare","text":"<p><code>run_compare()</code> convertit <code>hash  chemin</code> \u2192 <code>chemin\\thash</code> via <code>awk</code> (offset fixe 64 chars pour le hash), puis utilise <code>sort</code>, <code>join</code>, <code>comm</code> avec <code>-t $'\\t'</code> \u2014 robuste aux chemins avec espaces.</p>"},{"location":"ancienne%20doc/manuel/#5-pipeline-batch-runnersh-pipelinejson","title":"5. Pipeline batch : runner.sh + pipeline.json","text":""},{"location":"ancienne%20doc/manuel/#probleme-resolu","title":"Probl\u00e8me r\u00e9solu","text":"<p>Lancer <code>integrity.sh</code> manuellement sur plusieurs dossiers depuis des partitions diff\u00e9rentes (VeraCrypt, disques externes) est error-prone : r\u00e9pertoire de travail incorrect, chemins absolus dans les bases, oubli de <code>cd</code>. <code>runner.sh</code> automatise et s\u00e9curise ces \u00e9tapes.</p> <p>D\u00e9pendance suppl\u00e9mentaire : <code>jq</code> (<code>apt install jq</code> dans WSL).</p>"},{"location":"ancienne%20doc/manuel/#pipelinejson-format","title":"pipeline.json \u2014 format","text":"<pre><code>{\n    \"pipeline\": [\n\n        {\n            \"op\":     \"compute\",\n            \"source\": \"/mnt/a/dossier_disque_1\",\n            \"bases\":  \"/mnt/c/Users/TonNom/Desktop/bases\",\n            \"nom\":    \"hashes_dossier_1.b3\"\n        },\n\n        {\n            \"op\":     \"compute\",\n            \"source\": \"/mnt/i/dossier_disque_2\",\n            \"bases\":  \"/mnt/c/Users/TonNom/Desktop/bases\",\n            \"nom\":    \"hashes_dossier_2.b3\"\n        },\n\n        {\n            \"op\":     \"verify\",\n            \"source\": \"/mnt/a/dossier_disque_1\",\n            \"base\":   \"/mnt/c/Users/TonNom/Desktop/bases/hashes_dossier_1.b3\"\n        },\n\n        {\n            \"op\":     \"compare\",\n            \"base_a\": \"/mnt/c/Users/TonNom/Desktop/bases/hashes_dossier_1.b3\",\n            \"base_b\": \"/mnt/c/Users/TonNom/Desktop/bases/hashes_dossier_2.b3\"\n        }\n\n    ]\n}</code></pre> <p>Champs requis par op\u00e9ration :</p> <code>op</code> Champs <code>compute</code> <code>source</code> \u2014 dossier \u00e0 hacher \u00b7 <code>bases</code> \u2014 dossier de destination \u00b7 <code>nom</code> \u2014 nom du <code>.b3</code> <code>verify</code> <code>source</code> \u2014 r\u00e9pertoire de travail d'origine \u00b7 <code>base</code> \u2014 chemin complet du <code>.b3</code> <code>compare</code> <code>base_a</code> \u2014 ancienne base \u00b7 <code>base_b</code> \u2014 nouvelle base"},{"location":"ancienne%20doc/manuel/#runnersh-comportement","title":"runner.sh \u2014 comportement","text":"<p>compute : <code>cd \"$source\"</code> puis <code>integrity.sh compute . \"$bases/$nom\"</code>. Le <code>.</code> garantit des chemins relatifs dans la base.</p> <p>verify : <code>cd \"$source\"</code> puis <code>integrity.sh verify \"$base\"</code>. Le <code>cd</code> reproduit le r\u00e9pertoire de travail d'origine du compute.</p> <p>compare : appel direct sans <code>cd</code>. <code>base_a</code> et <code>base_b</code> sont des chemins absolus vers les <code>.b3</code>.</p> <p>Validation : <code>jq empty</code> v\u00e9rifie la syntaxe JSON \u00e0 l'entr\u00e9e. Champs manquants et op\u00e9rations inconnues produisent un message <code>ERREUR</code> avec num\u00e9ro de bloc, sans stacktrace <code>jq</code>.</p>"},{"location":"ancienne%20doc/manuel/#lancement-windows-double-clic","title":"Lancement Windows (double-clic)","text":"<pre><code>@echo off\nwsl bash /mnt/c/Users/TonNom/Desktop/runner.sh\npause</code></pre>"},{"location":"ancienne%20doc/manuel/#chemins-wsl-partitions-veracrypt","title":"Chemins WSL \u2014 partitions VeraCrypt","text":"Windows WSL <code>A:\\</code> <code>/mnt/a/</code> <code>C:\\</code> <code>/mnt/c/</code> <code>H:\\</code> <code>/mnt/h/</code> <code>I:\\</code> <code>/mnt/i/</code> <p>Si VeraCrypt remonte une partition sur une lettre diff\u00e9rente, seul le champ <code>source</code> dans <code>pipeline.json</code> est \u00e0 modifier. La base <code>.b3</code> reste valide car ses chemins sont relatifs.</p>"},{"location":"ancienne%20doc/manuel/#6-performances-et-optimisation-disque","title":"6. Performances et optimisation disque","text":"<p>Sur HDD (150 Mo/s), SSD SATA (500 Mo/s) ou SSD NVMe s\u00e9quentiel, le disque est syst\u00e9matiquement le goulot. b3sum \u00e0 1 Go/s sur un c\u0153ur ne sera jamais le facteur limitant.</p> <p>La boucle s\u00e9quentielle de <code>compute_with_progress</code> est l\u00e9g\u00e8rement moins efficace que <code>xargs -P 4</code> sur SSD NVMe avec de nombreux petits fichiers, mais identique sur HDD \u2014 cas principal pour gros volumes. Le gain ETA justifie le choix.</p> <p>Pour SSD NVMe + pas besoin d'ETA :</p> <pre><code>find ./dossier -type f -print0 | sort -z | xargs -0 -P 4 b3sum &gt; base.b3</code></pre>"},{"location":"ancienne%20doc/manuel/#7-limites-et-angles-morts","title":"7. Limites et angles morts","text":"Sc\u00e9nario D\u00e9tect\u00e9 ? Explication Fichier corrompu Oui Hash diff\u00e9rent \u2192 FAILED ou divergence compare Fichier manquant Oui FAILED (No such file) ou section DISPARUS Fichier ajout\u00e9 Oui (compare) Section NOUVEAUX Dossier vide Non <code>find -type f</code> ignore les dossiers vides Permissions/timestamps Non b3sum ne hache que le contenu binaire Clone identique Non Hash identique \u2014 ind\u00e9tectable par d\u00e9finition Corruption de la base .b3 Non La base n'est pas auto-prot\u00e9g\u00e9e"},{"location":"ancienne%20doc/manuel/#proteger-la-base","title":"Prot\u00e9ger la base","text":"<pre><code>b3sum hashes_2024-01-15.b3 &gt; hashes_2024-01-15.b3.check\nb3sum --check hashes_2024-01-15.b3.check</code></pre> <p>Stocker la base sur un support distinct. Sur VeraCrypt : stocker les <code>.b3</code> sur <code>C:</code>, jamais sur la partition v\u00e9rifi\u00e9e.</p>"},{"location":"ancienne%20doc/manuel/#renommages-et-changements-de-chemin","title":"Renommages et changements de chemin","text":"<p><code>b3sum --check</code> compare les chemins litt\u00e9ralement. Tout renommage de dossier produit des FAILED sur tous les fichiers, m\u00eame si le contenu est intact.</p> <pre><code>sed 's|./ancien_nom/|./nouveau_nom/|g' base.b3 &gt; base_corrigee.b3\nb3sum --check base_corrigee.b3</code></pre>"},{"location":"ancienne%20doc/manuel/#8-reference-rapide","title":"8. R\u00e9f\u00e9rence rapide","text":"<pre><code># Calcul\nfind ./dossier -type f -print0 | sort -z | xargs -0 b3sum &gt; base.b3\n\n# V\u00e9rification\n./integrity.sh verify base.b3\n\n# Comparaison\n./integrity.sh compare ancienne.b3 nouvelle.b3\n\n# Pipeline multi-dossiers\n./runner.sh                        # lit pipeline.json dans le m\u00eame dossier\n./runner.sh /chemin/pipeline.json  # config explicite\n\n# Compter les fichiers index\u00e9s\nwc -l base.b3\n\n# Fichier unique\nb3sum fichier.bin\n\n# Prot\u00e9ger la base\nb3sum base.b3 &gt; base.b3.check</code></pre> Situation Mode Commande Premi\u00e8re indexation compute <code>./integrity.sh compute ./dossier base.b3</code> Multi-dossiers / VeraCrypt runner <code>./runner.sh</code> V\u00e9rifier apr\u00e8s transfert verify <code>./integrity.sh verify base.b3</code> Comparer deux archives compare <code>./integrity.sh compare old.b3 new.b3</code> Fichier unique ad hoc <code>b3sum fichier.bin</code>"},{"location":"ancienne%20doc/manuel/#9-annexe-alternatives-et-extensions","title":"9. Annexe \u2014 Alternatives et extensions","text":""},{"location":"ancienne%20doc/manuel/#a1-outils-fim","title":"A.1 Outils FIM","text":"Outil Usage Complexit\u00e9 Pertinent si\u2026 Tripwire Audit syst\u00e8me local Moyenne Serveur Linux, conformit\u00e9 PCI-DSS/HIPAA Samhain FIM distribu\u00e9, alertes SIEM \u00c9lev\u00e9e Infrastructure d'entreprise AIDE Alternative open source \u00e0 Tripwire Moyenne Remplacement direct de Tripwire ZFS Checksum natif sur chaque bloc Faible (si migration possible) Protection transparente <p>b3sum/xxHash3 sont des primitives. Tripwire et Samhain sont des syst\u00e8mes qui maintiennent un \u00e9tat de r\u00e9f\u00e9rence et d\u00e9tectent les d\u00e9rives.</p>"},{"location":"ancienne%20doc/manuel/#a2-integration-automatisee","title":"A.2 Int\u00e9gration automatis\u00e9e","text":"<pre><code># Crontab \u2014 v\u00e9rification hebdomadaire\n0 2 * * 0 /opt/integrity.sh --quiet verify /var/lib/integrity/base.b3 &gt;&gt; /var/log/integrity.log 2&gt;&amp;1\n\n# Post-transfert rsync\nrsync -av source/ dest/ &amp;&amp; b3sum --check base.b3\n\n# Alerte email\nb3sum --check base.b3 2&gt;&amp;1 | grep FAILED | mail -s 'Alerte int\u00e9grit\u00e9' admin@example.com</code></pre>"},{"location":"ancienne%20doc/progression-eta/","title":"Progression temps r\u00e9el et estimation ETA","text":""},{"location":"ancienne%20doc/progression-eta/#le-probleme","title":"Le probl\u00e8me","text":"<p>Le pipeline <code>find | sort | xargs b3sum</code> est une bo\u00eete noire : <code>b3sum</code> ne remonte aucune progression. Par d\u00e9faut, le mode <code>compute</code> s'ex\u00e9cute en silence jusqu'\u00e0 compl\u00e9tion - aucun indicateur de dur\u00e9e ni d'avancement.</p>"},{"location":"ancienne%20doc/progression-eta/#pourquoi-leta-necessite-de-casser-le-pipeline-xargs","title":"Pourquoi l'ETA n\u00e9cessite de casser le pipeline <code>xargs</code>","text":"<p>Intercaler <code>pv</code> dans le pipeline existant est techniquement possible mais inutilisable ici : mesurer le d\u00e9bit sur un flux <code>cat | pv | b3sum</code> produit un hash global du flux concat\u00e9n\u00e9, pas une ligne par fichier. Le fichier <code>.b3</code> r\u00e9sultant est invalide pour <code>--check</code> ou <code>compare</code>.</p> <pre><code># Cette approche est invalide - ne pas utiliser\nTOTAL=$(find \"$TARGET\" -type f -print0 | xargs -0 du -sb | awk '{sum+=$1} END {print sum}')\nfind \"$TARGET\" -type f -print0 | sort -z \\\n  | xargs -0 cat \\\n  | pv -s \"$TOTAL\" \\\n  | b3sum \\\n  &gt; \"$HASHFILE\"\n# Produit un hash unique du flux concat\u00e9n\u00e9 - inutilisable</code></pre> <p>La seule approche compatible avec le format <code>.b3</code> : remplacer <code>xargs</code> par une boucle bash explicite, fichier par fichier. Le contr\u00f4le de progression devient trivial. Le co\u00fbt en performance est n\u00e9gligeable - le disque est le goulot, pas le shell.</p>"},{"location":"ancienne%20doc/progression-eta/#implementation-finale-compute_with_progress","title":"Impl\u00e9mentation finale : <code>compute_with_progress</code>","text":"<pre><code>compute_with_progress() {\n  local target=\"$1\"\n  local hashfile=\"$2\"\n\n  local -a files\n  mapfile -d '' files &lt; &lt;(find \"$target\" -type f -print0 | sort -z)\n\n  local total_files=${#files[@]}\n  local total_bytes\n  total_bytes=$(du -sb \"$target\" | awk '{print $1}')\n\n  local bytes_done=0\n  local t_start\n  t_start=$(date +%s)\n\n  local i=0\n  for file in \"${files[@]}\"; do\n    b3sum \"$file\" &gt;&gt; \"$hashfile\"\n\n    bytes_done=$(( bytes_done + $(stat -c%s \"$file\") ))\n    i=$(( i + 1 ))\n\n    local t_now elapsed\n    t_now=$(date +%s)\n    elapsed=$(( t_now - t_start ))\n\n    if (( bytes_done &gt; 0 &amp;&amp; elapsed &gt; 0 )); then\n      local speed remaining\n      speed=$(( bytes_done / elapsed ))\n      remaining=$(( (total_bytes - bytes_done) / speed ))\n      printf \"\\r[%d/%d] ETA : %dm %02ds   \" \\\n        \"$i\" \"$total_files\" $(( remaining / 60 )) $(( remaining % 60 ))\n    fi\n  done\n\n  printf \"\\r%*s\\r\" 40 \"\"  # effacer la ligne de progression\n}</code></pre> <p><code>mapfile -d ''</code> au lieu de <code>FILES=($(find ...))</code> : la substitution de commande <code>$(...)</code> d\u00e9coupe sur les espaces et les retours \u00e0 la ligne - les noms de fichiers avec espaces seraient cass\u00e9s en plusieurs \u00e9l\u00e9ments. <code>mapfile -d ''</code> lit le flux nul-s\u00e9par\u00e9 produit par <code>-print0</code> et charge chaque chemin comme un \u00e9l\u00e9ment distinct du tableau, sans ambigu\u00eft\u00e9.</p>"},{"location":"ancienne%20doc/progression-eta/#mecanique-de-lestimation","title":"M\u00e9canique de l'estimation","text":"<p>L'ETA repose sur trois mesures :</p> <ul> <li>octets trait\u00e9s - cumul\u00e9s apr\u00e8s chaque fichier via <code>stat -c%s</code></li> <li>octets totaux - calcul\u00e9s une fois avant la boucle via <code>du -sb</code></li> <li>d\u00e9bit instantan\u00e9 - <code>octets_trait\u00e9s / secondes_\u00e9coul\u00e9es</code></li> </ul> <pre><code>ETA = (octets_restants) / d\u00e9bit_moyen\n    = (total - fait) / (fait / elapsed)</code></pre> <p>Le d\u00e9bit moyen converge apr\u00e8s ~10\u201320 secondes de traitement. Avant ce seuil, l'ETA est instable - comportement identique \u00e0 <code>rsync</code>, <code>cp --progress</code>, ou tout outil du m\u00eame type. Ce n'est pas un d\u00e9faut d'impl\u00e9mentation, c'est une contrainte statistique inh\u00e9rente \u00e0 toute estimation par extrapolation lin\u00e9aire sur fen\u00eatre courte.</p>"},{"location":"ancienne%20doc/progression-eta/#cout-du-changement-de-strategie","title":"Co\u00fbt du changement de strat\u00e9gie","text":"Pipeline <code>xargs</code> Boucle bash (avec progression) D\u00e9bit sur HDD Optimal Identique - I/O impose le rythme D\u00e9bit sur SSD s\u00e9quentiel Optimal Identique D\u00e9bit sur SSD <code>-P 4</code> +20\u201340 % Non applicable - boucle s\u00e9quentielle Progression temps r\u00e9el Non Oui ETA Non Oui <p>Cas o\u00f9 la boucle d\u00e9grade les performances : SSD avec <code>-P 4</code>. Le parall\u00e9lisme par <code>xargs</code> n'est pas reproductible en boucle bash sans complexit\u00e9 significative. Sur HDD - cas le plus courant pour de gros volumes - la diff\u00e9rence est nulle.</p>"},{"location":"ancienne%20doc/validation/","title":"Tests et validation - integrity.sh","text":"<p>Niveau d'exigence : production, admin syst\u00e8me. Chaque cas doit \u00eatre ex\u00e9cut\u00e9 et son r\u00e9sultat v\u00e9rifi\u00e9 explicitement.</p>"},{"location":"ancienne%20doc/validation/#environnement-de-test","title":"Environnement de test","text":"<pre><code># Cr\u00e9er un environnement de test isol\u00e9\nmkdir -p /tmp/integrity-test/{data,output}\ncd /tmp/integrity-test\n\n# Cr\u00e9er des fichiers de test avec contenu connu\necho \"contenu alpha\" &gt; data/alpha.txt\necho \"contenu beta\"  &gt; data/beta.txt\necho \"contenu gamma\" &gt; data/gamma.txt\nmkdir -p data/sub\necho \"contenu delta\" &gt; data/sub/delta.txt</code></pre>"},{"location":"ancienne%20doc/validation/#cas-de-test","title":"Cas de test","text":""},{"location":"ancienne%20doc/validation/#t01-compute-de-base","title":"T01 - Compute de base","text":"<pre><code>./integrity.sh compute ./data base_t01.b3</code></pre> <p>R\u00e9sultat attendu :</p> <ul> <li>Fichier <code>base_t01.b3</code> cr\u00e9\u00e9 avec 4 lignes (une par fichier).</li> <li>Message <code>Base enregistr\u00e9e : base_t01.b3 (4 fichiers)</code>.</li> <li>Chaque ligne au format <code>&lt;hash64chars&gt;  ./data/&lt;chemin&gt;</code>.</li> </ul> <pre><code># V\u00e9rification\nwc -l base_t01.b3           # \u2192 4\nhead -1 base_t01.b3         # \u2192 hash + chemin lisibles</code></pre>"},{"location":"ancienne%20doc/validation/#t02-verify-sans-modification","title":"T02 - Verify sans modification","text":"<pre><code>b3sum --check base_t01.b3</code></pre> <p>R\u00e9sultat attendu : 4 lignes <code>OK</code>, aucun <code>FAILED</code>, exit code 0.</p> <pre><code>echo $?   # \u2192 0</code></pre>"},{"location":"ancienne%20doc/validation/#t03-verify-apres-corruption-dun-fichier","title":"T03 - Verify apr\u00e8s corruption d'un fichier","text":"<pre><code>echo \"contenu modifi\u00e9\" &gt; data/beta.txt\nb3sum --check base_t01.b3</code></pre> <p>R\u00e9sultat attendu :</p> <ul> <li><code>./data/beta.txt: FAILED</code></li> <li><code>b3sum: WARNING: 1 computed checksum did NOT match</code></li> <li>Exit code non nul.</li> </ul> <pre><code>echo $?   # \u2192 1\nb3sum --check base_t01.b3 2&gt;&amp;1 | grep FAILED   # \u2192 ./data/beta.txt: FAILED</code></pre>"},{"location":"ancienne%20doc/validation/#t04-verify-apres-suppression-dun-fichier","title":"T04 - Verify apr\u00e8s suppression d'un fichier","text":"<pre><code># Restaurer l'\u00e9tat T01 d'abord\necho \"contenu beta\" &gt; data/beta.txt\n\n# Supprimer un fichier\nrm data/gamma.txt\nb3sum --check base_t01.b3</code></pre> <p>R\u00e9sultat attendu :</p> <ul> <li><code>./data/gamma.txt: FAILED</code> (No such file or directory)</li> <li>Exit code non nul.</li> </ul>"},{"location":"ancienne%20doc/validation/#t05-compare-aucune-difference","title":"T05 - Compare : aucune diff\u00e9rence","text":"<pre><code># Restaurer l'\u00e9tat T01\necho \"contenu gamma\" &gt; data/gamma.txt\n\n# Cr\u00e9er une seconde base identique\n./integrity.sh compute ./data base_t05.b3\n./integrity.sh compare base_t01.b3 base_t05.b3</code></pre> <p>R\u00e9sultat attendu : sections <code>MODIFI\u00c9S</code>, <code>DISPARUS</code>, <code>NOUVEAUX</code> toutes vides. Rapport sauvegard\u00e9.</p>"},{"location":"ancienne%20doc/validation/#t06-compare-fichier-modifie","title":"T06 - Compare : fichier modifi\u00e9","text":"<pre><code>echo \"contenu beta modifi\u00e9\" &gt; data/beta.txt\n./integrity.sh compute ./data base_t06.b3\n./integrity.sh compare base_t01.b3 base_t06.b3</code></pre> <p>R\u00e9sultat attendu :</p> <ul> <li>Section <code>FICHIERS MODIFI\u00c9S</code> contient <code>./data/beta.txt</code> avec ancien et nouveau hash.</li> <li>Sections <code>DISPARUS</code> et <code>NOUVEAUX</code> vides.</li> </ul>"},{"location":"ancienne%20doc/validation/#t07-compare-fichier-supprime-fichier-ajoute","title":"T07 - Compare : fichier supprim\u00e9 + fichier ajout\u00e9","text":"<pre><code># Repartir d'une base propre\necho \"contenu beta\" &gt; data/beta.txt\n./integrity.sh compute ./data base_t07_old.b3\n\n# Modifier l'\u00e9tat\nrm data/alpha.txt\necho \"contenu epsilon\" &gt; data/epsilon.txt\n./integrity.sh compute ./data base_t07_new.b3\n\n./integrity.sh compare base_t07_old.b3 base_t07_new.b3</code></pre> <p>R\u00e9sultat attendu :</p> <ul> <li><code>DISPARUS</code> : <code>./data/alpha.txt</code></li> <li><code>NOUVEAUX</code> : <code>./data/epsilon.txt</code></li> <li><code>MODIFI\u00c9S</code> : vide</li> </ul>"},{"location":"ancienne%20doc/validation/#t08-robustesse-fichier-avec-espace-dans-le-nom","title":"T08 - Robustesse : fichier avec espace dans le nom","text":"<pre><code>echo \"contenu avec espace\" &gt; \"data/fichier avec espace.txt\"\n./integrity.sh compute ./data base_t08.b3\nb3sum --check base_t08.b3</code></pre> <p>R\u00e9sultat attendu : tous les fichiers <code>OK</code>, y compris <code>fichier avec espace.txt</code>.</p>"},{"location":"ancienne%20doc/validation/#t09-robustesse-dossier-vide-limite-connue","title":"T09 - Robustesse : dossier vide (limite connue)","text":"<pre><code>mkdir data/dossier_vide\n./integrity.sh compute ./data base_t09.b3</code></pre> <p>R\u00e9sultat attendu : <code>dossier_vide</code> absent de <code>base_t09.b3</code>. Comportement normal et document\u00e9 - <code>find -type f</code> n'indexe pas les dossiers vides.</p>"},{"location":"ancienne%20doc/validation/#t10-chemin-absolu-vs-relatif-piege-critique","title":"T10 - Chemin absolu vs relatif (pi\u00e8ge critique)","text":"<pre><code># Calculer avec chemin absolu - mauvaise pratique\nb3sum $(find /tmp/integrity-test/data -type f) &gt; base_absolu.b3\nhead -1 base_absolu.b3   # \u2192 chemin absolu /tmp/integrity-test/data/...\n\n# Calculer avec chemin relatif - bonne pratique\ncd /tmp/integrity-test\nfind ./data -type f -print0 | sort -z | xargs -0 b3sum &gt; base_relatif.b3\nhead -1 base_relatif.b3  # \u2192 chemin relatif ./data/...</code></pre> <p>R\u00e9sultat attendu : les deux bases sont incompatibles entre elles. Confirme que les chemins absolus cassent la portabilit\u00e9.</p>"},{"location":"ancienne%20doc/validation/#nettoyage","title":"Nettoyage","text":"<pre><code>rm -rf /tmp/integrity-test</code></pre>"},{"location":"ancienne%20doc/validation/#criteres-de-qualite-globaux","title":"Crit\u00e8res de qualit\u00e9 globaux","text":"Crit\u00e8re Exigence D\u00e9tection corruption 100 % des fichiers modifi\u00e9s d\u00e9tect\u00e9s (T03) D\u00e9tection suppression 100 % des fichiers manquants d\u00e9tect\u00e9s (T04) Faux positifs Z\u00e9ro - verify sur base intacte = 100 % OK (T02) Noms avec espaces Trait\u00e9s sans erreur (T08) Rapport compare Sauvegard\u00e9 sur disque, horodat\u00e9 (T05\u2013T07) Exit code Non nul si au moins un FAILED (T03, T04) Mode strict <code>-euo pipefail</code> Le script s'arr\u00eate sur toute erreur non g\u00e9r\u00e9e"},{"location":"development/architecture/","title":"Architecture","text":"<p>D\u00e9cisions techniques, choix d'impl\u00e9mentation et rationale.</p>"},{"location":"development/architecture/#vue-densemble","title":"Vue d'ensemble","text":"<p>hash_tool est compos\u00e9 de trois couches :</p> <pre><code>runner.sh               \u2190 orchestration pipeline\n    \u2514\u2500\u2500 src/integrity.sh        \u2190 logique m\u00e9tier (compute / verify / compare)\n            \u2514\u2500\u2500 src/lib/report.sh   \u2190 g\u00e9n\u00e9ration des rapports HTML</code></pre> <p>Chaque couche a une responsabilit\u00e9 unique et des d\u00e9pendances strictement unidirectionnelles.</p>"},{"location":"development/architecture/#choix-algorithmique-blake3-vs-alternatives","title":"Choix algorithmique \u2014 BLAKE3 vs alternatives","text":""},{"location":"development/architecture/#pourquoi-blake3-et-non-xxhash3","title":"Pourquoi BLAKE3 et non xxHash3","text":"<p>xxHash3 est techniquement suffisant pour d\u00e9tecter des erreurs accidentelles \u2014 pas d'adversaire dans ce cas d'usage. BLAKE3 est retenu pour une seule raison : co\u00fbt marginal nul. Sur HDD (150 Mo/s) ou SATA SSD (500 Mo/s), le disque est syst\u00e9matiquement le goulot. BLAKE3 \u00e0 ~1 Go/s (1 c\u0153ur) ne sera jamais le facteur limitant. Le headroom cryptographique est gratuit.</p> <p>Si le besoin \u00e9volue vers un contexte avec adversaire (signature, authentification), BLAKE3 reste utilisable sans changer de workflow ni de format de base.</p>"},{"location":"development/architecture/#pourquoi-ne-pas-utiliser-sha-256-ou-sha-512","title":"Pourquoi ne pas utiliser SHA-256 ou SHA-512","text":"<ul> <li>BLAKE3 est ~3\u20135\u00d7 plus rapide que SHA-256 sur les m\u00eames donn\u00e9es</li> <li>Format de sortie <code>b3sum</code> identique \u00e0 <code>sha256sum</code> \u2014 interop\u00e9rabilit\u00e9 outil/format conserv\u00e9e</li> <li>Pas de d\u00e9pendance suppl\u00e9mentaire : <code>b3sum</code> est disponible dans Alpine, Debian, Ubuntu, Homebrew</li> </ul>"},{"location":"development/architecture/#format-du-fichier-b3","title":"Format du fichier <code>.b3</code>","text":"<p>Le format est directement celui produit par <code>b3sum</code> :</p> <pre><code>&lt;hash_64_chars&gt;  &lt;chemin&gt;</code></pre> <p>Deux espaces \u2014 convention <code>b3sum</code>/<code>sha256sum</code>. Ce choix d\u00e9lib\u00e9r\u00e9 permet :</p> <ul> <li>Interop\u00e9rabilit\u00e9 directe : <code>b3sum --check base.b3</code> fonctionne sans aucun post-traitement</li> <li>Lisibilit\u00e9 humaine : <code>grep</code>, <code>awk</code>, <code>sort</code> op\u00e8rent directement sur le fichier</li> <li>Z\u00e9ro format propri\u00e9taire : pas de serialisation, pas de parser d\u00e9di\u00e9</li> </ul> <p>L'offset fixe du hash (64 chars + 2 espaces = position 67) est exploit\u00e9 dans <code>run_compare()</code> pour parser les lignes sans ambigu\u00eft\u00e9 m\u00eame avec des chemins contenant des espaces :</p> <pre><code>awk '{ print substr($0,67) \"\\t\" substr($0,1,64) }' base.b3</code></pre>"},{"location":"development/architecture/#chemins-relatifs-decision-fondamentale","title":"Chemins relatifs \u2014 d\u00e9cision fondamentale","text":"<p>Les bases <code>.b3</code> stockent des chemins relatifs. C'est une contrainte non n\u00e9gociable :</p> <ul> <li>Un chemin absolu <code>/mnt/veracrypt1/photos/img.jpg</code> devient invalide si la partition est remont\u00e9e sur <code>/mnt/veracrypt2/</code> ou un point de montage diff\u00e9rent</li> <li>Un chemin relatif <code>./photos/img.jpg</code> reste valide quel que soit le point de montage, d\u00e8s lors qu'on lance <code>verify</code> depuis le bon r\u00e9pertoire de travail</li> </ul> <p><code>runner.sh</code> encapsule cette contrainte via <code>cd \"$source\"</code> + <code>integrity.sh compute . ...</code> \u2014 l'utilisateur n'a pas \u00e0 y penser.</p>"},{"location":"development/architecture/#gestion-du-repertoire-de-travail-dans-runnersh","title":"Gestion du r\u00e9pertoire de travail dans runner.sh","text":"<p>Chaque op\u00e9ration <code>compute</code> et <code>verify</code> est ex\u00e9cut\u00e9e dans un sous-shell :</p> <pre><code>( cd \"$source\" &amp;&amp; \"$INTEGRITY\" compute . \"$bases_abs/$nom\" )</code></pre> <p>Le <code>cd</code> est isol\u00e9 dans <code>( )</code> \u2014 il ne fuite pas vers les blocs suivants du pipeline. Sans cette isolation, un <code>cd</code> dans un bloc <code>compute</code> affecterait le r\u00e9pertoire de travail de tous les blocs suivants.</p> <p>De m\u00eame pour <code>RESULTATS_DIR</code> sur les blocs <code>compare</code> avec champ <code>resultats</code> :</p> <pre><code>RESULTATS_DIR=\"$resultats_abs\" \"$INTEGRITY\" compare \"$base_a\" \"$base_b\"</code></pre> <p><code>RESULTATS_DIR</code> est pass\u00e9 comme variable d'environnement pr\u00e9fix\u00e9e \u00e0 la commande \u2014 scope limit\u00e9 \u00e0 cet appel, sans <code>export</code>, sans modification du processus parent.</p>"},{"location":"development/architecture/#robustesse-aux-noms-de-fichiers-avec-espaces","title":"Robustesse aux noms de fichiers avec espaces","text":"<p>Trois points critiques :</p> <p>1. <code>find -print0</code> + <code>sort -z</code> + <code>mapfile -d ''</code></p> <pre><code>mapfile -d '' files &lt; &lt;(find \"$target\" -type f -print0 | sort -z)</code></pre> <p><code>find -print0</code> s\u00e9pare les chemins par des octets nuls (pas des newlines). <code>sort -z</code> trie sur le m\u00eame s\u00e9parateur. <code>mapfile -d ''</code> charge le tableau avec le m\u00eame s\u00e9parateur. Aucune confusion possible avec des espaces ou des newlines dans les noms.</p> <p>2. S\u00e9parateur tab dans <code>run_compare()</code></p> <p>Apr\u00e8s conversion <code>hash  chemin</code> \u2192 <code>chemin\\thash</code>, toutes les op\u00e9rations (<code>sort</code>, <code>join</code>, <code>comm</code>, <code>cut</code>) utilisent <code>-t $'\\t'</code>. Un chemin contenant des espaces ne fragmente pas les champs.</p> <p>3. <code>\"$@\"</code> et guillemets syst\u00e9matiques</p> <p>Tous les arguments sont propag\u00e9s entre guillemets doubles. <code>shellcheck</code> enforce ce point (T00 dans la suite de tests).</p>"},{"location":"development/architecture/#progression-eta-pourquoi-casser-le-pipeline-xargs","title":"Progression ETA \u2014 pourquoi casser le pipeline xargs","text":"<p>Le pipeline naturel <code>find | sort | xargs b3sum</code> est une bo\u00eete noire : <code>b3sum</code> ne remonte aucune progression.</p> <p>Intercaler <code>pv</code> est invalide : mesurer le d\u00e9bit sur le flux concat\u00e9n\u00e9 <code>cat | pv | b3sum</code> produit un hash unique du flux, pas une ligne par fichier \u2014 le <code>.b3</code> r\u00e9sultant est inutilisable pour <code>--check</code>.</p> <p>La boucle bash fichier par fichier est la seule approche compatible. Le co\u00fbt en performance est nul sur HDD (disque = goulot). Sur SSD NVMe avec <code>-P 4</code>, la parall\u00e9lisation <code>xargs</code> offrirait +20\u201340% \u2014 mais l'ETA est incompatible avec le parall\u00e9lisme sans complexit\u00e9 majeure.</p> <p>La progression est \u00e9crite sur <code>/dev/tty</code> directement :</p> <pre><code>printf \"\\r[%d/%d] ETA : %dm %02ds   \" ... &gt; /dev/tty</code></pre> <p><code>/dev/tty</code> est le terminal courant, ind\u00e9pendamment des redirections. Cela garantit que la progression n'est jamais captur\u00e9e dans le fichier <code>.b3</code> ni dans un pipe parent.</p>"},{"location":"development/architecture/#rapport-html-css-inline","title":"Rapport HTML \u2014 CSS inline","text":"<p><code>report.html</code> est autonome : tout le CSS est inline, aucune d\u00e9pendance externe. Raison : le rapport doit \u00eatre lisible hors ligne, sur un NAS sans acc\u00e8s internet, dans un gestionnaire de fichiers local. Un CDN externe (<code>fonts.googleapis.com</code>, etc.) serait inaccessible dans ces contextes.</p> <p>L'import Google Fonts dans le CSS est donc purement d\u00e9coratif \u2014 le fallback <code>system-ui, sans-serif</code> et <code>monospace</code> fonctionne parfaitement sans r\u00e9seau.</p>"},{"location":"development/architecture/#horodatage-anti-ecrasement","title":"Horodatage anti-\u00e9crasement","text":"<p><code>make_result_dir()</code> v\u00e9rifie l'existence du dossier cible et ajoute un suffixe <code>_YYYYMMDD-HHMMSS</code> en cas de collision :</p> <pre><code>if [ -d \"$outdir\" ]; then\n    outdir=\"${outdir}_$(date +%Y%m%d-%H%M%S)\"\nfi</code></pre> <p>Aucun r\u00e9sultat n'est jamais \u00e9cras\u00e9 silencieusement. Cette d\u00e9cision est volontairement conservative : conserver l'historique complet des v\u00e9rifications a plus de valeur que d'\u00e9conomiser de l'espace disque.</p>"},{"location":"development/architecture/#structure-src-vs-racine","title":"Structure src/ vs racine","text":"<p>La s\u00e9paration <code>src/integrity.sh</code> + <code>src/lib/report.sh</code> vs <code>runner.sh</code> \u00e0 la racine suit une convention explicite :</p> <ul> <li><code>runner.sh</code> \u00e0 la racine : point d'entr\u00e9e utilisateur, documentation visible, lancement direct</li> <li><code>src/</code> : code interne, pas destin\u00e9 \u00e0 \u00eatre appel\u00e9 directement par l'utilisateur dans le cas g\u00e9n\u00e9ral</li> <li><code>src/lib/</code> : modules internes, sourc\u00e9s par <code>integrity.sh</code>, pr\u00e9parent l'extension future (<code>notify.sh</code>, <code>export.sh</code>)</li> </ul>"},{"location":"development/architecture/#validation-json-dans-runnersh","title":"Validation JSON dans runner.sh","text":"<pre><code>jq empty \"$CONFIG\" 2&gt;/dev/null || { echo \"ERREUR : JSON invalide : $CONFIG\" &gt;&amp;2; exit 1; }</code></pre> <p><code>jq empty</code> parse le JSON sans produire de sortie \u2014 uniquement un exit code. L'erreur de <code>jq</code> est redirig\u00e9e vers <code>/dev/null</code> ; le message d'erreur est celui de <code>runner.sh</code>, pas une stacktrace <code>jq</code> brute. Ce pattern \u00e9vite d'exposer les d\u00e9tails internes de <code>jq</code> \u00e0 l'utilisateur.</p>"},{"location":"development/architecture/#dependances-externes-decisions","title":"D\u00e9pendances externes \u2014 d\u00e9cisions","text":"Outil Alternatif envisag\u00e9 Raison du choix <code>b3sum</code> <code>sha256sum</code>, <code>xxhash</code> BLAKE3, performance, format compatible <code>jq</code> parser bash custom Validation JSON native, robustesse, maintenabilit\u00e9 Alpine 3.19 (Docker) Ubuntu, Debian slim ~14 Mo vs ~80 Mo, <code>b3sum</code> disponible dans community <code>bash &gt;= 4</code> <code>sh</code>, <code>dash</code> <code>mapfile</code>, tableaux associatifs, <code>BASH_VERSINFO</code>"},{"location":"development/changelog/","title":"Changelog","text":"<p>Toutes les modifications notables de hash_tool sont document\u00e9es ici.</p> <p>Le format suit Keep a Changelog.</p>"},{"location":"development/changelog/#013-debug-dockerisation-et-documentation","title":"[0.13] \u2014 D\u00e9bug dockerisation et documentation","text":""},{"location":"development/changelog/#ajoute","title":"Ajout\u00e9","text":"<ul> <li><code>hash_tool-positionnement-open-source.docx</code> : positionnement du projet dans l'environnement open source, preuve de valeur.</li> <li><code>hash_tool-presentation.docx</code> : pr\u00e9sentation macro du projet.</li> </ul>"},{"location":"development/changelog/#modifie","title":"Modifi\u00e9","text":"<ul> <li><code>Dockerfile</code> : suppression du multi-stage et du t\u00e9l\u00e9chargement GitHub. <code>b3sum</code> install\u00e9 depuis les packages Alpine community \u2014 plus propre, pas de <code>wget</code>, pas de probl\u00e8me de nom de binaire. La version Alpine 3.19 est stable et maintenue.</li> </ul>"},{"location":"development/changelog/#012-dockerisation","title":"[0.12] \u2014 Dockerisation","text":""},{"location":"development/changelog/#ajoute_1","title":"Ajout\u00e9","text":"<ul> <li><code>Dockerfile</code> : image Alpine 3.19 avec <code>b3sum</code>, <code>jq</code>, <code>bash</code>, <code>coreutils</code>, <code>findutils</code>. Image finale ~14 Mo.</li> <li><code>docker/entrypoint.sh</code> : dispatcher des commandes (<code>compute</code>, <code>verify</code>, <code>compare</code>, <code>runner</code>, <code>shell</code>, <code>help</code>, <code>version</code>). Support <code>--quiet</code> en premier argument.</li> <li><code>docker-compose.yml</code> : services <code>integrity</code>, <code>pipeline</code>, <code>cron</code> (profil optionnel).</li> <li><code>.dockerignore</code> : exclusion des donn\u00e9es, r\u00e9sultats, tests et docs du contexte de build.</li> <li><code>docs/docker.md</code> : guide complet (build, volumes, NAS Synology, cron Debian, ARM64, Compose).</li> </ul>"},{"location":"development/changelog/#volumes-conventionnels","title":"Volumes conventionnels","text":"Volume conteneur Usage <code>/data</code> Donn\u00e9es \u00e0 hacher (<code>:ro</code> recommand\u00e9) <code>/bases</code> Fichiers <code>.b3</code> <code>/pipelines</code> Fichiers <code>pipeline.json</code> <code>/resultats</code> R\u00e9sultats compare/verify"},{"location":"development/changelog/#011-restructuration-rapport-html-compare","title":"[0.11] \u2014 Restructuration + rapport HTML compare","text":""},{"location":"development/changelog/#restructuration","title":"Restructuration","text":"<pre><code>hash_tool/\n\u251c\u2500\u2500 runner.sh\n\u251c\u2500\u2500 src/\n\u2502   \u251c\u2500\u2500 integrity.sh\n\u2502   \u2514\u2500\u2500 lib/\n\u2502       \u2514\u2500\u2500 report.sh          \u2190 nouveau, extrait de integrity.sh\n\u251c\u2500\u2500 pipelines/\n\u2502   \u251c\u2500\u2500 pipeline.json\n\u2502   \u2514\u2500\u2500 pipeline-full.json\n\u2514\u2500\u2500 reports/\n    \u2514\u2500\u2500 template.html</code></pre>"},{"location":"development/changelog/#ajoute_2","title":"Ajout\u00e9","text":"<ul> <li><code>src/lib/report.sh</code> : g\u00e9n\u00e9ration HTML autonome (CSS inline). Th\u00e8me sombre, police monospace, compteurs, badge statut.</li> <li><code>reports/template.html</code> : barebone de r\u00e9f\u00e9rence documentant les placeholders.</li> <li>Champ optionnel <code>\"resultats\"</code> sur les blocs <code>compare</code> du pipeline.</li> <li>Test TP10b : champ <code>resultats</code> personnalis\u00e9 et isolation de <code>RESULTATS_DIR</code>.</li> </ul>"},{"location":"development/changelog/#modifie_1","title":"Modifi\u00e9","text":"<ul> <li><code>runner.sh</code> : chemin <code>INTEGRITY</code> et <code>CONFIG</code> mis \u00e0 jour. Isolation des <code>cd</code> en sous-shells. Lecture du champ <code>resultats</code> optionnel.</li> <li><code>src/integrity.sh</code> : d\u00e9l\u00e8gue la g\u00e9n\u00e9ration HTML \u00e0 <code>lib/report.sh</code>.</li> </ul>"},{"location":"development/changelog/#010-pipeline-json-tests-pipeline","title":"[0.10] \u2014 Pipeline JSON + tests pipeline","text":""},{"location":"development/changelog/#modifie_2","title":"Modifi\u00e9","text":"<ul> <li><code>pipeline.json</code> : migration de la syntaxe custom vers JSON standard. Champ <code>op</code> remplace les noms de blocs. Pars\u00e9 par <code>jq</code>.</li> <li><code>runner.sh</code> : suppression du parser bash custom. Remplacement par <code>jq</code>. Validation JSON en entr\u00e9e. Messages d'erreur avec num\u00e9ro de bloc.</li> </ul>"},{"location":"development/changelog/#ajoute_3","title":"Ajout\u00e9","text":"<ul> <li><code>tests/run_tests_pipeline.sh</code> : 12 cas TP01\u2013TP12.</li> </ul>"},{"location":"development/changelog/#09-pipeline-batch-runnersh-configtxt","title":"[0.9] \u2014 Pipeline batch : runner.sh + config.txt","text":""},{"location":"development/changelog/#ajoute_4","title":"Ajout\u00e9","text":"<ul> <li><code>runner.sh</code> : ex\u00e9cuteur de pipeline batch. Gestion automatique du <code>cd</code> avant <code>compute</code> et <code>verify</code>.</li> <li><code>config.txt</code> : format structur\u00e9 <code>pipeline = { ... }</code> (remplac\u00e9 par JSON en 0.10).</li> <li><code>runner.bat</code> : lanceur Windows pour double-clic.</li> </ul>"},{"location":"development/changelog/#08-batch_computesh","title":"[0.8] \u2014 batch_compute.sh","text":""},{"location":"development/changelog/#ajoute_5","title":"Ajout\u00e9","text":"<ul> <li><code>batch_compute.sh</code> : lancer plusieurs <code>compute</code> en un script. Remplac\u00e9 par <code>runner.sh</code> en 0.9.</li> </ul>"},{"location":"development/changelog/#07-robustesse-compare-chemins-avec-espaces","title":"[0.7] \u2014 Robustesse compare : chemins avec espaces","text":""},{"location":"development/changelog/#corrige","title":"Corrig\u00e9","text":"<ul> <li><code>run_compare()</code> : bug critique \u2014 <code>sort -k2,2</code>, <code>join</code>, <code>awk</code> fragmentaient les chemins avec espaces. Correction par conversion pr\u00e9alable en <code>chemin\\thash</code> via <code>awk</code> avec offset fixe (hash = 64 chars). S\u00e9parateur <code>$'\\t'</code> explicite sur toutes les op\u00e9rations.</li> </ul>"},{"location":"development/changelog/#06-robustesse-et-mode-silencieux","title":"[0.6] \u2014 Robustesse et mode silencieux","text":""},{"location":"development/changelog/#ajoute_6","title":"Ajout\u00e9","text":"<ul> <li>Flag <code>--quiet</code> : supprime toute sortie terminal, exit code propag\u00e9.</li> <li><code>say()</code> : point d'entr\u00e9e unique pour la sortie terminal.</li> <li><code>file_size()</code> : abstraction portable <code>stat -c%s</code> / <code>stat -f%z</code>.</li> <li>V\u00e9rification <code>bash &gt;= 4</code> en t\u00eate de script.</li> <li><code>make_result_dir()</code> : horodatage automatique en cas de collision.</li> <li><code>trap EXIT</code> dans <code>run_compare()</code> : nettoyage garanti des fichiers temporaires.</li> <li>T12 : couverture <code>--quiet</code>. T13 : horodatage. T14 : argument invalide.</li> </ul>"},{"location":"development/changelog/#corrige_1","title":"Corrig\u00e9","text":"<ul> <li><code>grep -c '.'</code> \u2192 <code>grep -c '^'</code> pour le comptage de lignes sur flux vide.</li> <li><code>sort -k2</code> \u2192 <code>sort -k2,2</code> pour limiter la cl\u00e9 de tri au seul champ chemin.</li> <li><code>find | wc -l</code> \u2192 <code>find -print0 | grep -zc ''</code> pour les noms avec newlines.</li> <li><code>stat -c%s</code> \u2192 <code>file_size()</code> pour la portabilit\u00e9 BSD/macOS.</li> </ul>"},{"location":"development/changelog/#05-documentation","title":"[0.5] \u2014 Documentation","text":""},{"location":"development/changelog/#modifie_3","title":"Modifi\u00e9","text":"<ul> <li><code>README.md</code> et <code>docs/manuel.md</code> : r\u00e8gle r\u00e9pertoire de travail pour <code>verify</code> pr\u00e9cis\u00e9e avec exemples correct/incorrect.</li> </ul>"},{"location":"development/changelog/#04-gardes-fous-et-signalisation-des-erreurs","title":"[0.4] \u2014 Gardes-fous et signalisation des erreurs","text":""},{"location":"development/changelog/#modifie_4","title":"Modifi\u00e9","text":"<ul> <li>Ajout <code>die()</code>, <code>assert_b3_valid()</code>, <code>assert_target_valid()</code>.</li> <li><code>verify</code> accepte <code>[dossier]</code> optionnel.</li> <li>R\u00e9solution chemin absolu du <code>.b3</code> avant <code>cd</code>.</li> <li><code>RESULTATS_DIR</code> : <code>${RESULTATS_DIR:-...}</code> au lieu d'assignation inconditionnelle.</li> <li><code>run_verify()</code> : trois \u00e9tats (<code>OK</code>, <code>ECHEC</code>, <code>ERREUR</code>), <code>failed.txt</code> supprim\u00e9 si z\u00e9ro \u00e9chec.</li> </ul>"},{"location":"development/changelog/#03-dossiers-de-resultats","title":"[0.3] \u2014 Dossiers de r\u00e9sultats","text":""},{"location":"development/changelog/#modifie_5","title":"Modifi\u00e9","text":"<ul> <li>Ajout <code>RESULTATS_DIR</code> et <code>make_result_dir()</code>.</li> <li><code>verify</code> produit <code>recap.txt</code> et <code>failed.txt</code>.</li> <li><code>compare</code> produit <code>recap.txt</code>, <code>modifies.b3</code>, <code>disparus.txt</code>, <code>nouveaux.txt</code>.</li> <li>Fichiers temporaires <code>compare</code> via <code>mktemp</code>.</li> </ul>"},{"location":"development/changelog/#02-integration-eta-et-tests-automatises","title":"[0.2] \u2014 Int\u00e9gration ETA et tests automatis\u00e9s","text":""},{"location":"development/changelog/#modifie_6","title":"Modifi\u00e9","text":"<ul> <li>Mode <code>compute</code> : d\u00e9l\u00e8gue \u00e0 <code>compute_with_progress()</code>.</li> <li><code>mapfile -d ''</code> remplace <code>FILES=($(find ...))</code> \u2014 gestion correcte des espaces.</li> <li>Progression sur <code>/dev/tty</code> \u2014 jamais dans le <code>.b3</code>.</li> <li>T11 : base ETA bit-\u00e0-bit identique \u00e0 la r\u00e9f\u00e9rence.</li> </ul>"},{"location":"development/changelog/#01-structure-initiale","title":"[0.1] \u2014 Structure initiale","text":""},{"location":"development/changelog/#ajoute_7","title":"Ajout\u00e9","text":"<ul> <li><code>integrity.sh</code> : trois modes <code>compute</code>, <code>verify</code>, <code>compare</code>. <code>set -euo pipefail</code>.</li> <li><code>README.md</code>, <code>docs/manuel.md</code>, <code>docs/progression-eta.md</code>.</li> <li><code>tests/run_tests.sh</code> : 11 cas T01\u2013T11.</li> <li><code>tests/validation.md</code> : protocole de test manuel.</li> </ul>"},{"location":"development/contributing/","title":"Contribuer &amp; Tests","text":""},{"location":"development/contributing/#environnement-de-developpement","title":"Environnement de d\u00e9veloppement","text":""},{"location":"development/contributing/#prerequis","title":"Pr\u00e9requis","text":"<pre><code># Debian / Ubuntu\nsudo apt install bash b3sum jq shellcheck\n\n# macOS\nbrew install bash b3sum jq shellcheck</code></pre> <p><code>shellcheck</code> est optionnel mais recommand\u00e9 \u2014 le test T00 le lance sur tous les scripts.</p>"},{"location":"development/contributing/#structure-des-tests","title":"Structure des tests","text":"<pre><code>tests/\n\u251c\u2500\u2500 run_tests.sh            \u2190 integrity.sh \u2014 15 cas T00\u2013T14\n\u2514\u2500\u2500 run_tests_pipeline.sh   \u2190 runner.sh + pipeline.json \u2014 13 cas TP01\u2013TP12</code></pre> <p>Chaque suite est ind\u00e9pendante, s'isole via <code>mktemp</code>, et retourne un exit code CI-compatible.</p>"},{"location":"development/contributing/#lancer-les-tests","title":"Lancer les tests","text":"<pre><code># Tests integrity.sh\ncd tests &amp;&amp; ./run_tests.sh\n\n# Tests runner.sh + pipeline.json\ncd tests &amp;&amp; ./run_tests_pipeline.sh\n\n# Les deux\ncd tests &amp;&amp; ./run_tests.sh &amp;&amp; ./run_tests_pipeline.sh</code></pre> <p>Sortie attendue (tous passants) :</p> <pre><code>\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\n  15/15 tests pass\u00e9s\n\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501</code></pre>"},{"location":"development/contributing/#couverture-run_testssh-t00t14","title":"Couverture \u2014 run_tests.sh (T00\u2013T14)","text":"Cas Description T00 ShellCheck sur <code>integrity.sh</code> et <code>run_tests.sh</code> T01 Compute de base \u2014 format et comptage lignes T02 Verify sans modification \u2014 OK, <code>failed.txt</code> absent T03 Verify apr\u00e8s corruption \u2014 ECHEC, <code>failed.txt</code> pr\u00e9sent T04 Verify apr\u00e8s suppression de fichier T05 Compare sans diff\u00e9rence \u2014 fichiers de r\u00e9sultats produits, tous vides T06 Compare avec fichier modifi\u00e9 \u2014 <code>modifies.b3</code> et <code>report.html</code> T07 Compare avec suppression + ajout \u2014 <code>disparus.txt</code> et <code>nouveaux.txt</code> T08 Robustesse \u2014 fichier avec espace dans le nom T09 Limite \u2014 dossier vide ignor\u00e9 par <code>find -type f</code> T10 Chemin absolu vs relatif \u2014 bases non interchangeables T11 Int\u00e9grit\u00e9 base ETA \u2014 bit-\u00e0-bit identique \u00e0 <code>xargs b3sum</code>, sans artefact <code>\\r</code> T12 Mode <code>--quiet</code> \u2014 stdout vide, fichiers produits, exit code propag\u00e9 T13 Horodatage anti-\u00e9crasement \u2014 deux dossiers distincts sur deux appels successifs T14 Argument invalide pour <code>verify</code> \u2014 message ERREUR explicite"},{"location":"development/contributing/#couverture-run_tests_pipelinesh-tp01tp12","title":"Couverture \u2014 run_tests_pipeline.sh (TP01\u2013TP12)","text":"Cas Description TP01 JSON invalide \u2014 message ERREUR sans stacktrace <code>jq</code> TP02 Cl\u00e9 <code>.pipeline</code> absente TP03 Champ <code>nom</code> manquant dans un bloc <code>compute</code> TP04 Op\u00e9ration inconnue TP05 Compute \u2014 <code>cd</code> correct, chemins relatifs dans la base, comptage fichiers TP06 Compute \u2014 dossier <code>source</code> absent TP07 Verify \u2014 bon r\u00e9pertoire de travail, v\u00e9rification OK, <code>recap.txt</code> produit TP08 Verify \u2014 corruption d\u00e9tect\u00e9e TP09 Verify \u2014 base <code>.b3</code> absente TP10 Compare \u2014 cinq fichiers de r\u00e9sultats produits TP10b Compare \u2014 champ <code>resultats</code> personnalis\u00e9, <code>RESULTATS_DIR</code> global non pollu\u00e9 TP11 Compare \u2014 <code>base_a</code> absente TP12 Pipeline complet : <code>compute \u00d7 2</code> + <code>verify</code> + <code>compare</code>"},{"location":"development/contributing/#ecrire-un-nouveau-test","title":"\u00c9crire un nouveau test","text":""},{"location":"development/contributing/#anatomie-dun-cas-dans-run_testssh","title":"Anatomie d'un cas dans run_tests.sh","text":"<pre><code>echo \"T15 \u2014 Description du cas\"\n# Setup sp\u00e9cifique au cas\nlocal out\nout=$(bash \"$INTEGRITY\" &lt;commande&gt; 2&gt;&amp;1 || true)   # || true : ne pas arr\u00eater sur exit non-nul\nassert_contains     \"label\"          \"pattern\"   \"$out\"\nassert_not_contains \"label n\u00e9gatif\"  \"absent\"    \"$out\"\nassert_file_exists  \"fichier cr\u00e9\u00e9\"   \"$OUTDIR/fichier.txt\"\necho \"\"</code></pre>"},{"location":"development/contributing/#regles","title":"R\u00e8gles","text":"<ul> <li>Toujours capturer la sortie avec <code>local out; out=$(... 2&gt;&amp;1 || true)</code> avant d'inspecter</li> <li><code>|| true</code> est obligatoire pour les commandes qui peuvent retourner un exit code non-nul sans que ce soit une erreur de test</li> <li>Nettoyer les effets de bord en fin de cas (restaurer les fichiers modifi\u00e9s, supprimer les fichiers cr\u00e9\u00e9s)</li> <li>Utiliser <code>WORKDIR</code> pour tous les chemins \u2014 jamais de chemins absolus en dur</li> </ul>"},{"location":"development/contributing/#helpers-disponibles","title":"Helpers disponibles","text":"<pre><code>pass \"label\"                           # incr\u00e9mente PASS, affiche vert\nfail \"label\"                           # incr\u00e9mente FAIL, affiche rouge\n\nassert_exit_zero    \"label\" cmd args   # v\u00e9rifie exit code 0\nassert_exit_nonzero \"label\" cmd args   # v\u00e9rifie exit code non-nul\nassert_contains     \"label\" \"pattern\" \"$output\"\nassert_not_contains \"label\" \"pattern\" \"$output\"\nassert_line_count   \"label\" N  \"$file\"\nassert_file_exists  \"label\" \"$file\"\nassert_file_absent  \"label\" \"$file\"</code></pre>"},{"location":"development/contributing/#conventions-de-code","title":"Conventions de code","text":""},{"location":"development/contributing/#bash","title":"Bash","text":"<ul> <li><code>set -euo pipefail</code> en t\u00eate de chaque script</li> <li><code>(( BASH_VERSINFO[0] &gt;= 4 ))</code> v\u00e9rifi\u00e9 \u00e0 l'entr\u00e9e</li> <li>Guillemets doubles syst\u00e9matiques sur toutes les variables (<code>\"$var\"</code>, <code>\"$@\"</code>)</li> <li><code>local</code> pour toutes les variables de fonctions</li> <li><code>die()</code> comme unique point de sortie sur erreur \u2014 message sur stderr</li> <li><code>say()</code> comme unique point de sortie terminal \u2014 d\u00e9sactiv\u00e9 en mode <code>--quiet</code></li> </ul>"},{"location":"development/contributing/#nommage","title":"Nommage","text":"<ul> <li>Fonctions : <code>snake_case</code></li> <li>Variables locales : <code>snake_case</code></li> <li>Constantes globales : <code>UPPER_SNAKE_CASE</code></li> <li>Fichiers : <code>kebab-case.sh</code> ou <code>snake_case.sh</code> (existant)</li> </ul>"},{"location":"development/contributing/#shellcheck","title":"ShellCheck","text":"<p>Z\u00e9ro warning ShellCheck requis. Lancer avant tout commit :</p> <pre><code>shellcheck src/integrity.sh runner.sh src/lib/report.sh docker/entrypoint.sh</code></pre>"},{"location":"development/contributing/#ajouter-un-nouveau-mode-a-integritysh","title":"Ajouter un nouveau mode \u00e0 integrity.sh","text":"<ol> <li>Ajouter le cas dans le <code>case \"$MODE\" in</code> de <code>src/integrity.sh</code></li> <li>\u00c9crire la fonction <code>run_&lt;mode&gt;()</code> dans <code>src/integrity.sh</code></li> <li>Mettre \u00e0 jour le <code>case \"$CMD\" in</code> de <code>docker/entrypoint.sh</code></li> <li>Ajouter les blocs dans <code>runner.sh</code> si le mode est orchestrable</li> <li>\u00c9crire les tests dans <code>run_tests.sh</code> et/ou <code>run_tests_pipeline.sh</code></li> <li>Mettre \u00e0 jour la documentation : <code>docs/reference/integrity-sh.md</code>, <code>README.md</code></li> </ol>"},{"location":"development/contributing/#ajouter-un-module-a-srclib","title":"Ajouter un module \u00e0 src/lib/","text":"<ol> <li>Cr\u00e9er <code>src/lib/&lt;module&gt;.sh</code> avec <code>#!/usr/bin/env bash</code> et un commentaire d'en-t\u00eate</li> <li>Le sourcer dans <code>src/integrity.sh</code> :    <pre><code>source \"$SCRIPT_DIR/lib/&lt;module&gt;.sh\"</code></pre></li> <li>L'ajouter dans le <code>Dockerfile</code> :    <pre><code>COPY src/lib/&lt;module&gt;.sh  ./src/lib/&lt;module&gt;.sh\nRUN chmod +x src/lib/&lt;module&gt;.sh</code></pre></li> </ol>"},{"location":"development/contributing/#processus-de-release","title":"Processus de release","text":"<ol> <li>Mettre \u00e0 jour <code>CHANGELOG.md</code> avec la nouvelle version et les changements</li> <li>V\u00e9rifier que tous les tests passent</li> <li>V\u00e9rifier ShellCheck sur tous les scripts</li> <li>Tagger le commit : <code>git tag v0.14</code></li> <li>Rebuilder l'image Docker : <code>docker build -t hash_tool:v0.14 -t hash_tool:latest .</code></li> </ol>"},{"location":"guides/cron-ci/","title":"Guide \u2014 CI / Cron","text":"<p>Int\u00e9gration de hash_tool dans des pipelines automatis\u00e9s : cron Linux, CI/CD, hooks Git.</p>"},{"location":"guides/cron-ci/#mode-quiet","title":"Mode <code>--quiet</code>","text":"<p>Toutes les commandes acceptent <code>--quiet</code> en premier argument. Ce flag :</p> <ul> <li>Supprime toute sortie terminal (stdout et stderr de <code>integrity.sh</code>)</li> <li>Conserve l'exit code : <code>0</code> = OK, <code>1</code> = ECHEC ou ERREUR</li> <li>Continue d'\u00e9crire les fichiers de r\u00e9sultats (<code>recap.txt</code>, <code>failed.txt</code>, <code>report.html</code>)</li> </ul> <p>C'est le mode \u00e0 utiliser syst\u00e9matiquement en automatisation \u2014 le script parent ou le syst\u00e8me de notification g\u00e8re la sortie.</p> <pre><code>./src/integrity.sh --quiet verify hashes.b3\necho \"Exit code : $?\"</code></pre>"},{"location":"guides/cron-ci/#cron-linux","title":"Cron Linux","text":""},{"location":"guides/cron-ci/#verification-nocturne-simple","title":"V\u00e9rification nocturne simple","text":"<pre><code># /etc/cron.d/hash-integrity\n# V\u00e9rification \u00e0 03h00 chaque nuit\n0 3 * * * user /opt/hash_tool/src/integrity.sh --quiet verify \\\n    /opt/bases/hashes.b3 /srv/data \\\n    &gt;&gt; /var/log/hash-integrity.log 2&gt;&amp;1 \\\n    || echo \"$(date) \u2014 ALERTE int\u00e9grit\u00e9\" | mail -s \"Alerte $(hostname)\" admin@example.com</code></pre>"},{"location":"guides/cron-ci/#avec-pipeline-complet","title":"Avec pipeline complet","text":"<pre><code># Recalcul hebdomadaire + comparaison (dimanche 02h00)\n0 2 * * 0 user /opt/hash_tool/runner.sh /opt/hash_tool/pipelines/pipeline-weekly.json \\\n    &gt;&gt; /var/log/hash-integrity-weekly.log 2&gt;&amp;1 \\\n    || mail -s \"ECHEC pipeline int\u00e9grit\u00e9 $(hostname)\" admin@example.com</code></pre>"},{"location":"guides/cron-ci/#rotation-des-logs","title":"Rotation des logs","text":"<pre><code># /etc/logrotate.d/hash-integrity\n/var/log/hash-integrity.log {\n    weekly\n    rotate 52\n    compress\n    missingok\n    notifempty\n}</code></pre>"},{"location":"guides/cron-ci/#cron-via-docker","title":"Cron via Docker","text":"<pre><code>0 3 * * * root \\\n    docker run --rm \\\n      -v /srv/data:/data:ro \\\n      -v /srv/bases:/bases:ro \\\n      -v /srv/resultats:/resultats \\\n      hash_tool --quiet verify /bases/hashes.b3 /data \\\n    &gt;&gt; /var/log/hash-integrity.log 2&gt;&amp;1 \\\n    || mail -s \"ALERTE int\u00e9grit\u00e9 $(hostname)\" admin@example.com</code></pre>"},{"location":"guides/cron-ci/#integration-cicd","title":"Int\u00e9gration CI/CD","text":""},{"location":"guides/cron-ci/#github-actions","title":"GitHub Actions","text":"<pre><code># .github/workflows/integrity-check.yml\nname: V\u00e9rification int\u00e9grit\u00e9\n\non:\n  schedule:\n    - cron: '0 3 * * *'   # 03h00 UTC chaque nuit\n  workflow_dispatch:        # d\u00e9clenchement manuel possible\n\njobs:\n  verify:\n    runs-on: ubuntu-latest\n\n    steps:\n      - name: Checkout\n        uses: actions/checkout@v4\n\n      - name: Installer b3sum\n        run: sudo apt-get install -y b3sum\n\n      - name: V\u00e9rifier l'int\u00e9grit\u00e9\n        run: |\n          ./src/integrity.sh --quiet verify bases/hashes.b3\n        env:\n          RESULTATS_DIR: /tmp/integrity-results\n\n      - name: Uploader les r\u00e9sultats\n        if: always()\n        uses: actions/upload-artifact@v4\n        with:\n          name: integrity-results\n          path: /tmp/integrity-results/\n          retention-days: 30</code></pre>"},{"location":"guides/cron-ci/#gitlab-ci","title":"GitLab CI","text":"<pre><code># .gitlab-ci.yml\nintegrity-verify:\n  stage: verify\n  image: alpine:3.19\n  before_script:\n    - apk add --no-cache bash b3sum\n  script:\n    - ./src/integrity.sh --quiet verify bases/hashes.b3\n  artifacts:\n    when: always\n    paths:\n      - integrity-results/\n    expire_in: 30 days\n  variables:\n    RESULTATS_DIR: integrity-results\n  rules:\n    - if: $CI_PIPELINE_SOURCE == \"schedule\"</code></pre>"},{"location":"guides/cron-ci/#hook-git-pre-commit","title":"Hook Git pre-commit","text":"<p>V\u00e9rifier l'int\u00e9grit\u00e9 d'un dossier avant chaque commit :</p> <pre><code>#!/usr/bin/env bash\n# .git/hooks/pre-commit\nset -euo pipefail\n\nBASES_DIR=\"$(git rev-parse --show-toplevel)/bases\"\nDATA_DIR=\"$(git rev-parse --show-toplevel)/data\"\n\nif [ -f \"$BASES_DIR/hashes.b3\" ]; then\n    echo \"V\u00e9rification int\u00e9grit\u00e9...\"\n    ./src/integrity.sh --quiet verify \"$BASES_DIR/hashes.b3\" \"$DATA_DIR\" || {\n        echo \"ERREUR : corruption d\u00e9tect\u00e9e. Commit annul\u00e9.\"\n        echo \"Consulter : $BASES_DIR/resultats/\"\n        exit 1\n    }\n    echo \"Int\u00e9grit\u00e9 OK.\"\nfi</code></pre> <pre><code>chmod +x .git/hooks/pre-commit</code></pre>"},{"location":"guides/cron-ci/#patterns-de-notification","title":"Patterns de notification","text":""},{"location":"guides/cron-ci/#email-via-mail","title":"Email via <code>mail</code>","text":"<pre><code>./src/integrity.sh --quiet verify hashes.b3 || \\\n    mail -s \"ALERTE int\u00e9grit\u00e9 $(hostname)\" admin@example.com &lt; \\\n    \"$(ls -d ~/integrity_resultats/resultats_hashes* | tail -1)/recap.txt\"</code></pre>"},{"location":"guides/cron-ci/#slack-webhook","title":"Slack webhook","text":"<pre><code>#!/usr/bin/env bash\nWEBHOOK_URL=\"https://hooks.slack.com/services/...\"\n\n./src/integrity.sh --quiet verify hashes.b3\nEXIT=$?\n\nif [ $EXIT -ne 0 ]; then\n    RECAP=$(cat \"$(ls -d ~/integrity_resultats/resultats_hashes* | tail -1)/recap.txt\")\n    curl -s -X POST \"$WEBHOOK_URL\" \\\n        -H 'Content-type: application/json' \\\n        --data \"{\\\"text\\\":\\\"\ud83d\udea8 *Alerte int\u00e9grit\u00e9* sur \\`$(hostname)\\`\\n\\`\\`\\`${RECAP}\\`\\`\\`\\\"}\"\nfi\n\nexit $EXIT</code></pre>"},{"location":"guides/cron-ci/#fichier-de-statut-pour-monitoring","title":"Fichier de statut pour monitoring","text":"<pre><code>#!/usr/bin/env bash\nSTATUS_FILE=/var/lib/hash-integrity/last-status\n\n./src/integrity.sh --quiet verify hashes.b3\nEXIT=$?\n\nmkdir -p \"$(dirname \"$STATUS_FILE\")\"\n{\n    echo \"date=$(date -Iseconds)\"\n    echo \"status=$([ $EXIT -eq 0 ] &amp;&amp; echo OK || echo FAILED)\"\n    echo \"exit_code=$EXIT\"\n} &gt; \"$STATUS_FILE\"\n\nexit $EXIT</code></pre> <p>Le fichier <code>last-status</code> peut \u00eatre lu par Zabbix, Nagios, Prometheus node_exporter (textfile collector), etc.</p>"},{"location":"guides/cron-ci/#gestion-des-resultats-en-ci","title":"Gestion des r\u00e9sultats en CI","text":"<p>Les r\u00e9sultats (<code>recap.txt</code>, <code>failed.txt</code>, <code>report.html</code>) s'accumulent dans <code>RESULTATS_DIR</code>. En CI, pointer vers un dossier temporaire :</p> <pre><code>export RESULTATS_DIR=/tmp/integrity-$(date +%Y%m%d-%H%M%S)\n./src/integrity.sh verify hashes.b3\n# Uploader $RESULTATS_DIR comme artefact CI</code></pre> <p>Ou utiliser le champ <code>resultats</code> dans <code>pipeline.json</code> pour un chemin explicite par run.</p>"},{"location":"guides/cron-ci/#recuperer-le-resume-en-script","title":"R\u00e9cup\u00e9rer le r\u00e9sum\u00e9 en script","text":"<pre><code># V\u00e9rifier et r\u00e9cup\u00e9rer le recap\n./src/integrity.sh --quiet verify hashes.b3\nEXIT=$?\n\nOUTDIR=$(ls -d \"${RESULTATS_DIR:-$HOME/integrity_resultats}/resultats_hashes\"* 2&gt;/dev/null | tail -1)\n\nif [ $EXIT -ne 0 ] &amp;&amp; [ -f \"$OUTDIR/failed.txt\" ]; then\n    NB_FAILED=$(grep -c ': FAILED' \"$OUTDIR/failed.txt\" || echo 0)\n    echo \"ECHEC : $NB_FAILED fichier(s) corrompu(s)\"\n    cat \"$OUTDIR/failed.txt\"\nfi\n\nexit $EXIT</code></pre>"},{"location":"guides/nas-synology/","title":"Guide \u2014 NAS Synology","text":"<p>D\u00e9ploiement et usage de hash_tool sur NAS Synology avec Docker.</p>"},{"location":"guides/nas-synology/#prerequis","title":"Pr\u00e9requis","text":"<ul> <li>DSM 7.x</li> <li>Container Manager (anciennement Docker Manager) install\u00e9 depuis le Centre de paquets</li> <li>Acc\u00e8s SSH au NAS (<code>ssh admin@192.168.1.x</code>)</li> </ul>"},{"location":"guides/nas-synology/#determiner-larchitecture","title":"D\u00e9terminer l'architecture","text":"<pre><code># Via SSH\nuname -m\n# amd64 \u2192 DS920+, DS923+, DS1621+, ...\n# aarch64 (arm64) \u2192 DS220+, DS420+, DS720+, DS923+ avec CPU AMD</code></pre> Mod\u00e8le (exemples) Architecture DS920+, DS1621+, RS1221+ amd64 DS220+, DS420+, DS720+ arm64 (aarch64) DS923+ amd64 (Ryzen R1600)"},{"location":"guides/nas-synology/#installation","title":"Installation","text":""},{"location":"guides/nas-synology/#via-ssh","title":"Via SSH","text":"<pre><code># Se connecter au NAS\nssh admin@192.168.1.x\n\n# Cloner ou copier hash_tool\ncd /volume1/docker\ngit clone https://github.com/hash_tool/hash_tool.git\ncd hash_tool\n\n# Build de l'image (adapter la plateforme)\n# amd64\ndocker build -t hash_tool .\n\n# arm64 (DS220+, DS420+...)\ndocker build --platform linux/arm64 -t hash_tool:arm64 .</code></pre>"},{"location":"guides/nas-synology/#verifier-limage","title":"V\u00e9rifier l'image","text":"<pre><code>docker run --rm hash_tool version\n# hash_tool\n#   b3sum : b3sum 1.x.x\n#   jq    : jq-1.x\n#   bash  : 5.x.x</code></pre>"},{"location":"guides/nas-synology/#structure-recommandee-sur-le-nas","title":"Structure recommand\u00e9e sur le NAS","text":"<pre><code>/volume1/\n\u251c\u2500\u2500 docker/\n\u2502   \u2514\u2500\u2500 hash_tool/          \u2190 scripts et Dockerfile\n\u251c\u2500\u2500 data/                   \u2190 donn\u00e9es \u00e0 surveiller (ou sous-dossiers par partage)\n\u2502   \u251c\u2500\u2500 photos/\n\u2502   \u251c\u2500\u2500 documents/\n\u2502   \u2514\u2500\u2500 backups/\n\u251c\u2500\u2500 bases/                  \u2190 fichiers .b3 (s\u00e9par\u00e9s des donn\u00e9es)\n\u2502   \u251c\u2500\u2500 hashes_photos.b3\n\u2502   \u251c\u2500\u2500 hashes_documents.b3\n\u2502   \u2514\u2500\u2500 hashes_backups.b3\n\u2514\u2500\u2500 rapports/               \u2190 r\u00e9sultats verify/compare\n    \u2514\u2500\u2500 ...</code></pre>"},{"location":"guides/nas-synology/#utilisation-via-ssh","title":"Utilisation via SSH","text":""},{"location":"guides/nas-synology/#compute","title":"Compute","text":"<pre><code>docker run --rm \\\n  -v /volume1/data/photos:/data:ro \\\n  -v /volume1/bases:/bases \\\n  hash_tool compute /data /bases/hashes_photos_$(date +%Y-%m-%d).b3</code></pre>"},{"location":"guides/nas-synology/#verify","title":"Verify","text":"<pre><code>docker run --rm \\\n  -v /volume1/data/photos:/data:ro \\\n  -v /volume1/bases:/bases:ro \\\n  -v /volume1/rapports:/resultats \\\n  hash_tool verify /bases/hashes_photos.b3 /data</code></pre>"},{"location":"guides/nas-synology/#pipeline-complet","title":"Pipeline complet","text":"<pre><code>docker run --rm \\\n  -v /volume1/data:/data:ro \\\n  -v /volume1/bases:/bases \\\n  -v /volume1/rapports:/resultats \\\n  -v /volume1/docker/hash_tool/pipelines/pipeline.json:/pipelines/pipeline.json:ro \\\n  hash_tool runner</code></pre>"},{"location":"guides/nas-synology/#automatisation-via-le-planificateur-de-taches-dsm","title":"Automatisation via le planificateur de t\u00e2ches DSM","text":"<p>DSM dispose d'un planificateur de t\u00e2ches int\u00e9gr\u00e9 (Panneau de configuration \u2192 Planificateur de t\u00e2ches).</p>"},{"location":"guides/nas-synology/#creer-une-tache-planifiee","title":"Cr\u00e9er une t\u00e2che planifi\u00e9e","text":"<ol> <li>Panneau de configuration \u2192 Planificateur de t\u00e2ches \u2192 Cr\u00e9er \u2192 T\u00e2che planifi\u00e9e \u2192 Script d\u00e9fini par l'utilisateur</li> <li>Onglet G\u00e9n\u00e9ral : nommer la t\u00e2che, s\u00e9lectionner l'utilisateur <code>root</code></li> <li>Onglet Calendrier : configurer la fr\u00e9quence (ex : hebdomadaire, dimanche 03h00)</li> <li>Onglet Param\u00e8tres de la t\u00e2che : coller le script ci-dessous</li> </ol>"},{"location":"guides/nas-synology/#script-de-tache-planifiee","title":"Script de t\u00e2che planifi\u00e9e","text":"<pre><code>#!/bin/bash\n\nLOG=\"/volume1/rapports/hash-integrity.log\"\nMAILTO=\"admin@example.com\"\n\necho \"$(date) \u2014 D\u00e9marrage v\u00e9rification int\u00e9grit\u00e9\" &gt;&gt; \"$LOG\"\n\ndocker run --rm \\\n  -v /volume1/data:/data:ro \\\n  -v /volume1/bases:/bases:ro \\\n  -v /volume1/rapports:/resultats \\\n  hash_tool --quiet verify /bases/hashes.b3 /data \\\n  &gt;&gt; \"$LOG\" 2&gt;&amp;1\n\nEXIT=$?\n\nif [ $EXIT -ne 0 ]; then\n    echo \"$(date) \u2014 ALERTE : v\u00e9rification \u00e9chou\u00e9e (exit $EXIT)\" &gt;&gt; \"$LOG\"\n    # Notification email DSM \u2014 n\u00e9cessite la configuration SMTP dans le Panneau de configuration\n    # synonotify -e \"hash_tool : corruption d\u00e9tect\u00e9e sur $(hostname)\"\nfi\n\necho \"$(date) \u2014 Fin (exit $EXIT)\" &gt;&gt; \"$LOG\"\nexit $EXIT</code></pre>"},{"location":"guides/nas-synology/#notifications-dsm-natives","title":"Notifications DSM natives","text":"<p>Pour utiliser le syst\u00e8me de notification DSM :</p> <pre><code># Envoyer une notification DSM (email, push, SMS selon config)\nsynodsmnotify @administrators \"hash_tool\" \"Corruption d\u00e9tect\u00e9e sur $(/bin/hostname)\"</code></pre>"},{"location":"guides/nas-synology/#docker-compose-sur-synology","title":"Docker Compose sur Synology","text":"<p>Adapter <code>docker-compose.yml</code> avec les chemins Synology :</p> <pre><code>x-volumes:\n  data:      &amp;vol-data      /volume1/data\n  bases:     &amp;vol-bases     /volume1/bases\n  pipelines: &amp;vol-pipelines /volume1/docker/hash_tool/pipelines\n  resultats: &amp;vol-resultats /volume1/rapports</code></pre> <p>Puis via Container Manager (interface graphique DSM) ou SSH :</p> <pre><code>cd /volume1/docker/hash_tool\ndocker compose run --rm integrity verify /bases/hashes.b3 /data</code></pre>"},{"location":"guides/nas-synology/#depannage","title":"D\u00e9pannage","text":""},{"location":"guides/nas-synology/#limage-ne-se-build-pas-sur-arm64","title":"L'image ne se build pas sur ARM64","text":"<pre><code># V\u00e9rifier l'architecture\nuname -m   # doit afficher aarch64\n\n# Builder avec la plateforme explicite\ndocker build --platform linux/arm64 -t hash_tool:arm64 .\n\n# Tagger pour utiliser sans suffixe\ndocker tag hash_tool:arm64 hash_tool</code></pre>"},{"location":"guides/nas-synology/#permission-denied-sur-volume1","title":"Permission denied sur /volume1","text":"<pre><code># Les conteneurs Docker tournent en root par d\u00e9faut\n# V\u00e9rifier que les dossiers sont accessibles\nls -la /volume1/data\nls -la /volume1/bases\n\n# Adapter les permissions si n\u00e9cessaire\nchmod 755 /volume1/bases</code></pre>"},{"location":"guides/nas-synology/#container-manager-ne-trouve-pas-limage","title":"Container Manager ne trouve pas l'image","text":"<p>Apr\u00e8s build via SSH, l'image appara\u00eet dans Container Manager \u2192 Images. Si elle n'appara\u00eet pas, rafra\u00eechir ou relancer le service Docker :</p> <pre><code>sudo synoservicectl --restart pkgctl-ContainerManager</code></pre>"},{"location":"guides/veracrypt/","title":"Guide \u2014 VeraCrypt &amp; disques multiples","text":"<p>Workflow complet pour archiver et v\u00e9rifier des donn\u00e9es sur partitions VeraCrypt avec <code>runner.sh</code>.</p>"},{"location":"guides/veracrypt/#principe","title":"Principe","text":"<p>Les partitions VeraCrypt sont mont\u00e9es comme des lettres de lecteur sous Windows / des points de montage sous Linux. Les donn\u00e9es n'existent en clair que pendant la session de montage. Il faut donc :</p> <ol> <li>Indexer avant d\u00e9montage \u2014 calculer les hashes pendant que les donn\u00e9es sont accessibles</li> <li>Stocker les <code>.b3</code> hors de la partition v\u00e9rifi\u00e9e \u2014 sur <code>C:</code> ou une partition non chiffr\u00e9e</li> <li>V\u00e9rifier apr\u00e8s remontage \u2014 au prochain acc\u00e8s, confirmer l'int\u00e9grit\u00e9</li> </ol>"},{"location":"guides/veracrypt/#correspondance-chemins-windows-wsl","title":"Correspondance chemins Windows / WSL","text":"Lecteur Windows Chemin WSL <code>A:\\</code> <code>/mnt/a/</code> <code>C:\\</code> <code>/mnt/c/</code> <code>H:\\</code> <code>/mnt/h/</code> <code>I:\\</code> <code>/mnt/i/</code> <p>Si VeraCrypt remonte une partition sur une lettre diff\u00e9rente d'une session \u00e0 l'autre, seul le champ <code>source</code> dans <code>pipeline.json</code> est \u00e0 modifier. Les bases <code>.b3</code> restent valides car leurs chemins sont relatifs.</p>"},{"location":"guides/veracrypt/#structure-recommandee","title":"Structure recommand\u00e9e","text":"<pre><code>C:\\Users\\TonNom\\Desktop\\\n\u251c\u2500\u2500 hash_tool\\                  \u2190 scripts (non chiffr\u00e9)\n\u2502   \u251c\u2500\u2500 runner.sh\n\u2502   \u251c\u2500\u2500 src\\integrity.sh\n\u2502   \u2514\u2500\u2500 pipelines\\\n\u2502       \u2514\u2500\u2500 pipeline-veracrypt.json\n\u251c\u2500\u2500 bases\\                      \u2190 fichiers .b3 (non chiffr\u00e9, hors VeraCrypt)\n\u2502   \u251c\u2500\u2500 hashes_disque_1.b3\n\u2502   \u251c\u2500\u2500 hashes_disque_2.b3\n\u2502   \u2514\u2500\u2500 hashes_disque_3.b3\n\u2514\u2500\u2500 rapports\\                   \u2190 r\u00e9sultats compare/verify\n    \u2514\u2500\u2500 ...</code></pre> <p>Stocker les .b3 hors de la partition v\u00e9rifi\u00e9e</p> <p>Si les <code>.b3</code> sont sur la m\u00eame partition VeraCrypt que les donn\u00e9es, une corruption du disque peut corrompre simultan\u00e9ment les donn\u00e9es et leur empreinte \u2014 rendant la v\u00e9rification inutile.</p> <p>Stocker les <code>.b3</code> sur <code>C:</code> (non chiffr\u00e9) ou une partition s\u00e9par\u00e9e.</p>"},{"location":"guides/veracrypt/#configuration-pipeline","title":"Configuration pipeline","text":""},{"location":"guides/veracrypt/#cas-simple-un-disque-compute-verify","title":"Cas simple \u2014 un disque, compute + verify","text":"<pre><code>{\n    \"pipeline\": [\n        {\n            \"op\":     \"compute\",\n            \"source\": \"/mnt/a/mes_archives\",\n            \"bases\":  \"/mnt/c/Users/TonNom/Desktop/bases\",\n            \"nom\":    \"hashes_disque_a.b3\"\n        },\n        {\n            \"op\":     \"verify\",\n            \"source\": \"/mnt/a/mes_archives\",\n            \"base\":   \"/mnt/c/Users/TonNom/Desktop/bases/hashes_disque_a.b3\"\n        }\n    ]\n}</code></pre>"},{"location":"guides/veracrypt/#cas-complet-trois-disques-avec-comparaison","title":"Cas complet \u2014 trois disques avec comparaison","text":"<pre><code>{\n    \"pipeline\": [\n\n        {\n            \"op\":     \"compute\",\n            \"source\": \"/mnt/a/dossier_disque_1\",\n            \"bases\":  \"/mnt/c/Users/TonNom/Desktop/bases\",\n            \"nom\":    \"hashes_disque_1.b3\"\n        },\n\n        {\n            \"op\":     \"compute\",\n            \"source\": \"/mnt/i/dossier_disque_2\",\n            \"bases\":  \"/mnt/c/Users/TonNom/Desktop/bases\",\n            \"nom\":    \"hashes_disque_2.b3\"\n        },\n\n        {\n            \"op\":     \"compute\",\n            \"source\": \"/mnt/h/dossier_disque_3\",\n            \"bases\":  \"/mnt/c/Users/TonNom/Desktop/bases\",\n            \"nom\":    \"hashes_disque_3.b3\"\n        },\n\n        {\n            \"op\":     \"verify\",\n            \"source\": \"/mnt/a/dossier_disque_1\",\n            \"base\":   \"/mnt/c/Users/TonNom/Desktop/bases/hashes_disque_1.b3\"\n        },\n\n        {\n            \"op\":        \"compare\",\n            \"base_a\":    \"/mnt/c/Users/TonNom/Desktop/bases/hashes_disque_1.b3\",\n            \"base_b\":    \"/mnt/c/Users/TonNom/Desktop/bases/hashes_disque_2.b3\",\n            \"resultats\": \"/mnt/c/Users/TonNom/Desktop/rapports/compare_1_vs_2\"\n        }\n\n    ]\n}</code></pre>"},{"location":"guides/veracrypt/#lanceur-windows-double-clic","title":"Lanceur Windows (double-clic)","text":"<p>Cr\u00e9er <code>lancer_integrity.bat</code> sur le bureau :</p> <pre><code>@echo off\necho Demarrage verification integrite...\nwsl bash /mnt/c/Users/TonNom/Desktop/hash_tool/runner.sh ^\n    /mnt/c/Users/TonNom/Desktop/hash_tool/pipelines/pipeline-veracrypt.json\nif %errorlevel% neq 0 (\n    echo.\n    echo ERREUR : le pipeline a echoue. Consulter les resultats.\n) else (\n    echo.\n    echo Pipeline termine avec succes.\n)\npause</code></pre>"},{"location":"guides/veracrypt/#workflows-types","title":"Workflows types","text":""},{"location":"guides/veracrypt/#workflow-darchivage-initial","title":"Workflow d'archivage initial","text":"<ol> <li>Monter les partitions VeraCrypt</li> <li>Double-clic sur <code>lancer_integrity.bat</code></li> <li>Attendre la fin (progression affich\u00e9e dans la console WSL)</li> <li>V\u00e9rifier que <code>recap.txt</code> indique OK</li> <li>D\u00e9monter les partitions</li> </ol>"},{"location":"guides/veracrypt/#workflow-de-verification-periodique","title":"Workflow de v\u00e9rification p\u00e9riodique","text":"<ol> <li>Monter les partitions VeraCrypt</li> <li>Modifier <code>pipeline.json</code> pour ne conserver que les blocs <code>verify</code> (supprimer les <code>compute</code>)</li> <li>Double-clic sur <code>lancer_integrity.bat</code></li> <li>Consulter <code>recap.txt</code> et <code>failed.txt</code> si pr\u00e9sent</li> <li>D\u00e9monter les partitions</li> </ol>"},{"location":"guides/veracrypt/#workflow-de-comparaison-apres-copie","title":"Workflow de comparaison apr\u00e8s copie","text":"<p>Apr\u00e8s avoir copi\u00e9 des donn\u00e9es d'un disque \u00e0 un autre :</p> <ol> <li><code>compute</code> sur la source (<code>base_a</code>)</li> <li><code>compute</code> sur la destination (<code>base_b</code>)</li> <li><code>compare base_a base_b</code> \u2192 <code>disparus.txt</code> et <code>nouveaux.txt</code> doivent \u00eatre vides, <code>modifies.b3</code> aussi</li> </ol>"},{"location":"guides/veracrypt/#nommage-des-bases","title":"Nommage des bases","text":"<p>Utiliser des noms dat\u00e9s pour conserver l'historique :</p> <pre><code>bases/\n\u251c\u2500\u2500 hashes_disque_1_2024-01-15.b3    \u2190 baseline initiale\n\u251c\u2500\u2500 hashes_disque_1_2024-06-01.b3    \u2190 apr\u00e8s ajout de fichiers\n\u2514\u2500\u2500 hashes_disque_1_2024-12-01.b3    \u2190 v\u00e9rification annuelle</code></pre> <p>Ne jamais \u00e9craser une base existante \u2014 chaque <code>.b3</code> est une preuve dat\u00e9e de l'\u00e9tat du disque.</p> <p>Tip</p> <p>Pour automatiser le nommage dat\u00e9 depuis Windows avec WSL : <pre><code>for /f %%i in ('wsl date +%%Y-%%m-%%d') do set DATE=%%i</code></pre></p>"},{"location":"reference/docker/","title":"R\u00e9f\u00e9rence \u2014 Docker","text":"<p>Utilisation de hash_tool via Docker. Aucune d\u00e9pendance (<code>b3sum</code>, <code>jq</code>, <code>bash</code>) \u00e0 installer sur l'h\u00f4te.</p> <p>Image : Alpine 3.19, ~14 Mo. Supporte <code>linux/amd64</code> et <code>linux/arm64</code>.</p>"},{"location":"reference/docker/#build","title":"Build","text":"<pre><code># Standard (amd64)\ndocker build -t hash_tool .\n\n# ARM64 \u2014 NAS Synology, Raspberry Pi, Apple Silicon\ndocker build --platform linux/arm64 -t hash_tool:arm64 .</code></pre>"},{"location":"reference/docker/#commandes-disponibles","title":"Commandes disponibles","text":"<pre><code>docker run [--rm] [-v ...] hash_tool [--quiet] &lt;commande&gt; [args]\n\n  compute &lt;dossier&gt; &lt;base.b3&gt;             Calcule les hashes\n  verify  &lt;base.b3&gt; [dossier]             V\u00e9rifie l'int\u00e9grit\u00e9\n  compare &lt;ancienne.b3&gt; &lt;nouvelle.b3&gt;     Compare deux bases\n  runner  [pipeline.json]                 Ex\u00e9cute un pipeline JSON\n  shell                                   Shell bash interactif (debug)\n  help                                    Aide\n  version                                 Versions des outils embarqu\u00e9s</code></pre>"},{"location":"reference/docker/#volumes","title":"Volumes","text":"Volume conteneur Usage Flag recommand\u00e9 <code>/data</code> Donn\u00e9es \u00e0 hacher <code>:ro</code> (lecture seule) <code>/bases</code> Fichiers <code>.b3</code> Lecture/\u00e9criture <code>/pipelines</code> Fichiers <code>pipeline.json</code> <code>:ro</code> <code>/resultats</code> R\u00e9sultats <code>verify</code>/<code>compare</code> Lecture/\u00e9criture <p><code>RESULTATS_DIR=/resultats</code> est d\u00e9fini par d\u00e9faut dans l'image.</p>"},{"location":"reference/docker/#exemples","title":"Exemples","text":""},{"location":"reference/docker/#compute","title":"Compute","text":"<pre><code>docker run --rm \\\n  -v /mes/donnees:/data:ro \\\n  -v /mes/bases:/bases \\\n  hash_tool compute /data /bases/hashes_$(date +%Y-%m-%d).b3</code></pre>"},{"location":"reference/docker/#verify","title":"Verify","text":"<pre><code>docker run --rm \\\n  -v /mes/donnees:/data:ro \\\n  -v /mes/bases:/bases:ro \\\n  -v /mes/resultats:/resultats \\\n  hash_tool verify /bases/hashes.b3 /data</code></pre>"},{"location":"reference/docker/#compare","title":"Compare","text":"<pre><code>docker run --rm \\\n  -v /mes/bases:/bases:ro \\\n  -v /mes/resultats:/resultats \\\n  hash_tool compare /bases/old.b3 /bases/new.b3</code></pre>"},{"location":"reference/docker/#pipeline-complet","title":"Pipeline complet","text":"<pre><code>docker run --rm \\\n  -v /mes/donnees:/data:ro \\\n  -v /mes/bases:/bases \\\n  -v /mes/resultats:/resultats \\\n  -v /chemin/pipeline.json:/pipelines/pipeline.json:ro \\\n  hash_tool runner</code></pre>"},{"location":"reference/docker/#mode-silencieux-cicron","title":"Mode silencieux \u2014 CI/cron","text":"<pre><code>docker run --rm \\\n  -v /mes/donnees:/data:ro \\\n  -v /mes/bases:/bases:ro \\\n  -v /mes/resultats:/resultats \\\n  hash_tool --quiet verify /bases/hashes.b3 /data \\\n  || echo \"ALERTE : corruption d\u00e9tect\u00e9e\"</code></pre>"},{"location":"reference/docker/#debug-interactif","title":"Debug interactif","text":"<pre><code>docker run --rm -it \\\n  -v /mes/donnees:/data \\\n  -v /mes/bases:/bases \\\n  hash_tool shell</code></pre>"},{"location":"reference/docker/#docker-compose","title":"Docker Compose","text":"<p>Adapter les chemins dans la section <code>x-volumes</code> de <code>docker-compose.yml</code> :</p> <pre><code>x-volumes:\n  data:      &amp;vol-data      /chemin/vers/donnees\n  bases:     &amp;vol-bases     /chemin/vers/bases\n  pipelines: &amp;vol-pipelines /chemin/vers/pipelines\n  resultats: &amp;vol-resultats /chemin/vers/resultats</code></pre> <p>Puis :</p> <pre><code># Commande ponctuelle\ndocker compose run --rm integrity verify /bases/hashes.b3 /data\ndocker compose run --rm integrity compute /data /bases/hashes.b3\n\n# Pipeline complet\ndocker compose run --rm pipeline\n\n# Build puis run\ndocker compose build &amp;&amp; docker compose run --rm pipeline</code></pre>"},{"location":"reference/docker/#variable-denvironnement","title":"Variable d'environnement","text":""},{"location":"reference/docker/#resultats_dir","title":"<code>RESULTATS_DIR</code>","text":"<p>Surcharger le dossier de r\u00e9sultats dans le conteneur :</p> <pre><code>docker run --rm \\\n  -v /mes/resultats:/mon_dossier_custom \\\n  -e RESULTATS_DIR=/mon_dossier_custom \\\n  hash_tool verify /bases/hashes.b3</code></pre>"},{"location":"reference/docker/#nas-synology","title":"NAS Synology","text":"<p>Sur DSM 7.x avec Docker Manager ou Portainer :</p> <pre><code>docker run --rm \\\n  -v /volume1/data:/data:ro \\\n  -v /volume1/bases:/bases \\\n  -v /volume1/resultats:/resultats \\\n  hash_tool verify /bases/hashes.b3 /data</code></pre> <p>Pour ARM64 (DS220+, DS923+, etc.) : builder avec <code>--platform linux/arm64</code>.</p> <p>Voir le guide NAS Synology pour la configuration compl\u00e8te.</p>"},{"location":"reference/docker/#cron-sur-debianubuntu","title":"Cron sur Debian/Ubuntu","text":"<pre><code># /etc/cron.d/hash-integrity\n0 3 * * * root \\\n  docker run --rm \\\n    -v /srv/data:/data:ro \\\n    -v /srv/bases:/bases:ro \\\n    -v /srv/resultats:/resultats \\\n    hash_tool --quiet verify /bases/hashes.b3 /data \\\n  &gt;&gt; /var/log/hash-integrity.log 2&gt;&amp;1 \\\n  || mail -s \"ALERTE int\u00e9grit\u00e9 $(hostname)\" admin@example.com</code></pre> <p>Voir le guide CI/Cron pour les patterns d'int\u00e9gration avanc\u00e9s.</p>"},{"location":"reference/docker/#taille-de-limage","title":"Taille de l'image","text":"Couche Taille approximative Alpine 3.19 ~7 Mo bash + jq + coreutils + findutils ~5 Mo b3sum (depuis Alpine community) ~2 Mo Scripts hash_tool &lt; 100 Ko Total ~14 Mo"},{"location":"reference/docker/#mise-a-jour-de-b3sum","title":"Mise \u00e0 jour de b3sum","text":"<p><code>b3sum</code> est install\u00e9 depuis les packages Alpine \u2014 mise \u00e0 jour via rebuild de l'image :</p> <pre><code>docker build --no-cache -t hash_tool .</code></pre> <p>Pour v\u00e9rifier la version embarqu\u00e9e :</p> <pre><code>docker run --rm hash_tool version</code></pre>"},{"location":"reference/integrity-sh/","title":"R\u00e9f\u00e9rence \u2014 integrity.sh","text":"<p>Script principal de v\u00e9rification d'int\u00e9grit\u00e9 BLAKE3.</p> <p>Emplacement : <code>src/integrity.sh</code></p>"},{"location":"reference/integrity-sh/#synopsis","title":"Synopsis","text":"<pre><code>integrity.sh [--quiet] &lt;mode&gt; [arguments...]\n\nModes :\n  compute &lt;dossier&gt; &lt;base.b3&gt;\n  verify  &lt;base.b3&gt; [dossier]\n  compare &lt;ancienne.b3&gt; &lt;nouvelle.b3&gt;</code></pre>"},{"location":"reference/integrity-sh/#options-globales","title":"Options globales","text":""},{"location":"reference/integrity-sh/#-quiet","title":"<code>--quiet</code>","text":"<p>Supprime toute sortie terminal. \u00c9crit uniquement dans les fichiers de r\u00e9sultats (<code>recap.txt</code>, <code>failed.txt</code>, <code>report.html</code>). L'exit code est conserv\u00e9.</p> <pre><code>./src/integrity.sh --quiet verify base.b3\necho $?   # 0 = OK, 1 = ECHEC ou ERREUR</code></pre> <p>Usage type : int\u00e9gration CI, cron, scripts parents qui g\u00e8rent eux-m\u00eames la sortie.</p> <p>Warning</p> <p>En mode <code>--quiet</code>, la progression ETA est \u00e9galement supprim\u00e9e pendant <code>compute</code>.</p>"},{"location":"reference/integrity-sh/#mode-compute","title":"Mode <code>compute</code>","text":"<p>Calcule les hashes BLAKE3 de tous les fichiers d'un dossier et les enregistre dans un fichier <code>.b3</code>.</p>"},{"location":"reference/integrity-sh/#syntaxe","title":"Syntaxe","text":"<pre><code>./src/integrity.sh compute &lt;dossier&gt; &lt;base.b3&gt;</code></pre>"},{"location":"reference/integrity-sh/#arguments","title":"Arguments","text":"Argument Type Description <code>&lt;dossier&gt;</code> chemin Dossier \u00e0 indexer. Relatif ou absolu, mais pr\u00e9f\u00e9rer relatif (voir avertissement ci-dessous). <code>&lt;base.b3&gt;</code> chemin fichier Fichier de sortie. Cr\u00e9\u00e9 ou \u00e9cras\u00e9. Ne doit pas \u00eatre un dossier existant."},{"location":"reference/integrity-sh/#comportement","title":"Comportement","text":"<ol> <li>Valide que <code>&lt;dossier&gt;</code> existe et contient au moins un fichier.</li> <li>Parcourt r\u00e9cursivement <code>&lt;dossier&gt;</code> avec <code>find -type f</code>.</li> <li>Trie les chemins (<code>sort -z</code>) pour garantir un ordre d\u00e9terministe.</li> <li>Calcule le hash BLAKE3 de chaque fichier avec <code>b3sum</code>.</li> <li>Affiche la progression et l'ETA sur <code>/dev/tty</code> (jamais dans le <code>.b3</code>).</li> <li>Enregistre les r\u00e9sultats dans <code>&lt;base.b3&gt;</code>.</li> </ol>"},{"location":"reference/integrity-sh/#format-du-fichier-b3","title":"Format du fichier <code>.b3</code>","text":"<pre><code>&lt;hash_64_chars&gt;  &lt;chemin&gt;</code></pre> <p>Deux espaces entre le hash et le chemin \u2014 convention <code>b3sum</code>/<code>sha256sum</code>.</p> <pre><code>a1b2c3d4e5f6a7b8c9d0e1f2a3b4c5d6e7f8a9b0c1d2e3f4a5b6c7d8e9f0a1b2  ./dossier/fichier.txt\ne5f6a7b8c9d0e1f2a3b4c5d6e7f8a9b0c1d2e3f4a5b6c7d8e9f0a1b2c3d4e5f6  ./dossier/sous/autre.bin</code></pre> <p>R\u00e8gle absolue : chemins relatifs</p> <p>Toujours passer un chemin relatif (<code>.</code> ou <code>./sous-dossier</code>) comme <code>&lt;dossier&gt;</code>. Un chemin absolu rend la base inutilisable si les donn\u00e9es sont d\u00e9plac\u00e9es ou remont\u00e9es sur un point de montage diff\u00e9rent.</p> <pre><code># Correct \u2014 chemin relatif dans la base\ncd /mnt/a/mes_donnees\n./src/integrity.sh compute . /mnt/c/bases/hashes.b3\n\n# Incorrect \u2014 chemin absolu, base non portable\n./src/integrity.sh compute /mnt/a/mes_donnees /mnt/c/bases/hashes.b3</code></pre> <p><code>runner.sh</code> g\u00e8re ce <code>cd</code> automatiquement.</p>"},{"location":"reference/integrity-sh/#progression-eta","title":"Progression ETA","text":"<p>Affich\u00e9e sur <code>/dev/tty</code> pendant le calcul, jamais dans le fichier <code>.b3</code> :</p> <pre><code>[47/142] ETA : 2m 34s</code></pre> <p>L'ETA converge apr\u00e8s ~10\u201320 secondes. Instable avant ce seuil \u2014 comportement normal, inh\u00e9rent \u00e0 l'extrapolation lin\u00e9aire.</p>"},{"location":"reference/integrity-sh/#exit-codes","title":"Exit codes","text":"Code Signification <code>0</code> Base calcul\u00e9e avec succ\u00e8s <code>1</code> Erreur (dossier introuvable, dossier vide, argument manquant)"},{"location":"reference/integrity-sh/#exemples","title":"Exemples","text":"<pre><code># Indexer le r\u00e9pertoire courant\n./src/integrity.sh compute . hashes_$(date +%Y-%m-%d).b3\n\n# Indexer un sous-dossier\n./src/integrity.sh compute ./archives hashes_archives.b3\n\n# Mode silencieux (pas d'ETA affich\u00e9)\n./src/integrity.sh --quiet compute . hashes.b3</code></pre>"},{"location":"reference/integrity-sh/#mode-verify","title":"Mode <code>verify</code>","text":"<p>V\u00e9rifie que les fichiers correspondent aux hashes stock\u00e9s dans la base <code>.b3</code>.</p>"},{"location":"reference/integrity-sh/#syntaxe_1","title":"Syntaxe","text":"<pre><code>./src/integrity.sh verify &lt;base.b3&gt; [dossier]</code></pre>"},{"location":"reference/integrity-sh/#arguments_1","title":"Arguments","text":"Argument Type Description <code>&lt;base.b3&gt;</code> chemin fichier Base de hashes \u00e0 utiliser pour la v\u00e9rification. <code>[dossier]</code> chemin (optionnel) R\u00e9pertoire de travail \u00e0 utiliser. Si absent, utilise le <code>pwd</code> courant."},{"location":"reference/integrity-sh/#comportement_1","title":"Comportement","text":"<ol> <li>Valide que <code>&lt;base.b3&gt;</code> est un fichier non vide au format b3sum valide.</li> <li>Si <code>[dossier]</code> est fourni, fait <code>cd</code> dans ce dossier avant v\u00e9rification.</li> <li>R\u00e9sout le chemin absolu de <code>&lt;base.b3&gt;</code> avant le <code>cd</code> (\u00e9vite l'invalidation du chemin relatif apr\u00e8s changement de r\u00e9pertoire).</li> <li>Lance <code>b3sum --check &lt;base.b3&gt;</code>.</li> <li>\u00c9crit les r\u00e9sultats dans <code>$RESULTATS_DIR/resultats_&lt;nom_base&gt;/</code>.</li> </ol> <p>R\u00e9pertoire de travail</p> <p><code>b3sum --check</code> r\u00e9sout les chemins relatifs depuis le <code>pwd</code>. Il faut imp\u00e9rativement lancer <code>verify</code> depuis le m\u00eame r\u00e9pertoire qu'au <code>compute</code> \u2014 ou passer ce r\u00e9pertoire en second argument.</p> <pre><code># Cas 1 : on est dans le bon r\u00e9pertoire\ncd /mnt/a/mes_donnees\n./src/integrity.sh verify /mnt/c/bases/hashes.b3\n\n# Cas 2 : on est ailleurs, on passe le r\u00e9pertoire d'origine\n./src/integrity.sh verify /mnt/c/bases/hashes.b3 /mnt/a/mes_donnees</code></pre>"},{"location":"reference/integrity-sh/#fichiers-produits","title":"Fichiers produits","text":"<p>Cr\u00e9\u00e9s dans <code>$RESULTATS_DIR/resultats_&lt;nom_base&gt;/</code> (horodat\u00e9 si le dossier existe d\u00e9j\u00e0) :</p> Fichier Pr\u00e9sence Contenu <code>recap.txt</code> Toujours Statut global, compteurs OK/FAILED, erreurs b3sum <code>failed.txt</code> Si \u00e9chec seulement Liste des fichiers FAILED ou en erreur"},{"location":"reference/integrity-sh/#statuts-de-sortie-terminal","title":"Statuts de sortie terminal","text":"Statut Condition Affichage <code>OK</code> Z\u00e9ro FAILED, z\u00e9ro erreur Message sobre une ligne <code>ECHEC</code> Au moins un FAILED Bloc <code>\u2588\u2588\u2588\u2588</code> visible, liste des fichiers <code>ERREUR</code> Erreur b3sum non li\u00e9e aux hashes Bloc <code>\u2588\u2588\u2588\u2588</code> visible, d\u00e9tail erreur"},{"location":"reference/integrity-sh/#exit-codes_1","title":"Exit codes","text":"Code Signification <code>0</code> Tous les fichiers int\u00e8gres <code>1</code> Au moins un FAILED ou erreur b3sum"},{"location":"reference/integrity-sh/#exemples_1","title":"Exemples","text":"<pre><code># V\u00e9rification depuis le bon r\u00e9pertoire\ncd /mnt/a/mes_donnees\n./src/integrity.sh verify /mnt/c/bases/hashes.b3\n\n# V\u00e9rification depuis n'importe o\u00f9 avec dossier explicite\n./src/integrity.sh verify /mnt/c/bases/hashes.b3 /mnt/a/mes_donnees\n\n# En CI \u2014 arr\u00eat imm\u00e9diat sur \u00e9chec\n./src/integrity.sh --quiet verify hashes.b3 || exit 1</code></pre>"},{"location":"reference/integrity-sh/#mode-compare","title":"Mode <code>compare</code>","text":"<p>Compare deux bases <code>.b3</code> et identifie les fichiers modifi\u00e9s, disparus et nouveaux.</p>"},{"location":"reference/integrity-sh/#syntaxe_2","title":"Syntaxe","text":"<pre><code>./src/integrity.sh compare &lt;ancienne.b3&gt; &lt;nouvelle.b3&gt;</code></pre>"},{"location":"reference/integrity-sh/#arguments_2","title":"Arguments","text":"Argument Type Description <code>&lt;ancienne.b3&gt;</code> chemin fichier Base de r\u00e9f\u00e9rence (snapshot ant\u00e9rieur). <code>&lt;nouvelle.b3&gt;</code> chemin fichier Base \u00e0 comparer (snapshot r\u00e9cent)."},{"location":"reference/integrity-sh/#comportement_2","title":"Comportement","text":"<ol> <li>Valide les deux fichiers <code>.b3</code>.</li> <li>Convertit chaque ligne <code>hash  chemin</code> en <code>chemin\\thash</code> (s\u00e9parateur tab) via <code>awk</code> avec offset fixe 64 chars \u2014 robuste aux chemins avec espaces.</li> <li>Trie par chemin.</li> <li><code>join</code> sur le chemin : identifie les fichiers pr\u00e9sents dans les deux bases \u2192 les modifi\u00e9s (hashes diff\u00e9rents).</li> <li><code>comm</code> sur les chemins : identifie les disparus (dans A, pas dans B) et les nouveaux (dans B, pas dans A).</li> <li>G\u00e9n\u00e8re les fichiers de r\u00e9sultats et le rapport HTML.</li> </ol>"},{"location":"reference/integrity-sh/#fichiers-produits_1","title":"Fichiers produits","text":"<p>Cr\u00e9\u00e9s dans <code>$RESULTATS_DIR/resultats_&lt;nom_ancienne_base&gt;/</code> :</p> Fichier Contenu <code>recap.txt</code> Commande, date, bases, compteurs modifi\u00e9s/disparus/nouveaux <code>modifies.b3</code> Fichiers pr\u00e9sents dans les deux bases avec hashes diff\u00e9rents. Format : <code>nouveau_hash  chemin</code> <code>disparus.txt</code> Chemins pr\u00e9sents dans <code>&lt;ancienne.b3&gt;</code> et absents de <code>&lt;nouvelle.b3&gt;</code> <code>nouveaux.txt</code> Chemins absents de <code>&lt;ancienne.b3&gt;</code> et pr\u00e9sents dans <code>&lt;nouvelle.b3&gt;</code> <code>report.html</code> Rapport visuel autonome (CSS inline, sans d\u00e9pendance externe)"},{"location":"reference/integrity-sh/#rapport-html","title":"Rapport HTML","text":"<p>Th\u00e8me sombre, lisible hors ligne. Contient :</p> <ul> <li>Badge statut : <code>IDENTIQUES</code> (vert) ou <code>DIFF\u00c9RENCES D\u00c9TECT\u00c9ES</code> (orange)</li> <li>Compteurs par cat\u00e9gorie</li> <li>Listes d\u00e9taill\u00e9es des fichiers affect\u00e9s</li> </ul>"},{"location":"reference/integrity-sh/#exit-codes_2","title":"Exit codes","text":"Code Signification <code>0</code> Comparaison effectu\u00e9e (qu'il y ait des diff\u00e9rences ou non) <code>1</code> Erreur (fichier introuvable, format invalide) <p>Note</p> <p><code>compare</code> retourne <code>0</code> m\u00eame si des diff\u00e9rences sont d\u00e9tect\u00e9es. C'est voulu : la pr\u00e9sence de diff\u00e9rences n'est pas une erreur, c'est une information. Pour d\u00e9tecter des diff\u00e9rences en script, lire <code>recap.txt</code> ou v\u00e9rifier si <code>modifies.b3</code>, <code>disparus.txt</code> ou <code>nouveaux.txt</code> sont non vides.</p>"},{"location":"reference/integrity-sh/#exemples_2","title":"Exemples","text":"<pre><code># Comparaison de deux snapshots\n./src/integrity.sh compare hashes_2024-01.b3 hashes_2024-02.b3\n\n# Avec destination personnalis\u00e9e (via variable d'env)\nRESULTATS_DIR=/srv/rapports ./src/integrity.sh compare old.b3 new.b3</code></pre>"},{"location":"reference/integrity-sh/#variable-denvironnement","title":"Variable d'environnement","text":""},{"location":"reference/integrity-sh/#resultats_dir","title":"<code>RESULTATS_DIR</code>","text":"<p>Dossier racine o\u00f9 sont cr\u00e9\u00e9s les sous-dossiers de r\u00e9sultats.</p> D\u00e9faut <code>~/integrity_resultats</code> Scope <code>verify</code> et <code>compare</code> Priorit\u00e9 Variable d'environnement &gt; valeur par d\u00e9faut dans le script <pre><code># Export global\nexport RESULTATS_DIR=/srv/rapports/integrity\n./src/integrity.sh verify hashes.b3\n\n# Surcharge ponctuelle\nRESULTATS_DIR=/tmp/test ./src/integrity.sh compare a.b3 b.b3</code></pre> <p><code>runner.sh</code> peut surcharger <code>RESULTATS_DIR</code> pour un bloc <code>compare</code> sp\u00e9cifique via le champ <code>resultats</code> du pipeline \u2014 sans affecter les autres blocs.</p>"},{"location":"reference/integrity-sh/#horodatage-automatique-des-resultats","title":"Horodatage automatique des r\u00e9sultats","text":"<p>Si <code>$RESULTATS_DIR/resultats_&lt;nom_base&gt;</code> existe d\u00e9j\u00e0 lors d'un nouvel appel, un suffixe horodat\u00e9 est ajout\u00e9 automatiquement :</p> <pre><code>~/integrity_resultats/\n\u251c\u2500\u2500 resultats_hashes_2024-01/\n\u251c\u2500\u2500 resultats_hashes_2024-01_20240215-143022/\n\u2514\u2500\u2500 resultats_hashes_2024-01_20240301-091547/</code></pre> <p>Aucun r\u00e9sultat n'est jamais \u00e9cras\u00e9 silencieusement.</p>"},{"location":"reference/integrity-sh/#limites-connues","title":"Limites connues","text":"Sc\u00e9nario D\u00e9tect\u00e9 ? Remarque Contenu de fichier modifi\u00e9 Oui Hash diff\u00e9rent Fichier supprim\u00e9 Oui FAILED (verify) ou DISPARUS (compare) Fichier ajout\u00e9 Oui (compare) Section NOUVEAUX Dossier vide Non <code>find -type f</code> ignore les dossiers vides Permissions / timestamps Non Seul le contenu binaire est hach\u00e9 Fichier renomm\u00e9 Non Vu comme suppression + ajout Clone bit-\u00e0-bit Non Hash identique par d\u00e9finition Corruption de la base <code>.b3</code> Non La base n'est pas auto-prot\u00e9g\u00e9e"},{"location":"reference/integrity-sh/#proteger-la-base-b3","title":"Prot\u00e9ger la base <code>.b3</code>","text":"<pre><code># Calculer le hash de la base elle-m\u00eame\nb3sum hashes.b3 &gt; hashes.b3.check\n\n# V\u00e9rifier la base avant usage\nb3sum --check hashes.b3.check</code></pre>"},{"location":"reference/integrity-sh/#gerer-les-renommages","title":"G\u00e9rer les renommages","text":"<pre><code># Mettre \u00e0 jour les chemins dans la base apr\u00e8s renommage\nsed 's|./ancien_nom/|./nouveau_nom/|g' hashes.b3 &gt; hashes_corrige.b3\nb3sum --check hashes_corrige.b3</code></pre>"},{"location":"reference/integrity-sh/#dependances-techniques","title":"D\u00e9pendances techniques","text":"Outil Usage <code>b3sum</code> Calcul et v\u00e9rification des hashes BLAKE3 <code>find</code> Parcours r\u00e9cursif du dossier <code>sort</code> Tri d\u00e9terministe des chemins <code>awk</code> Conversion format <code>hash chemin</code> \u2194 <code>chemin\\thash</code> <code>join</code> Identification des fichiers modifi\u00e9s (inner join sur le chemin) <code>comm</code> Identification des disparus et nouveaux (set difference) <code>stat</code> Taille de fichier pour le calcul ETA <code>du</code> Taille totale du dossier pour le calcul ETA <code>mktemp</code> Fichiers temporaires isol\u00e9s dans <code>compare</code>"},{"location":"reference/runner-sh/","title":"R\u00e9f\u00e9rence \u2014 runner.sh &amp; pipeline.json","text":"<p>Orchestrateur de pipeline pour ex\u00e9cuter plusieurs op\u00e9rations <code>integrity.sh</code> en s\u00e9quence.</p> <p>Emplacement : <code>runner.sh</code> D\u00e9pendance suppl\u00e9mentaire : <code>jq</code></p>"},{"location":"reference/runner-sh/#synopsis","title":"Synopsis","text":"<pre><code>runner.sh [pipeline.json]</code></pre> Argument D\u00e9faut Description <code>pipeline.json</code> <code>pipelines/pipeline.json</code> Chemin vers le fichier de configuration du pipeline."},{"location":"reference/runner-sh/#pourquoi-runnersh","title":"Pourquoi runner.sh","text":"<p>Lancer <code>integrity.sh</code> manuellement sur plusieurs dossiers est error-prone :</p> <ul> <li>Oublier le <code>cd</code> avant <code>compute</code> \u2192 chemins absolus dans la base</li> <li>Mauvais r\u00e9pertoire de travail pour <code>verify</code> \u2192 faux positifs massifs</li> <li>Ordre d'ex\u00e9cution non garanti sur des appels s\u00e9par\u00e9s</li> </ul> <p><code>runner.sh</code> \u00e9limine ces risques : il g\u00e8re automatiquement les <code>cd</code>, valide les chemins avant ex\u00e9cution, et s'arr\u00eate imm\u00e9diatement sur toute erreur (<code>set -euo pipefail</code>).</p>"},{"location":"reference/runner-sh/#format-pipelinejson","title":"Format pipeline.json","text":""},{"location":"reference/runner-sh/#structure-generale","title":"Structure g\u00e9n\u00e9rale","text":"<pre><code>{\n    \"pipeline\": [\n        { \"op\": \"compute\", ... },\n        { \"op\": \"verify\",  ... },\n        { \"op\": \"compare\", ... }\n    ]\n}</code></pre> <p>Le tableau <code>pipeline</code> est ex\u00e9cut\u00e9 s\u00e9quentiellement. En cas d'erreur sur un bloc, l'ex\u00e9cution s'arr\u00eate imm\u00e9diatement.</p>"},{"location":"reference/runner-sh/#operation-compute","title":"Op\u00e9ration <code>compute</code>","text":"<p>Calcule les hashes d'un dossier et produit un fichier <code>.b3</code>.</p> <pre><code>{\n    \"op\":     \"compute\",\n    \"source\": \"/chemin/vers/dossier\",\n    \"bases\":  \"/chemin/vers/dossier_bases\",\n    \"nom\":    \"hashes.b3\"\n}</code></pre> Champ Requis Description <code>op</code> Oui <code>\"compute\"</code> <code>source</code> Oui Dossier \u00e0 indexer. <code>runner.sh</code> fait <code>cd</code> dans ce dossier avant le compute \u2014 les chemins dans la base seront relatifs. <code>bases</code> Oui Dossier o\u00f9 enregistrer le fichier <code>.b3</code>. Cr\u00e9\u00e9 automatiquement si inexistant. <code>nom</code> Oui Nom du fichier <code>.b3</code> \u00e0 cr\u00e9er dans <code>bases</code>. <p>Comportement interne : <code>cd \"$source\"</code> puis <code>integrity.sh compute . \"$bases/$nom\"</code>. Le <code>.</code> garantit des chemins relatifs dans la base.</p>"},{"location":"reference/runner-sh/#operation-verify","title":"Op\u00e9ration <code>verify</code>","text":"<p>V\u00e9rifie l'int\u00e9grit\u00e9 d'un dossier contre une base <code>.b3</code>.</p> <pre><code>{\n    \"op\":     \"verify\",\n    \"source\": \"/chemin/vers/dossier\",\n    \"base\":   \"/chemin/vers/hashes.b3\"\n}</code></pre> Champ Requis Description <code>op</code> Oui <code>\"verify\"</code> <code>source</code> Oui R\u00e9pertoire de travail d'origine (celui depuis lequel le <code>compute</code> a \u00e9t\u00e9 fait). <code>base</code> Oui Chemin complet du fichier <code>.b3</code>. <p>Comportement interne : r\u00e9solution du chemin absolu de <code>base</code>, puis <code>cd \"$source\"</code>, puis <code>integrity.sh verify \"$base_abs\"</code>.</p>"},{"location":"reference/runner-sh/#operation-compare","title":"Op\u00e9ration <code>compare</code>","text":"<p>Compare deux bases <code>.b3</code>.</p> <pre><code>{\n    \"op\":        \"compare\",\n    \"base_a\":    \"/chemin/vers/ancienne.b3\",\n    \"base_b\":    \"/chemin/vers/nouvelle.b3\",\n    \"resultats\": \"/chemin/vers/dossier_resultats\"\n}</code></pre> Champ Requis Description <code>op</code> Oui <code>\"compare\"</code> <code>base_a</code> Oui Ancienne base (r\u00e9f\u00e9rence). <code>base_b</code> Oui Nouvelle base (\u00e0 comparer). <code>resultats</code> Non Dossier de destination des r\u00e9sultats. Surcharge <code>RESULTATS_DIR</code> pour ce seul bloc. Cr\u00e9\u00e9 automatiquement si inexistant. <p>Champ <code>resultats</code> : l'isolation est garantie par un sous-shell \u2014 <code>RESULTATS_DIR</code> du processus parent n'est pas modifi\u00e9. Les autres blocs du pipeline continuent d'utiliser la valeur globale de <code>RESULTATS_DIR</code>.</p>"},{"location":"reference/runner-sh/#exemple-complet-veracrypt-multi-disques","title":"Exemple complet \u2014 VeraCrypt multi-disques","text":"<pre><code>{\n    \"pipeline\": [\n\n        {\n            \"op\":     \"compute\",\n            \"source\": \"/mnt/a/dossier_disque_1\",\n            \"bases\":  \"/mnt/c/Users/TonNom/Desktop/bases\",\n            \"nom\":    \"hashes_disque_1.b3\"\n        },\n\n        {\n            \"op\":     \"compute\",\n            \"source\": \"/mnt/i/dossier_disque_2\",\n            \"bases\":  \"/mnt/c/Users/TonNom/Desktop/bases\",\n            \"nom\":    \"hashes_disque_2.b3\"\n        },\n\n        {\n            \"op\":     \"verify\",\n            \"source\": \"/mnt/a/dossier_disque_1\",\n            \"base\":   \"/mnt/c/Users/TonNom/Desktop/bases/hashes_disque_1.b3\"\n        },\n\n        {\n            \"op\":        \"compare\",\n            \"base_a\":    \"/mnt/c/Users/TonNom/Desktop/bases/hashes_disque_1.b3\",\n            \"base_b\":    \"/mnt/c/Users/TonNom/Desktop/bases/hashes_disque_2.b3\",\n            \"resultats\": \"/mnt/c/Users/TonNom/Desktop/rapports/compare_1_vs_2\"\n        }\n\n    ]\n}</code></pre>"},{"location":"reference/runner-sh/#validation-et-messages-derreur","title":"Validation et messages d'erreur","text":"<p><code>runner.sh</code> valide la configuration avant d'ex\u00e9cuter quoi que ce soit :</p> Probl\u00e8me Message JSON invalide <code>ERREUR : JSON invalide : /chemin/pipeline.json</code> Cl\u00e9 <code>.pipeline</code> absente <code>ERREUR : tableau .pipeline vide ou absent</code> Champ requis manquant <code>ERREUR : Bloc #2 : champ 'nom' manquant ou vide.</code> Op\u00e9ration inconnue <code>ERREUR : Bloc #3 : op\u00e9ration inconnue : 'migrate'</code> Dossier source introuvable <code>ERREUR : Bloc #1 compute : dossier source introuvable : /mnt/a/...</code> Base <code>.b3</code> introuvable <code>ERREUR : Bloc #2 verify : base .b3 introuvable : /mnt/c/...</code> <p>Tous les messages d'erreur incluent le num\u00e9ro de bloc pour faciliter le d\u00e9bogage.</p>"},{"location":"reference/runner-sh/#variables-denvironnement","title":"Variables d'environnement","text":""},{"location":"reference/runner-sh/#resultats_dir","title":"<code>RESULTATS_DIR</code>","text":"<p>Dossier de r\u00e9sultats global pour tous les blocs <code>verify</code> et <code>compare</code> sans champ <code>resultats</code> explicite.</p> <pre><code>export RESULTATS_DIR=/srv/rapports\n./runner.sh</code></pre> <p>D\u00e9faut : <code>~/integrity_resultats</code> (h\u00e9rit\u00e9 de <code>integrity.sh</code>).</p>"},{"location":"reference/runner-sh/#exit-codes","title":"Exit codes","text":"Code Signification <code>0</code> Pipeline ex\u00e9cut\u00e9 enti\u00e8rement sans erreur <code>1</code> Erreur sur un bloc (bloc suivant non ex\u00e9cut\u00e9)"},{"location":"reference/runner-sh/#lancement-depuis-windows","title":"Lancement depuis Windows","text":"<p>Cr\u00e9er un fichier <code>.bat</code> sur le bureau :</p> <pre><code>@echo off\nwsl bash /mnt/c/Users/TonNom/Desktop/hash_tool/runner.sh\npause</code></pre> <p>Double-clic pour ex\u00e9cuter. La fen\u00eatre reste ouverte apr\u00e8s ex\u00e9cution gr\u00e2ce \u00e0 <code>pause</code>.</p> <p>Pour un pipeline explicite :</p> <pre><code>@echo off\nwsl bash /mnt/c/Users/TonNom/Desktop/hash_tool/runner.sh ^\n    /mnt/c/Users/TonNom/Desktop/mon-pipeline.json\npause</code></pre>"},{"location":"reference/runner-sh/#isolation-des-sous-shells","title":"Isolation des sous-shells","text":"<p><code>runner.sh</code> utilise des sous-shells <code>( )</code> pour isoler les <code>cd</code> :</p> <pre><code># Le cd ne fuite pas vers les blocs suivants\n( cd \"$source\" &amp;&amp; integrity.sh compute . \"$bases/$nom\" )</code></pre> <p>Chaque bloc <code>compute</code> et <code>verify</code> d\u00e9marre dans le r\u00e9pertoire courant du processus principal, quels que soient les <code>cd</code> des blocs pr\u00e9c\u00e9dents. La variable <code>RESULTATS_DIR</code> est de m\u00eame isol\u00e9e pour les blocs <code>compare</code> avec un champ <code>resultats</code> explicite.</p>"}]}