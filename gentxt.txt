# === Arborescence du dossier ===

hash_tool
├── .github
│   └── workflows
│       └── ci.yml
├── docker
│   └── entrypoint.sh
├── docs
│   ├── development
│   │   ├── architecture.md
│   │   ├── changelog.md
│   │   ├── contributing.md
│   │   └── roadmap.md
│   ├── docs
│   ├── guides
│   │   ├── cron-ci.md
│   │   ├── nas-synology.md
│   │   └── veracrypt.md
│   ├── reference
│   │   ├── docker.md
│   │   ├── integrity-sh.md
│   │   └── runner-sh.md
│   ├── spec
│   │   ├── api-interne.md
│   │   └── b3-format.md
│   ├── troubleshooting 
│   │   └── troubleshooting_1.md
│   ├── getting-started.md
│   └── index.md
├── hors_git
│   ├── TODO - améliorations
│   │   ├── ameliorations - audit.md
│   │   └── ameliorations - roadmap.md
│   ├── TODO - messages exceptions
│   │   └── message d'erreur.md
│   ├── [terminé] -- TODO - CLI
│   │   ├── ameliorations todo.txt
│   │   ├── cli unique.md
│   │   ├── commandes_prevues.md
│   │   ├── helpers_commandes.md
│   │   ├── pipeline-amelioree.json
│   │   ├── pipeline_json.md
│   │   └── sidecar file for metadata.md
│   ├── _misc
│   │   ├── environment.md
│   │   └── progression-eta.md
│   ├── changelog
│   │   ├── 2026-02-22-11-39 -- CHANGELOG.md
│   │   └── 2026-02-26-12-03 -- changelog.md
│   ├── chemin relatif et absolu
│   │   ├── chemins relatifs et absolu.md
│   │   └── llm -- feature chemin relatif - presentation du pb.md
│   ├── docker
│   │   ├── docker.md
│   │   ├── hash_tool-docker-documentation.docx
│   │   └── hash_tool-docker-documentation.pdf
│   ├── documentation 
│   │   ├── llm -- Intégration Read the Docs.md
│   │   ├── llm -- Test FDP et Commandes Hash-Tool.md
│   │   └── requirements-docs.txt
│   ├── documentation dev
│   │   ├── guide - changelog - bonne pratique.md
│   │   ├── guide - git - convention message.md
│   │   ├── guide - git - gestion des branches - niveau avancé.md
│   │   ├── guide - git - gestion des branches.md
│   │   ├── guide - git - quand faire un commit.md
│   │   ├── guide - github - config.md
│   │   └── guide- git - pratique - dev et master.md
│   ├── interet du projet
│   │   ├── blabla
│   │   ├── hash_tool-positionnement-open-source.docx
│   │   └── hash_tool-positionnement-open-source.pdf
│   ├── presentation hash tool
│   │   ├── hash_tool-presentation.docx
│   │   ├── hash_tool-presentation.pdf
│   │   └── manuel.md
│   ├── tests
│   │   ├── TODO -- tests
│   │   │   ├── _audit test.md
│   │   │   ├── _cours appliqué -- test.md
│   │   │   ├── _cours appliqué -- test.pdf
│   │   │   ├── _descriptif maj.md
│   │   │   ├── _protocole maj claude.md
│   │   │   ├── ci-cd.md
│   │   │   ├── docker-tests.md
│   │   │   ├── edge-cases.md
│   │   │   ├── fixtures.md
│   │   │   ├── index.md
│   │   │   ├── integration-tests.md
│   │   │   ├── regression-tests.md
│   │   │   ├── strategy.md
│   │   │   ├── tap-format.md
│   │   │   ├── test docker.md
│   │   │   ├── tests todo.txt
│   │   │   └── unit-tests.md
│   │   ├── 2026-02-26-17-13 -- manuel.md
│   │   ├── tests -- doc 1.md
│   │   └── tests -- doc 2.md
│   └── TODO.md
├── mon_dossier
│   ├── bases
│   │   ├── hashes_destination.b3
│   │   ├── hashes_source.b3
│   │   └── hashes_source.b3.meta.json
│   ├── destination
│   │   ├── fichier (1).txt
│   │   ├── fichier (2).txt
│   │   ├── fichier (3).txt
│   │   └── fichier (4).txt
│   ├── result
│   │   └── resultats_hashes_source
│   │       └── modifies.b3
│   └── source
│       ├── fichier (1).txt
│       ├── fichier (2).txt
│       ├── fichier (3).txt
│       └── fichier (4).txt
├── pipelines
│   ├── pipeline-amelioree.json
│   ├── pipeline-debug-deux-adresses.json
│   ├── pipeline-debug.json
│   ├── pipeline-veracrypt.json
│   └── pipeline.json
├── reports
│   └── template.html
├── site
│   ├── assets
│   │   ├── images
│   │   │   └── favicon.png
│   │   ├── javascripts
│   │   │   ├── lunr
│   │   │   │   ├── min
│   │   │   │   │   ├── lunr.ar.min.js
│   │   │   │   │   ├── lunr.da.min.js
│   │   │   │   │   ├── lunr.de.min.js
│   │   │   │   │   ├── lunr.du.min.js
│   │   │   │   │   ├── lunr.el.min.js
│   │   │   │   │   ├── lunr.es.min.js
│   │   │   │   │   ├── lunr.fi.min.js
│   │   │   │   │   ├── lunr.fr.min.js
│   │   │   │   │   ├── lunr.he.min.js
│   │   │   │   │   ├── lunr.hi.min.js
│   │   │   │   │   ├── lunr.hu.min.js
│   │   │   │   │   ├── lunr.hy.min.js
│   │   │   │   │   ├── lunr.it.min.js
│   │   │   │   │   ├── lunr.ja.min.js
│   │   │   │   │   ├── lunr.jp.min.js
│   │   │   │   │   ├── lunr.kn.min.js
│   │   │   │   │   ├── lunr.ko.min.js
│   │   │   │   │   ├── lunr.multi.min.js
│   │   │   │   │   ├── lunr.nl.min.js
│   │   │   │   │   ├── lunr.no.min.js
│   │   │   │   │   ├── lunr.pt.min.js
│   │   │   │   │   ├── lunr.ro.min.js
│   │   │   │   │   ├── lunr.ru.min.js
│   │   │   │   │   ├── lunr.sa.min.js
│   │   │   │   │   ├── lunr.stemmer.support.min.js
│   │   │   │   │   ├── lunr.sv.min.js
│   │   │   │   │   ├── lunr.ta.min.js
│   │   │   │   │   ├── lunr.te.min.js
│   │   │   │   │   ├── lunr.th.min.js
│   │   │   │   │   ├── lunr.tr.min.js
│   │   │   │   │   ├── lunr.vi.min.js
│   │   │   │   │   └── lunr.zh.min.js
│   │   │   │   ├── tinyseg.js
│   │   │   │   └── wordcut.js
│   │   │   ├── workers
│   │   │   │   ├── search.2c215733.min.js
│   │   │   │   └── search.2c215733.min.js.map
│   │   │   ├── bundle.79ae519e.min.js
│   │   │   └── bundle.79ae519e.min.js.map
│   │   └── stylesheets
│   │       ├── main.484c7ddc.min.css
│   │       ├── main.484c7ddc.min.css.map
│   │       ├── palette.ab4e12ef.min.css
│   │       └── palette.ab4e12ef.min.css.map
│   ├── development
│   │   ├── ROADMAP
│   │   │   └── index.html
│   │   ├── architecture
│   │   │   └── index.html
│   │   ├── changelog
│   │   │   └── index.html
│   │   └── contributing
│   │       └── index.html
│   ├── getting-started
│   │   └── index.html
│   ├── guides
│   │   ├── cron-ci
│   │   │   └── index.html
│   │   ├── nas-synology
│   │   │   └── index.html
│   │   └── veracrypt
│   │       └── index.html
│   ├── reference
│   │   ├── docker
│   │   │   └── index.html
│   │   ├── integrity-sh
│   │   │   └── index.html
│   │   └── runner-sh
│   │       └── index.html
│   ├── search
│   │   └── search_index.json
│   ├── spec
│   │   ├── api-interne
│   │   │   └── index.html
│   │   └── b3-format
│   │       └── index.html
│   ├── troubleshooting 
│   │   └── troubleshooting_1
│   │       └── index.html
│   ├── 404.html
│   ├── index.html
│   ├── sitemap.xml
│   └── sitemap.xml.gz
├── src
│   ├── lib
│   │   ├── core.sh
│   │   ├── report.sh
│   │   ├── results.sh
│   │   └── ui.sh
│   └── integrity.sh
├── tests
│   ├── run_tests.sh
│   ├── run_tests_core.sh
│   └── run_tests_pipeline.sh
├── .dockerignore
├── .gitignore
├── Dockerfile
├── README.md
├── docker-compose.yml
├── hash-tool
├── mkdocs.yml
├── runner.sh
├── temp commande.md
└── todo claude.md


# === Contenu des fichiers ===

--- Fichier : .dockerignore ---
# .dockerignore - hash_tool
#
# Exclut du contexte de build Docker ce qui n'est pas nécessaire.
# Réduit la taille du contexte envoyé au daemon.

# Données utilisateur - jamais dans l'image
mon_dossier/
*.b3

# Résultats
resultats/
~/integrity_resultats/

# Tests - non requis dans l'image de production
tests/

# Documentation - non requise dans l'image
docs/
autre/
reports/
*.md
!README.md

# Fichiers temporaires
temp.txt
*.tmp
*.log

# Outils de développement
.git/
.gitignore


--- Fichier : .gitignore ---
# == Données utilisateur =======================================================
*.b3

# == Résultats =================================================================
resultats/
integrity_resultats/

# == Docker ====================================================================
# Ne pas ignorer : Dockerfile, .dockerignore, docker-compose.yml, docker/
# Ignorer les artefacts de build local
.docker/

# == Fichiers temporaires ======================================================
# Exclure les fichiers contenant le mot "temp" n'importe où dans le nom
*temp*

*.tmp
*.log
*.bak

# == OS ========================================================================
.DS_Store
Thumbs.db
desktop.ini

# == Éditeurs =================================================================
.vscode/
.idea/
*.swp
*.swo
*~

# == doc perso =================================================================
hors_git/

# == fichiers utils de dev =================================================================
.concat_config.json
gentxt.txt

# == doc généree =================================================================
site/


--- Fichier : Dockerfile ---
# =============================================================================
# hash_tool - Dockerfile
#
# Image Alpine légère (~15 Mo) avec b3sum et jq.
# Supporte linux/amd64 et linux/arm64 (NAS Synology, Raspberry Pi, etc.)
#
# b3sum est installé depuis les packages Alpine (community) - plus fiable
# que le téléchargement manuel depuis GitHub Releases.
#
# Build :
#   docker build -t hash_tool .
#   docker build --platform linux/arm64 -t hash_tool:arm64 .
#
# Utilisation :
#   docker run --rm -v /mes/donnees:/data hash_tool verify /data/base.b3
#   docker run --rm -v /mes/donnees:/data -v /mes/bases:/bases hash_tool compute /data /bases/hashes.b3
#   docker run --rm -v /chemin/pipeline.json:/pipelines/pipeline.json \
#              -v /mes/donnees:/data -v /mes/bases:/bases -v /mes/resultats:/resultats \
#              hash_tool runner /pipelines/pipeline.json
# =============================================================================

FROM alpine:3.19

LABEL maintainer="hash_tool" \
      description="Vérification d'intégrité BLAKE3 - integrity.sh + runner.sh" \
      org.opencontainers.image.source="https://github.com/hash_tool"

# Toutes les dépendances depuis apk - pas de wget, pas de binaire externe
# b3sum est dans Alpine community depuis v3.15
RUN apk add --no-cache \
      bash \
      jq \
      b3sum \
      coreutils \
      findutils \
    && rm -rf /var/cache/apk/*

# == Copie des scripts ========================================================

WORKDIR /app

COPY runner.sh           ./runner.sh
COPY src/integrity.sh    ./src/integrity.sh
COPY src/lib/report.sh   ./src/lib/report.sh

RUN chmod +x runner.sh src/integrity.sh src/lib/report.sh

# == Entrypoint ===============================================================

COPY docker/entrypoint.sh /entrypoint.sh
RUN chmod +x /entrypoint.sh

# == Volumes ==================================================================
#
# /data       → données à hacher (montage en lecture seule recommandé)
# /bases      → fichiers .b3 (lecture/écriture)
# /pipelines  → fichiers pipeline.json
# /resultats  → résultats compare/verify
#
VOLUME ["/data", "/bases", "/pipelines", "/resultats"]

# RESULTATS_DIR par défaut redirigé vers /resultats (volume monté)
ENV RESULTATS_DIR=/resultats

ENTRYPOINT ["/entrypoint.sh"]
CMD ["help"]

--- Fichier : README.md ---
# hash_tool - Vérification d'intégrité BLAKE3

voir ReadTheDocs 



--- Fichier : docker-compose.yml ---
# docker-compose.yml - hash_tool
#
# Cas d'usage typiques :
#   docker compose run --rm integrity compute /data /bases/hashes.b3
#   docker compose run --rm integrity verify  /bases/hashes.b3 /data
#   docker compose run --rm integrity compare /bases/old.b3 /bases/new.b3
#   docker compose run --rm pipeline
#
# Adapter les volumes (section x-volumes) selon l'environnement :
#   - Windows/WSL   : /mnt/c/Users/TonNom/...
#   - NAS Synology  : /volume1/...
#   - Serveur Debian: /srv/...

# == Chemins à adapter ========================================================
x-volumes:
  data:      &vol-data      /chemin/vers/donnees     # données à hacher (lecture seule)
  bases:     &vol-bases     /chemin/vers/bases        # fichiers .b3
  pipelines: &vol-pipelines /chemin/vers/pipelines   # fichiers pipeline.json
  resultats: &vol-resultats /chemin/vers/resultats   # résultats compare/verify

# == Services =================================================================
services:

  # Service principal - compute / verify / compare
  integrity:
    image: hash_tool
    build:
      context: .
      dockerfile: Dockerfile
    volumes:
      - *vol-data:/data:ro
      - *vol-bases:/bases
      - *vol-resultats:/resultats
    environment:
      - RESULTATS_DIR=/resultats
    # Pas de commande par défaut - passer la commande à docker compose run
    # Ex : docker compose run --rm integrity verify /bases/hashes.b3 /data

  # Service pipeline - exécute runner.sh avec pipeline.json monté
  pipeline:
    image: hash_tool
    build:
      context: .
      dockerfile: Dockerfile
    volumes:
      - *vol-data:/data:ro
      - *vol-bases:/bases
      - *vol-pipelines:/pipelines
      - *vol-resultats:/resultats
    environment:
      - RESULTATS_DIR=/resultats
    command: ["runner", "/pipelines/pipeline.json"]

  # Service cron - vérification périodique (optionnel)
  # Nécessite : docker compose up -d cron
  cron:
    image: hash_tool
    build:
      context: .
      dockerfile: Dockerfile
    volumes:
      - *vol-data:/data:ro
      - *vol-bases:/bases:ro
      - *vol-resultats:/resultats
    environment:
      - RESULTATS_DIR=/resultats
      - CRON_SCHEDULE=0 3 * * *       # 03h00 chaque nuit
      - CRON_BASE=/bases/hashes.b3    # base à vérifier
    # Le service cron tourne en boucle - nécessite l'image étendue avec crond
    # Voir docs/docker-cron.md pour le setup complet
    command: ["shell"]
    profiles: ["cron"]   # non démarré par défaut (docker compose --profile cron up)
    restart: unless-stopped


--- Fichier : hash-tool ---
#!/usr/bin/env bash
# hash-tool - Interface CLI unique pour hash_tool
#
# Abstraction de la couche d'exécution : détecte automatiquement si l'exécution
# native est possible (b3sum disponible), sinon délègue à Docker.
#
# Usage :
#   hash-tool <commande> [options]
#
# Commandes :
#   compute     Calcule les empreintes d'un dossier.
#   verify      Vérifie l'intégrité d'un dossier à partir d'une base.
#   compare     Compare deux bases d'empreintes.
#   runner      Exécute un pipeline JSON.
#   list        Liste les bases d'empreintes disponibles dans un dossier.
#   diff        Affiche les différences entre une base et un dossier courant.
#   stats       Affiche des statistiques sur une base d'empreintes.
#   check-env   Analyse l'environnement d'exécution (natif ou conteneur).
#   version     Affiche la version du logiciel.
#   help        Affiche cette aide.
#
# Dépendances natives : bash >= 4, b3sum, jq
# Dépendances Docker  : docker (image hash_tool)

set -euo pipefail

# == Version ===================================================================

HASH_TOOL_VERSION="2.0.0"

# == Résolution du répertoire du script ========================================

SCRIPT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"
INTEGRITY="$SCRIPT_DIR/src/integrity.sh"
RUNNER="$SCRIPT_DIR/runner.sh"
DOCKER_IMAGE="${HASH_TOOL_DOCKER_IMAGE:-hash_tool}"

# == Couleurs ==================================================================

_red()    { echo -e "\033[0;31m$*\033[0m"; }
_green()  { echo -e "\033[0;32m$*\033[0m"; }
_yellow() { echo -e "\033[0;33m$*\033[0m"; }
_cyan()   { echo -e "\033[0;36m$*\033[0m"; }
_dim()    { echo -e "\033[2m$*\033[0m"; }
_bold()   { echo -e "\033[1m$*\033[0m"; }

# == Détection de l'environnement ==============================================

_native_available() {
  command -v b3sum &>/dev/null \
    && command -v jq   &>/dev/null \
    && [ -f "$INTEGRITY" ] \
    && [ -x "$INTEGRITY" ]
}

_docker_available() {
  command -v docker &>/dev/null \
    && docker image inspect "$DOCKER_IMAGE" &>/dev/null 2>&1
}

_detect_exec_mode() {
  if _native_available; then
    echo "native"
  elif _docker_available; then
    echo "docker"
  else
    echo "none"
  fi
}

EXEC_MODE="$(_detect_exec_mode)"

# == Helpers ===================================================================

die() { echo "ERREUR : $*" >&2; exit 1; }

_require_native_or_die() {
  [ "$EXEC_MODE" = "native" ] || die "Exécution native requise pour cette commande (b3sum, jq, integrity.sh introuvables)."
}

# Argument parser : extrait les options nommées et les positionne dans des variables
# Usage : _parse_args "$@"  → positionne OPT_* variables
_parse_args() {
  OPT_DATA=""
  OPT_BASE=""
  OPT_OLD=""
  OPT_NEW=""
  OPT_PIPELINE=""
  OPT_SAVE=""
  OPT_META=""
  OPT_QUIET=0
  OPT_VERBOSE=0
  OPT_READONLY=0
  OPT_EXTRA=()

  while [[ $# -gt 0 ]]; do
    case "$1" in
      -data)      OPT_DATA="$2";     shift 2 ;;
      -base)      OPT_BASE="$2";     shift 2 ;;
      -old)       OPT_OLD="$2";      shift 2 ;;
      -new)       OPT_NEW="$2";      shift 2 ;;
      -pipeline)  OPT_PIPELINE="$2"; shift 2 ;;
      -save)      OPT_SAVE="$2";     shift 2 ;;
      -meta)      OPT_META="$2";     shift 2 ;;
      -quiet)     OPT_QUIET=1;       shift   ;;
      -verbose)   OPT_VERBOSE=1;     shift   ;;
      -readonly)  OPT_READONLY=1;    shift   ;;
      -help|--help|-h) return 99     ;;  # signal d'aide
      *)          OPT_EXTRA+=("$1"); shift   ;;
    esac
  done
}

# == Sidecar file ==============================================================

# _sidecar_write <b3_path> <data_dir> [meta_comment]
_sidecar_write() {
  local b3_path="$1"
  local data_dir="$2"
  local comment="${3:-}"
  local sidecar_path="${b3_path}.meta.json"

  local nb_files
  nb_files=$(wc -l < "$b3_path" 2>/dev/null || echo 0)

  jq -n \
    --arg version  "hash-tool v${HASH_TOOL_VERSION}" \
    --arg date     "$(date -u +%Y-%m-%dT%H:%M:%SZ)" \
    --arg comment  "$comment" \
    --arg dir      "$data_dir" \
    --argjson nb   "$nb_files" \
    --argjson ro   "$OPT_READONLY" \
    '{
      created_by: $version,
      date:       $date,
      comment:    $comment,
      parameters: {
        directory:  $dir,
        hash_algo:  "blake3",
        readonly:   ($ro == 1),
        nb_files:   $nb
      }
    }' > "$sidecar_path"

  echo "Sidecar : $sidecar_path"
}

# _sidecar_read <b3_path>  →  affiche le sidecar si présent
_sidecar_read() {
  local b3_path="$1"
  local sidecar_path="${b3_path}.meta.json"
  if [ -f "$sidecar_path" ]; then
    echo "--- Métadonnées (sidecar) ---"
    jq '.' "$sidecar_path" 2>/dev/null || cat "$sidecar_path"
    echo "-----------------------------"
  fi
}

# == Exécution native vs Docker ================================================

# Wrapper : exécute integrity.sh en natif ou via Docker
_run_integrity() {
  if [ "$EXEC_MODE" = "native" ]; then
    local quiet_flag=""
    (( OPT_QUIET )) && quiet_flag="--quiet"
    bash "$INTEGRITY" $quiet_flag "$@"
  elif [ "$EXEC_MODE" = "docker" ]; then
    _run_docker_integrity "$@"
  else
    die "Aucun environnement d'exécution disponible. Installez b3sum+jq ou construisez l'image Docker '${DOCKER_IMAGE}'."
  fi
}

# Wrapper Docker pour integrity.sh
_run_docker_integrity() {
  local args=("$@")
  # Volumes à monter selon la commande
  local volumes=()

  case "${args[0]}" in
    compute)
      volumes+=(-v "${args[1]}:/data:ro" -v "$(dirname "${args[2]}"):/bases")
      set -- compute /data "$(basename "${args[2]}")"
      ;;
    verify)
      local base_dir; base_dir="$(dirname "${args[1]}")"
      local base_name; base_name="$(basename "${args[1]}")"
      volumes+=(-v "${base_dir}:/bases:ro")
      [ -n "${args[2]:-}" ] && volumes+=(-v "${args[2]}:/data:ro")
      set -- verify "/bases/${base_name}" ${args[2]:+/data}
      ;;
    compare)
      local dir_a; dir_a="$(dirname "${args[1]}")"
      local dir_b; dir_b="$(dirname "${args[2]}")"
      volumes+=(-v "${dir_a}:/bases_a:ro" -v "${dir_b}:/bases_b:ro")
      if [ -n "${RESULTATS_DIR:-}" ]; then
        volumes+=(-v "${RESULTATS_DIR}:/resultats")
      fi
      set -- compare "/bases_a/$(basename "${args[1]}")" "/bases_b/$(basename "${args[2]}")"
      ;;
    *)
      die "Commande non supportée en mode Docker : ${args[0]}"
      ;;
  esac

  docker run --rm "${volumes[@]}" \
    -e RESULTATS_DIR="${RESULTATS_DIR:-/resultats}" \
    "$DOCKER_IMAGE" "$@"
}

# == Commandes =================================================================

# _check_help <subcmd> "$@"
# Si le premier argument positionnel est "help", affiche l'aide de la sous-commande
# et quitte. À appeler EN TÊTE de chaque cmd_* avant _parse_args.
_check_help() {
  local subcmd="$1"
  shift
  for arg in "$@"; do
    case "$arg" in
      help|--help|-h)
        cmd_help "$subcmd"
        exit 0
        ;;
    esac
  done
}

cmd_compute() {
  _check_help compute "$@"
  _parse_args "$@"

  # Vérification des paramètres obligatoires
  [ -n "$OPT_DATA" ] || die "compute : -data <dossier> requis."
  [ -d "$OPT_DATA" ] || die "compute : dossier introuvable : $OPT_DATA"

  # 1. Préparation du dossier de sauvegarde
  local save_dir="${OPT_SAVE:-.}"
  mkdir -p "$save_dir"
  
  # 2. Calcul du chemin ABSOLU du dossier de sauvegarde pour le sous-shell
  local save_dir_abs
  save_dir_abs="$(cd "$save_dir" && pwd)"
  
  # 3. Détermination du nom du fichier .b3
  local data_basename
  data_basename="$(basename "$(realpath "$OPT_DATA")")"
  local b3_file="${save_dir_abs}/hashes_${data_basename}.b3"

  # 4. Exécution dans un sous-shell
  # On utilise des guillemets autour de "$OPT_DATA" et "$b3_file" pour gérer les espaces
  (
    cd "$OPT_DATA" || exit 1
    _run_integrity compute "." "$b3_file"
  )

  # 5. Écriture du Sidecar (Métadonnées)
  # On vérifie si le fichier .b3 a bien été créé avant d'écrire le sidecar
  if [ -f "$b3_file" ]; then
    local data_path_abs
    data_path_abs="$(realpath "$OPT_DATA")"
    _sidecar_write "$b3_file" "$data_path_abs" "$OPT_META"
  fi
}

cmd_verify() {
  _check_help verify "$@"
  _parse_args "$@"
  [ -n "$OPT_BASE" ] || die "verify : -base <fichier.b3> requis."

  if [ -n "$OPT_SAVE" ]; then
    export RESULTATS_DIR="$OPT_SAVE"
    mkdir -p "$OPT_SAVE"
  fi

  _sidecar_read "$OPT_BASE"
  _run_integrity verify "$OPT_BASE" ${OPT_DATA:+"$OPT_DATA"}
}

cmd_compare() {
  _check_help compare "$@"
  _parse_args "$@"
  [ -n "$OPT_OLD" ] || die "compare : -old <ancienne.b3> requis."
  [ -n "$OPT_NEW" ] || die "compare : -new <nouvelle.b3> requis."

  if [ -n "$OPT_SAVE" ]; then
    export RESULTATS_DIR="$OPT_SAVE"
    mkdir -p "$OPT_SAVE"
  fi

  _sidecar_read "$OPT_OLD"
  _sidecar_read "$OPT_NEW"
  _run_integrity compare "$OPT_OLD" "$OPT_NEW"
}

cmd_runner() {
  _check_help runner "$@"
  _parse_args "$@"

  local pipeline_file="${OPT_PIPELINE:-${SCRIPT_DIR}/pipelines/pipeline.json}"
  [ -f "$pipeline_file" ] || die "runner : pipeline introuvable : $pipeline_file"

  if [ -n "$OPT_SAVE" ]; then
    export RESULTATS_DIR="$OPT_SAVE"
    mkdir -p "$OPT_SAVE"
  fi

  if [ "$EXEC_MODE" = "native" ]; then
    bash "$RUNNER" "$pipeline_file"
  elif [ "$EXEC_MODE" = "docker" ]; then
    local pipeline_dir; pipeline_dir="$(dirname "$(realpath "$pipeline_file")")"
    local pipeline_name; pipeline_name="$(basename "$pipeline_file")"
    docker run --rm \
      -v "${pipeline_dir}:/pipelines:ro" \
      -e RESULTATS_DIR="${RESULTATS_DIR:-/resultats}" \
      "$DOCKER_IMAGE" runner "/pipelines/${pipeline_name}"
  else
    die "Aucun environnement d'exécution disponible."
  fi
}

cmd_list() {
  _check_help list "$@"
  _parse_args "$@"
  local dir="${OPT_DATA:-${OPT_BASE:-.}}"

  echo "=== Bases d'empreintes dans : $dir ==="
  echo ""

  local found=0
  while IFS= read -r -d '' f; do
    found=1
    local nb_files
    nb_files=$(wc -l < "$f" 2>/dev/null || echo "?")
    local size
    size=$(du -sh "$f" 2>/dev/null | cut -f1 || echo "?")
    local sidecar_flag=""
    [ -f "${f}.meta.json" ] && sidecar_flag=" [+meta]"

    printf "  %-40s  %6s fichiers  %5s%s\n" "$(basename "$f")" "$nb_files" "$size" "$sidecar_flag"

    # Affiche le commentaire du sidecar si présent
    if [ -f "${f}.meta.json" ]; then
      local comment date
      comment=$(jq -r '.comment // empty' "${f}.meta.json" 2>/dev/null || true)
      date=$(jq -r '.date // empty' "${f}.meta.json" 2>/dev/null || true)
      [ -n "$comment" ] && printf "  %s→ %s (%s)\n" "   " "$comment" "$date"
    fi
  done < <(find "$dir" -maxdepth 2 -name "*.b3" -type f -print0 | sort -z)

  if (( found == 0 )); then
    echo "  Aucune base .b3 trouvée dans : $dir"
  fi
}

cmd_diff() {
  _parse_args "$@"
  [ -n "$OPT_BASE" ] || die "diff : -base <fichier.b3> requis."

  local workdir="${OPT_DATA:-.}"
  [ -d "$workdir" ] || die "diff : dossier introuvable : $workdir"

  echo "=== DIFF : $(basename "$OPT_BASE") vs $workdir ==="
  echo ""

  # Fichiers dans la base
  local tmp_base tmp_dir
  tmp_base=$(mktemp)
  tmp_dir=$(mktemp)
  trap 'rm -f "$tmp_base" "$tmp_dir"' EXIT

  # Extrait les chemins relatifs de la base (colonne 2+)
  awk '{ print substr($0,67) }' "$OPT_BASE" | sort > "$tmp_base"

  # Parcourt le dossier courant avec le même préfixe que la base
  local prefix
  prefix=$(awk '{ p=substr($0,67); sub(/[^/]+$/, "", p); print p; exit }' "$OPT_BASE" 2>/dev/null || echo "./")

  find "$workdir" -type f | sed "s|^${workdir%/}/||" | sed "s|^|${prefix}|" | sort > "$tmp_dir"

  local disparus nouveaux
  disparus=$(comm -23 "$tmp_base" "$tmp_dir" | wc -l)
  nouveaux=$(comm -13 "$tmp_base" "$tmp_dir" | wc -l)

  echo "  Fichiers disparus depuis la base : $disparus"
  if (( disparus > 0 )); then
    comm -23 "$tmp_base" "$tmp_dir" | while IFS= read -r f; do
      echo "    - $f"
    done
  fi
  echo ""
  echo "  Nouveaux fichiers non indexés : $nouveaux"
  if (( nouveaux > 0 )); then
    comm -13 "$tmp_base" "$tmp_dir" | while IFS= read -r f; do
      echo "    + $f"
    done
  fi

  rm -f "$tmp_base" "$tmp_dir"
  trap - EXIT
}

cmd_stats() {
  _parse_args "$@"
  local b3_file="${OPT_BASE:-${OPT_EXTRA[0]:-}}"
  [ -n "$b3_file" ] || die "stats : -base <fichier.b3> requis."
  [ -f "$b3_file" ] || die "stats : fichier introuvable : $b3_file"

  echo "=== Statistiques : $(basename "$b3_file") ==="
  echo ""

  local nb_files
  nb_files=$(wc -l < "$b3_file")
  local file_size
  file_size=$(du -sh "$b3_file" | cut -f1)
  local b3_path
  b3_path=$(realpath "$b3_file")

  printf "  Fichier base     : %s\n" "$b3_path"
  printf "  Taille fichier   : %s\n" "$file_size"
  printf "  Fichiers indexés : %s\n" "$nb_files"

  # Extensions les plus fréquentes
  echo ""
  echo "  Extensions :"
  awk '{print $NF}' "$b3_file" \
    | grep -oE '\.[^./]+$' \
    | sort | uniq -c | sort -rn | head -10 \
    | while read -r count ext; do
        printf "    %-12s  %5s fichiers\n" "$ext" "$count"
      done

  # Sidecar
  if [ -f "${b3_file}.meta.json" ]; then
    echo ""
    _sidecar_read "$b3_file"
  fi
}

cmd_check_env() {
  echo "=== check-env : Analyse de l'environnement ==="
  echo ""

  # b3sum
  if command -v b3sum &>/dev/null; then
    local b3ver; b3ver=$(b3sum --version 2>/dev/null || echo "version inconnue")
    _green "  [OK] b3sum disponible : $b3ver"
  else
    _red   "  [KO] b3sum introuvable (requis pour exécution native)"
  fi

  # jq
  if command -v jq &>/dev/null; then
    local jqver; jqver=$(jq --version 2>/dev/null || echo "version inconnue")
    _green "  [OK] jq disponible : $jqver"
  else
    _red   "  [KO] jq introuvable (requis pour pipelines JSON)"
  fi

  # bash
  _green "  [OK] bash $BASH_VERSION"
  if (( BASH_VERSINFO[0] < 4 )); then
    _red "  [KO] bash >= 4 requis"
  fi

  # integrity.sh
  if [ -f "$INTEGRITY" ] && [ -x "$INTEGRITY" ]; then
    _green "  [OK] integrity.sh présent et exécutable : $INTEGRITY"
  else
    _red   "  [KO] integrity.sh introuvable ou non exécutable : $INTEGRITY"
  fi

  # runner.sh
  if [ -f "$RUNNER" ] && [ -x "$RUNNER" ]; then
    _green "  [OK] runner.sh présent et exécutable : $RUNNER"
  else
    _red   "  [KO] runner.sh introuvable ou non exécutable : $RUNNER"
  fi

  # Docker
  echo ""
  if command -v docker &>/dev/null; then
    local dver; dver=$(docker --version 2>/dev/null || echo "version inconnue")
    _green "  [OK] Docker disponible : $dver"
    if docker image inspect "$DOCKER_IMAGE" &>/dev/null 2>&1; then
      _green "  [OK] Image Docker '$DOCKER_IMAGE' disponible"
    else
      _yellow "  [--] Image Docker '$DOCKER_IMAGE' absente (docker build requis)"
    fi
  else
    _yellow "  [--] Docker non disponible (optionnel)"
  fi

  echo ""
  echo "  Mode d'exécution sélectionné : $(_bold "$EXEC_MODE")"

  case "$EXEC_MODE" in
    native) _green "  → Exécution native active" ;;
    docker) _yellow "  → Exécution Docker active (fallback)" ;;
    none)   _red    "  → Aucun environnement disponible - impossible d'exécuter" ;;
  esac
}

cmd_version() {
  echo "hash-tool v${HASH_TOOL_VERSION}"
  echo "Moteur : BLAKE3 (b3sum)"
  if command -v b3sum &>/dev/null; then
    b3sum --version 2>/dev/null || true
  fi
}

cmd_help() {
  local subcmd="${1:-}"

  case "$subcmd" in
    compute)
      cat <<'EOF'
hash-tool compute -data <dossier> [-save <dossier>] [-meta <texte>] [-quiet] [-readonly]

  Calcule les empreintes BLAKE3 de tous les fichiers du dossier source.
  Génère un fichier .b3 et un sidecar .meta.json associé.

  Options :
    -data <dossier>   Dossier à analyser (requis).
    -save <dossier>   Dossier de sortie pour le .b3 (défaut : répertoire courant).
    -meta <texte>     Commentaire stocké dans le sidecar JSON.
    -quiet            Mode silencieux (pas de sortie terminal).
    -readonly         Documente le flag dans le sidecar (pas d'effet sur b3sum).

  Exemple :
    hash-tool compute -data ./donnees -save ./bases -meta "Snapshot initial"
EOF
      ;;
    verify)
      cat <<'EOF'
hash-tool verify -base <fichier.b3> [-data <dossier>] [-save <dossier>] [-quiet]

  Vérifie l'intégrité d'un dossier à partir d'une base d'empreintes.

  Options :
    -base <fichier.b3>  Base d'empreintes (requis).
    -data <dossier>     Dossier à vérifier (défaut : répertoire courant au moment du compute).
    -save <dossier>     Dossier de sortie des résultats (surcharge RESULTATS_DIR).
    -quiet              Mode silencieux.

  Exemple :
    hash-tool verify -base ./bases/hashes_donnees.b3 -data ./donnees
EOF
      ;;
    compare)
      cat <<'EOF'
hash-tool compare -old <ancienne.b3> -new <nouvelle.b3> [-save <dossier>]

  Compare deux bases d'empreintes et produit un rapport HTML.

  Options :
    -old <ancienne.b3>  Ancienne base (référence).
    -new <nouvelle.b3>  Nouvelle base (à comparer).
    -save <dossier>     Dossier de sortie des résultats.

  Exemple :
    hash-tool compare -old snap1.b3 -new snap2.b3 -save ./rapports
EOF
      ;;
    runner)
      cat <<'EOF'
hash-tool runner -pipeline <fichier.json> [-save <dossier>]

  Exécute un pipeline JSON définissant une suite d'opérations.
  Format pipeline : voir pipelines/pipeline-amelioree.json

  Options :
    -pipeline <fichier.json>  Fichier pipeline (défaut : pipelines/pipeline.json).
    -save <dossier>           Dossier de résultats global (surcharge RESULTATS_DIR).

  Exemple :
    hash-tool runner -pipeline ./pipelines/mon_pipeline.json -save ./resultats
EOF
      ;;
    list)
      cat <<'EOF'
hash-tool list [-data <dossier>]

  Liste toutes les bases .b3 disponibles dans un dossier, avec leurs
  métadonnées sidecar si présentes.

  Options :
    -data <dossier>  Dossier à parcourir (défaut : répertoire courant).

  Exemple :
    hash-tool list -data ./bases
EOF
      ;;
    diff)
      cat <<'EOF'
hash-tool diff -base <fichier.b3> [-data <dossier>]

  Affiche les différences entre une base d'empreintes et l'état actuel
  d'un dossier (fichiers disparus, nouveaux fichiers non indexés).
  Ne recalcule pas les hashes - uniquement comparaison des chemins.

  Options :
    -base <fichier.b3>  Base de référence (requis).
    -data <dossier>     Dossier courant à comparer (défaut : .).

  Exemple :
    hash-tool diff -base ./bases/hashes_donnees.b3 -data ./donnees
EOF
      ;;
    stats)
      cat <<'EOF'
hash-tool stats -base <fichier.b3>

  Affiche des statistiques sur une base d'empreintes :
  nombre de fichiers, taille, distribution des extensions, métadonnées sidecar.

  Options :
    -base <fichier.b3>  Base à analyser (requis).

  Exemple :
    hash-tool stats -base ./bases/hashes_donnees.b3
EOF
      ;;
    check-env)
      cat <<'EOF'
hash-tool check-env

  Analyse l'environnement d'exécution : vérifie la disponibilité de
  b3sum, jq, bash >= 4, integrity.sh, runner.sh et Docker.
  Indique le mode d'exécution sélectionné (natif ou Docker).
EOF
      ;;
    *)
      cat <<EOF
hash-tool v${HASH_TOOL_VERSION} - Vérification d'intégrité BLAKE3

Usage : hash-tool <commande> [options]

Commandes :
  compute     Calcule les empreintes d'un dossier.
  verify      Vérifie l'intégrité d'un dossier à partir d'une base.
  compare     Compare deux bases d'empreintes.
  runner      Exécute un pipeline JSON.
  list        Liste les bases d'empreintes disponibles.
  diff        Affiche les différences entre une base et un dossier.
  stats       Affiche des statistiques sur une base.
  check-env   Analyse l'environnement d'exécution.
  version     Affiche la version.
  help        Affiche cette aide (ou 'help <commande>' pour le détail).

Options générales :
  -data <chemin>      Dossier à analyser.
  -base <chemin>      Fichier base d'empreintes (.b3).
  -old <chemin>       Ancienne base (pour compare).
  -new <chemin>       Nouvelle base (pour compare).
  -pipeline <chemin>  Fichier pipeline JSON (pour runner).
  -save <chemin>      Dossier de sortie pour les résultats.
  -meta <texte>       Commentaire pour le sidecar JSON (compute).
  -quiet              Mode silencieux.
  -verbose            Mode verbeux.
  -readonly           Marque le compute comme lecture seule dans le sidecar.

Mode d'exécution : $EXEC_MODE
  L'interface reste identique quel que soit le mode d'exécution.
  Docker est utilisé en fallback si l'exécution native est impossible.

Exemples :
  hash-tool compute   -data ./donnees -save ./bases -meta "Snapshot initial"
  hash-tool verify    -base ./bases/hashes_donnees.b3 -data ./donnees
  hash-tool compare   -old ancien.b3 -new nouveau.b3 -save ./rapports
  hash-tool runner    -pipeline ./pipelines/pipeline.json
  hash-tool list      -data ./bases
  hash-tool diff      -base ./bases/hashes_donnees.b3 -data ./donnees
  hash-tool stats     -base ./bases/hashes_donnees.b3
  hash-tool check-env
EOF
      ;;
  esac
}

# == Dispatch ==================================================================

CMD="${1:-help}"
shift || true

case "$CMD" in
  compute)   cmd_compute   "$@" ;;
  verify)    cmd_verify    "$@" ;;
  compare)   cmd_compare   "$@" ;;
  runner)    cmd_runner    "$@" ;;
  list)      cmd_list      "$@" ;;
  diff)      cmd_diff      "$@" ;;
  stats)     cmd_stats     "$@" ;;
  check-env) cmd_check_env "$@" ;;
  version)   cmd_version   "$@" ;;
  help|-h|--help) cmd_help "$@" ;;
  *)
    echo "Commande inconnue : '$CMD'" >&2
    echo "Utiliser : hash-tool help" >&2
    exit 1
    ;;
esac


--- Fichier : mkdocs.yml ---
site_name: hash_tool
site_description: Vérification d'intégrité de fichiers par hachage BLAKE3
site_author: hash_tool
docs_dir: docs
site_dir: site

repo_url: https://github.com/hash_tool/hash_tool
repo_name: hash_tool/hash_tool
edit_uri: edit/main/docs/

theme:
  name: material
  language: fr
  palette:
    - scheme: slate
      primary: indigo
      accent: indigo
      toggle:
        icon: material/brightness-4
        name: Passer en mode clair
    - scheme: default
      primary: indigo
      accent: indigo
      toggle:
        icon: material/brightness-7
        name: Passer en mode sombre
  font:
    text: DM Sans
    code: JetBrains Mono
  features:
    - navigation.tabs
    - navigation.tabs.sticky
    - navigation.sections
    - navigation.expand
    - navigation.top
    - navigation.footer
    - search.suggest
    - search.highlight
    - content.code.copy
    - content.code.annotate
    - content.tabs.link
  icon:
    repo: fontawesome/brands/github

plugins:
  - search:
      lang: fr

markdown_extensions:
  - admonition
  - pymdownx.details
  - pymdownx.superfences
  - pymdownx.highlight:
      anchor_linenums: true
      line_spans: __span
      pygments_lang_class: true
  - pymdownx.inlinehilite
  - pymdownx.snippets
  - pymdownx.tabbed:
      alternate_style: true
  - tables
  - attr_list
  - md_in_html
  - toc:
      permalink: true

extra:
  social:
    - icon: fontawesome/brands/github
      link: https://github.com/hash_tool/hash_tool

nav:
  - Accueil: index.md
  - Démarrage rapide: getting-started.md

  - Référence:
    - integrity.sh: reference/integrity-sh.md
    - runner.sh & pipeline.json: reference/runner-sh.md
    - Docker: reference/docker.md

  - Spécifications:
    - Format .b3: spec/b3-format.md
    - API interne: spec/api-interne.md

  - Guides:
    - VeraCrypt & disques multiples: guides/veracrypt.md
    - CI / Cron: guides/cron-ci.md
    - NAS Synology: guides/nas-synology.md

  - Développement:
    - Architecture: development/architecture.md
    - Contribuer & Tests: development/contributing.md
    - Roadmap & Positionnement: development/roadmap.md
    - Changelog: development/changelog.md

  - Aide:
    - Troubleshooting: troubleshooting /troubleshooting_1.md

--- Fichier : runner.sh ---
#!/usr/bin/env bash
# runner.sh - Exécuteur de pipeline integrity.sh depuis pipeline.json
#
# Supporte deux formats de pipeline :
#
#   Format legacy (rétrocompatible) :
#     { "pipeline": [ { "op": "compute", "source": "...", "bases": "...", "nom": "..." }, ... ] }
#
#   Format étendu (recommandé) :
#     { "pipeline": [ {
#         "type":        "compute",
#         "params":      { "input": "...", "output_dir": "...", "filename": "..." },
#         "options":     { "quiet": false, "verbose": false, "readonly": false },
#         "meta":        { "comment": "..." },
#         "description": "Texte explicatif de l'étape"
#       }, ... ] }
#
# Usage :
#   ./runner.sh                          # lit pipelines/pipeline.json
#   ./runner.sh /chemin/pipeline.json    # config explicite
#
# Dépendances : bash >= 4, jq, src/integrity.sh

set -euo pipefail

# == Chemins ===================================================================

SCRIPT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"
INTEGRITY="$SCRIPT_DIR/src/integrity.sh"
CONFIG="${1:-$SCRIPT_DIR/pipelines/pipeline.json}"

# == Prérequis =================================================================

(( BASH_VERSINFO[0] >= 4 )) || { echo "ERREUR : bash >= 4 requis" >&2; exit 1; }

command -v jq &>/dev/null  || { echo "ERREUR : jq non trouvé (apt install jq)" >&2; exit 1; }
[ -f "$INTEGRITY" ]        || { echo "ERREUR : src/integrity.sh introuvable : $INTEGRITY" >&2; exit 1; }
[ -f "$CONFIG" ]           || { echo "ERREUR : config introuvable : $CONFIG" >&2; exit 1; }

# == Validation JSON ===========================================================

jq empty "$CONFIG" 2>/dev/null || { echo "ERREUR : JSON invalide : $CONFIG" >&2; exit 1; }

nb_ops=$(jq '.pipeline | length' "$CONFIG")
(( nb_ops > 0 )) || { echo "ERREUR : tableau .pipeline vide ou absent" >&2; exit 1; }

# == Fonctions utilitaires =====================================================

die() { echo "ERREUR : $*" >&2; exit 1; }

# Détecte si un bloc utilise le format legacy ("op") ou étendu ("type")
_bloc_format() {
  local idx="$1"
  local has_op has_type
  has_op=$(jq -r --argjson i "$idx" '.pipeline[$i].op // empty' "$CONFIG")
  has_type=$(jq -r --argjson i "$idx" '.pipeline[$i].type // empty' "$CONFIG")
  if [ -n "$has_type" ]; then
    echo "extended"
  elif [ -n "$has_op" ]; then
    echo "legacy"
  else
    echo "unknown"
  fi
}

# Lit un champ JSON obligatoire dans le format legacy
require_field() {
  local idx="$1" field="$2"
  local val
  val=$(jq -r --argjson i "$idx" '.pipeline[$i].'"$field" "$CONFIG")
  if [ "$val" = "null" ] || [ -z "$val" ]; then
    die "Bloc #$((idx+1)) : champ '$field' manquant ou vide."
  fi
  echo "$val"
}

# Lit un champ JSON optionnel - retourne "" si absent
optional_field() {
  local idx="$1" field="$2"
  local val
  val=$(jq -r --argjson i "$idx" '.pipeline[$i].'"$field // empty" "$CONFIG" 2>/dev/null || true)
  echo "${val:-}"
}

# Lit un champ dans params{} du format étendu (obligatoire)
require_param() {
  local idx="$1" param="$2"
  local val
  val=$(jq -r --argjson i "$idx" ".pipeline[\$i].params.${param} // empty" "$CONFIG" 2>/dev/null || true)
  [ -n "$val" ] || die "Bloc #$((idx+1)) : params.${param} manquant ou vide."
  echo "$val"
}

# Lit un champ dans params{} du format étendu (optionnel)
optional_param() {
  local idx="$1" param="$2"
  local val
  val=$(jq -r --argjson i "$idx" ".pipeline[\$i].params.${param} // empty" "$CONFIG" 2>/dev/null || true)
  echo "${val:-}"
}

# Lit un flag dans options{} du format étendu (retourne 0 si absent/false)
option_flag() {
  local idx="$1" opt="$2"
  local val
  val=$(jq -r --argjson i "$idx" ".pipeline[\$i].options.${opt} // false" "$CONFIG" 2>/dev/null || echo "false")
  [ "$val" = "true" ] && echo 1 || echo 0
}

# Lit le commentaire meta du format étendu
meta_comment() {
  local idx="$1"
  local val
  val=$(jq -r --argjson i "$idx" '.pipeline[$i].meta.comment // empty' "$CONFIG" 2>/dev/null || true)
  echo "${val:-}"
}

# == Opérations - Format legacy ================================================

run_compute_legacy() {
  local i="$1"
  local source bases nom
  source=$(require_field "$i" "source")
  bases=$(require_field "$i" "bases")
  nom=$(require_field "$i" "nom")

  echo "=== COMPUTE : $source ==="
  [ -d "$source" ] || die "Bloc #$((i+1)) compute : dossier source introuvable : $source"

  mkdir -p "$bases"
  local bases_abs
  bases_abs="$(cd "$bases" && pwd)"
  ( cd "$source" && "$INTEGRITY" compute . "$bases_abs/$nom" )
}

run_verify_legacy() {
  local i="$1"
  local source base
  source=$(require_field "$i" "source")
  base=$(require_field "$i" "base")

  echo "=== VERIFY : $source ==="
  [ -d "$source" ] || die "Bloc #$((i+1)) verify : dossier source introuvable : $source"
  [ -f "$base" ]   || die "Bloc #$((i+1)) verify : base .b3 introuvable : $base"

  local base_abs
  base_abs="$(cd "$(dirname "$base")" && pwd)/$(basename "$base")"
  ( cd "$source" && "$INTEGRITY" verify "$base_abs" )
}

run_compare_legacy() {
  local i="$1"
  local base_a base_b
  base_a=$(require_field "$i" "base_a")
  base_b=$(require_field "$i" "base_b")

  echo "=== COMPARE : $(basename "$base_a") vs $(basename "$base_b") ==="
  [ -f "$base_a" ] || die "Bloc #$((i+1)) compare : base_a introuvable : $base_a"
  [ -f "$base_b" ] || die "Bloc #$((i+1)) compare : base_b introuvable : $base_b"

  local resultats_dir
  resultats_dir=$(optional_field "$i" "resultats")

  if [ -n "$resultats_dir" ]; then
    mkdir -p "$resultats_dir"
    local resultats_abs
    resultats_abs="$(cd "$resultats_dir" && pwd)"
    echo "    → résultats dans : $resultats_abs"
    RESULTATS_DIR="$resultats_abs" "$INTEGRITY" compare "$base_a" "$base_b"
  else
    "$INTEGRITY" compare "$base_a" "$base_b"
  fi
}

# == Opérations - Format étendu ================================================

run_compute_extended() {
  local i="$1"
  local input output_dir filename
  input=$(require_param "$i" "input")
  output_dir=$(require_param "$i" "output_dir")
  filename=$(require_param "$i" "filename")

  local quiet
  # shellcheck disable=SC2034  # verbose : lu par l'appelant ou réservé pour usage futur
  local verbose
  quiet=$(option_flag "$i" "quiet")
  verbose=$(option_flag "$i" "verbose")
  local comment
  comment=$(meta_comment "$i")

  local desc
  desc=$(jq -r --argjson i "$i" '.pipeline[$i].description // empty' "$CONFIG" 2>/dev/null || true)

  echo "=== COMPUTE : $input ==="
  [ -n "$desc" ] && echo "    → $desc"
  [ -n "$comment" ] && echo "    → meta: $comment"

  [ -d "$input" ] || die "Bloc #$((i+1)) compute : dossier source introuvable : $input"

  mkdir -p "$output_dir"
  local output_abs
  output_abs="$(cd "$output_dir" && pwd)"

  local quiet_flag=""
  (( quiet )) && quiet_flag="--quiet"

  # shellcheck disable=SC2086
  ( cd "$input" && "$INTEGRITY" $quiet_flag compute . "$output_abs/$filename" )

  # Sidecar : génération si jq disponible et commentaire présent
  local b3_path="${output_abs}/${filename}"
  if [ -f "$b3_path" ] && command -v jq &>/dev/null; then
    local nb_files; nb_files=$(wc -l < "$b3_path" 2>/dev/null || echo 0)
    jq -n \
      --arg version  "hash-tool runner" \
      --arg date     "$(date -u +%Y-%m-%dT%H:%M:%SZ)" \
      --arg comment  "$comment" \
      --arg dir      "$input" \
      --argjson nb   "$nb_files" \
      '{
        created_by: $version,
        date:       $date,
        comment:    $comment,
        parameters: { directory: $dir, hash_algo: "blake3", nb_files: $nb }
      }' > "${b3_path}.meta.json"
    echo "    → sidecar : ${b3_path}.meta.json"
  fi
}

run_verify_extended() {
  local i="$1"
  local input base
  input=$(require_param "$i" "input")
  base=$(require_param "$i" "base")

  local quiet; quiet=$(option_flag "$i" "quiet")
  local desc
  desc=$(jq -r --argjson i "$i" '.pipeline[$i].description // empty' "$CONFIG" 2>/dev/null || true)

  echo "=== VERIFY : $input ==="
  [ -n "$desc" ] && echo "    → $desc"

  [ -d "$input" ] || die "Bloc #$((i+1)) verify : dossier source introuvable : $input"
  [ -f "$base" ]  || die "Bloc #$((i+1)) verify : base .b3 introuvable : $base"

  local base_abs
  base_abs="$(cd "$(dirname "$base")" && pwd)/$(basename "$base")"

  local quiet_flag=""
  (( quiet )) && quiet_flag="--quiet"

  # shellcheck disable=SC2086
  ( cd "$input" && "$INTEGRITY" $quiet_flag verify "$base_abs" )
}

run_compare_extended() {
  local i="$1"
  local input ref_base output_dir
  input=$(require_param "$i" "input")
  ref_base=$(require_param "$i" "reference")
  output_dir=$(optional_param "$i" "output_dir")

  local quiet; quiet=$(option_flag "$i" "quiet")
  local desc
  desc=$(jq -r --argjson i "$i" '.pipeline[$i].description // empty' "$CONFIG" 2>/dev/null || true)

  echo "=== COMPARE : $(basename "$ref_base") vs $(basename "$input") ==="
  [ -n "$desc" ] && echo "    → $desc"

  [ -f "$ref_base" ] || die "Bloc #$((i+1)) compare : référence introuvable : $ref_base"
  [ -f "$input" ]    || die "Bloc #$((i+1)) compare : base courante introuvable : $input"

  local quiet_flag=""
  (( quiet )) && quiet_flag="--quiet"

  if [ -n "$output_dir" ]; then
    mkdir -p "$output_dir"
    local output_abs
    output_abs="$(cd "$output_dir" && pwd)"
    echo "    → résultats dans : $output_abs"
    # shellcheck disable=SC2086
    RESULTATS_DIR="$output_abs" "$INTEGRITY" $quiet_flag compare "$ref_base" "$input"
  else
    # shellcheck disable=SC2086
    "$INTEGRITY" $quiet_flag compare "$ref_base" "$input"
  fi
}

# Pour les commandes sans effet réel dans le pipeline mais documentées
run_list_extended() {
  local i="$1"
  local input_dir
  input_dir=$(require_param "$i" "input_dir")
  local desc
  desc=$(jq -r --argjson i "$i" '.pipeline[$i].description // empty' "$CONFIG" 2>/dev/null || true)

  echo "=== LIST : $input_dir ==="
  [ -n "$desc" ] && echo "    → $desc"

  find "$input_dir" -maxdepth 2 -name "*.b3" -type f | sort | while IFS= read -r f; do
    local nb; nb=$(wc -l < "$f" 2>/dev/null || echo "?")
    printf "  %-40s  %6s fichiers\n" "$(basename "$f")" "$nb"
  done
}

run_diff_extended() {
  local i="$1"
  local input ref_dir
  input=$(require_param "$i" "input")
  ref_dir=$(require_param "$i" "reference_dir")
  local desc
  desc=$(jq -r --argjson i "$i" '.pipeline[$i].description // empty' "$CONFIG" 2>/dev/null || true)

  echo "=== DIFF : $(basename "$input") vs $ref_dir ==="
  [ -n "$desc" ] && echo "    → $desc"
  [ -f "$input" ]  || die "Bloc #$((i+1)) diff : base introuvable : $input"
  [ -d "$ref_dir" ] || die "Bloc #$((i+1)) diff : dossier introuvable : $ref_dir"

  local tmp_base tmp_dir
  tmp_base=$(mktemp)
  tmp_dir=$(mktemp)
  trap 'rm -f "$tmp_base" "$tmp_dir"' EXIT

  awk '{ print substr($0,67) }' "$input" | sort > "$tmp_base"
  local prefix
  prefix=$(awk '{ p=substr($0,67); sub(/[^/]+$/, "", p); print p; exit }' "$input" 2>/dev/null || echo "./")
  find "$ref_dir" -type f | sed "s|^${ref_dir%/}/||" | sed "s|^|${prefix}|" | sort > "$tmp_dir"

  local dis; dis=$(comm -23 "$tmp_base" "$tmp_dir" | wc -l)
  local nou; nou=$(comm -13 "$tmp_base" "$tmp_dir" | wc -l)
  echo "  Disparus : $dis  |  Nouveaux : $nou"

  rm -f "$tmp_base" "$tmp_dir"
  trap - EXIT
}

run_stats_extended() {
  local i="$1"
  local input
  input=$(require_param "$i" "input")
  local desc
  desc=$(jq -r --argjson i "$i" '.pipeline[$i].description // empty' "$CONFIG" 2>/dev/null || true)

  echo "=== STATS : $(basename "$input") ==="
  [ -n "$desc" ] && echo "    → $desc"
  [ -f "$input" ] || die "Bloc #$((i+1)) stats : base introuvable : $input"

  local nb; nb=$(wc -l < "$input")
  local sz; sz=$(du -sh "$input" | cut -f1)
  echo "  Fichiers indexés : $nb  |  Taille : $sz"
}

run_checkenv_extended() {
  local i="$1"
  local desc
  desc=$(jq -r --argjson i "$i" '.pipeline[$i].description // empty' "$CONFIG" 2>/dev/null || true)
  echo "=== CHECK-ENV ==="
  [ -n "$desc" ] && echo "    → $desc"
  command -v b3sum &>/dev/null && echo "  b3sum : OK" || echo "  b3sum : KO"
  command -v jq    &>/dev/null && echo "  jq    : OK" || echo "  jq    : KO"
}

run_version_extended() {
  local i="$1"
  echo "=== VERSION ==="
  command -v b3sum &>/dev/null && b3sum --version || echo "b3sum non disponible"
}

# == Dispatch par bloc =========================================================

dispatch_bloc() {
  local i="$1"
  local fmt
  fmt=$(_bloc_format "$i")

  case "$fmt" in
    legacy)
      local op
      op=$(jq -r --argjson i "$i" '.pipeline[$i].op' "$CONFIG")
      if [ "$op" = "null" ] || [ -z "$op" ]; then
        die "Bloc #$((i+1)) : champ 'op' manquant."
      fi
      case "$op" in
        compute) run_compute_legacy "$i" ;;
        verify)  run_verify_legacy  "$i" ;;
        compare) run_compare_legacy "$i" ;;
        *)       die "Bloc #$((i+1)) : opération inconnue : '$op'" ;;
      esac
      ;;
    extended)
      local type
      type=$(jq -r --argjson i "$i" '.pipeline[$i].type' "$CONFIG")
      case "$type" in
        compute)   run_compute_extended   "$i" ;;
        verify)    run_verify_extended    "$i" ;;
        compare)   run_compare_extended   "$i" ;;
        list)      run_list_extended      "$i" ;;
        diff)      run_diff_extended      "$i" ;;
        stats)     run_stats_extended     "$i" ;;
        check-env) run_checkenv_extended  "$i" ;;
        version)   run_version_extended   "$i" ;;
        runner)    die "Bloc #$((i+1)) : 'runner' imbriqué non supporté." ;;
        *)         die "Bloc #$((i+1)) : type inconnu : '$type'" ;;
      esac
      ;;
    *)
      die "Bloc #$((i+1)) : ni 'op' (legacy) ni 'type' (étendu) trouvé."
      ;;
  esac
}

# == Main ======================================================================

echo "=== PIPELINE DÉMARRÉ : $(date) ==="
echo "=== Config : $CONFIG ($nb_ops opération(s)) ==="
echo ""

for (( i=0; i<nb_ops; i++ )); do
  dispatch_bloc "$i"
  echo ""
done

echo "=== PIPELINE TERMINÉ : $(date) ==="

--- Fichier : temp commande.md ---


## tester "mon_dossier" 

bash \
hash-tool \
compute \
-data "./mon_dossier/source" \
-save "./mon_dossier/bases" \
-meta "source, base initiale"

bash \
hash-tool \
compute \
-data "./mon_dossier/destination" \
-save "./mon_dossier/bases" \
-meta "destination, base initiale"

bash \
hash-tool \
compare \
-old "./mon_dossier/bases/hashes_source.b3" \
-new "./mon_dossier/bases/hashes_destination.b3" \
-save "./mon_dossier/result" 


## Tester avec un dossier sur le bureau et un dans "mon_dossier" 

bash \
hash-tool \
compute \
-data "./mon_dossier/source" \
-save "./mon_dossier/bases" \
-meta "source, base initiale"

bash \
hash-tool \
compute \
-data "/home/me-dell/Bureau/dossier bureau/destination" \
-save "/home/me-dell/Bureau/dossier bureau/bases" \
-meta "destination, base initiale" 

bash \
hash-tool \
compare \
-old "/home/me-dell/Bureau/dossier bureau/bases/hashes_destination.b3" \
-new "/media/veracrypt1/partition_laptop/divers/config ordinateur/2 en cours -- 2025-00-00 -- backup/d11 installation/hash_tool/mon_dossier/bases/hashes_source.b3" \
-save "/home/me-dell/Bureau/dossier bureau/rapport" 

--- Fichier : todo claude.md ---

continuer le codage des tests

débug les fail 

comprendre le CI de github 

tester docker et l'env aussi 

comprendre l'archi de test 

voir si toutes les features de "TODO test" ont été implémentées 



--- Fichier : mon_dossier/destination/fichier (1).txt ---
Contrary to popular belief, Lorem Ipsum is not simply random text. It has roots in a piece of classical Latin literature from 45 BC, making it over 2000 years old. Richard McClintock, a Latin professor at Hampden-Sydney College in Virginia, looked up one of the more obscure Latin words, consectetur, from a Lorem Ipsum passage, and going through the cites of the word in classical literature, discovered the undoubtable source. Lorem Ipsum comes from sections 1.10.32 and 1.10.33 of "de Finibus Bonorum et Malorum" (The Extremes of Good and Evil) by Cicero, written in 45 BC. This book is a treatise on the theory of ethics, very popular during the Renaissance. The first line of Lorem Ipsum, "Lorem ipsum dolor sit amet..", comes from a line in section 1.10.32.



--- Fichier : mon_dossier/destination/fichier (2).txt ---
There are many variations of passages of Lorem Ipsum available, but the majority have suffered alteration in some form, by injected humour, or randomised words which don't look even slightly believable. If you are going to use a passage of Lorem Ipsum, you need to be sure there isn't anything embarrassing hidden in the middle of text. All the Lorem Ipsum generators on the Internet tend to repeat predefined chunks as necessary, making this the first true generator on the Internet. It uses a dictionary of over 200 Latin words, combined with a handful of model sentence structures, to generate Lorem Ipsum which looks reasonable. The generated Lorem Ipsum is therefore always free from repetition, injected humour, or non-characteristic words etc.



--- Fichier : mon_dossier/destination/fichier (3).txt ---
Lorem Ipsum is simply dummy text of the printing and typesetting industry. Lorem Ipsum has been the industry's standard dummy text ever since the 1500s, when an unknown printer took a galley of type and scrambled it to make a type specimen book. It has survived not only five centuries, but also the leap into electronic typesetting, remaining essentially unchanged. It was popularised in the 1960s with the release of Letraset sheets containing Lorem Ipsum passages, and more recently with desktop publishing software like Aldus PageMaker including versions of Lorem Ipsum.



--- Fichier : mon_dossier/destination/fichier (4).txt ---
It is a long established fact that a reader will be distracted by the readable content of a page when looking at its layout. The point of using Lorem Ipsum is that it has a more-or-less normal distribution of letters, as opposed to using 'Content here, content here', making it look like readable English. Many desktop publishing packages and web page editors now use Lorem Ipsum as their default model text, and a search for 'lorem ipsum' will uncover many web sites still in their infancy. Various versions have evolved over the years, sometimes by accident, sometimes on purpose (injected humour and the like).



--- Fichier : mon_dossier/source/fichier (1).txt ---
Contrary to popular belief, Lorem Ipsum is not simply random text. It has roots in a piece of classical Latin literature from 45 BC, making it over 2000 years old. Richard McClintock, a Latin professor at Hampden-Sydney College in Virginia, looked up one of the more obscure Latin words, consectetur, from a Lorem Ipsum passage, and going through the cites of the word in classical literature, discovered the undoubtable source. Lorem Ipsum comes from sections 1.10.32 and 1.10.33 of "de Finibus Bonorum et Malorum" (The Extremes of Good and Evil) by Cicero, written in 45 BC. This book is a treatise on the theory of ethics, very popular during the Renaissance. The first line of Lorem Ipsum, "Lorem ipsum dolor sit amet..", comes from a line in section 1.10.32.

fichier modifié



--- Fichier : mon_dossier/source/fichier (2).txt ---
There are many variations of passages of Lorem Ipsum available, but the majority have suffered alteration in some form, by injected humour, or randomised words which don't look even slightly believable. If you are going to use a passage of Lorem Ipsum, you need to be sure there isn't anything embarrassing hidden in the middle of text. All the Lorem Ipsum generators on the Internet tend to repeat predefined chunks as necessary, making this the first true generator on the Internet. It uses a dictionary of over 200 Latin words, combined with a handful of model sentence structures, to generate Lorem Ipsum which looks reasonable. The generated Lorem Ipsum is therefore always free from repetition, injected humour, or non-characteristic words etc.



--- Fichier : mon_dossier/source/fichier (3).txt ---
Lorem Ipsum is simply dummy text of the printing and typesetting industry. Lorem Ipsum has been the industry's standard dummy text ever since the 1500s, when an unknown printer took a galley of type and scrambled it to make a type specimen book. It has survived not only five centuries, but also the leap into electronic typesetting, remaining essentially unchanged. It was popularised in the 1960s with the release of Letraset sheets containing Lorem Ipsum passages, and more recently with desktop publishing software like Aldus PageMaker including versions of Lorem Ipsum.



--- Fichier : mon_dossier/source/fichier (4).txt ---
It is a long established fact that a reader will be distracted by the readable content of a page when looking at its layout. The point of using Lorem Ipsum is that it has a more-or-less normal distribution of letters, as opposed to using 'Content here, content here', making it look like readable English. Many desktop publishing packages and web page editors now use Lorem Ipsum as their default model text, and a search for 'lorem ipsum' will uncover many web sites still in their infancy. Various versions have evolved over the years, sometimes by accident, sometimes on purpose (injected humour and the like).



--- Fichier : mon_dossier/bases/hashes_source.b3.meta.json ---
{
  "created_by": "hash-tool v2.0.0",
  "date": "2026-02-26T12:38:45Z",
  "comment": "source, base initiale",
  "parameters": {
    "directory": "/media/veracrypt1/partition_laptop/divers/config ordinateur/2 en cours -- 2025-00-00 -- backup/d11 installation/hash_tool/mon_dossier/source",
    "hash_algo": "blake3",
    "readonly": false,
    "nb_files": 4
  }
}


--- Fichier : tests/run_tests.sh ---
#!/usr/bin/env bash
# run_tests.sh - suite de tests automatisée pour integrity.sh
# Usage    : cd tests && ./run_tests.sh
# Prérequis: b3sum, stat, du ; integrity.sh dans ../src/

set -euo pipefail

SCRIPT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"
INTEGRITY="$SCRIPT_DIR/../src/integrity.sh"
WORKDIR="$(mktemp -d /tmp/integrity-test.XXXXXX)"
export RESULTATS_DIR="$WORKDIR/resultats"

GREEN='\033[0;32m'
RED='\033[0;31m'
NC='\033[0m'

PASS=0; FAIL=0; TOTAL=0

pass() { echo -e "${GREEN}  PASS${NC} - $1"; PASS=$((PASS+1)); TOTAL=$((TOTAL+1)); }
fail() { echo -e "${RED}  FAIL${NC} - $1"; FAIL=$((FAIL+1)); TOTAL=$((TOTAL+1)); }

assert_exit_zero()    { local l="$1"; shift; if "$@" >/dev/null 2>&1;  then pass "$l"; else fail "$l"; fi; }
assert_exit_nonzero() { local l="$1"; shift; if ! "$@" >/dev/null 2>&1; then pass "$l"; else fail "$l"; fi; }

assert_contains() {
  local label="$1" pattern="$2" output="$3"
  if echo "$output" | grep -q "$pattern"; then pass "$label"; else fail "$label (pattern: '$pattern' absent)"; fi
}

assert_not_contains() {
  local label="$1" pattern="$2" output="$3"
  if ! echo "$output" | grep -q "$pattern"; then pass "$label"; else fail "$label (pattern: '$pattern' présent à tort)"; fi
}

assert_line_count() {
  local label="$1" expected="$2" file="$3"
  local actual; actual=$(wc -l < "$file")
  if [ "$actual" -eq "$expected" ]; then pass "$label"; else fail "$label (attendu: $expected, obtenu: $actual)"; fi
}

assert_file_exists() {
  local label="$1" file="$2"
  if [ -f "$file" ]; then pass "$label"; else fail "$label (absent : $file)"; fi
}

assert_file_absent() {
  local label="$1" file="$2"
  if [ ! -f "$file" ]; then pass "$label"; else fail "$label (présent à tort : $file)"; fi
}

setup() {
  mkdir -p "$WORKDIR/data/sub"
  echo "contenu alpha" > "$WORKDIR/data/alpha.txt"
  echo "contenu beta"  > "$WORKDIR/data/beta.txt"
  echo "contenu gamma" > "$WORKDIR/data/gamma.txt"
  echo "contenu delta" > "$WORKDIR/data/sub/delta.txt"
}

teardown() { rm -rf "$WORKDIR"; }

run_tests() {
  cd "$WORKDIR"

  echo ""
  echo "========================================"
  echo "  integrity.sh - suite de tests"
  echo "  Workdir : $WORKDIR"
  echo "========================================"
  echo ""

  echo "T00 - ShellCheck"
  if command -v shellcheck &>/dev/null; then
    assert_exit_zero "ShellCheck integrity.sh"       shellcheck "$INTEGRITY"
    assert_exit_zero "ShellCheck src/lib/core.sh"    shellcheck "$SCRIPT_DIR/../src/lib/core.sh"
    assert_exit_zero "ShellCheck src/lib/ui.sh"      shellcheck "$SCRIPT_DIR/../src/lib/ui.sh"
    assert_exit_zero "ShellCheck src/lib/report.sh"  shellcheck "$SCRIPT_DIR/../src/lib/report.sh"
    assert_exit_zero "ShellCheck src/lib/results.sh" shellcheck "$SCRIPT_DIR/../src/lib/results.sh"
    assert_exit_zero "ShellCheck runner.sh"          shellcheck "$SCRIPT_DIR/../runner.sh"
  else
    echo "  SKIP - shellcheck non installé"
  fi
  echo ""

  echo "T01 - Compute de base"
  bash "$INTEGRITY" compute ./data base_t01.b3 >/dev/null 2>&1
  assert_line_count "base_t01.b3 contient 4 lignes" 4 base_t01.b3
  assert_contains   "format <hash>  <chemin>"       "  ./data/" "$(head -1 base_t01.b3)"
  echo ""

  echo "T02 - Verify sans modification"
  local out_t02; out_t02=$(bash "$INTEGRITY" verify base_t01.b3 2>&1 || true)
  assert_not_contains "aucun FAILED" "FAILED" "$out_t02"
  assert_contains     "terminal OK"  "OK"     "$out_t02"
  local outdir_t02; outdir_t02=$(find "${RESULTATS_DIR}" -maxdepth 1 -type d -name "resultats_base_t01*" 2>/dev/null | sort | tail -1)
  assert_file_exists  "recap.txt créé"              "${outdir_t02}/recap.txt"
  assert_file_absent  "failed.txt absent si 0 échec" "${outdir_t02}/failed.txt"
  echo ""

  echo "T03 - Verify après corruption"
  echo "contenu modifié" > data/beta.txt
  local out_t03; out_t03=$(bash "$INTEGRITY" verify base_t01.b3 2>&1 || true)
  assert_contains "ECHEC affiché"    "ECHEC"   "$out_t03"
  assert_contains "beta.txt FAILED"  "FAILED"  "$out_t03"
  local outdir_t03; outdir_t03=$(find "${RESULTATS_DIR}" -maxdepth 1 -type d -name "resultats_base_t01*" 2>/dev/null | sort | tail -1)
  assert_file_exists "failed.txt créé"    "${outdir_t03}/failed.txt"
  assert_contains    "failed.txt beta"    "beta.txt" "$(cat "${outdir_t03}/failed.txt")"
  echo "contenu beta" > data/beta.txt
  echo ""

  echo "T04 - Verify après suppression"
  rm data/gamma.txt
  local out_t04; out_t04=$(bash "$INTEGRITY" verify base_t01.b3 2>&1 || true)
  assert_contains "gamma.txt FAILED" "FAILED" "$out_t04"
  echo "contenu gamma" > data/gamma.txt
  echo ""

  echo "T05 - Compare : aucune différence"
  bash "$INTEGRITY" compute ./data base_t05.b3 >/dev/null 2>&1
  bash "$INTEGRITY" compare base_t01.b3 base_t05.b3 >/dev/null 2>&1
  local outdir_t05; outdir_t05=$(find "${RESULTATS_DIR}" -maxdepth 1 -type d -name "resultats_base_t01*" 2>/dev/null | sort | tail -1)
  assert_file_exists "recap.txt"    "${outdir_t05}/recap.txt"
  assert_file_exists "modifies.b3"  "${outdir_t05}/modifies.b3"
  assert_file_exists "report.html"  "${outdir_t05}/report.html"
  assert_line_count  "modifies vide" 0 "${outdir_t05}/modifies.b3"
  assert_line_count  "disparus vide" 0 "${outdir_t05}/disparus.txt"
  assert_line_count  "nouveaux vide" 0 "${outdir_t05}/nouveaux.txt"
  echo ""

  echo "T06 - Compare : fichier modifié"
  echo "contenu beta modifié" > data/beta.txt
  bash "$INTEGRITY" compute ./data base_t06.b3 >/dev/null 2>&1
  bash "$INTEGRITY" compare base_t01.b3 base_t06.b3 >/dev/null 2>&1
  local outdir_t06; outdir_t06=$(find "${RESULTATS_DIR}" -maxdepth 1 -type d -name "resultats_base_t01*" 2>/dev/null | sort | tail -1)
  assert_contains "modifies contient beta" "beta.txt" "$(cat "${outdir_t06}/modifies.b3")"
  assert_file_exists "report.html généré" "${outdir_t06}/report.html"
  assert_contains    "report.html contient beta" "beta" "$(cat "${outdir_t06}/report.html")"
  echo "contenu beta" > data/beta.txt
  echo ""

  echo "T07 - Compare : suppression + ajout"
  bash "$INTEGRITY" compute ./data base_t07_old.b3 >/dev/null 2>&1
  rm data/alpha.txt
  echo "contenu epsilon" > data/epsilon.txt
  bash "$INTEGRITY" compute ./data base_t07_new.b3 >/dev/null 2>&1
  bash "$INTEGRITY" compare base_t07_old.b3 base_t07_new.b3 >/dev/null 2>&1
  local outdir_t07; outdir_t07=$(find "${RESULTATS_DIR}" -maxdepth 1 -type d -name "resultats_base_t07_old*" 2>/dev/null | sort | tail -1)
  assert_contains "disparus alpha"   "alpha.txt"   "$(cat "${outdir_t07}/disparus.txt")"
  assert_contains "nouveaux epsilon" "epsilon.txt" "$(cat "${outdir_t07}/nouveaux.txt")"
  echo "contenu alpha" > data/alpha.txt
  rm data/epsilon.txt
  echo ""

  echo "T08 - Robustesse : fichier avec espace"
  echo "contenu espace" > "data/fichier avec espace.txt"
  bash "$INTEGRITY" compute ./data base_t08.b3 >/dev/null 2>&1
  local out_t08; out_t08=$(bash "$INTEGRITY" verify base_t08.b3 2>&1 || true)
  assert_not_contains "aucun FAILED" "FAILED" "$out_t08"
  rm "data/fichier avec espace.txt"
  echo ""

  echo "T09 - Limite : dossier vide ignoré"
  mkdir data/dossier_vide
  bash "$INTEGRITY" compute ./data base_t09.b3 >/dev/null 2>&1
  assert_not_contains "dossier_vide absent" "dossier_vide" "$(cat base_t09.b3)"
  pass "comportement conforme"
  rmdir data/dossier_vide
  echo ""

  echo "T10 - Chemin absolu vs relatif"
  find "$WORKDIR/data" -type f -print0 | sort -z | xargs -0 b3sum > base_absolu.b3
  find ./data          -type f -print0 | sort -z | xargs -0 b3sum > base_relatif.b3
  assert_contains     "base absolue → chemin absolu"   "  /"      "$(head -1 base_absolu.b3)"
  assert_contains     "base relative → chemin relatif" "\./data/" "$(head -1 base_relatif.b3)"
  assert_not_contains "bases non interchangeables"     "$(head -1 base_absolu.b3)" "$(head -1 base_relatif.b3)"
  echo ""

  echo "T11 - ETA : base identique à référence"
  find ./data -type f -print0 | sort -z | xargs -0 b3sum > base_ref.b3
  bash "$INTEGRITY" compute ./data base_eta.b3 >/dev/null 2>&1
  assert_exit_zero    "base ETA == référence" diff base_ref.b3 base_eta.b3
  assert_not_contains "pas de ligne ETA"      "ETA" "$(cat base_eta.b3)"
  assert_not_contains "pas de \\r"            $'\r' "$(cat base_eta.b3)"
  echo ""

  echo "T12 - Mode --quiet"
  bash "$INTEGRITY" compute ./data base_t12.b3 >/dev/null 2>&1
  local out_quiet_ok; out_quiet_ok=$(bash "$INTEGRITY" --quiet verify base_t12.b3 2>&1 || true)
  assert_not_contains "--quiet OK : pas de stdout" "OK"        "$out_quiet_ok"
  assert_not_contains "--quiet OK : pas de stdout" "Résultats" "$out_quiet_ok"
  local outdir_t12; outdir_t12=$(find "${RESULTATS_DIR}" -maxdepth 1 -type d -name "resultats_base_t12*" 2>/dev/null | sort | tail -1)
  assert_file_exists  "recap.txt produit --quiet" "${outdir_t12}/recap.txt"

  echo "contenu corrompu" > data/beta.txt
  local exit_quiet; bash "$INTEGRITY" --quiet verify base_t12.b3 >/dev/null 2>&1 && exit_quiet=0 || exit_quiet=$?
  if [ "$exit_quiet" -ne 0 ]; then pass "--quiet propage exit code"; else fail "--quiet propage exit code"; fi
  echo "contenu beta" > data/beta.txt

  local out_quiet_cmp; out_quiet_cmp=$(bash "$INTEGRITY" --quiet compute ./data base_t12c.b3 2>&1 || true)
  assert_not_contains "--quiet compute : pas de stdout" "Base enregistrée" "$out_quiet_cmp"
  echo ""

  echo "T13 - Horodatage anti-écrasement"
  bash "$INTEGRITY" compute ./data base_t13.b3 >/dev/null 2>&1
  bash "$INTEGRITY" verify base_t13.b3 >/dev/null 2>&1 || true
  sleep 1
  bash "$INTEGRITY" verify base_t13.b3 >/dev/null 2>&1 || true
  local nb_r; nb_r=$(find "${RESULTATS_DIR}" -maxdepth 1 -type d -name "resultats_base_t13*" 2>/dev/null | wc -l)
  if [ "$nb_r" -ge 2 ]; then pass "deux dossiers distincts"; else fail "écrasement détecté ($nb_r dossier(s))"; fi
  echo ""

  echo "T14 - verify : dossier argument invalide"
  local out_t14; out_t14=$(bash "$INTEGRITY" verify base_t01.b3 /chemin/inexistant 2>&1 || true)
  assert_contains "ERREUR si dossier invalide" "ERREUR" "$out_t14"
  echo ""

  # =========================================================================
  # T15-T20 : cas limites supplémentaires
  # =========================================================================

  echo "T15 - Nom de fichier avec newline (mapfile -d '' doit tenir)"
  # Crée un fichier dont le nom contient un newline
  local newline_file
  newline_file="$(printf 'data/nom\nfichier.txt')"
  printf 'contenu newline' > "$newline_file"
  bash "$INTEGRITY" compute ./data base_t15.b3 >/dev/null 2>&1
  # Le .b3 doit contenir une ligne valide pour ce fichier
  local t15_lines; t15_lines=$(wc -l < base_t15.b3)
  if [ "$t15_lines" -ge 4 ]; then pass "T15 .b3 contient les 4+ fichiers dont le nom avec newline"; else fail "T15 .b3 incomplet ($t15_lines lignes)"; fi
  # Verify ne doit pas échouer
  local out_t15; out_t15=$(bash "$INTEGRITY" verify base_t15.b3 2>&1 || true)
  assert_not_contains "T15 verify sans FAILED" "FAILED" "$out_t15"
  rm -f "$newline_file"
  echo ""

  echo "T16 - Fichiers avec caractères HTML dans le nom"
  echo "contenu script" > "data/<script>.txt"
  echo "contenu amp"    > "data/a&b.txt"
  bash "$INTEGRITY" compute ./data base_t16.b3 >/dev/null 2>&1
  bash "$INTEGRITY" compare base_t01.b3 base_t16.b3 >/dev/null 2>&1
  local outdir_t16; outdir_t16=$(find "${RESULTATS_DIR}" -maxdepth 1 -type d -name "resultats_base_t01*" 2>/dev/null | sort | tail -1)
  assert_file_exists "T16 report.html généré" "${outdir_t16}/report.html"
  # Les chemins bruts doivent apparaître dans nouveaux.txt (sans échappement HTML)
  assert_contains "T16 <script>.txt dans nouveaux.txt" "<script>.txt" "$(cat "${outdir_t16}/nouveaux.txt")"
  assert_contains "T16 a&b.txt dans nouveaux.txt"     "a&b.txt"     "$(cat "${outdir_t16}/nouveaux.txt")"
  # report.html doit échapper correctement (pas de < ou & non échappés dans le rendu HTML)
  local html_t16; html_t16=$(cat "${outdir_t16}/report.html")
  # On vérifie que la séquence brute "<script>" n'est PAS telle quelle dans le HTML
  # (doit être &lt;script&gt; ou équivalent) - si html_escape n'existe pas, on signale
  if echo "$html_t16" | grep -q "&lt;script&gt;\|&amp;" 2>/dev/null; then
    pass "T16 échappement HTML présent dans report.html"
  elif echo "$html_t16" | grep -qF "<script>.txt"; then
    fail "T16 échappement HTML ABSENT dans report.html (XSS potentiel)"
  else
    pass "T16 report.html ne contient pas le nom brut (chemin absent ou échappé)"
  fi
  rm -f "data/<script>.txt" "data/a&b.txt"
  echo ""

  echo "T17 - Compare sans différence → report.html affiche IDENTIQUES"
  bash "$INTEGRITY" compute ./data base_t17a.b3 >/dev/null 2>&1
  bash "$INTEGRITY" compute ./data base_t17b.b3 >/dev/null 2>&1
  bash "$INTEGRITY" compare base_t17a.b3 base_t17b.b3 >/dev/null 2>&1
  local outdir_t17; outdir_t17=$(find "${RESULTATS_DIR}" -maxdepth 1 -type d -name "resultats_base_t17a*" 2>/dev/null | sort | tail -1)
  assert_file_exists "T17 report.html créé" "${outdir_t17}/report.html"
  local html_t17; html_t17=$(cat "${outdir_t17}/report.html")
  # Le rapport doit indiquer que les bases sont identiques (mot-clé "IDENTIQUES" ou "identique" ou "0 modification")
  if echo "$html_t17" | grep -qi "identique\|0 modification\|aucune différence\|aucune diff"; then
    pass "T17 report.html mentionne l'identité des bases"
  else
    fail "T17 report.html ne mentionne pas l'identité (cherchez le pattern attendu dans votre template)"
  fi
  echo ""

  echo "T18 - --quiet sur compare : stdout vide, fichiers produits"
  bash "$INTEGRITY" compute ./data base_t18a.b3 >/dev/null 2>&1
  echo "contenu beta modifié" > data/beta.txt
  bash "$INTEGRITY" compute ./data base_t18b.b3 >/dev/null 2>&1
  echo "contenu beta" > data/beta.txt
  local out_t18; out_t18=$(bash "$INTEGRITY" --quiet compare base_t18a.b3 base_t18b.b3 2>&1 || true)
  assert_not_contains "T18 --quiet compare : pas de stdout" "Résultats"  "$out_t18"
  assert_not_contains "T18 --quiet compare : pas de stdout" "Comparaison" "$out_t18"
  local outdir_t18; outdir_t18=$(find "${RESULTATS_DIR}" -maxdepth 1 -type d -name "resultats_base_t18a*" 2>/dev/null | sort | tail -1)
  assert_file_exists "T18 recap.txt produit en --quiet"    "${outdir_t18}/recap.txt"
  assert_file_exists "T18 modifies.b3 produit en --quiet"  "${outdir_t18}/modifies.b3"
  assert_file_exists "T18 report.html produit en --quiet"  "${outdir_t18}/report.html"
  assert_contains    "T18 modifies.b3 contient beta.txt"   "beta.txt" "$(cat "${outdir_t18}/modifies.b3")"
  echo ""

  echo "T19 - Lien symbolique dans le dossier source"
  # Crée un lien symbolique pointant vers un fichier existant
  ln -s "$WORKDIR/data/alpha.txt" "data/lien_alpha.txt" 2>/dev/null || true
  # Vérifie que compute ne plante pas
  local t19_exit=0
  bash "$INTEGRITY" compute ./data base_t19.b3 >/dev/null 2>&1 || t19_exit=$?
  if [ "$t19_exit" -eq 0 ]; then
    pass "T19 compute avec lien symbolique → exit 0"
    # Documente si le lien est suivi ou ignoré
    if grep -q "lien_alpha" base_t19.b3 2>/dev/null; then
      pass "T19 lien symbolique : suivi (inclus dans .b3)"
    else
      pass "T19 lien symbolique : ignoré (absent du .b3) - comportement à documenter"
    fi
  else
    fail "T19 compute avec lien symbolique → exit $t19_exit (plantage)"
  fi
  rm -f "data/lien_alpha.txt"
  echo ""

  echo "T20 - verify avec dossier source inexistant → exit 1"
  local out_t20; out_t20=$(bash "$INTEGRITY" verify base_t01.b3 /dossier/source/totalement/inexistant 2>&1 || true)
  assert_contains "T20 ERREUR si dossier source inexistant" "ERREUR" "$out_t20"
  # Doit être différent de T14 qui testait un dossier passé comme argument optionnel
  # Ici on s'assure que l'exit code est non-zéro
  local t20_exit=0
  bash "$INTEGRITY" verify base_t01.b3 /dossier/source/totalement/inexistant >/dev/null 2>&1 || t20_exit=$?
  if [ "$t20_exit" -ne 0 ]; then pass "T20 exit code non-zéro"; else fail "T20 exit code nul (attendu non-zéro)"; fi
  echo ""
}

# == Main ======================================================================

command -v b3sum &>/dev/null || { echo -e "${RED}ERREUR${NC} : b3sum non trouvé."; exit 1; }
[ -f "$INTEGRITY" ]          || { echo -e "${RED}ERREUR${NC} : integrity.sh introuvable : $INTEGRITY"; exit 1; }

setup
run_tests
teardown

echo "========================================"
if [ "$FAIL" -eq 0 ]; then
  echo -e "  ${GREEN}$PASS/$TOTAL tests passés${NC}"
else
  echo -e "  ${GREEN}$PASS${NC}/${TOTAL} passés - ${RED}$FAIL échec(s)${NC}"
fi
echo "========================================"
echo ""

[ "$FAIL" -eq 0 ]

--- Fichier : tests/run_tests_core.sh ---
#!/usr/bin/env bash
# run_tests_core.sh - Tests unitaires de src/lib/core.sh
# Usage    : cd tests && ./run_tests_core.sh
# Prérequis: bash >= 4, b3sum
#
# Source directement core.sh sans passer par integrity.sh.
# Chaque groupe de tests est isolé dans un sous-répertoire de WORKDIR.

set -euo pipefail

SCRIPT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"
WORKDIR="$(mktemp -d /tmp/integrity-core-test.XXXXXX)"
export RESULTATS_DIR="$WORKDIR/resultats"
mkdir -p "$RESULTATS_DIR"

# == Sourcing des modules =========================================================

# ui.sh doit être sourcé avant core.sh (die() est définie dans ui.sh)
# On redéfinit die() localement pour capturer les appels sans quitter le processus de test.
QUIET=0
die() { echo "die: $*" >&2; return 1; }

# shellcheck source=../src/lib/core.sh
source "$SCRIPT_DIR/../src/lib/core.sh"

# == Infrastructure de test =======================================================

GREEN='\033[0;32m'
RED='\033[0;31m'
NC='\033[0m'

PASS=0; FAIL=0; TOTAL=0

pass() { echo -e "${GREEN}  PASS${NC} - $1"; PASS=$((PASS+1)); TOTAL=$((TOTAL+1)); }
fail() { echo -e "${RED}  FAIL${NC} - $1"; FAIL=$((FAIL+1)); TOTAL=$((TOTAL+1)); }

assert_exit_zero() {
  local label="$1"; shift
  local _rc=0
  ( set -e; "$@" ) >/dev/null 2>&1 || _rc=$?
  if [ "$_rc" -eq 0 ]; then pass "$label"; else fail "$label (exit $_rc attendu 0)"; fi
}

assert_exit_nonzero() {
  local label="$1"; shift
  local _rc=0
  ( set -e; "$@" ) >/dev/null 2>&1 || _rc=$?
  if [ "$_rc" -ne 0 ]; then pass "$label"; else fail "$label (exit 0 attendu non-zéro)"; fi
}

assert_contains() {
  local label="$1" pattern="$2" output="$3"
  if echo "$output" | grep -qF "$pattern"; then pass "$label"; else fail "$label (pattern absent: '$pattern')"; fi
}

assert_not_contains() {
  local label="$1" pattern="$2" output="$3"
  if ! echo "$output" | grep -qF "$pattern"; then pass "$label"; else fail "$label (pattern présent à tort: '$pattern')"; fi
}

assert_equals() {
  local label="$1" expected="$2" actual="$3"
  if [ "$actual" = "$expected" ]; then pass "$label"; else fail "$label (attendu: '$expected', obtenu: '$actual')"; fi
}

assert_numeric_eq() {
  local label="$1" expected="$2" actual="$3"
  if [ "$actual" -eq "$expected" ] 2>/dev/null; then pass "$label"; else fail "$label (attendu: $expected, obtenu: $actual)"; fi
}

# Hash b3sum 64 chars valide à partir d'une chaîne
_make_hash() { printf '%s' "$1" | b3sum --no-names; }

# Génère un fichier .b3 valide à partir d'un dossier
_compute_b3() {
  local dir="$1" out="$2"
  find "$dir" -type f -print0 | sort -z | xargs -0 b3sum > "$out"
}

teardown() { rm -rf "$WORKDIR"; }
trap teardown EXIT

# _run_core <fonction> [args...]
#
# Exécute une fonction de core.sh dans un sous-shell isolé.
# Nécessaire car die() fait return 1 et set -e tuerait le processus principal.
# Retourne le code de sortie de la fonction.
_run_core() {
  (
    QUIET=0
    die() { echo "die: $*" >&2; exit 1; }
    # shellcheck source=../src/lib/core.sh
    source "$SCRIPT_DIR/../src/lib/core.sh"
    "$@"
  ) 2>/dev/null
}

_run_core_stderr() {
  (
    QUIET=0
    die() { echo "die: $*" >&2; exit 1; }
    # shellcheck source=../src/lib/core.sh
    source "$SCRIPT_DIR/../src/lib/core.sh"
    "$@"
  ) 2>&1
}

# == T_CORE01 - core_assert_b3_valid =============================================

echo ""
echo "========================================"
echo "  T_CORE01 - core_assert_b3_valid"
echo "========================================"

# CU01 : fichier absent → exit 1
assert_exit_nonzero "CU01 fichier absent → exit 1" \
  _run_core core_assert_b3_valid "/tmp/inexistant_$$.b3"

# CU02 : répertoire passé → exit 1
assert_exit_nonzero "CU02 répertoire au lieu de fichier → exit 1" \
  _run_core core_assert_b3_valid "$WORKDIR"

# CU03 : fichier vide → exit 1
_cu03="$WORKDIR/vide.b3"; touch "$_cu03"
assert_exit_nonzero "CU03 fichier vide → exit 1" \
  _run_core core_assert_b3_valid "$_cu03"

# CU04 : format invalide (ligne sans hash) → exit 1
_cu04="$WORKDIR/bad_format.b3"; echo "ligne_sans_format_b3sum" > "$_cu04"
assert_exit_nonzero "CU04 format invalide → exit 1" \
  _run_core core_assert_b3_valid "$_cu04"

# CU05 : une seule ligne valide → exit 0
_cu05="$WORKDIR/valid_single.b3"
printf '%064d  ./fichier.txt\n' 0 > "$_cu05"
assert_exit_zero "CU05 une ligne valide → exit 0" \
  _run_core core_assert_b3_valid "$_cu05"

# CU06 : plusieurs lignes toutes valides → exit 0
_cu06="$WORKDIR/valid_multi.b3"
{ printf '%064d  ./alpha.txt\n' 0; printf '%064d  ./beta.txt\n' 1; } > "$_cu06"
assert_exit_zero "CU06 plusieurs lignes valides → exit 0" \
  _run_core core_assert_b3_valid "$_cu06"

# CU07 : lignes mixtes valides/invalides → exit 1
_cu07="$WORKDIR/mixed.b3"
{ printf '%064d  ./alpha.txt\n' 0; echo "ligne_invalide"; } > "$_cu07"
assert_exit_nonzero "CU07 lignes mixtes → exit 1" \
  _run_core core_assert_b3_valid "$_cu07"

# CU08 : label personnalisé transmis au message d'erreur
_cu08_err=$(_run_core_stderr core_assert_b3_valid "/inexistant.b3" "MON_LABEL" || true)
assert_contains "CU08 label personnalisé dans message d'erreur" "MON_LABEL" "$_cu08_err"

# CU09 : hash avec lettres minuscules (format b3sum réel)
_cu09="$WORKDIR/real_hash.b3"
printf 'abcdef1234567890abcdef1234567890abcdef1234567890abcdef1234567890  ./x.txt\n' > "$_cu09"
assert_exit_zero "CU09 hash lettres minuscules réel → exit 0" \
  _run_core core_assert_b3_valid "$_cu09"

# CU10 : chemin avec espace dans la ligne valide → exit 0
_cu10="$WORKDIR/space_path.b3"
printf '%064d  ./fichier avec espace.txt\n' 0 > "$_cu10"
assert_exit_zero "CU10 chemin avec espace → exit 0" \
  _run_core core_assert_b3_valid "$_cu10"

# CU11 : chemin avec caractères spéciaux HTML → exit 0
_cu11="$WORKDIR/html_chars.b3"
printf '%064d  ./<script>.txt\n' 0 > "$_cu11"
assert_exit_zero "CU11 chemin avec <> → exit 0" \
  _run_core core_assert_b3_valid "$_cu11"

# == T_CORE02 - core_assert_target_valid =========================================

echo ""
echo "========================================"
echo "  T_CORE02 - core_assert_target_valid"
echo "========================================"

# CU12 : chemin inexistant → exit 1
assert_exit_nonzero "CU12 chemin inexistant → exit 1" \
  _run_core core_assert_target_valid "/chemin/totalement/inexistant_$$"

# CU13 : fichier régulier passé (pas un dossier) → exit 1
_cu13_f="$WORKDIR/un_fichier.txt"; touch "$_cu13_f"
assert_exit_nonzero "CU13 fichier régulier (pas dossier) → exit 1" \
  _run_core core_assert_target_valid "$_cu13_f"

# CU14 : dossier vide (aucun fichier) → exit 1
_cu14_d="$WORKDIR/dossier_vide"; mkdir -p "$_cu14_d"
assert_exit_nonzero "CU14 dossier vide → exit 1" \
  _run_core core_assert_target_valid "$_cu14_d"

# CU15 : dossier avec un fichier → exit 0
_cu15_d="$WORKDIR/dossier_un_fichier"; mkdir -p "$_cu15_d"
echo "contenu" > "$_cu15_d/f.txt"
assert_exit_zero "CU15 dossier avec fichier → exit 0" \
  _run_core core_assert_target_valid "$_cu15_d"

# CU16 : dossier avec sous-dossiers uniquement (pas de fichiers réguliers) → exit 1
_cu16_d="$WORKDIR/dossier_sous_dir"; mkdir -p "$_cu16_d/sub"
assert_exit_nonzero "CU16 dossier sans fichiers réguliers → exit 1" \
  _run_core core_assert_target_valid "$_cu16_d"

# CU17 : dossier avec fichiers dans sous-dossiers → exit 0
_cu17_d="$WORKDIR/dossier_sub_files"; mkdir -p "$_cu17_d/sub"
echo "contenu" > "$_cu17_d/sub/f.txt"
assert_exit_zero "CU17 dossier avec fichiers dans sous-dossiers → exit 0" \
  _run_core core_assert_target_valid "$_cu17_d"

# == T_CORE03 - core_compute =====================================================

echo ""
echo "========================================"
echo "  T_CORE03 - core_compute"
echo "========================================"

# Données de base pour les tests compute
_cu_compute_dir="$WORKDIR/data_compute"
mkdir -p "$_cu_compute_dir"
echo "alpha"   > "$_cu_compute_dir/alpha.txt"
echo "beta"    > "$_cu_compute_dir/beta.txt"
echo "gamma"   > "$_cu_compute_dir/gamma.txt"

# CU18 : fichier .b3 créé
_cu18_b3="$WORKDIR/cu18.b3"
( cd "$WORKDIR" && core_compute "data_compute" "$_cu18_b3" "" )
[ -f "$_cu18_b3" ] && pass "CU18 fichier .b3 créé" || fail "CU18 fichier .b3 absent"

# CU19 : N lignes pour N fichiers
_cu19_lines=$(wc -l < "$_cu18_b3")
assert_numeric_eq "CU19 3 lignes pour 3 fichiers" 3 "$_cu19_lines"

# CU20 : format <hash64>  <chemin>
_cu20_line=$(head -1 "$_cu18_b3")
if echo "$_cu20_line" | grep -qE '^[0-9a-f]{64}  .+'; then
  pass "CU20 format <hash64>  <chemin> correct"
else
  fail "CU20 format inattendu : $_cu20_line"
fi

# CU21 : chemin relatif préservé
assert_contains "CU21 chemin relatif dans .b3" "data_compute/" "$(cat "$_cu18_b3")"

# CU22 : fichier avec espace dans le nom
_cu22_d="$WORKDIR/data_cu22"; mkdir -p "$_cu22_d"
echo "espace" > "$_cu22_d/fichier avec espace.txt"
_cu22_b3="$WORKDIR/cu22.b3"
( cd "$WORKDIR" && core_compute "data_cu22" "$_cu22_b3" "" )
assert_contains "CU22 chemin avec espace dans .b3" "fichier avec espace.txt" "$(cat "$_cu22_b3")"
_cu22_lines=$(wc -l < "$_cu22_b3")
assert_numeric_eq "CU22 une seule ligne" 1 "$_cu22_lines"

# CU23 : fichier de taille zéro - doit figurer dans le .b3
_cu23_d="$WORKDIR/data_cu23"; mkdir -p "$_cu23_d"
touch "$_cu23_d/zero.bin"
_cu23_b3="$WORKDIR/cu23.b3"
( cd "$WORKDIR" && core_compute "data_cu23" "$_cu23_b3" "" )
assert_contains "CU23 fichier taille zéro présent dans .b3" "zero.bin" "$(cat "$_cu23_b3")"

# CU24 : callback appelé N fois
_cu24_d="$WORKDIR/data_cu24"; mkdir -p "$_cu24_d"
for i in 1 2 3 4 5; do echo "contenu $i" > "$_cu24_d/f${i}.txt"; done
_cu24_b3="$WORKDIR/cu24.b3"
_cu24_count=0
_counter_callback() { _cu24_count=$((_cu24_count + 1)); }
( cd "$WORKDIR" && core_compute "data_cu24" "$_cu24_b3" "_counter_callback" )
# Note : le callback étant appelé dans un sous-shell, on le ré-exécute en scope courant
_cu24_count=0
_cu24_b3b="$WORKDIR/cu24b.b3"
core_compute "$_cu24_d" "$_cu24_b3b" "_counter_callback"
assert_numeric_eq "CU24 callback appelé 5 fois" 5 "$_cu24_count"

# CU25 : callback reçoit les bons arguments (i, total, bytes_done, total_bytes, eta)
_cu25_d="$WORKDIR/data_cu25"; mkdir -p "$_cu25_d"
echo "data" > "$_cu25_d/f1.txt"
_cu25_b3="$WORKDIR/cu25.b3"
_cu25_args=()
_args_callback() { _cu25_args=("$@"); }
core_compute "$_cu25_d" "$_cu25_b3" "_args_callback"
if [ "${#_cu25_args[@]}" -eq 5 ]; then
  pass "CU25 callback reçoit 5 arguments"
else
  fail "CU25 callback reçoit ${#_cu25_args[@]} arguments (attendu 5)"
fi
# i=1, total=1
assert_numeric_eq "CU25 i=1"     1 "${_cu25_args[0]}"
assert_numeric_eq "CU25 total=1" 1 "${_cu25_args[1]}"

# CU26 : le fichier .b3 ne contient pas de lignes ETA ou \r
assert_not_contains "CU26 pas de 'ETA' dans .b3"  "ETA"  "$(cat "$_cu18_b3")"
if ! grep -qP '\r' "$_cu18_b3" 2>/dev/null; then
  pass "CU26 pas de \\r dans .b3"
else
  fail "CU26 \\r détecté dans .b3"
fi

# CU27 : idempotence - deux compute produisent des fichiers identiques
_cu27_b3a="$WORKDIR/cu27a.b3"; _cu27_b3b="$WORKDIR/cu27b.b3"
( cd "$WORKDIR" && core_compute "data_compute" "$_cu27_b3a" "" )
( cd "$WORKDIR" && core_compute "data_compute" "$_cu27_b3b" "" )
assert_exit_zero "CU27 idempotence - fichiers identiques" diff "$_cu27_b3a" "$_cu27_b3b"

# == T_CORE04 - core_verify ======================================================

echo ""
echo "========================================"
echo "  T_CORE04 - core_verify"
echo "========================================"

# Setup commun pour les tests verify
_cv_dir="$WORKDIR/data_verify"; mkdir -p "$_cv_dir"
echo "alpha"   > "$_cv_dir/alpha.txt"
echo "beta"    > "$_cv_dir/beta.txt"
echo "gamma"   > "$_cv_dir/gamma.txt"
echo "delta"   > "$_cv_dir/delta.txt"
_cv_b3="$WORKDIR/verify_base.b3"
( cd "$_cv_dir" && b3sum ./*.txt | sort > "$_cv_b3" )

# CU28 : tous les fichiers intègres → exit 0, STATUS=OK
( cd "$_cv_dir" && core_verify "$_cv_b3" )
_cu28_exit=$?
assert_numeric_eq "CU28 exit 0 si tout OK" 0 "$_cu28_exit"
assert_equals "CU28 STATUS=OK" "OK" "$CORE_VERIFY_STATUS"

# CU29 : un fichier corrompu → exit 1, STATUS=ECHEC
echo "corrompu" > "$_cv_dir/beta.txt"
_cu29_exit=0
( cd "$_cv_dir" && core_verify "$_cv_b3" ) || _cu29_exit=$?
if [ "$_cu29_exit" -ne 0 ]; then pass "CU29 exit non-zéro si corruption"; else fail "CU29 doit détecter la corruption"; fi
assert_equals "CU29 STATUS=ECHEC" "ECHEC" "$CORE_VERIFY_STATUS"
assert_numeric_eq "CU29 NB_FAIL=1" 1 "$CORE_VERIFY_NB_FAIL"
echo "beta" > "$_cv_dir/beta.txt"
# Recalcul propre
( cd "$_cv_dir" && b3sum ./*.txt | sort > "$_cv_b3" )

# CU30 : plusieurs fichiers corrompus
echo "corrompu_alpha" > "$_cv_dir/alpha.txt"
echo "corrompu_beta"  > "$_cv_dir/beta.txt"
_cu30_exit=0
( cd "$_cv_dir" && core_verify "$_cv_b3" ) || _cu30_exit=$?
if [ "$_cu30_exit" -ne 0 ]; then pass "CU30 exit non-zéro si 2 corruptions"; else fail "CU30 doit détecter 2 corruptions"; fi
if [ "$CORE_VERIFY_NB_FAIL" -ge 2 ]; then pass "CU30 NB_FAIL>=2"; else fail "CU30 NB_FAIL=$CORE_VERIFY_NB_FAIL (attendu >=2)"; fi
echo "alpha" > "$_cv_dir/alpha.txt"
echo "beta"  > "$_cv_dir/beta.txt"
( cd "$_cv_dir" && b3sum ./*.txt | sort > "$_cv_b3" )

# CU31 : fichier supprimé → exit 1, chemin dans LINES_FAIL
rm "$_cv_dir/gamma.txt"
_cu31_exit=0
( cd "$_cv_dir" && core_verify "$_cv_b3" ) || _cu31_exit=$?
if [ "$_cu31_exit" -ne 0 ]; then pass "CU31 exit non-zéro si fichier supprimé"; else fail "CU31 doit détecter la suppression"; fi
assert_contains "CU31 gamma.txt dans LINES_FAIL" "gamma.txt" "$CORE_VERIFY_LINES_FAIL"
echo "gamma" > "$_cv_dir/gamma.txt"
( cd "$_cv_dir" && b3sum ./*.txt | sort > "$_cv_b3" )

# CU32 : variables CORE_VERIFY_* non nulles en cas nominal
( cd "$_cv_dir" && core_verify "$_cv_b3" )
[ -n "$CORE_VERIFY_STATUS" ]     && pass "CU32 CORE_VERIFY_STATUS non nul"     || fail "CU32 CORE_VERIFY_STATUS vide"
[ -n "$CORE_VERIFY_NB_OK" ]      && pass "CU32 CORE_VERIFY_NB_OK non nul"      || fail "CU32 CORE_VERIFY_NB_OK vide"
[ -n "$CORE_VERIFY_NB_FAIL" ]    && pass "CU32 CORE_VERIFY_NB_FAIL non nul"    || fail "CU32 CORE_VERIFY_NB_FAIL vide"

# CU33 : NB_OK correct (4 fichiers)
assert_numeric_eq "CU33 NB_OK=4" 4 "$CORE_VERIFY_NB_OK"

# CU34 : LINES_FAIL contient le bon chemin après corruption d'un fichier spécifique
echo "corrompu" > "$_cv_dir/beta.txt"
( cd "$_cv_dir" && core_verify "$_cv_b3" ) || true
assert_contains "CU34 LINES_FAIL contient beta.txt" "beta.txt" "$CORE_VERIFY_LINES_FAIL"
echo "beta" > "$_cv_dir/beta.txt"
( cd "$_cv_dir" && b3sum ./*.txt | sort > "$_cv_b3" )

# CU35 : STATUS=ERREUR si fichier illisible
chmod 000 "$_cv_dir/alpha.txt"
( cd "$_cv_dir" && core_verify "$_cv_b3" ) || true
if [ "$CORE_VERIFY_STATUS" = "ERREUR" ] || [ "$CORE_VERIFY_NB_FAIL" -gt 0 ]; then
  pass "CU35 fichier illisible détecté (ERREUR ou FAIL)"
else
  fail "CU35 fichier illisible non détecté (STATUS=$CORE_VERIFY_STATUS)"
fi
chmod 644 "$_cv_dir/alpha.txt"
( cd "$_cv_dir" && b3sum ./*.txt | sort > "$_cv_b3" )

# == T_CORE05 - core_compare =====================================================

echo ""
echo "========================================"
echo "  T_CORE05 - core_compare"
echo "========================================"

# Helper : crée deux bases à partir de deux dossiers et compare
_run_compare() {
  local old_dir="$1" new_dir="$2" old_b3="$3" new_b3="$4" outdir="$5"
  ( cd "$old_dir" && b3sum ./* 2>/dev/null | sort > "$old_b3" ) 2>/dev/null || true
  ( cd "$new_dir" && b3sum ./* 2>/dev/null | sort > "$new_b3" ) 2>/dev/null || true
  mkdir -p "$outdir"
  core_compare "$old_b3" "$new_b3" "$outdir"
}

# CU36 : bases identiques → tout à 0
_cu36_d="$WORKDIR/cu36"; mkdir -p "$_cu36_d"
echo "a" > "$_cu36_d/a.txt"; echo "b" > "$_cu36_d/b.txt"
_cu36_old="$WORKDIR/cu36_old.b3"; _cu36_new="$WORKDIR/cu36_new.b3"
_cu36_out="$WORKDIR/cu36_out"
( cd "$_cu36_d" && b3sum ./*.txt | sort > "$_cu36_old" )
cp "$_cu36_old" "$_cu36_new"
mkdir -p "$_cu36_out"
core_compare "$_cu36_old" "$_cu36_new" "$_cu36_out"
assert_numeric_eq "CU36 NB_MOD=0 bases identiques" 0 "$CORE_COMPARE_NB_MOD"
assert_numeric_eq "CU36 NB_DIS=0 bases identiques" 0 "$CORE_COMPARE_NB_DIS"
assert_numeric_eq "CU36 NB_NOU=0 bases identiques" 0 "$CORE_COMPARE_NB_NOU"

# CU37 : un fichier modifié
_cu37_old_d="$WORKDIR/cu37_old"; _cu37_new_d="$WORKDIR/cu37_new"
mkdir -p "$_cu37_old_d" "$_cu37_new_d"
echo "v1_alpha" > "$_cu37_old_d/alpha.txt"
echo "v1_beta"  > "$_cu37_old_d/beta.txt"
echo "v2_alpha" > "$_cu37_new_d/alpha.txt"   # modifié
echo "v1_beta"  > "$_cu37_new_d/beta.txt"
_cu37_ob="$WORKDIR/cu37_old.b3"; _cu37_nb="$WORKDIR/cu37_new.b3"; _cu37_out="$WORKDIR/cu37_out"
( cd "$_cu37_old_d" && b3sum ./*.txt | sort > "$_cu37_ob" )
( cd "$_cu37_new_d" && b3sum ./*.txt | sort > "$_cu37_nb" )
mkdir -p "$_cu37_out"
core_compare "$_cu37_ob" "$_cu37_nb" "$_cu37_out"
assert_numeric_eq "CU37 NB_MOD=1"          1 "$CORE_COMPARE_NB_MOD"
assert_contains   "CU37 alpha.txt modifié" "alpha.txt" "$(cat "$_cu37_out/modifies.b3")"

# CU38 : plusieurs fichiers modifiés
_cu38_old_d="$WORKDIR/cu38_old"; _cu38_new_d="$WORKDIR/cu38_new"
mkdir -p "$_cu38_old_d" "$_cu38_new_d"
for f in a b c; do
  echo "v1_$f" > "$_cu38_old_d/${f}.txt"
  echo "v2_$f" > "$_cu38_new_d/${f}.txt"
done
_cu38_ob="$WORKDIR/cu38_old.b3"; _cu38_nb="$WORKDIR/cu38_new.b3"; _cu38_out="$WORKDIR/cu38_out"
( cd "$_cu38_old_d" && b3sum ./*.txt | sort > "$_cu38_ob" )
( cd "$_cu38_new_d" && b3sum ./*.txt | sort > "$_cu38_nb" )
mkdir -p "$_cu38_out"
core_compare "$_cu38_ob" "$_cu38_nb" "$_cu38_out"
assert_numeric_eq "CU38 NB_MOD=3" 3 "$CORE_COMPARE_NB_MOD"

# CU39 : un fichier disparu
_cu39_old_d="$WORKDIR/cu39_old"; _cu39_new_d="$WORKDIR/cu39_new"
mkdir -p "$_cu39_old_d" "$_cu39_new_d"
echo "alpha" > "$_cu39_old_d/alpha.txt"
echo "beta"  > "$_cu39_old_d/beta.txt"
echo "beta"  > "$_cu39_new_d/beta.txt"   # alpha disparu
_cu39_ob="$WORKDIR/cu39_old.b3"; _cu39_nb="$WORKDIR/cu39_new.b3"; _cu39_out="$WORKDIR/cu39_out"
( cd "$_cu39_old_d" && b3sum ./*.txt | sort > "$_cu39_ob" )
( cd "$_cu39_new_d" && b3sum ./*.txt | sort > "$_cu39_nb" )
mkdir -p "$_cu39_out"
core_compare "$_cu39_ob" "$_cu39_nb" "$_cu39_out"
assert_numeric_eq "CU39 NB_DIS=1"          1 "$CORE_COMPARE_NB_DIS"
assert_contains   "CU39 alpha.txt disparu" "alpha.txt" "$(cat "$_cu39_out/disparus.txt")"

# CU40 : un fichier nouveau
_cu40_old_d="$WORKDIR/cu40_old"; _cu40_new_d="$WORKDIR/cu40_new"
mkdir -p "$_cu40_old_d" "$_cu40_new_d"
echo "alpha"   > "$_cu40_old_d/alpha.txt"
echo "alpha"   > "$_cu40_new_d/alpha.txt"
echo "epsilon" > "$_cu40_new_d/epsilon.txt"  # nouveau
_cu40_ob="$WORKDIR/cu40_old.b3"; _cu40_nb="$WORKDIR/cu40_new.b3"; _cu40_out="$WORKDIR/cu40_out"
( cd "$_cu40_old_d" && b3sum ./*.txt | sort > "$_cu40_ob" )
( cd "$_cu40_new_d" && b3sum ./*.txt | sort > "$_cu40_nb" )
mkdir -p "$_cu40_out"
core_compare "$_cu40_ob" "$_cu40_nb" "$_cu40_out"
assert_numeric_eq "CU40 NB_NOU=1"            1 "$CORE_COMPARE_NB_NOU"
assert_contains   "CU40 epsilon.txt nouveau" "epsilon.txt" "$(cat "$_cu40_out/nouveaux.txt")"

# CU41 : combinaison modifié + disparu + nouveau
_cu41_old_d="$WORKDIR/cu41_old"; _cu41_new_d="$WORKDIR/cu41_new"
mkdir -p "$_cu41_old_d" "$_cu41_new_d"
echo "v1"     > "$_cu41_old_d/modifie.txt"
echo "v1_dis" > "$_cu41_old_d/disparu.txt"
echo "v2"     > "$_cu41_new_d/modifie.txt"
echo "nvx"    > "$_cu41_new_d/nouveau.txt"
_cu41_ob="$WORKDIR/cu41_old.b3"; _cu41_nb="$WORKDIR/cu41_new.b3"; _cu41_out="$WORKDIR/cu41_out"
( cd "$_cu41_old_d" && b3sum ./*.txt | sort > "$_cu41_ob" )
( cd "$_cu41_new_d" && b3sum ./*.txt | sort > "$_cu41_nb" )
mkdir -p "$_cu41_out"
core_compare "$_cu41_ob" "$_cu41_nb" "$_cu41_out"
assert_numeric_eq "CU41 NB_MOD=1" 1 "$CORE_COMPARE_NB_MOD"
assert_numeric_eq "CU41 NB_DIS=1" 1 "$CORE_COMPARE_NB_DIS"
assert_numeric_eq "CU41 NB_NOU=1" 1 "$CORE_COMPARE_NB_NOU"

# CU42 : chemin avec espace
_cu42_old_d="$WORKDIR/cu42_old"; _cu42_new_d="$WORKDIR/cu42_new"
mkdir -p "$_cu42_old_d" "$_cu42_new_d"
echo "v1" > "$_cu42_old_d/fichier avec espace.txt"
echo "v2" > "$_cu42_new_d/fichier avec espace.txt"
_cu42_ob="$WORKDIR/cu42_old.b3"; _cu42_nb="$WORKDIR/cu42_new.b3"; _cu42_out="$WORKDIR/cu42_out"
( cd "$_cu42_old_d" && b3sum "fichier avec espace.txt" > "$_cu42_ob" )
( cd "$_cu42_new_d" && b3sum "fichier avec espace.txt" > "$_cu42_nb" )
mkdir -p "$_cu42_out"
core_compare "$_cu42_ob" "$_cu42_nb" "$_cu42_out"
assert_contains   "CU42 chemin avec espace dans modifies.b3" "fichier avec espace.txt" "$(cat "$_cu42_out/modifies.b3")"
assert_numeric_eq "CU42 NB_MOD=1"                            1 "$CORE_COMPARE_NB_MOD"

# CU43 : chemin avec &
_cu43_old_d="$WORKDIR/cu43_old"; _cu43_new_d="$WORKDIR/cu43_new"
mkdir -p "$_cu43_old_d" "$_cu43_new_d"
echo "v1" > "$_cu43_old_d/a&b.txt"
echo "v2" > "$_cu43_new_d/a&b.txt"
_cu43_ob="$WORKDIR/cu43_old.b3"; _cu43_nb="$WORKDIR/cu43_new.b3"; _cu43_out="$WORKDIR/cu43_out"
( cd "$_cu43_old_d" && b3sum "a&b.txt" > "$_cu43_ob" )
( cd "$_cu43_new_d" && b3sum "a&b.txt" > "$_cu43_nb" )
mkdir -p "$_cu43_out"
core_compare "$_cu43_ob" "$_cu43_nb" "$_cu43_out"
assert_contains "CU43 chemin avec & dans modifies.b3" "a&b.txt" "$(cat "$_cu43_out/modifies.b3")"

# CU44 : chemin avec < et >
_cu44_old_d="$WORKDIR/cu44_old"; _cu44_new_d="$WORKDIR/cu44_new"
mkdir -p "$_cu44_old_d" "$_cu44_new_d"
echo "v1" > "$_cu44_old_d/<script>.txt"
echo "v2" > "$_cu44_new_d/<script>.txt"
_cu44_ob="$WORKDIR/cu44_old.b3"; _cu44_nb="$WORKDIR/cu44_new.b3"; _cu44_out="$WORKDIR/cu44_out"
( cd "$_cu44_old_d" && b3sum "<script>.txt" > "$_cu44_ob" )
( cd "$_cu44_new_d" && b3sum "<script>.txt" > "$_cu44_nb" )
mkdir -p "$_cu44_out"
core_compare "$_cu44_ob" "$_cu44_nb" "$_cu44_out"
assert_contains "CU44 chemin avec <> dans modifies.b3" "<script>.txt" "$(cat "$_cu44_out/modifies.b3")"
# Pas d'échappement HTML dans .b3 (fichier binaire, pas HTML)
assert_not_contains "CU44 pas d'&lt; dans modifies.b3" "&lt;" "$(cat "$_cu44_out/modifies.b3")"

# CU45 : format de modifies.b3 = "<nouveau_hash>  <chemin>" (format b3sum)
_cu45_line=$(head -1 "$_cu44_out/modifies.b3")
if echo "$_cu45_line" | grep -qE '^[0-9a-f]{64}  .+'; then
  pass "CU45 format modifies.b3 conforme b3sum"
else
  fail "CU45 format modifies.b3 inattendu : $_cu45_line"
fi

# CU46 : variables CORE_COMPARE_NB_* définies après appel
_cu46_out="$WORKDIR/cu46_out"; mkdir -p "$_cu46_out"
core_compare "$_cu36_old" "$_cu36_new" "$_cu46_out"
[ -n "${CORE_COMPARE_NB_MOD+x}" ] && pass "CU46 NB_MOD défini" || fail "CU46 NB_MOD non défini"
[ -n "${CORE_COMPARE_NB_DIS+x}" ] && pass "CU46 NB_DIS défini" || fail "CU46 NB_DIS non défini"
[ -n "${CORE_COMPARE_NB_NOU+x}" ] && pass "CU46 NB_NOU défini" || fail "CU46 NB_NOU non défini"

# CU47 : pas de fichiers tmp résiduels après appel (pattern mktemp standard)
# Note : core_compare nettoie via trap EXIT interne ; on vérifie qu'aucun /tmp/tmp.* récent ne traîne
_tmp_before=$(find /tmp -maxdepth 1 -name 'tmp.*' -newer "$WORKDIR" 2>/dev/null | wc -l)
core_compare "$_cu36_old" "$_cu36_new" "$_cu46_out" 2>/dev/null || true
_tmp_after=$(find /tmp -maxdepth 1 -name 'tmp.*' -newer "$WORKDIR" 2>/dev/null | wc -l)
if [ "$_tmp_after" -le "$_tmp_before" ]; then
  pass "CU47 fichiers tmp nettoyés"
else
  fail "CU47 fichiers tmp résiduels détectés ($((tmp_after - tmp_before)))"
fi

# CU48 : outdir absent → comportement défini (mkdir requis par l'appelant)
_cu48_nonexist="$WORKDIR/cu48_outdir_nonexist"
_cu48_exit=0
core_compare "$_cu36_old" "$_cu36_new" "$_cu48_nonexist" 2>/dev/null || _cu48_exit=$?
# Comportement attendu : échec ou création du dossier selon implémentation.
# On documente ce qui se passe sans imposer un exit code (outdir inexistant est précondition violée).
if [ "$_cu48_exit" -ne 0 ] || [ -d "$_cu48_nonexist" ]; then
  pass "CU48 outdir absent : comportement défini (exit=$_cu48_exit, dir_created=$([ -d "$_cu48_nonexist" ] && echo oui || echo non))"
else
  fail "CU48 outdir absent : comportement indéfini"
fi

# == T_CORE06 - core_make_result_dir =============================================

echo ""
echo "========================================"
echo "  T_CORE06 - core_make_result_dir"
echo "========================================"

_cu_res_root="$WORKDIR/resultats_test"; mkdir -p "$_cu_res_root"

# CU49 : création normale
_cu49_b3="$WORKDIR/hashes.b3"; touch "$_cu49_b3"
_cu49_result=$(core_make_result_dir "$_cu49_b3" "$_cu_res_root")
[ -d "$_cu49_result" ] && pass "CU49 dossier créé" || fail "CU49 dossier absent"
assert_contains "CU49 nom contient 'resultats_hashes'" "resultats_hashes" "$_cu49_result"

# CU50 : anti-collision - dossier existant → suffixe horodaté
# Le dossier résultats_hashes existe déjà depuis CU49
_cu50_result=$(core_make_result_dir "$_cu49_b3" "$_cu_res_root")
if [ "$_cu50_result" != "$_cu49_result" ]; then
  pass "CU50 anti-collision : nouveau dossier créé"
else
  fail "CU50 anti-collision : même dossier retourné (écrasement)"
fi
[ -d "$_cu50_result" ] && pass "CU50 nouveau dossier existe" || fail "CU50 nouveau dossier absent"

# CU51 : deux appels successifs → deux dossiers distincts
_cu51_b3="$WORKDIR/autre.b3"; touch "$_cu51_b3"
_cu51_r1=$(core_make_result_dir "$_cu51_b3" "$_cu_res_root")
sleep 1
_cu51_r2=$(core_make_result_dir "$_cu51_b3" "$_cu_res_root")
if [ "$_cu51_r1" != "$_cu51_r2" ]; then
  pass "CU51 deux appels → deux dossiers distincts"
else
  fail "CU51 deux appels → même dossier (collision)"
fi

# CU52 : nom sans extension .b3
_cu52_b3="$WORKDIR/base"; touch "$_cu52_b3"
_cu52_result=$(core_make_result_dir "$_cu52_b3" "$_cu_res_root")
assert_contains "CU52 nom sans extension → resultats_base" "resultats_base" "$_cu52_result"

# CU53 : nom avec chemin imbriqué → basename only
_cu53_b3="/chemin/vers/hashes.b3"
# On ne crée pas ce fichier - on teste seulement la logique de nommage
_cu53_result=$(core_make_result_dir "$_cu53_b3" "$_cu_res_root")
assert_contains "CU53 chemin imbriqué → resultats_hashes" "resultats_hashes" "$_cu53_result"
# Ne doit pas contenir le chemin complet
assert_not_contains "CU53 pas de chemin absolu dans le nom" "/chemin/vers/" "$_cu53_result"

# == Résultats ===================================================================

echo ""
echo "========================================"
if [ "$FAIL" -eq 0 ]; then
  echo -e "  ${GREEN}$PASS/$TOTAL tests passés${NC}"
else
  echo -e "  ${GREEN}$PASS${NC}/${TOTAL} passés - ${RED}$FAIL échec(s)${NC}"
fi
echo "========================================"
echo ""

[ "$FAIL" -eq 0 ]

--- Fichier : tests/run_tests_pipeline.sh ---
#!/usr/bin/env bash
# run_tests_pipeline.sh - Tests automatisés pour runner.sh + pipeline.json
#
# Couvre : parsing JSON, compute, verify, compare, champ resultats, erreurs
#
# Prérequis : bash >= 4, jq, b3sum
#             runner.sh    à ../
#             integrity.sh à ../src/
# Usage     : cd tests && ./run_tests_pipeline.sh

set -euo pipefail

SCRIPT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"
RUNNER="$SCRIPT_DIR/../runner.sh"
INTEGRITY="$SCRIPT_DIR/../src/integrity.sh"
WORKDIR="$(mktemp -d /tmp/integrity-pipeline-test.XXXXXX)"
export RESULTATS_DIR="$WORKDIR/resultats"

GREEN='\033[0;32m'
RED='\033[0;31m'
NC='\033[0m'

PASS=0; FAIL=0; TOTAL=0

pass() { echo -e "${GREEN}  PASS${NC} - $1"; PASS=$((PASS+1)); TOTAL=$((TOTAL+1)); }
fail() { echo -e "${RED}  FAIL${NC} - $1"; FAIL=$((FAIL+1)); TOTAL=$((TOTAL+1)); }

assert_contains() {
    local label="$1" pattern="$2" output="$3"
    if echo "$output" | grep -q "$pattern"; then pass "$label"; else fail "$label (pattern '$pattern' absent)"; fi
}

assert_not_contains() {
    local label="$1" pattern="$2" output="$3"
    if ! echo "$output" | grep -q "$pattern"; then pass "$label"; else fail "$label (pattern '$pattern' présent à tort)"; fi
}

assert_file_exists() {
    local label="$1" file="$2"
    if [ -f "$file" ]; then pass "$label"; else fail "$label (absent : $file)"; fi
}

assert_file_absent() {
    local label="$1" file="$2"
    if [ ! -f "$file" ]; then pass "$label"; else fail "$label (présent à tort : $file)"; fi
}

assert_line_count() {
    local label="$1" expected="$2" file="$3"
    local actual; actual=$(wc -l < "$file")
    if [ "$actual" -eq "$expected" ]; then pass "$label"; else fail "$label (attendu $expected, obtenu $actual)"; fi
}

write_config() {
    local path="$WORKDIR/pipeline.json"
    cat > "$path"
    echo "$path"
}

setup() {
    mkdir -p "$WORKDIR"/{src_a,src_b,bases,resultats}

    echo "alpha content" > "$WORKDIR/src_a/alpha.txt"
    echo "beta content"  > "$WORKDIR/src_a/beta.txt"
    mkdir -p "$WORKDIR/src_a/sub"
    echo "delta content" > "$WORKDIR/src_a/sub/delta.txt"

    echo "gamma content" > "$WORKDIR/src_b/gamma.txt"
    echo "delta content" > "$WORKDIR/src_b/delta.txt"
}

teardown() { rm -rf "$WORKDIR"; }

run_tests() {
    cd "$WORKDIR"

    echo ""
    echo "========================================"
    echo "  runner.sh - suite de tests"
    echo "  Workdir : $WORKDIR"
    echo "========================================"
    echo ""

    echo "TP00 - Permissions integrity.sh"
    if [ -x "$INTEGRITY" ]; then pass "integrity.sh est exécutable"; else fail "integrity.sh non exécutable (chmod +x requis)"; fi
    echo ""

    # == TP01 : JSON invalide ==================================================
    echo "TP01 - JSON invalide : erreur propre sans stacktrace jq"
    local cfg_invalid="$WORKDIR/invalid.json"
    echo "{ pipeline: [ BROKEN" > "$cfg_invalid"
    local out_tp01; out_tp01=$(bash "$RUNNER" "$cfg_invalid" 2>&1 || true)
    assert_contains     "ERREUR signalée"         "ERREUR"      "$out_tp01"
    assert_not_contains "pas de stacktrace jq"    "parse error" "$out_tp01"
    echo ""

    # == TP02 : .pipeline absent ===============================================
    echo "TP02 - .pipeline absent"
    local cfg_no_pipeline
    cfg_no_pipeline=$(write_config <<'EOF'
{ "config": [] }
EOF
)
    local out_tp02; out_tp02=$(bash "$RUNNER" "$cfg_no_pipeline" 2>&1 || true)
    assert_contains "ERREUR si .pipeline absent" "ERREUR" "$out_tp02"
    echo ""

    # == TP03 : champ manquant =================================================
    echo "TP03 - Champ 'nom' manquant dans compute"
    local cfg_missing
    cfg_missing=$(write_config <<EOF
{
    "pipeline": [
        { "op": "compute", "source": "$WORKDIR/src_a", "bases": "$WORKDIR/bases" }
    ]
}
EOF
)
    local out_tp03; out_tp03=$(bash "$RUNNER" "$cfg_missing" 2>&1 || true)
    assert_contains "ERREUR signalée"       "ERREUR" "$out_tp03"
    assert_contains "champ 'nom' mentionné" "nom"    "$out_tp03"
    echo ""

    # == TP04 : opération inconnue =============================================
    echo "TP04 - Opération inconnue"
    local cfg_unknown
    cfg_unknown=$(write_config <<'EOF'
{ "pipeline": [ { "op": "migrate", "source": "/tmp" } ] }
EOF
)
    local out_tp04; out_tp04=$(bash "$RUNNER" "$cfg_unknown" 2>&1 || true)
    assert_contains "ERREUR signalée"           "ERREUR"   "$out_tp04"
    assert_contains "nom de l'op dans l'erreur" "migrate"  "$out_tp04"
    echo ""

    # == TP05 : compute - chemins relatifs =====================================
    echo "TP05 - Compute : cd correct, chemins relatifs dans la base"
    local cfg_compute
    cfg_compute=$(write_config <<EOF
{
    "pipeline": [
        { "op": "compute", "source": "$WORKDIR/src_a", "bases": "$WORKDIR/bases", "nom": "hashes_a.b3" }
    ]
}
EOF
)
    bash "$RUNNER" "$cfg_compute" >/dev/null 2>&1
    assert_file_exists "base hashes_a.b3 créée" "$WORKDIR/bases/hashes_a.b3"
    local first_path; first_path=$(awk '{print $2}' "$WORKDIR/bases/hashes_a.b3" | head -1)
    assert_contains     "chemin relatif (./) dans base"    "./"       "$first_path"
    assert_not_contains "pas de chemin absolu dans base"   "$WORKDIR" "$first_path"
    assert_line_count   "3 fichiers indexés"               3          "$WORKDIR/bases/hashes_a.b3"
    echo ""

    # == TP06 : compute - source absente ======================================
    echo "TP06 - Compute : source absente → erreur"
    local cfg_absent
    cfg_absent=$(write_config <<EOF
{
    "pipeline": [
        { "op": "compute", "source": "$WORKDIR/inexistant", "bases": "$WORKDIR/bases", "nom": "ko.b3" }
    ]
}
EOF
)
    local out_tp06; out_tp06=$(bash "$RUNNER" "$cfg_absent" 2>&1 || true)
    assert_contains    "ERREUR signalée"              "ERREUR"  "$out_tp06"
    assert_file_absent "pas de base créée si source KO" "$WORKDIR/bases/ko.b3"
    echo ""

    # == TP07 : verify - OK ===================================================
    echo "TP07 - Verify : répertoire de travail correct, vérification OK"
    local cfg_verify
    cfg_verify=$(write_config <<EOF
{
    "pipeline": [
        { "op": "verify", "source": "$WORKDIR/src_a", "base": "$WORKDIR/bases/hashes_a.b3" }
    ]
}
EOF
)
    local out_tp07; out_tp07=$(bash "$RUNNER" "$cfg_verify" 2>&1 || true)
    assert_contains     "verify OK"     "OK"     "$out_tp07"
    assert_not_contains "aucun FAILED"  "FAILED" "$out_tp07"
    local outdir_tp07; outdir_tp07=$(find "${RESULTATS_DIR}" -maxdepth 1 -type d -name "resultats_hashes_a*" 2>/dev/null | sort | tail -1)
    assert_file_exists  "recap.txt produit" "${outdir_tp07}/recap.txt"
    echo ""

    # == TP08 : verify - corruption ===========================================
    echo "TP08 - Verify : corruption détectée"
    echo "contenu corrompu" > "$WORKDIR/src_a/alpha.txt"
    local out_tp08; out_tp08=$(bash "$RUNNER" "$cfg_verify" 2>&1 || true)
    assert_contains "ECHEC détecté" "ECHEC" "$out_tp08"
    echo "alpha content"   > "$WORKDIR/src_a/alpha.txt"
    echo ""

    # == TP09 : verify - base absente =========================================
    echo "TP09 - Verify : base .b3 absente → erreur"
    local cfg_verify_bad
    cfg_verify_bad=$(write_config <<EOF
{
    "pipeline": [
        { "op": "verify", "source": "$WORKDIR/src_a", "base": "$WORKDIR/bases/fantome.b3" }
    ]
}
EOF
)
    local out_tp09; out_tp09=$(bash "$RUNNER" "$cfg_verify_bad" 2>&1 || true)
    assert_contains "ERREUR si base absente" "ERREUR" "$out_tp09"
    echo ""

    # == TP10 : compare - résultats produits (RESULTATS_DIR par défaut) ========
    echo "TP10 - Compare : fichiers de résultats produits (sans champ resultats)"
    local cfg_compute_b
    cfg_compute_b=$(write_config <<EOF
{
    "pipeline": [
        { "op": "compute", "source": "$WORKDIR/src_b", "bases": "$WORKDIR/bases", "nom": "hashes_b.b3" }
    ]
}
EOF
)
    bash "$RUNNER" "$cfg_compute_b" >/dev/null 2>&1

    local cfg_compare
    cfg_compare=$(write_config <<EOF
{
    "pipeline": [
        { "op": "compare", "base_a": "$WORKDIR/bases/hashes_a.b3", "base_b": "$WORKDIR/bases/hashes_b.b3" }
    ]
}
EOF
)
    bash "$RUNNER" "$cfg_compare" >/dev/null 2>&1
    local outdir_tp10; outdir_tp10=$(find "${RESULTATS_DIR}" -maxdepth 1 -type d -name "resultats_hashes_a*" 2>/dev/null | sort | tail -1)
    assert_file_exists "recap.txt"    "${outdir_tp10}/recap.txt"
    assert_file_exists "modifies.b3"  "${outdir_tp10}/modifies.b3"
    assert_file_exists "disparus.txt" "${outdir_tp10}/disparus.txt"
    assert_file_exists "nouveaux.txt" "${outdir_tp10}/nouveaux.txt"
    assert_file_exists "report.html"  "${outdir_tp10}/report.html"
    echo ""

    # == TP10b : compare - champ resultats personnalisé =======================
    echo "TP10b - Compare : champ 'resultats' personnalisé dans pipeline.json"
    local custom_dir="$WORKDIR/mon_rapport_custom"
    local cfg_compare_custom
    cfg_compare_custom=$(write_config <<EOF
{
    "pipeline": [
        {
            "op":       "compare",
            "base_a":   "$WORKDIR/bases/hashes_a.b3",
            "base_b":   "$WORKDIR/bases/hashes_b.b3",
            "resultats": "$custom_dir"
        }
    ]
}
EOF
)
    bash "$RUNNER" "$cfg_compare_custom" >/dev/null 2>&1
    local outdir_custom; outdir_custom=$(find "${custom_dir}" -maxdepth 1 -type d -name "resultats_hashes_a*" 2>/dev/null | sort | tail -1)
    assert_file_exists "rapport dans dossier custom"            "${outdir_custom}/recap.txt"
    assert_file_exists "report.html dans dossier custom"        "${outdir_custom}/report.html"
    # Vérifier que le dossier par défaut n'a PAS reçu ce résultat
    local nb_before; nb_before=$(find "${RESULTATS_DIR}" -maxdepth 1 -type d -name "resultats_hashes_a*" 2>/dev/null | wc -l)
    bash "$RUNNER" "$cfg_compare_custom" >/dev/null 2>&1
    local nb_after; nb_after=$(find "${RESULTATS_DIR}" -maxdepth 1 -type d -name "resultats_hashes_a*" 2>/dev/null | wc -l)
    if [ "$nb_before" -eq "$nb_after" ]; then
        pass "champ resultats isolé : RESULTATS_DIR par défaut non pollué"
    else
        fail "champ resultats isolé : RESULTATS_DIR par défaut non pollué"
    fi
    echo ""

    # == TP11 : compare - base_a absente ======================================
    echo "TP11 - Compare : base_a absente → erreur"
    local cfg_compare_bad
    cfg_compare_bad=$(write_config <<EOF
{
    "pipeline": [
        { "op": "compare", "base_a": "$WORKDIR/bases/fantome.b3", "base_b": "$WORKDIR/bases/hashes_b.b3" }
    ]
}
EOF
)
    local out_tp11; out_tp11=$(bash "$RUNNER" "$cfg_compare_bad" 2>&1 || true)
    assert_contains "ERREUR si base_a absente" "ERREUR" "$out_tp11"
    echo ""

    # == TP12 : pipeline complet ===============================================
    echo "TP12 - Pipeline complet : compute × 2 + verify + compare"
    rm -f "$WORKDIR/bases/hashes_a.b3" "$WORKDIR/bases/hashes_b.b3"
    local cfg_full
    cfg_full=$(write_config <<EOF
{
    "pipeline": [
        { "op": "compute", "source": "$WORKDIR/src_a", "bases": "$WORKDIR/bases", "nom": "hashes_a.b3" },
        { "op": "compute", "source": "$WORKDIR/src_b", "bases": "$WORKDIR/bases", "nom": "hashes_b.b3" },
        { "op": "verify",  "source": "$WORKDIR/src_a", "base":  "$WORKDIR/bases/hashes_a.b3" },
        { "op": "compare", "base_a": "$WORKDIR/bases/hashes_a.b3", "base_b": "$WORKDIR/bases/hashes_b.b3",
          "resultats": "$WORKDIR/resultats_pipeline" }
    ]
}
EOF
)
    local out_tp12; out_tp12=$(bash "$RUNNER" "$cfg_full" 2>&1 || true)
    assert_contains     "COMPUTE mentionné"     "COMPUTE" "$out_tp12"
    assert_contains     "VERIFY mentionné"      "VERIFY"  "$out_tp12"
    assert_contains     "COMPARE mentionné"     "COMPARE" "$out_tp12"
    assert_file_exists  "hashes_a.b3 créée"     "$WORKDIR/bases/hashes_a.b3"
    assert_file_exists  "hashes_b.b3 créée"     "$WORKDIR/bases/hashes_b.b3"
    assert_not_contains "pas d'ERREUR"          "ERREUR"  "$out_tp12"
    local outdir_tp12; outdir_tp12=$(find "${WORKDIR}/resultats_pipeline" -maxdepth 1 -type d -name "resultats_hashes_a*" 2>/dev/null | sort | tail -1)
    assert_file_exists  "report.html pipeline complet" "${outdir_tp12}/report.html"
    echo ""
}

# == Main ======================================================================

for dep in jq b3sum; do
    command -v "$dep" &>/dev/null || { echo -e "${RED}ERREUR${NC} : $dep non trouvé."; exit 1; }
done

[ -f "$RUNNER" ]    || { echo -e "${RED}ERREUR${NC} : runner.sh introuvable : $RUNNER";      exit 1; }
[ -f "$INTEGRITY" ] || { echo -e "${RED}ERREUR${NC} : src/integrity.sh introuvable : $INTEGRITY"; exit 1; }

setup
run_tests
teardown

echo "========================================"
if [ "$FAIL" -eq 0 ]; then
    echo -e "  ${GREEN}$PASS/$TOTAL tests passés${NC}"
else
    echo -e "  ${GREEN}$PASS${NC}/${TOTAL} passés - ${RED}$FAIL échec(s)${NC}"
fi
echo "========================================"
echo ""

[ "$FAIL" -eq 0 ]

--- Fichier : hors_git/TODO.md ---


# TODO 

- il faut que la comparaison, les bases de hash aussi vienne avec des métadonnées
  - par exemple un fichier "[nom de la base] - métadonnée.json" avec les métadonnées , un sidecar file 

## Documentation 

- améliorer la documentation
  - ajouter le contenu des .docx dans la doc en ligne 
  - ajouter la doc des tests aussi 
  Remarque : qu'est-ce que je dois mettre dans la documentation? est-ce que la façon dont c'est codé doit être dans la doc ?? Typiquement les README, moi j'ai envie de les mettre dans les tests. Une documentation pour l'utilisateur final et une autre pour le dev ??? 

les docx sont vraiment bien rédigés, là la doc est merdique de fou, pas du tout perspicace ... 

## Chemins relatifs

"Toujours lancer compute depuis le dossier qui contient les données, pas depuis un dossier parent. Les chemins dans le .b3 sont relatifs au pwd au moment du compute." 

J'aime pas ça, je veux comprendre pourquoi ça fait ça 

## Tests 

- tests de non régression 
- test unitaires avec rapport 

## Misc 

- bien comprendre l'outil produit
- restructurer 
- rendre public et partager 


## requirements et environment.yml 

pourquoi il y a pas ça ? 
il y a le docker mais pas la version simple classiques 

## anglais

migrer la doc en anglais 


--- Fichier : hors_git/tests/2026-02-26-17-13 -- manuel.md ---
# Manuel des tests — hash_tool

- [Manuel des tests — hash\_tool](#manuel-des-tests--hash_tool)
  - [Vue d'ensemble](#vue-densemble)
    - [Pyramide des tests](#pyramide-des-tests)
  - [Prérequis](#prérequis)
  - [Lancer les tests](#lancer-les-tests)
    - [Sortie attendue](#sortie-attendue)
  - [Suite 1 — `run_tests.sh` (T00–T20)](#suite-1--run_testssh-t00t20)
    - [Données de test](#données-de-test)
    - [Catalogue des cas](#catalogue-des-cas)
      - [T00 — ShellCheck](#t00--shellcheck)
      - [T01 — Compute de base](#t01--compute-de-base)
      - [T02 — Verify sans modification](#t02--verify-sans-modification)
      - [T03 — Verify après corruption](#t03--verify-après-corruption)
      - [T04 — Verify après suppression](#t04--verify-après-suppression)
      - [T05 — Compare : aucune différence](#t05--compare--aucune-différence)
      - [T06 — Compare : fichier modifié](#t06--compare--fichier-modifié)
      - [T07 — Compare : suppression + ajout](#t07--compare--suppression--ajout)
      - [T08 — Robustesse : fichier avec espace dans le nom](#t08--robustesse--fichier-avec-espace-dans-le-nom)
      - [T09 — Dossier vide ignoré](#t09--dossier-vide-ignoré)
      - [T10 — Chemin absolu vs chemin relatif](#t10--chemin-absolu-vs-chemin-relatif)
      - [T11 — ETA : base identique à la référence `b3sum`](#t11--eta--base-identique-à-la-référence-b3sum)
      - [T12 — Mode `--quiet`](#t12--mode---quiet)
      - [T13 — Horodatage anti-écrasement](#t13--horodatage-anti-écrasement)
      - [T14 — Verify avec dossier source inexistant](#t14--verify-avec-dossier-source-inexistant)
      - [T15 — Nom de fichier avec newline](#t15--nom-de-fichier-avec-newline)
      - [T16 — Caractères HTML dans les noms de fichiers](#t16--caractères-html-dans-les-noms-de-fichiers)
      - [T17 — Compare sans différence → report.html mentionne "IDENTIQUES"](#t17--compare-sans-différence--reporthtml-mentionne-identiques)
      - [T18 — `--quiet` sur `compare`](#t18----quiet-sur-compare)
      - [T19 — Lien symbolique dans le dossier source](#t19--lien-symbolique-dans-le-dossier-source)
      - [T20 — `verify` avec dossier source totalement inexistant](#t20--verify-avec-dossier-source-totalement-inexistant)
  - [Suite 2 — `run_tests_pipeline.sh` (TP00–TP12)](#suite-2--run_tests_pipelinesh-tp00tp12)
    - [Données de test](#données-de-test-1)
    - [Catalogue des cas](#catalogue-des-cas-1)
  - [Suite 3 — `run_tests_core.sh` (CU01–CU53)](#suite-3--run_tests_coresh-cu01cu53)
    - [Mécanisme de sourcing](#mécanisme-de-sourcing)
    - [T\_CORE01 — `core_assert_b3_valid` (CU01–CU11)](#t_core01--core_assert_b3_valid-cu01cu11)
    - [T\_CORE02 — `core_assert_target_valid` (CU12–CU17)](#t_core02--core_assert_target_valid-cu12cu17)
    - [T\_CORE03 — `core_compute` (CU18–CU27)](#t_core03--core_compute-cu18cu27)
    - [T\_CORE04 — `core_verify` (CU28–CU35)](#t_core04--core_verify-cu28cu35)
    - [T\_CORE05 — `core_compare` (CU36–CU48)](#t_core05--core_compare-cu36cu48)
    - [T\_CORE06 — `core_make_result_dir` (CU49–CU53)](#t_core06--core_make_result_dir-cu49cu53)
  - [CI GitHub Actions](#ci-github-actions)
    - [Jobs](#jobs)
  - [Infrastructure commune des suites](#infrastructure-commune-des-suites)
    - [Helpers d'assertion](#helpers-dassertion)
    - [Isolation](#isolation)
    - [Code de sortie](#code-de-sortie)
  - [Ajouter un nouveau test](#ajouter-un-nouveau-test)
    - [Dans `run_tests.sh` ou `run_tests_pipeline.sh`](#dans-run_testssh-ou-run_tests_pipelinesh)
    - [Dans `run_tests_core.sh`](#dans-run_tests_coresh)
    - [Règle de nommage](#règle-de-nommage)
  - [Diagnostic des échecs](#diagnostic-des-échecs)



## Vue d'ensemble

La suite de tests de `hash_tool` est organisée en trois couches complémentaires, chacune ciblant un niveau d'abstraction différent.

```
tests/
├── run_tests.sh            ← intégration : integrity.sh    (T00–T20)
├── run_tests_pipeline.sh   ← intégration : runner.sh       (TP00–TP12)
└── run_tests_core.sh       ← unitaires   : src/lib/core.sh (CU01–CU53)

.github/
└── workflows/
    └── ci.yml              ← CI GitHub Actions (déclenché sur push et PR)
```

### Pyramide des tests

```
          ┌────────────────┐
          │  Intégration   │  run_tests.sh + run_tests_pipeline.sh
          │  T00–T20       │  Testent les commandes via integrity.sh
          │  TP00–TP12     │  Testent les pipelines via runner.sh
          ├────────────────┤
          │   Unitaires    │  run_tests_core.sh
          │   CU01–CU53    │  Testent core.sh en isolation directe
          └────────────────┘
```

Les tests d'intégration valident le comportement observable de l'outil (sorties, fichiers produits, codes de retour). Les tests unitaires valident la logique interne de `core.sh` fonction par fonction, indépendamment du reste du pipeline.

---

## Prérequis

| Dépendance | Usage | Installation |
|---|---|---|
| `bash >= 4` | Interpréteur de toutes les suites | Natif Linux ; macOS : `brew install bash` |
| `b3sum` | Calcul et vérification des empreintes BLAKE3 | `apt install b3sum` |
| `jq` | Parsing JSON dans `run_tests_pipeline.sh` | `apt install jq` |
| `shellcheck` | Analyse statique (T00) | `apt install shellcheck` |

---

## Lancer les tests

Toutes les suites s'exécutent depuis le répertoire `tests/` :

```bash
# Tests d'intégration — integrity.sh
cd tests && ./run_tests.sh

# Tests d'intégration — runner.sh + pipeline JSON
cd tests && ./run_tests_pipeline.sh

# Tests unitaires — core.sh
cd tests && ./run_tests_core.sh
```

Pour lancer toutes les suites en séquence et échouer dès le premier échec :

```bash
cd tests && ./run_tests.sh && ./run_tests_pipeline.sh && ./run_tests_core.sh
```

### Sortie attendue

Chaque suite affiche le résultat de chaque cas sous la forme `PASS` (vert) ou `FAIL` (rouge), puis un récapitulatif final :

```
========================================
  21/21 tests passés
========================================
```

En cas d'échec, le résumé indique le nombre d'échecs et le code de sortie est `1`. La CI interprète ce code pour marquer le build comme failing.

---

## Suite 1 — `run_tests.sh` (T00–T20)

**Cible :** `src/integrity.sh`
**Type :** intégration fonctionnelle
**Prérequis :** `b3sum`, optionnellement `shellcheck`

Cette suite invoque `integrity.sh` comme un utilisateur final le ferait — via `bash integrity.sh <commande>` — et vérifie les sorties terminal, les fichiers produits et les codes de retour.

### Données de test

`setup()` crée un dossier de travail temporaire (`/tmp/integrity-test.XXXXXX`) avec la structure suivante :

```
$WORKDIR/
└── data/
    ├── alpha.txt        "contenu alpha"
    ├── beta.txt         "contenu beta"
    ├── gamma.txt        "contenu gamma"
    └── sub/
        └── delta.txt    "contenu delta"
```

`teardown()` supprime le `WORKDIR` à la fin, même en cas d'échec (via `trap`).

### Catalogue des cas

#### T00 — ShellCheck

Analyse statique de `integrity.sh` et de `run_tests.sh` eux-mêmes. Le cas est ignoré (`SKIP`) si `shellcheck` n'est pas installé.

#### T01 — Compute de base

Vérifie que `compute` produit un fichier `.b3` contenant exactement 4 lignes (une par fichier) et que le format de chaque ligne est `<hash64>  <chemin>`.

#### T02 — Verify sans modification

Après un `compute` propre, `verify` doit signaler `OK` sans aucun `FAILED`. Le dossier de résultats doit contenir `recap.txt` mais pas `failed.txt`.

#### T03 — Verify après corruption

Corrompt `beta.txt`, relance `verify`. Vérifie que `ECHEC` et `FAILED` apparaissent dans la sortie, que `failed.txt` est créé et contient le chemin du fichier corrompu.

#### T04 — Verify après suppression

Supprime `gamma.txt`, relance `verify`. Le fichier supprimé doit apparaître comme `FAILED`.

#### T05 — Compare : aucune différence

Compare deux bases identiques. Les fichiers `modifies.b3`, `disparus.txt` et `nouveaux.txt` doivent être vides (0 ligne).

#### T06 — Compare : fichier modifié

Modifie `beta.txt` entre les deux snapshots. `modifies.b3` doit contenir `beta.txt`. `report.html` doit être créé et mentionner `beta`.

#### T07 — Compare : suppression + ajout

Supprime `alpha.txt` et crée `epsilon.txt` entre les deux snapshots. `disparus.txt` doit contenir `alpha.txt`, `nouveaux.txt` doit contenir `epsilon.txt`.

#### T08 — Robustesse : fichier avec espace dans le nom

Crée `fichier avec espace.txt`. `compute` puis `verify` doivent fonctionner sans `FAILED`.

#### T09 — Dossier vide ignoré

Crée `data/dossier_vide/` sans fichiers. `compute` ne doit pas inclure `dossier_vide` dans le `.b3` — seuls les fichiers réguliers sont indexés.

#### T10 — Chemin absolu vs chemin relatif

Vérifie que les chemins dans le `.b3` reflètent exactement comment `find` a été appelé : chemin absolu si `find /abs/path`, chemin relatif si `find ./data`. Les deux bases ne sont pas interchangeables.

#### T11 — ETA : base identique à la référence `b3sum`

Génère une base de référence via `b3sum` direct, puis via `integrity.sh compute`. Les deux fichiers doivent être identiques bit à bit. Aucune ligne `ETA` ni caractère `\r` ne doit figurer dans le `.b3`.

#### T12 — Mode `--quiet`

`--quiet verify` : aucune sortie sur stdout, `recap.txt` toujours produit, exit code propagé (non-zéro si corruption).  
`--quiet compute` : aucune ligne "Base enregistrée" sur stdout.

#### T13 — Horodatage anti-écrasement

Lance `verify` deux fois avec un `sleep 1` entre les deux. Deux dossiers de résultats distincts doivent être créés (anti-collision par suffixe `_YYYYMMDD-HHMMSS`).

#### T14 — Verify avec dossier source inexistant

Passe un chemin inexistant comme argument optionnel de `verify`. La sortie doit contenir `ERREUR`.

#### T15 — Nom de fichier avec newline

Crée un fichier dont le nom contient un caractère newline littéral. `compute` doit indexer tous les fichiers correctement (1 ligne par fichier, le newline ne crée pas de ligne supplémentaire). `verify` doit passer sans `FAILED`.

Ce cas valide que `mapfile -d ''` et `find -print0` gèrent bien les noms avec newline, contrairement à un `find | while read`.

#### T16 — Caractères HTML dans les noms de fichiers

Crée `<script>.txt` et `a&b.txt`. Vérifie que ces chemins apparaissent correctement dans `nouveaux.txt`. Vérifie que `report.html` échappe les caractères `<`, `>`, `&` pour éviter toute injection HTML.

#### T17 — Compare sans différence → report.html mentionne "IDENTIQUES"

Compare deux bases identiques. `report.html` doit contenir une mention explicite de l'identité des bases (mot-clé `identique`, `0 modification` ou équivalent selon le template).

#### T18 — `--quiet` sur `compare`

`--quiet compare` : aucune sortie "Résultats" ou "Comparaison" sur stdout. Les quatre fichiers de résultat (`recap.txt`, `modifies.b3`, `disparus.txt`, `nouveaux.txt`) doivent être produits.

#### T19 — Lien symbolique dans le dossier source

Crée un lien symbolique dans `data/`. `compute` ne doit pas planter. Le comportement (suivi ou ignoré) est documenté par le test sans l'imposer — c'est un comportement à documenter.

#### T20 — `verify` avec dossier source totalement inexistant

Chemin d'argument totalement inexistant (pas simplement vide). La sortie doit contenir `ERREUR` et le code de sortie doit être non-zéro. Cas distinct de T14 (qui passe le chemin comme argument optionnel).

---

## Suite 2 — `run_tests_pipeline.sh` (TP00–TP12)

**Cible :** `runner.sh` + `src/integrity.sh`
**Type :** intégration du pipeline JSON
**Prérequis :** `b3sum`, `jq`

Cette suite construit des fichiers `pipeline.json` à la volée via `write_config()` et les passe à `runner.sh`. Elle teste la validation JSON, les erreurs de configuration, et les pipelines complets.

### Données de test

```
$WORKDIR/
├── src_a/
│   ├── alpha.txt    "alpha content"
│   ├── beta.txt     "beta content"
│   └── sub/
│       └── delta.txt  "delta content"
└── src_b/
    ├── gamma.txt    "gamma content"
    └── delta.txt    "delta content"
```

### Catalogue des cas

**TP00** — Vérification que `integrity.sh` est exécutable (chmod +x requis).

**TP01** — JSON invalide : `runner.sh` doit signaler `ERREUR` sans afficher la stacktrace de `jq` (`parse error`).

**TP02** — Clé `.pipeline` absente : `ERREUR` attendue.

**TP03** — Champ `nom` manquant dans un bloc `compute` : `ERREUR` mentionnant le champ manquant.

**TP04** — Opération inconnue (`"op": "migrate"`) : `ERREUR` mentionnant le nom de l'opération.

**TP05** — `compute` correct : chemins relatifs dans le `.b3`, base créée, 3 fichiers indexés.

**TP06** — `compute` avec source absente : `ERREUR`, le `.b3` de sortie ne doit pas être créé.

**TP07** — `verify` correct : exit 0, aucun `FAILED`.

**TP08** — `verify` après corruption : exit non-zéro, `FAILED` dans la sortie.

**TP09** — `compare` correct : `report.html` créé, `modifies.b3` non vide si différences.

**TP10** — `compare` avec champ `resultats` personnalisé : les résultats sont écrits dans le dossier spécifié, pas dans `RESULTATS_DIR`.

**TP10b** — Isolation de `RESULTATS_DIR` : le champ `resultats` d'un bloc ne fuite pas vers les blocs suivants.

**TP11** — `compare` avec `base_a` absente : `ERREUR` attendue.

**TP12** — Pipeline complet (compute × 2 + verify + compare) : toutes les étapes exécutées, `COMPUTE`, `VERIFY`, `COMPARE` mentionnés dans la sortie, `report.html` produit, aucune `ERREUR`.

---

## Suite 3 — `run_tests_core.sh` (CU01–CU53)

**Cible :** `src/lib/core.sh` (fonctions individuelles)
**Type :** tests unitaires
**Prérequis :** `b3sum`

Cette suite source directement `core.sh` sans passer par `integrity.sh`. Chaque fonction est testée en isolation avec des données minimales construites dans le test lui-même. La fonction `die()` est redéfinie localement pour capturer les appels sans tuer le processus de test.

### Mécanisme de sourcing

```bash
# die() redéfinie pour capturer les appels sans exit
die() { echo "die: $*" >&2; return 1; }

# Sourcing direct
source "$SCRIPT_DIR/../src/lib/core.sh"
```

Toutes les fonctions internes (`_b3_to_path_hash`, `_core_file_size`) sont également accessibles après sourcing.

### T_CORE01 — `core_assert_b3_valid` (CU01–CU11)

Valide qu'un fichier `.b3` est syntaxiquement correct avant traitement.

| CU | Cas | Résultat attendu |
|---|---|---|
| CU01 | Fichier absent | exit 1 |
| CU02 | Répertoire passé à la place d'un fichier | exit 1 |
| CU03 | Fichier vide | exit 1 |
| CU04 | Format invalide (ligne sans hash) | exit 1 |
| CU05 | Une seule ligne valide | exit 0 |
| CU06 | Plusieurs lignes toutes valides | exit 0 |
| CU07 | Lignes mixtes valides/invalides | exit 1 |
| CU08 | Label personnalisé dans le message d'erreur | message contient le label |
| CU09 | Hash en lettres minuscules (format b3sum réel) | exit 0 |
| CU10 | Chemin avec espace | exit 0 |
| CU11 | Chemin avec `<` et `>` | exit 0 |

### T_CORE02 — `core_assert_target_valid` (CU12–CU17)

Valide qu'un dossier source est exploitable par `compute`.

| CU | Cas | Résultat attendu |
|---|---|---|
| CU12 | Chemin inexistant | exit 1 |
| CU13 | Fichier régulier (pas un dossier) | exit 1 |
| CU14 | Dossier vide (aucun fichier) | exit 1 |
| CU15 | Dossier avec un fichier | exit 0 |
| CU16 | Dossier avec sous-dossiers uniquement (pas de fichiers réguliers) | exit 1 |
| CU17 | Dossier avec fichiers dans sous-dossiers | exit 0 |

### T_CORE03 — `core_compute` (CU18–CU27)

Teste le calcul des empreintes BLAKE3 et la production du fichier `.b3`.

| CU | Cas | Résultat attendu |
|---|---|---|
| CU18 | Cas nominal | fichier `.b3` créé |
| CU19 | N fichiers → N lignes | 3 lignes pour 3 fichiers |
| CU20 | Format des lignes | `^[0-9a-f]{64}  .+` |
| CU21 | Chemin relatif préservé | chemin commence par le préfixe du dossier |
| CU22 | Fichier avec espace dans le nom | une seule ligne, chemin correct |
| CU23 | Fichier de taille zéro | ligne présente dans le `.b3` |
| CU24 | Callback appelé N fois | count = nombre de fichiers |
| CU25 | Callback reçoit 5 arguments | `(i, total_files, bytes_done, total_bytes, eta_seconds)` |
| CU26 | Aucune ligne ETA dans le `.b3` | pas de `ETA` ni `\r` |
| CU27 | Idempotence | deux compute sur le même dossier → fichiers identiques bit à bit |

### T_CORE04 — `core_verify` (CU28–CU35)

Teste la vérification d'intégrité via `b3sum --check`.

| CU | Cas | Résultat attendu |
|---|---|---|
| CU28 | Tous les fichiers intègres | exit 0, `CORE_VERIFY_STATUS="OK"` |
| CU29 | Un fichier corrompu | exit 1, `STATUS="ECHEC"`, `NB_FAIL=1` |
| CU30 | Plusieurs fichiers corrompus | exit 1, `NB_FAIL >= 2` |
| CU31 | Un fichier supprimé | exit 1, chemin dans `CORE_VERIFY_LINES_FAIL` |
| CU32 | Variables `CORE_VERIFY_*` non nulles en cas nominal | toutes les variables définies |
| CU33 | `CORE_VERIFY_NB_OK` correct | 4 pour 4 fichiers intègres |
| CU34 | `CORE_VERIFY_LINES_FAIL` contient le bon chemin | `beta.txt` si `beta.txt` corrompu |
| CU35 | Fichier illisible (chmod 000) | `STATUS="ERREUR"` ou `NB_FAIL > 0` |

### T_CORE05 — `core_compare` (CU36–CU48)

Teste la comparaison de deux bases `.b3`. C'est la fonction la plus critique — un bug ici produit des faux positifs massifs (cf. bug v0.7 avec les chemins contenant des espaces).

| CU | Cas | Résultat attendu |
|---|---|---|
| CU36 | Bases identiques | `NB_MOD=0`, `NB_DIS=0`, `NB_NOU=0` |
| CU37 | Un fichier modifié | `NB_MOD=1`, fichier dans `modifies.b3` |
| CU38 | Plusieurs fichiers modifiés | `NB_MOD=3` |
| CU39 | Un fichier disparu | `NB_DIS=1`, chemin dans `disparus.txt` |
| CU40 | Un fichier nouveau | `NB_NOU=1`, chemin dans `nouveaux.txt` |
| CU41 | Combinaison modifié + disparu + nouveau | chacun dans sa liste |
| CU42 | Chemin avec espace | chemin complet avec espace dans `modifies.b3` |
| CU43 | Chemin avec `&` | chemin correct, pas d'échappement parasite |
| CU44 | Chemin avec `<` et `>` | chemin correct dans `modifies.b3`, pas d'`&lt;` |
| CU45 | Format de `modifies.b3` | `^[0-9a-f]{64}  <chemin>` (nouveau hash) |
| CU46 | Variables `CORE_COMPARE_NB_*` définies | toutes non nulles après appel |
| CU47 | Nettoyage des fichiers temporaires | pas de résidu `/tmp/tmp.*` |
| CU48 | `outdir` absent avant l'appel | comportement défini (précondition violée) |

### T_CORE06 — `core_make_result_dir` (CU49–CU53)

Teste la création des dossiers de résultats horodatés.

| CU | Cas | Résultat attendu |
|---|---|---|
| CU49 | Création normale | dossier `resultats_<nom>` créé, chemin retourné sur stdout |
| CU50 | Anti-collision (dossier existant) | nouveau dossier avec suffixe `_YYYYMMDD-HHMMSS` |
| CU51 | Deux appels successifs (sleep 1) | deux dossiers distincts |
| CU52 | Nom sans extension `.b3` | dossier `resultats_<nom>` sans extension |
| CU53 | Chemin imbriqué (`/chemin/vers/hashes.b3`) | `resultats_hashes` (basename uniquement) |

---

## CI GitHub Actions

**Fichier :** `.github/workflows/ci.yml`  
**Déclenchement :** `push` et `pull_request` sur toutes les branches.

### Jobs

**`tests` (matrice ubuntu-22.04 / ubuntu-24.04)**

Installe `b3sum`, `jq`, `shellcheck`, puis exécute dans l'ordre :

1. `run_tests.sh` (T00–T20)
2. `run_tests_pipeline.sh` (TP00–TP12)
3. `run_tests_core.sh` (CU01–CU53)
4. `shellcheck` sur tous les scripts (`integrity.sh`, `runner.sh`, `src/lib/*.sh`, `docker/entrypoint.sh`, les trois suites de test)

Les artefacts (`/tmp/integrity-test*/`) sont uploadés en `always()` pour diagnostic post-mortem.

**`docker`**

Construit l'image, puis enchaîne les smoke tests :

- `version` : l'image démarre correctement
- `help` : le dispatcher fonctionne
- `check-env` : les dépendances internes sont disponibles
- `compute` via volume : produit un `.b3` non vide
- `verify` via volume : exit 0 sur une base propre
- Commande inconnue → exit non-zéro : l'entrypoint rejette les commandes invalides

La matrice ubuntu-22.04 / ubuntu-24.04 couvre des versions différentes de `bash`, `b3sum` et `awk`, ce qui détecte les régressions dues à des comportements légèrement différents entre distributions.

---

## Infrastructure commune des suites

### Helpers d'assertion

Toutes les suites partagent le même jeu de helpers :

```bash
pass()               # incrémente PASS et TOTAL, affiche en vert
fail()               # incrémente FAIL et TOTAL, affiche en rouge
assert_exit_zero()   # passe si la commande sort avec exit 0
assert_exit_nonzero  # passe si la commande sort avec exit non-zéro
assert_contains()    # passe si le pattern est présent dans la chaîne
assert_not_contains  # passe si le pattern est absent de la chaîne
assert_line_count()  # passe si le fichier contient exactement N lignes
assert_file_exists() # passe si le fichier existe
assert_file_absent() # passe si le fichier est absent
```

### Isolation

Chaque suite crée son propre `WORKDIR` via `mktemp -d` et le détruit via `trap teardown EXIT`. Aucune donnée ne persiste entre deux exécutions. Les suites peuvent être lancées en parallèle sans conflit.

### Code de sortie

Chaque suite se termine par `[ "$FAIL" -eq 0 ]`, ce qui produit exit 0 si tous les tests passent, exit 1 sinon. La CI interprète ce code directement.

---

## Ajouter un nouveau test

### Dans `run_tests.sh` ou `run_tests_pipeline.sh`

Ajouter le cas dans la fonction `run_tests()`, après le dernier cas existant :

```bash
echo "T21 - Description du cas"
# ... setup spécifique au cas
local out_t21; out_t21=$(bash "$INTEGRITY" <commande> 2>&1 || true)
assert_contains "T21 assertion" "pattern_attendu" "$out_t21"
echo ""
```

Incrémenter le numéro séquentiellement. Ne pas modifier les cas existants.

### Dans `run_tests_core.sh`

Identifier la fonction concernée (T_CORE01 à T_CORE06), ajouter le cas à la fin du groupe correspondant avec le prochain numéro CU disponible :

```bash
# CU54 : description du nouveau cas
_cu54_dir="$WORKDIR/cu54"
mkdir -p "$_cu54_dir"
# ... setup
<appel_de_fonction_core>
assert_exit_zero "CU54 description" <commande>
```

Toute nouvelle fonction de `core.sh` doit avoir son propre groupe `T_CORE0N`.

### Règle de nommage

Les labels des assertions doivent inclure le numéro du cas (`T15`, `CU42`, `TP10b`) pour faciliter la localisation en cas d'échec.

---

## Diagnostic des échecs

Un `FAIL` dans la sortie indique le pattern attendu lorsque c'est pertinent :

```
  FAIL - T16 échappement HTML présent dans report.html (pattern absent: '&lt;')
```

Pour investiguer manuellement, reproduire les étapes du cas en question dans un répertoire temporaire :

```bash
WORKDIR=$(mktemp -d)
INTEGRITY="$(pwd)/src/integrity.sh"
export RESULTATS_DIR="$WORKDIR/resultats"
mkdir -p "$WORKDIR/data"
echo "contenu" > "$WORKDIR/data/alpha.txt"
cd "$WORKDIR"
# ... reproduire les commandes du cas
```

Pour les tests unitaires, sourcer `core.sh` directement dans un shell interactif :

```bash
die() { echo "die: $*" >&2; return 1; }
source src/lib/core.sh
# Appeler la fonction directement
core_assert_b3_valid /tmp/mon_fichier.b3
echo "exit: $?"
```

--- Fichier : hors_git/tests/tests -- doc 1.md ---
# Tests et validation - integrity.sh

**Niveau d'exigence :** production, admin système. Chaque cas doit être exécuté et son résultat vérifié explicitement.

---

## Environnement de test

```bash
# Créer un environnement de test isolé
mkdir -p /tmp/integrity-test/{data,output}
cd /tmp/integrity-test

# Créer des fichiers de test avec contenu connu
echo "contenu alpha" > data/alpha.txt
echo "contenu beta"  > data/beta.txt
echo "contenu gamma" > data/gamma.txt
mkdir -p data/sub
echo "contenu delta" > data/sub/delta.txt
```

---

## Cas de test

### T01 - Compute de base

```bash
./integrity.sh compute ./data base_t01.b3
```

**Résultat attendu :**

- Fichier `base_t01.b3` créé avec 4 lignes (une par fichier).
- Message `Base enregistrée : base_t01.b3 (4 fichiers)`.
- Chaque ligne au format `<hash64chars>  ./data/<chemin>`.

```bash
# Vérification
wc -l base_t01.b3           # → 4
head -1 base_t01.b3         # → hash + chemin lisibles
```

---

### T02 - Verify sans modification

```bash
b3sum --check base_t01.b3
```

**Résultat attendu :** 4 lignes `OK`, aucun `FAILED`, exit code 0.

```bash
echo $?   # → 0
```

---

### T03 - Verify après corruption d'un fichier

```bash
echo "contenu modifié" > data/beta.txt
b3sum --check base_t01.b3
```

**Résultat attendu :**

- `./data/beta.txt: FAILED`
- `b3sum: WARNING: 1 computed checksum did NOT match`
- Exit code non nul.

```bash
echo $?   # → 1
b3sum --check base_t01.b3 2>&1 | grep FAILED   # → ./data/beta.txt: FAILED
```

---

### T04 - Verify après suppression d'un fichier

```bash
# Restaurer l'état T01 d'abord
echo "contenu beta" > data/beta.txt

# Supprimer un fichier
rm data/gamma.txt
b3sum --check base_t01.b3
```

**Résultat attendu :**

- `./data/gamma.txt: FAILED` (No such file or directory)
- Exit code non nul.

---

### T05 - Compare : aucune différence

```bash
# Restaurer l'état T01
echo "contenu gamma" > data/gamma.txt

# Créer une seconde base identique
./integrity.sh compute ./data base_t05.b3
./integrity.sh compare base_t01.b3 base_t05.b3
```

**Résultat attendu :** sections `MODIFIÉS`, `DISPARUS`, `NOUVEAUX` toutes vides. Rapport sauvegardé.

---

### T06 - Compare : fichier modifié

```bash
echo "contenu beta modifié" > data/beta.txt
./integrity.sh compute ./data base_t06.b3
./integrity.sh compare base_t01.b3 base_t06.b3
```

**Résultat attendu :**

- Section `FICHIERS MODIFIÉS` contient `./data/beta.txt` avec ancien et nouveau hash.
- Sections `DISPARUS` et `NOUVEAUX` vides.

---

### T07 - Compare : fichier supprimé + fichier ajouté

```bash
# Repartir d'une base propre
echo "contenu beta" > data/beta.txt
./integrity.sh compute ./data base_t07_old.b3

# Modifier l'état
rm data/alpha.txt
echo "contenu epsilon" > data/epsilon.txt
./integrity.sh compute ./data base_t07_new.b3

./integrity.sh compare base_t07_old.b3 base_t07_new.b3
```

**Résultat attendu :**

- `DISPARUS` : `./data/alpha.txt`
- `NOUVEAUX` : `./data/epsilon.txt`
- `MODIFIÉS` : vide

---

### T08 - Robustesse : fichier avec espace dans le nom

```bash
echo "contenu avec espace" > "data/fichier avec espace.txt"
./integrity.sh compute ./data base_t08.b3
b3sum --check base_t08.b3
```

**Résultat attendu :** tous les fichiers `OK`, y compris `fichier avec espace.txt`.

---

### T09 - Robustesse : dossier vide (limite connue)

```bash
mkdir data/dossier_vide
./integrity.sh compute ./data base_t09.b3
```

**Résultat attendu :** `dossier_vide` absent de `base_t09.b3`. Comportement normal et documenté - `find -type f` n'indexe pas les dossiers vides.

---

### T10 - Chemin absolu vs relatif (piège critique)

```bash
# Calculer avec chemin absolu - mauvaise pratique
b3sum $(find /tmp/integrity-test/data -type f) > base_absolu.b3
head -1 base_absolu.b3   # → chemin absolu /tmp/integrity-test/data/...

# Calculer avec chemin relatif - bonne pratique
cd /tmp/integrity-test
find ./data -type f -print0 | sort -z | xargs -0 b3sum > base_relatif.b3
head -1 base_relatif.b3  # → chemin relatif ./data/...
```

**Résultat attendu :** les deux bases sont incompatibles entre elles. Confirme que les chemins absolus cassent la portabilité.

---

## Nettoyage

```bash
rm -rf /tmp/integrity-test
```

---

## Critères de qualité globaux

| Critère | Exigence |
|---|---|
| Détection corruption | 100 % des fichiers modifiés détectés (T03) |
| Détection suppression | 100 % des fichiers manquants détectés (T04) |
| Faux positifs | Zéro - verify sur base intacte = 100 % OK (T02) |
| Noms avec espaces | Traités sans erreur (T08) |
| Rapport compare | Sauvegardé sur disque, horodaté (T05–T07) |
| Exit code | Non nul si au moins un FAILED (T03, T04) |
| Mode strict `-euo pipefail` | Le script s'arrête sur toute erreur non gérée |


--- Fichier : hors_git/tests/tests -- doc 2.md ---
# Explication du code — run_tests.sh + run_tests_pipeline.sh

---

## Vue d'ensemble

Deux suites de tests indépendantes, bash pur, sans framework externe.

```
tests/
├── run_tests.sh            ← integrity.sh — 15 cas T00–T14
└── run_tests_pipeline.sh   ← runner.sh + pipeline.json — 12 cas TP01–TP12
```

Chaque suite : prérequis → setup → tests → teardown → rapport + exit code CI.

---

## PARTIE 1 — run_tests.sh (integrity.sh)

### 1.1 Configuration et chemins

```bash
SCRIPT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"
INTEGRITY="$SCRIPT_DIR/../integrity.sh"
WORKDIR="$(mktemp -d /tmp/integrity-test.XXXXXX)"
```

- `SCRIPT_DIR` : répertoire absolu du script, indépendant du `pwd` appelant.
- `INTEGRITY` : chemin relatif à `run_tests.sh` — déplaçables ensemble sans modifier les chemins.
- `WORKDIR` : répertoire temporaire isolé par `mktemp`, suffix aléatoire 6 chars.

### 1.2 Système de comptage

```bash
PASS=0; FAIL=0; TOTAL=0
pass() { echo -e "${GREEN}  PASS${NC} — $1"; (( PASS++ )); (( TOTAL++ )); }
fail() { echo -e "${RED}  FAIL${NC} — $1"; (( FAIL++ )); (( TOTAL++ )); }
```

`TOTAL` permet de détecter un test sauté silencieusement.

### 1.3 Fonctions d'assertion

**`assert_exit_zero` / `assert_exit_nonzero`** : exécute une commande, vérifie le code de retour. `> /dev/null 2>&1` supprime toute sortie. `shift` consomme le label pour que `"$@"` ne contienne que la commande.

**`assert_contains` / `assert_not_contains`** : cherche un pattern dans une chaîne capturée. La capture via `local out=$(commande)` avant l'assertion permet plusieurs inspections sans relancer la commande.

**`assert_line_count`** : `wc -l < fichier` (sans le nom) — pas d'affichage du nom par `wc`.

**`assert_file_exists` / `assert_file_absent`** : présence ou absence d'un fichier régulier.

### 1.4 Setup / Teardown

4 fichiers déterministes (contenu connu → hashes reproductibles). `sub/delta.txt` valide la récursivité de `find`. `teardown()` supprime `WORKDIR` entier.

### 1.5 Pattern || true

```bash
local out
out=$(commande 2>&1 || true)
```

Critique : sans `|| true`, un code de retour non nul sous `-euo pipefail` interrompt le script avant que l'assertion enregistre l'échec.

### 1.6 Cas de test spécifiques

**T00 — ShellCheck** : analyse statique sur `integrity.sh` et `run_tests.sh`. `SKIP` propre si non installé.

**T11 — Intégrité base avec ETA** : vérifie que `compute_with_progress` produit une base bit-à-bit identique à `find | sort | xargs b3sum`, sans artefact `ETA` ni `\r`.

**T12 — Mode `--quiet`** : stdout vide sur verify OK, verify ECHEC, et compute. Exit code non nul propagé. Fichiers de résultats produits malgré `--quiet`.

**T13 — Horodatage** : deux `verify` successifs sur la même base → deux dossiers distincts (pas d'écrasement). `sleep 1` garantit des timestamps différents.

**T14 — Argument invalide** : `verify base.b3 /chemin/inexistant` → `ERREUR` explicite.

### 1.7 Tableau des cas

| Cas | Description |
|---|---|
| T00 | ShellCheck (analyse statique) |
| T01 | Compute de base |
| T02 | Verify sans modification |
| T03 | Verify après corruption |
| T04 | Verify après suppression |
| T05 | Compare sans différence |
| T06 | Compare avec fichier modifié |
| T07 | Compare avec fichier supprimé + ajouté |
| T08 | Noms de fichiers avec espaces |
| T09 | Dossiers vides ignorés |
| T10 | Chemins absolus vs relatifs |
| T11 | Intégrité base avec ETA |
| T12 | Mode `--quiet` |
| T13 | Horodatage anti-écrasement |
| T14 | Argument invalide pour verify |

---

## PARTIE 2 — run_tests_pipeline.sh (runner.sh + pipeline.json)

### 2.1 Configuration et chemins

```bash
SCRIPT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"
RUNNER="$SCRIPT_DIR/../runner.sh"
INTEGRITY="$SCRIPT_DIR/../integrity.sh"
WORKDIR="$(mktemp -d /tmp/integrity-pipeline-test.XXXXXX)"
export RESULTATS_DIR="$WORKDIR/resultats"
```

`RESULTATS_DIR` est exporté pour que `integrity.sh` (appelé par `runner.sh`) redirige ses résultats dans le `WORKDIR` isolé — pas dans `~/integrity_resultats`.

### 2.2 Helper write_config

```bash
write_config() {
    local path="$WORKDIR/pipeline.json"
    cat > "$path"
    echo "$path"
}
```

Lit le JSON depuis stdin (heredoc), l'écrit dans `WORKDIR/pipeline.json`, retourne le chemin. Permet de générer un `pipeline.json` différent par test sans fichiers temporaires nommés à la main.

Usage :

```bash
local cfg
cfg=$(write_config <<EOF
{ "pipeline": [ { "op": "compute", ... } ] }
EOF
)
bash "$RUNNER" "$cfg"
```

### 2.3 Stratégie de test par cas

**TP01–TP04 (parsing)** : tests négatifs — chaque test passe un JSON ou une config invalide et vérifie que `runner.sh` échoue avec un message `ERREUR` explicite, sans stacktrace `jq` brute ni crash silencieux.

**TP05–TP06 (compute)** : TP05 vérifie trois invariants sur la base produite — existence, chemins relatifs (`./ `en début de chemin), comptage exact de fichiers. TP06 vérifie l'échec propre sur source absente.

**TP07–TP09 (verify)** : TP07 vérifie le bon répertoire de travail (vérification OK, `recap.txt` produit). TP08 vérifie la détection de corruption. TP09 vérifie l'échec propre sur base absente.

**TP10–TP11 (compare)** : TP10 vérifie les quatre fichiers de résultats produits. TP11 vérifie l'échec propre sur `base_a` absente.

**TP12 (pipeline complet)** : test d'intégration — compute × 2 + verify + compare dans un seul `pipeline.json`. Vérifie les labels dans la sortie, les bases créées, et l'absence d'erreur.

### 2.4 Résolution des dossiers de résultats

```bash
outdir_tp07=$(ls -d "${RESULTATS_DIR}/resultats_hashes_a"* 2>/dev/null | tail -1)
```

`tail -1` récupère le dossier le plus récent — compatible avec l'horodatage automatique de `make_result_dir()`. Sans `tail -1`, si un dossier `resultats_hashes_a` existe déjà d'un test précédent, `ls` retourne plusieurs lignes et l'assertion porte sur la mauvaise.

### 2.5 Prérequis et exécution

```bash
cd tests
./run_tests_pipeline.sh
```

Prérequis : `jq`, `b3sum`, `bash >= 4`, `runner.sh` et `integrity.sh` dans le répertoire parent. Exit code CI-compatible : 0 si tous passent, 1 si au moins un échec.

### 2.6 Tableau des cas

| Cas | Description |
|---|---|
| TP01 | JSON invalide — erreur propre sans stacktrace jq |
| TP02 | Clé `.pipeline` absente |
| TP03 | Champ `nom` manquant dans compute |
| TP04 | Opération inconnue |
| TP05 | Compute — cd correct, chemins relatifs, comptage |
| TP06 | Compute — dossier source absent |
| TP07 | Verify — bon répertoire de travail, OK |
| TP08 | Verify — corruption détectée |
| TP09 | Verify — base .b3 absente |
| TP10 | Compare — fichiers de résultats produits |
| TP11 | Compare — base_a absente |
| TP12 | Pipeline complet compute + verify + compare |

---

## Prérequis globaux

```bash
# run_tests.sh
apt install b3sum shellcheck   # shellcheck optionnel

# run_tests_pipeline.sh
apt install b3sum jq
```

Les deux suites sont indépendantes et peuvent être lancées séparément.

--- Fichier : hors_git/tests/TODO -- tests/_audit test.md ---
## Analyse de la situation actuelle

La suite actuelle (`run_tests.sh` T00-T14, `run_tests_pipeline.sh` TP01-TP12b) est une suite d'**intégration fonctionnelle** bash-pur. Les tests sont bien structurés mais présentent des lacunes structurelles significatives.

---

## Diagnostic des lacunes

**Ce qui manque par couche :**

**1. Tests unitaires de `core.sh`** — inexistants. Les fonctions `core_compute`, `core_verify`, `core_compare`, `core_assert_b3_valid` sont testées uniquement via le pipeline complet `integrity.sh`. Un bug dans `core_compare` est difficile à isoler.

**2. Couverture des cas limites absente :**
- Fichiers de taille 0 dans `compute` (comportement ETA sur `fsize == 0`)
- Base `.b3` avec chemins mixtes relatifs/absolus — `core_assert_b3_valid` ne le détecte pas
- Dossier source avec des milliers de fichiers (performances, comptage ETA)
- Liens symboliques — comportement non documenté, non testé
- Noms de fichiers avec newlines — `mapfile -d ''` devrait tenir mais aucun test
- Fichiers binaires larges — ETA réaliste ?

**3. Tests de régression sur le format `.b3`** — aucun test ne vérifie que le format produit par `core_compute` est **bit-à-bit compatible** avec un `b3sum` direct (T11 le fait partiellement mais pas sur les cas limites).

**4. Tests de l'output HTML** — `report.html` est vérifié uniquement par présence de fichier et présence d'un pattern. Pas de validation de structure HTML, pas de test sur l'échappement (`html_escape`), pas de test sur des chemins avec `<`, `>`, `&`.

**5. Absence totale de CI** — les tests ne tournent que localement, aucune garantie sur les PRs.

**6. Pas de test de performance / régression de temps** — aucun seuil.

**7. Pas de test de `--quiet` sur `compare`** — T12 couvre `verify` et `compute` mais pas `compare`.

**8. `entrypoint.sh` non testé** — la couche Docker est entièrement aveugle.

---

## Recommandations structurées

### Niveau 1 — Tests unitaires `core.sh` (priorité haute)

Créer `tests/run_tests_core.sh` — teste chaque fonction de `core.sh` en isolation, en sourçant directement `core.sh` sans passer par `integrity.sh`.

```bash
# Pattern : source les modules directement
QUIET=0
source "$SCRIPT_DIR/../src/lib/ui.sh"
source "$SCRIPT_DIR/../src/lib/core.sh"

# Test core_assert_b3_valid
test_assert_b3_valid_fichier_absent() {
    core_assert_b3_valid "/tmp/inexistant.b3" 2>/dev/null && fail "doit exit 1" || pass "fichier absent → exit 1"
}

test_assert_b3_valid_ligne_invalide() {
    echo "ligne_sans_format" > /tmp/bad.b3
    core_assert_b3_valid /tmp/bad.b3 2>/dev/null && fail "doit exit 1" || pass "format invalide → exit 1"
}

# Test core_compare isolation
test_compare_chemins_avec_esperluette() {
    echo "aaa...64chars...  ./a&b.txt" > "$old"
    echo "bbb...64chars...  ./a&b.txt" > "$new"
    core_compare "$old" "$new" "$outdir"
    assert_contains "chemin avec & dans modifies" "a&b.txt" "$(cat $outdir/modifies.b3)"
}
```

Cas critiques à couvrir :
- `core_assert_b3_valid` : fichier absent, dossier, vide, format invalide, lignes mixtes valides/invalides
- `core_compare` : chemins avec espaces, `&`, `<`, `>`, fichiers identiques, tous modifiés, tous disparus, tous nouveaux
- `core_make_result_dir` : collision de noms, permissions insuffisantes
- `core_compute` : dossier vide (doit lever une erreur via `core_assert_target_valid`), fichier de taille 0, lien symbolique

### Niveau 2 — Cas limites manquants dans les suites existantes

Ajouter dans `run_tests.sh` :

- **T15** : fichier avec newline dans le nom (`$'nom\nfichier.txt'`) — `mapfile -d ''` doit tenir
- **T16** : fichier avec caractères HTML (`<script>.txt`, `a&b.txt`) — vérifier l'échappement dans `report.html`
- **T17** : `compare` sans différence → `report.html` affiche "IDENTIQUES"
- **T18** : `--quiet` sur `compare` — stdout vide, fichiers produits
- **T19** : lien symbolique dans le dossier source — comportement documenté (ignoré ou suivi ?)
- **T20** : `verify` avec `[dossier]` inexistant → exit 1 (T14 couvre déjà mais pas exactement ce cas)

### Niveau 3 — Tests de non-régression du format `.b3`

Fixture figée : créer `tests/fixtures/reference.b3` contenant les hashes attendus pour `tests/fixtures/data/`. À chaque run, `core_compute` doit produire un fichier identique octet par octet. Détecte toute régression dans le format de sortie, le tri, les séparateurs.

```bash
test_compute_stable() {
    bash "$INTEGRITY" compute ./fixtures/data /tmp/output.b3
    diff tests/fixtures/reference.b3 /tmp/output.b3 || fail "régression format .b3"
    pass "format .b3 stable"
}
```

### Niveau 4 — CI GitHub Actions

```yaml
# .github/workflows/ci.yml
name: CI
on: [push, pull_request]

jobs:
  tests:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - run: sudo apt-get install -y b3sum jq shellcheck
      - run: cd tests && ./run_tests.sh
      - run: cd tests && ./run_tests_pipeline.sh
      - run: cd tests && ./run_tests_core.sh          # nouveau
      - run: shellcheck src/integrity.sh runner.sh src/lib/*.sh docker/entrypoint.sh
      - uses: actions/upload-artifact@v4
        if: always()
        with:
          name: test-results
          path: /tmp/integrity-test*/

  docker:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - run: docker build -t hash_tool .
      - run: docker run --rm hash_tool version
      - run: |
          docker run --rm \
            -v /tmp/testdata:/data:ro \
            -v /tmp/testbases:/bases \
            hash_tool compute /data /bases/test.b3
```

Ajouter une matrice pour tester sur Ubuntu 22.04 et 24.04 (versions différentes de `b3sum`, `bash`, `awk`).

### Niveau 5 — Rapport de test structuré

Modifier `run_tests.sh` pour produire un rapport TAP (Test Anything Protocol) — format standard, consommable par n'importe quel CI :

```bash
echo "TAP version 14"
echo "1..$TOTAL"
pass() { echo "ok $TOTAL - $1"; }
fail() { echo "not ok $TOTAL - $1"; }
```

Ou JSON minimal pour intégration dashboard :

```bash
# En fin de suite
cat > /tmp/test-report.json <<JSON
{
  "suite": "run_tests.sh",
  "timestamp": "$(date -Iseconds)",
  "total": $TOTAL,
  "passed": $PASS,
  "failed": $FAIL
}
JSON
```

---

## Priorisation

| Priorité | Action | Impact | Effort |
|---|---|---|---|
| 1 | CI GitHub Actions (minimal) | Détection régression sur PR | ~2h |
| 2 | `run_tests_core.sh` — tests unitaires | Isolation des bugs | ~4h |
| 3 | Fixtures de non-régression format `.b3` | Détection silencieuse | ~1h |
| 4 | Cas limites HTML escaping (T16) | Bug latent confirmé | ~1h |
| 5 | T15 newlines, T18 `--quiet compare` | Couverture lacunaire | ~1h |
| 6 | Tests `entrypoint.sh` Docker | Couverture Docker nulle | ~3h |
| 7 | Rapport TAP / JSON | Intégration dashboard | ~1h |

Le delta le plus impactant à court terme : **CI + tests unitaires `core.sh`**. La suite actuelle fonctionne mais ne détecte les régressions que si quelqu'un pense à lancer les tests manuellement.

--- Fichier : hors_git/tests/TODO -- tests/_cours appliqué -- test.md ---
# Tests logiciels — Cours appliqué à `hash_tool`

> Ce cours couvre les notions abordées dans l'analyse de la suite de tests de `hash_tool` : tests unitaires, d'intégration, de non-régression, CI/CD, rapports de tests. Chaque notion est expliquée puis illustrée avec des exemples tirés du projet.

---

## Table des matières

1. [Pourquoi tester ?](#1-pourquoi-tester-)
2. [La pyramide des tests](#2-la-pyramide-des-tests)
3. [Tests unitaires](#3-tests-unitaires)
4. [Tests d'intégration](#4-tests-dintégration)
5. [Tests de non-régression](#5-tests-de-non-régression)
6. [Tests de cas limites (edge cases)](#6-tests-de-cas-limites-edge-cases)
7. [ShellCheck — analyse statique](#7-shellcheck--analyse-statique)
8. [Le protocole TAP](#8-le-protocole-tap)
9. [CI/CD — Intégration et déploiement continus](#9-cicd--intégration-et-déploiement-continus)
10. [Isolation et reproductibilité](#10-isolation-et-reproductibilité)
11. [Couverture de tests](#11-couverture-de-tests)
12. [Fixtures et données de test](#12-fixtures-et-données-de-test)
13. [Synthèse — Appliquer tout ça à hash_tool](#13-synthèse--appliquer-tout-ça-à-hash_tool)

---

## 1. Pourquoi tester ?

Un test est une vérification automatisée qu'un comportement attendu est bien produit par le code. Sans tests :

- Une modification dans `core.sh` peut casser `compare` sans que personne s'en aperçoive avant qu'un utilisateur perde des données.
- Impossible de refactoriser avec confiance — chaque changement est un pari.
- Le debugging est lent : il faut reproduire le problème manuellement à chaque fois.

Avec des tests :

- Un test qui échoue localise immédiatement la régression.
- Le code peut être modifié, optimisé, réorganisé — les tests garantissent que le comportement observable reste stable.
- La documentation implicite : un test qui s'appelle `test_compare_chemins_avec_espaces` documente un comportement et une contrainte du système.

### Dans hash_tool

La suite `run_tests.sh` permet de valider en quelques secondes que `integrity.sh` fonctionne correctement sur 14 scénarios. Sans elle, valider manuellement chaque cas (compute, verify OK, verify après corruption, compare avec ajout/suppression, mode quiet…) prendrait 30 minutes et serait oublié à la prochaine modification.

---

## 2. La pyramide des tests

La pyramide des tests est un modèle qui décrit comment répartir les efforts de test selon le niveau d'abstraction.

```
         /\
        /  \
       / E2E\        Tests de bout en bout (End-to-End)
      /______\       Rares, lents, fragiles
     /        \
    / Intégration\   Tests d'intégration
   /______________\  Moyennement nombreux
  /                \
 /   Unitaires      \ Tests unitaires
/____________________\ Nombreux, rapides, précis
```

| Niveau | Quoi | Vitesse | Fragilité | Nb recommandé |
|---|---|---|---|---|
| Unitaire | Une fonction isolée | Milliseconde | Faible | Maximum |
| Intégration | Plusieurs modules ensemble | Secondes | Moyenne | Moyen |
| E2E | Système complet, interface réelle | Minutes | Élevée | Minimum |

### Dans hash_tool

Actuellement, `run_tests.sh` et `run_tests_pipeline.sh` sont **presque exclusivement des tests d'intégration** — ils testent `integrity.sh` et `runner.sh` comme boîtes noires, sans tester les fonctions de `core.sh` individuellement. La pyramide est inversée : le bas (unitaire) est vide, le milieu (intégration) est bien couvert.

---

## 3. Tests unitaires

Un test unitaire vérifie une seule unité de code — généralement une fonction — en isolation complète. Il ne dépend d'aucun autre module, réseau, système de fichiers (sauf si la fonction elle-même écrit des fichiers).

### Caractéristiques

- **Rapide** : pas d'I/O disque, pas de processus externes.
- **Précis** : si un test unitaire échoue, le bug est dans cette fonction, nulle part ailleurs.
- **Indépendant** : l'ordre d'exécution n'a pas d'importance.

### Exemple concret — tester `core_assert_b3_valid`

```bash
# Sans tests unitaires : on teste via integrity.sh
./src/integrity.sh verify fichier_corrompu.b3
# → si ça échoue, est-ce core_assert_b3_valid ? core_verify ? ui.sh ?

# Avec tests unitaires : on source core.sh directement
QUIET=0
source ./src/lib/ui.sh
source ./src/lib/core.sh

test_b3_valide_fichier_absent() {
    core_assert_b3_valid "/tmp/inexistant_xyz.b3" 2>/dev/null
    # Doit retourner exit code 1
    [ $? -ne 0 ] && echo "PASS" || echo "FAIL"
}

test_b3_valide_format_invalide() {
    echo "cette ligne n'est pas un hash b3sum" > /tmp/bad.b3
    core_assert_b3_valid /tmp/bad.b3 2>/dev/null
    [ $? -ne 0 ] && echo "PASS - format invalide rejeté" || echo "FAIL"
    rm -f /tmp/bad.b3
}
```

La différence clé : on **source** `core.sh` au lieu d'appeler `integrity.sh`. Les fonctions deviennent directement accessibles dans le shell courant.

### Pourquoi c'est important ici

`core.sh` contient l'algorithme central : `core_compare` utilise `awk`, `join`, `comm`. Un bug dans la conversion `hash  chemin` → `chemin\thash` produit des faux positifs massifs (comme le bug décrit dans le changelog 0.7 : 26 569 "modifiés" pour 1 seul fichier réellement changé). Un test unitaire sur `core_compare` aurait détecté ça immédiatement.

---

## 4. Tests d'intégration

Un test d'intégration vérifie que plusieurs modules fonctionnent correctement **ensemble**. Il teste les interfaces entre les composants.

### Ce qu'il détecte

- Un module A produit un format que le module B ne sait pas lire.
- Une variable d'environnement attendue par B n'est pas positionnée par A.
- Un `cd` dans A modifie le répertoire courant de B (c'est exactement le bug isolé dans `runner.sh` : les `cd` fuyaient entre les blocs du pipeline).

### Exemple — tester l'intégration `core.sh` + `results.sh`

```bash
# Test d'intégration : core_verify produit des variables
# que results_write_verify sait exploiter

source ./src/lib/ui.sh
source ./src/lib/core.sh
source ./src/lib/results.sh

OUTDIR=$(mktemp -d)
echo "contenu" > /tmp/fichier_test.txt
./src/integrity.sh compute /tmp/fichier_test.txt /tmp/base_test.b3

# core_verify positionne CORE_VERIFY_STATUS, NB_OK, etc.
core_verify /tmp/base_test.b3

# results_write_verify doit savoir lire ces variables
results_write_verify "$OUTDIR" /tmp/base_test.b3 \
    "$CORE_VERIFY_STATUS" "$CORE_VERIFY_NB_OK" "$CORE_VERIFY_NB_FAIL" \
    "$CORE_VERIFY_LINES_FAIL" "$CORE_VERIFY_LINES_ERR"

# Vérifier que recap.txt est produit avec le bon contenu
grep -q "STATUT : OK" "$OUTDIR/recap.txt" && echo "PASS" || echo "FAIL"
```

### Dans hash_tool

`run_tests.sh` est une suite d'intégration : elle appelle `integrity.sh` comme le ferait un utilisateur, et vérifie les fichiers produits et les messages affichés. C'est utile et nécessaire, mais insuffisant seul — un test d'intégration qui échoue ne dit pas *où* est le problème.

---

## 5. Tests de non-régression

Un test de non-régression (TNR) vérifie qu'une fonctionnalité qui marchait avant **marche toujours** après une modification. Il capture un comportement connu et le fige.

### Principe

1. À un instant T, le système produit un output correct → on le capture comme référence.
2. À chaque modification ultérieure, on vérifie que l'output est toujours identique à la référence.
3. Si l'output change → soit c'est un bug (la modification a cassé quelque chose), soit c'est intentionnel (il faut alors mettre à jour la référence).

### Exemple — non-régression du format `.b3`

```bash
# Étape 1 : créer la fixture (fait une seule fois, commitée dans le repo)
mkdir -p tests/fixtures/data
echo "contenu alpha" > tests/fixtures/data/alpha.txt
echo "contenu beta"  > tests/fixtures/data/beta.txt

cd tests/fixtures
../../src/integrity.sh compute ./data reference.b3
# reference.b3 est commitée dans git

# Étape 2 : test de non-régression (lancé à chaque PR)
test_format_b3_stable() {
    cd tests/fixtures
    ../../src/integrity.sh compute ./data /tmp/output_test.b3
    diff reference.b3 /tmp/output_test.b3
    [ $? -eq 0 ] && echo "PASS - format .b3 stable" || echo "FAIL - régression détectée"
}
```

Si quelqu'un modifie `core_compute` et introduit accidentellement un espace en trop dans le séparateur, ou change l'ordre de tri — le `diff` échoue immédiatement.

### Ce que le TNR détecte que les autres tests ne détectent pas

Un TNR détecte des **changements subtils de comportement** qui ne cassent pas les tests fonctionnels mais altèrent le format ou le résultat. Par exemple :
- Un `b3sum` mis à jour qui change le format de sortie.
- Un `sort` qui change de comportement selon la locale (`LC_ALL`).
- L'ajout d'une ligne vide dans le `.b3` par une nouvelle version de `find`.

---

## 6. Tests de cas limites (edge cases)

Un cas limite est une entrée qui se situe aux frontières du comportement normal — là où les bugs se cachent le plus souvent.

### Catégories de cas limites

**Valeurs vides ou nulles**
```bash
# Que se passe-t-il avec un dossier vide ?
mkdir /tmp/dossier_vide
./src/integrity.sh compute /tmp/dossier_vide /tmp/vide.b3
# core_assert_target_valid doit lever une erreur
```

**Caractères spéciaux dans les noms**

Les noms de fichiers peuvent contenir des espaces, des newlines, des caractères HTML. Chacun peut casser un traitement textuel naïf.

```bash
# Espace dans le nom
echo "contenu" > "tests/data/fichier avec espace.txt"
# Apostrophe
echo "contenu" > "tests/data/l'important.txt"
# Caractère HTML — dangereux dans report.html
echo "contenu" > "tests/data/<script>alert.txt"
# Newline dans le nom (cas extrême mais légal sur Linux)
echo "contenu" > $'tests/data/nom\navec\nnewline.txt'
```

**Taille extrême**
```bash
# Fichier de taille zéro
touch tests/data/fichier_vide.bin
# → core_compute : bytes_done += 0, ETA correcte ?
```

**Cas limites de comparaison**

```bash
# Tous les fichiers identiques → modifies.b3 vide
# Tous les fichiers supprimés → disparus.txt contient tout
# Un seul fichier dans la base → comportement sur base minimale
```

### Pourquoi les cas limites cassent souvent le code

Le code est typiquement écrit et testé sur des cas "normaux". Les cas limites exposent des hypothèses implicites :

- `awk '{print $2}'` — hypothèse : le chemin ne contient pas d'espace. Faux.
- `grep -c '.'` — hypothèse : retourne 0 sur flux vide. Faux, `grep` retourne exit code 1 sur flux vide, ce qui crash un script avec `set -e`. (C'est le bug corrigé en v0.6.)
- `sort -k2` — hypothèse : le tri sur le champ 2 s'arrête au champ 2. Faux, `sort -k2` trie du champ 2 jusqu'à la fin de ligne. (Bug corrigé en v0.6, remplacé par `sort -k2,2`.)

---

## 7. ShellCheck — analyse statique

L'analyse statique examine le code **sans l'exécuter** pour détecter des erreurs potentielles. Pour bash, l'outil de référence est **ShellCheck**.

### Ce que ShellCheck détecte

```bash
# Variable non quotée → éclate sur les espaces
for f in $(find . -type f); do     # ← SC2044 : use find -exec or while read
    echo $f                         # ← SC2086 : double quote to prevent globbing
done

# Comparaison de chaînes avec [ ] au lieu de [[ ]]
if [ $VAR == "valeur" ]; then       # ← SC2039 : use [[ ]] in bash

# Variable utilisée avant d'être définie
echo $UNDEFINED_VAR                 # ← SC2154 : variable referenced but not assigned

# Pipe dans un sous-shell
cat file | read var                 # ← SC2031 : var will be in a subshell
```

### Dans hash_tool

Le test T00 dans `run_tests.sh` lance ShellCheck sur `integrity.sh` :

```bash
# T00 - ShellCheck
if command -v shellcheck &>/dev/null; then
    assert_exit_zero "ShellCheck integrity.sh" shellcheck "$INTEGRITY"
else
    echo "  SKIP - shellcheck non installé"
fi
```

ShellCheck est la première ligne de défense — il détecte des bugs sans même exécuter les scripts. Zéro warning ShellCheck est une condition non négociable avant toute PR.

---

## 8. Le protocole TAP

TAP (Test Anything Protocol) est un format texte standard pour les résultats de tests. Il est lisible par les humains et parseable par les outils CI.

### Format

```
TAP version 14
1..5
ok 1 - core_assert_b3_valid : fichier absent → exit 1
ok 2 - core_assert_b3_valid : format invalide → exit 1
not ok 3 - core_compare : chemins avec espaces
# Expected: beta.txt in modifies.b3
# Got: (empty)
ok 4 - core_make_result_dir : horodatage anti-écrasement
ok 5 - mode --quiet : stdout vide
```

### Structure

- `1..N` : nombre total de tests annoncé en tête.
- `ok N - description` : test réussi.
- `not ok N - description` : test échoué.
- `# commentaire` : diagnostic supplémentaire (indentation sous un `not ok`).

### Implémentation dans bash

```bash
#!/usr/bin/env bash
TOTAL=0; PASS=0; FAIL=0

plan() { echo "1..$1"; }
ok()     { TOTAL=$((TOTAL+1)); PASS=$((PASS+1)); echo "ok $TOTAL - $1"; }
not_ok() { TOTAL=$((TOTAL+1)); FAIL=$((FAIL+1)); echo "not ok $TOTAL - $1"; }

plan 3

# Test 1
if core_assert_b3_valid /tmp/inexistant 2>/dev/null; then
    not_ok "fichier absent doit échouer"
else
    ok "fichier absent → exit 1"
fi

# Test 2
echo "aa  ./fichier.txt" > /tmp/valid.b3  # hash trop court
if core_assert_b3_valid /tmp/valid.b3 2>/dev/null; then
    not_ok "hash invalide doit échouer"
else
    ok "hash invalide → exit 1"
fi
```

### Avantage

Le format TAP est **interopérable** : GitHub Actions, GitLab CI, Jenkins, et des dizaines d'outils savent parser TAP et afficher des rapports visuels sans configuration supplémentaire.

---

## 9. CI/CD — Intégration et déploiement continus

### Définitions

**CI (Continuous Integration)** : à chaque push ou pull request, un serveur exécute automatiquement les tests. Si un test échoue, la modification est bloquée ou signalée.

**CD (Continuous Deployment)** : si les tests passent, le code est automatiquement déployé en production.

Pour un outil comme hash_tool, le CD n'est pas pertinent (pas de service web à déployer). La CI, en revanche, est essentielle.

### Pourquoi la CI est indispensable

Sans CI : les tests ne sont lancés que si le développeur y pense. En pratique, ils ne sont lancés qu'avant les releases, et pas systématiquement.

Avec CI : chaque modification est testée automatiquement, dans un environnement propre (pas les dépendances locales du développeur), sur les versions exactes des outils installés.

### GitHub Actions — anatomie d'un workflow

```yaml
# .github/workflows/ci.yml
name: CI

on:
  push:              # déclenché à chaque push
  pull_request:      # déclenché à chaque PR

jobs:
  tests:
    runs-on: ubuntu-latest  # environnement propre, recréé à chaque run

    steps:
      # 1. Récupérer le code
      - uses: actions/checkout@v4

      # 2. Installer les dépendances
      - run: sudo apt-get install -y b3sum jq shellcheck

      # 3. Lancer les suites de tests
      - run: cd tests && ./run_tests.sh
      - run: cd tests && ./run_tests_pipeline.sh

      # 4. ShellCheck
      - run: shellcheck src/integrity.sh runner.sh src/lib/*.sh

      # 5. Uploader les artefacts (résultats) même si les tests échouent
      - uses: actions/upload-artifact@v4
        if: always()   # ← important : s'exécute même si les steps précédents échouent
        with:
          name: test-results
          path: /tmp/integrity-test*/
          retention-days: 7
```

### Matrice de tests

Un test peut passer sur Ubuntu 22.04 et échouer sur 24.04 si la version de `b3sum` ou de `awk` a changé de comportement. La matrice permet de tester plusieurs environnements en parallèle :

```yaml
jobs:
  tests:
    strategy:
      matrix:
        os: [ubuntu-22.04, ubuntu-24.04]
        bash: ["5.1", "5.2"]

    runs-on: ${{ matrix.os }}
    steps:
      - run: bash --version
      - run: cd tests && ./run_tests.sh
```

### Test Docker dans la CI

```yaml
  docker:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - run: docker build -t hash_tool .
      - run: docker run --rm hash_tool version
      - name: Test compute dans Docker
        run: |
          mkdir -p /tmp/testdata /tmp/testbases
          echo "contenu" > /tmp/testdata/fichier.txt
          docker run --rm \
            -v /tmp/testdata:/data:ro \
            -v /tmp/testbases:/bases \
            hash_tool compute /data /bases/test.b3
          test -f /tmp/testbases/test.b3 && echo "PASS" || echo "FAIL"
```

---

## 10. Isolation et reproductibilité

Un test doit être **isolé** : son résultat ne dépend pas des autres tests, de l'état du système, ni de l'ordre d'exécution. Il doit être **reproductible** : relancé 10 fois dans 10 environnements différents, il donne le même résultat.

### Les ennemis de l'isolation

**État partagé** : une variable globale modifiée par un test affecte le suivant.

```bash
# ❌ Mauvais : RESULTATS_DIR partagé entre les tests
export RESULTATS_DIR=/tmp/resultats_partages
test_verify_ok() { ... }
test_verify_echec() { ... }   # peut lire les résultats du test précédent
```

```bash
# ✓ Correct : chaque test a son propre WORKDIR
test_verify_ok() {
    local WORKDIR=$(mktemp -d)
    export RESULTATS_DIR="$WORKDIR/resultats"
    # ... test ...
    rm -rf "$WORKDIR"   # nettoyage garanti
}
```

**Répertoire courant** : un test qui fait `cd` et ne revient pas casse le suivant.

```bash
# ❌ Mauvais
test_compute() {
    cd /tmp/montest
    ../integrity.sh compute . base.b3
    # Si le test échoue ici, le cd ne revient jamais
}

# ✓ Correct : sous-shell isolé
test_compute() {
    (
        cd /tmp/montest
        ../integrity.sh compute . base.b3
    )   # le cd est confiné dans le sous-shell
}
```

**Fichiers temporaires** : un test qui échoue à mi-chemin laisse des fichiers qui perturbent le suivant.

```bash
# ✓ Correct : trap pour nettoyage garanti même en cas d'échec
test_compute() {
    local tmpdir=$(mktemp -d)
    trap "rm -rf $tmpdir" EXIT   # nettoyage garanti
    # ... test ...
}
```

### Dans hash_tool

`run_tests.sh` utilise un `WORKDIR=$(mktemp -d /tmp/integrity-test.XXXXXX)` créé en `setup()` et détruit en `teardown()`. Tous les tests opèrent dans ce répertoire temporaire, jamais dans les fichiers du projet ou du système hôte.

---

## 11. Couverture de tests

La couverture (coverage) mesure quelle proportion du code est exercée par les tests.

### Types de couverture

**Couverture de lignes** : chaque ligne est-elle exécutée au moins une fois ?

**Couverture de branches** : chaque branche d'un `if`/`case` est-elle testée (chemin vrai ET chemin faux) ?

```bash
# Cette fonction a 2 branches
if (( fsize > 0 )); then
    bytes_done=$(( bytes_done + fsize ))
    # ← branche testée si fsize > 0
fi
# ← branche testée si fsize == 0 (fichier vide)

# Un test avec uniquement des fichiers non-vides → couverture 50% de cette condition
```

**Couverture de chemins** : chaque combinaison possible de branches est-elle testée ? (Combinatoire explosive, rare en pratique.)

### Lacunes de couverture dans hash_tool

En analysant le code, voici des branches **non testées** :

```bash
# Dans _core_file_size() — branche BSD
_core_file_size() {
    if stat -c%s "$f" 2>/dev/null; then   # ← testé sur Linux
        return
    fi
    stat -f%z "$f"   # ← jamais testé (macOS uniquement)
}

# Dans core_compute — callback vide
core_compute "$target" "$hashfile" ""   # ← jamais testé sans callback

# Dans ui_progress_callback — cas bytes_done == 0
# La branche (bytes_done > 0 && eta_seconds > 0) est testée
# Mais (bytes_done == 0) — premier fichier, juste après démarrage ?
```

### Comment mesurer la couverture en bash

Il n'existe pas d'outil de couverture natif pour bash équivalent à `coverage.py`. La méthode pragmatique est manuelle : relire chaque branche du code et vérifier qu'un test l'exerce.

Pour les projets bash critiques, `bashcov` (basé sur `xtrace`) ou simplement `set -x` avec analyse de log permettent de voir quelles lignes sont exécutées.

---

## 12. Fixtures et données de test

Une fixture est un ensemble de données préparées à l'avance, dans un état connu, utilisées comme entrée des tests.

### Types de fixtures

**Données dynamiques** : créées dans le `setup()` du test, détruites dans le `teardown()`.

```bash
setup() {
    mkdir -p "$WORKDIR/data/sub"
    echo "contenu alpha" > "$WORKDIR/data/alpha.txt"
    echo "contenu beta"  > "$WORKDIR/data/beta.txt"
}
```

C'est l'approche de `run_tests.sh` : les fichiers de test sont créés à chaque run. Avantage : pas de fichiers à maintenir dans le repo. Inconvénient : si la fixture est complexe (arborescence de 500 fichiers avec des noms spéciaux), le setup devient lui-même un code à maintenir et à tester.

**Fixtures statiques (commitées dans git)** : fichiers présents dans le repo, utilisés comme référence immuable.

```
tests/
└── fixtures/
    ├── data/
    │   ├── alpha.txt
    │   └── beta.txt
    └── reference.b3   ← résultat attendu, commité dans git
```

```bash
test_format_b3_stable() {
    cd tests/fixtures
    ../../src/integrity.sh compute ./data /tmp/output.b3 >/dev/null 2>&1
    diff reference.b3 /tmp/output.b3
    [ $? -eq 0 ] && pass "format stable" || fail "régression format"
}
```

Si `reference.b3` change dans un PR, c'est visible dans le diff git — c'est un signal fort qu'il faut examiner.

### Fixtures pour les cas limites

Certains cas limites sont difficiles à créer dynamiquement de manière fiable. Les fixtures statiques les capturent une fois pour toutes :

```
tests/fixtures/
├── edge_cases/
│   ├── fichier avec espaces.txt
│   ├── fichier&special<chars>.txt
│   └── .fichier_cache
└── reference_edge.b3
```

---

## 13. Synthèse — Appliquer tout ça à hash_tool

### Ce qui existe et fonctionne bien

`run_tests.sh` (T00-T14) et `run_tests_pipeline.sh` (TP01-TP12b) forment une suite d'intégration solide. L'isolation via `mktemp`, le `teardown()` systématique, les helpers `pass()`/`fail()` — c'est une base professionnelle.

### Ce qui manque, par ordre de priorité

**1. CI GitHub Actions** — sans CI, les tests ne sont lancés que si on y pense. Action : créer `.github/workflows/ci.yml`.

**2. Tests unitaires de `core.sh`** — créer `tests/run_tests_core.sh` qui source `core.sh` directement et teste chaque fonction en isolation. Priorité : `core_compare` (algorithme complexe, bug historique).

**3. Fixture de non-régression du format `.b3`** — commiter `tests/fixtures/reference.b3` et ajouter un test qui vérifie que `core_compute` produit exactement ce fichier.

**4. Cas limites manquants** :
- Fichier avec newline dans le nom (T15)
- Caractères HTML dans le nom de fichier → vérifier l'échappement dans `report.html` (T16)
- `--quiet` sur `compare` (T18)
- Fichier de taille zéro — comportement ETA (T19)

**5. Rapport TAP** — modifier les suites pour produire un output TAP, consommable par la CI sans configuration supplémentaire.

### Architecture cible de la suite de tests

```
tests/
├── run_tests.sh              ← intégration integrity.sh (T00-T20+)
├── run_tests_pipeline.sh     ← intégration runner.sh (TP01-TP12b+)
├── run_tests_core.sh         ← unitaires core.sh (nouveau)
├── run_tests_docker.sh       ← intégration entrypoint.sh (nouveau)
└── fixtures/
    ├── data/
    │   ├── alpha.txt
    │   ├── beta.txt
    │   ├── fichier avec espaces.txt
    │   └── <script>edge.txt
    └── reference.b3           ← non-régression format .b3
```

### Règle d'or

Un test n'a de valeur que s'il est **lancé automatiquement**. Un test dans un fichier que personne ne lance est une illusion de couverture. La CI est le seul mécanisme qui garantit que les tests sont effectivement exécutés à chaque modification.

---

*Fin du cours — toutes les notions sont illustrées avec des exemples tirés du code réel de `hash_tool`.*

--- Fichier : hors_git/tests/TODO -- tests/_cours appliqué -- test.pdf ---
[Fichier binaire ou illisible, contenu ignoré]

--- Fichier : hors_git/tests/TODO -- tests/_descriptif maj.md ---
En me basant sur l'audit complet (tests unitaires `core.sh`, non-régression format `.b3`, edge cases, CI GitHub Actions, tests Docker/environnement, protocole TAP, fixtures), voici la structure documentaire que je propose :

```
docs/development/testing/
│
├── index.md
│   Vue d'ensemble de la stratégie de test : pyramide, suites existantes,
│   suites à créer, liens vers chaque document.
│
├── strategy.md
│   Décision formelle : objectifs de couverture, règles de priorité,
│   définition de "done" pour un test, politique ShellCheck zéro warning.
│
├── unit-tests.md
│   Spécification de run_tests_core.sh : liste exhaustive des fonctions à
│   tester, cas nominal + cas d'erreur pour chaque fonction de core.sh,
│   mécanisme de sourcing direct, contrat d'isolation.
│
├── integration-tests.md
│   Spécification des extensions à run_tests.sh (T15-T20+) et
│   run_tests_pipeline.sh : cas manquants identifiés, oracle de chaque test,
│   comportement attendu documenté.
│
├── regression-tests.md
│   Spécification du mécanisme de non-régression format .b3 : création des
│   fixtures, procédure de mise à jour de reference.b3, règle de décision
│   (diff intentionnel vs bug).
│
├── edge-cases.md
│   Catalogue exhaustif des cas limites : noms avec espaces/newlines/
│   caractères HTML, fichiers vide, base .b3 minimale, locales, etc.
│   Pour chaque cas : input, comportement attendu, risque si non testé.
│
├── docker-tests.md
│   Spécification de run_tests_docker.sh : tests de build, tests
│   entrypoint.sh commande par commande, tests de taille d'image, tests
│   multi-plateforme amd64/arm64, prérequis Docker Buildx.
│
├── fixtures.md
│   Spécification de l'arborescence tests/fixtures/ : quels fichiers
│   créer, pourquoi chacun, procédure pour ajouter une nouvelle fixture,
│   règle de nommage.
│
├── tap-format.md
│   Spécification du format TAP à adopter : structure du header, format
│   ok/not ok, diagnostics, helpers bash à implémenter dans chaque suite,
│   compatibilité GitHub Actions.
│
└── ci-cd.md
    Spécification du workflow GitHub Actions : jobs (unit, integration,
    docker), matrice OS, conditions de déclenchement, gestion des
    artefacts, règles de blocage des PRs.
```

---

**Logique de la structure :**

- `index.md` + `strategy.md` sont les documents de décision — ils répondent à *pourquoi* et *quoi*.
- Les cinq fichiers `*-tests.md` + `edge-cases.md` sont les documents de spécification — ils répondent à *comment tester quoi exactement*.
- `fixtures.md` + `tap-format.md` sont des documents transversaux — ils décrivent des mécanismes utilisés par plusieurs suites.
- `ci-cd.md` est le document d'infrastructure — il décrit l'automatisation qui donne de la valeur à tout le reste.

Chaque fichier peut être rédigé et implémenté indépendamment, dans l'ordre de priorité de l'audit : `ci-cd.md` → `unit-tests.md` → `regression-tests.md` → `edge-cases.md` → `docker-tests.md`.

--- Fichier : hors_git/tests/TODO -- tests/_protocole maj claude.md ---
Bonne approche. Voici la démarche et les prompts, dans l'ordre.

---

## Principe général

Claude ne peut pas tout générer en un seul prompt — le contexte est trop large et le code produit serait non vérifiable. La bonne méthode : **une session par livrable**, avec à chaque fois le contexte minimal nécessaire et une vérification avant de passer à la suite.

L'ordre est imposé par les dépendances : `helpers-tap.sh` doit exister avant les suites qui le sourcent. Les fixtures doivent exister avant les tests de non-régression. La CI doit référencer des fichiers qui existent.

---

## Étape 1 — `helpers-tap.sh`

**Pourquoi en premier :** toutes les suites de tests le sourcent. C'est la fondation.

**Fichiers à fournir à Claude :**
- `tap-format.md`
- `tests/run_tests.sh` (pour comprendre le style et les helpers existants)

**Prompt :**
```
Tu vas créer le fichier tests/helpers-tap.sh pour le projet hash_tool.

Voici la spécification : [coller tap-format.md]

Voici la suite de tests existante pour comprendre le style du projet : [coller run_tests.sh]

Contraintes :
- bash >= 4, set -euo pipefail
- ShellCheck zéro warning
- Compatible avec la détection CI (variable $CI) : format coloré en local, format TAP en CI
- Toutes les fonctions assert_* documentées avec leur signature en commentaire
- Le fichier doit pouvoir être sourcé sans être exécuté directement (pas de logique au top-level)

Produis uniquement le fichier tests/helpers-tap.sh, complet et prêt à l'emploi.
```

**Vérification avant de continuer :**
```bash
shellcheck tests/helpers-tap.sh
bash -c 'source tests/helpers-tap.sh && echo "sourcing OK"'
```

---

## Étape 2 — `tests/fixtures/`

**Pourquoi en deuxième :** les tests de non-régression et plusieurs tests unitaires s'appuient sur les fixtures. Elles doivent exister avant d'écrire les tests qui les utilisent.

**Fichiers à fournir :**
- `fixtures.md`

**Prompt :**
```
Tu vas créer les fichiers de fixtures pour le projet hash_tool.

Voici la spécification : [coller fixtures.md]

Crée les fichiers suivants avec exactement le contenu spécifié :
- tests/fixtures/data/alpha.txt
- tests/fixtures/data/beta.txt
- tests/fixtures/data/gamma.txt
- tests/fixtures/data/sub/delta.txt
- tests/fixtures/data-edge/fichier avec espaces.txt
- tests/fixtures/data-edge/fichier&special.txt
- tests/fixtures/data-edge/zero_bytes.bin

Pour les fichiers data-edge avec des noms spéciaux (espaces, &), donne-moi les commandes bash 
exactes pour les créer, car les noms ne peuvent pas être représentés directement dans tous les contextes.

Ne génère pas encore reference.b3 — il sera généré après coup avec la commande réelle.
```

**Après la création des fichiers, générer `reference.b3` manuellement :**
```bash
cd tests/fixtures
../../src/integrity.sh compute ./data bases/reference.b3
cat bases/reference.b3   # vérifier le contenu
git add .
git commit -m "test(fixtures): add reference data and edge cases"
```

---

## Étape 3 — `tests/run_tests_core.sh`

**Pourquoi maintenant :** c'est la suite la plus importante (tests unitaires de `core.sh`), et elle ne dépend que de `helpers-tap.sh` et des fixtures.

**Fichiers à fournir :**
- `unit-tests.md` (spécification complète avec les 53 cas)
- `src/lib/core.sh` (code à tester)
- `src/lib/ui.sh` (nécessaire pour `die()`)
- `tests/helpers-tap.sh` (créé à l'étape 1)
- `tests/run_tests.sh` (pour le style)

**Prompt — partie 1 : structure + tests CU01–CU27 :**
```
Tu vas créer tests/run_tests_core.sh pour le projet hash_tool.

Voici la spécification des tests à implémenter : [coller unit-tests.md]

Voici le code à tester :
[coller src/lib/core.sh]
[coller src/lib/ui.sh]

Voici les helpers disponibles : [coller tests/helpers-tap.sh]

Contraintes :
- bash >= 4, set -euo pipefail, ShellCheck zéro warning
- Sourcer directement src/lib/ui.sh et src/lib/core.sh (pas passer par integrity.sh)
- Chaque test est isolé dans sa propre fonction, avec son propre WORKDIR local
- trap EXIT pour nettoyage garanti
- Format TAP (via helpers-tap.sh)

Pour cette première partie, implémente :
- La structure du fichier (shebang, setup, sourcing, teardown)
- Les tests CU01 à CU27 (core_assert_b3_valid, core_assert_target_valid, core_compute)

Je validerai cette partie avant de te demander la suite.
```

**Vérification intermédiaire :**
```bash
shellcheck tests/run_tests_core.sh
cd tests && ./run_tests_core.sh 2>&1 | head -40
```

**Prompt — partie 2 : tests CU28–CU53 :**
```
Voici la suite de tests run_tests_core.sh produite à l'étape précédente : [coller le fichier]

Continue en ajoutant les tests :
- CU28 à CU35 (core_verify)
- CU36 à CU48 (core_compare — la plus critique)
- CU49 à CU53 (core_make_result_dir)

Appends ces tests au fichier existant. Respecte le style et la structure déjà en place.
Fais particulièrement attention à CU42–CU44 : chemins avec espaces, &, et chevrons dans core_compare.
```

**Vérification finale :**
```bash
shellcheck tests/run_tests_core.sh
cd tests && ./run_tests_core.sh
# Tous les tests doivent passer
```

---

## Étape 4 — Extensions de `run_tests.sh` (T15–T20)

**Fichiers à fournir :**
- `integration-tests.md` (section "Extensions de run_tests.sh")
- `tests/run_tests.sh` (fichier existant à modifier)
- `tests/helpers-tap.sh`

**Prompt :**
```
Tu vas modifier tests/run_tests.sh pour y ajouter les cas T15 à T20.

Voici la spécification des nouveaux cas : [coller la section "Extensions de run_tests.sh" de integration-tests.md]

Voici le fichier actuel à modifier : [coller run_tests.sh]

Contraintes :
- Ne pas modifier les cas existants T00–T14
- Ajouter T15–T20 après T14, avant le bloc de résultats final
- Migrer les helpers pass()/fail() vers helpers-tap.sh en ajoutant : source "$(dirname "$0")/helpers-tap.sh"
- ShellCheck zéro warning
- T16 (HTML escaping) : les assertions doivent vérifier &lt; et &gt; dans report.html, pas <script>

Produis le fichier run_tests.sh complet modifié.
```

**Vérification :**
```bash
shellcheck tests/run_tests.sh
cd tests && ./run_tests.sh
```

---

## Étape 5 — Extensions de `run_tests_pipeline.sh` (TP13–TP15)

**Même approche que l'étape 4.**

**Fichiers à fournir :**
- `integration-tests.md` (section "Extensions de run_tests_pipeline.sh")
- `tests/run_tests_pipeline.sh` (fichier existant)
- `tests/helpers-tap.sh`

**Prompt :**
```
Tu vas modifier tests/run_tests_pipeline.sh pour y ajouter les cas TP13 à TP15.

Voici la spécification : [coller la section "Extensions de run_tests_pipeline.sh" de integration-tests.md]

Voici le fichier actuel : [coller run_tests_pipeline.sh]

Contraintes :
- Ne pas modifier les cas existants TP01–TP12b
- Ajouter TP13–TP15 après TP12b
- Migrer vers helpers-tap.sh
- ShellCheck zéro warning
- TP13 : créer explicitement un dossier source corrompu distinct du dossier source propre

Produis le fichier run_tests_pipeline.sh complet modifié.
```

---

## Étape 6 — Test de non-régression dans `run_tests.sh`

**Ce test dépend de `reference.b3` généré à l'étape 2.**

**Fichiers à fournir :**
- `regression-tests.md`
- `tests/run_tests.sh` (version modifiée à l'étape 4)

**Prompt :**
```
Tu vas ajouter un test de non-régression dans tests/run_tests.sh.

Voici la spécification : [coller regression-tests.md]

Voici le fichier actuel : [coller run_tests.sh modifié]

Ajoute une section "T_REG — Non-régression format .b3" avec les tests T_REG01 à T_REG06 
tels que spécifiés. 

Le test T_REG01 doit :
- Vérifier que tests/fixtures/bases/reference.b3 existe (SKIP sinon avec tap_skip)
- Lancer compute sur tests/fixtures/data/
- Faire un diff bit-à-bit avec reference.b3
- En cas d'échec, afficher le diff (limité à 20 lignes) pour faciliter le diagnostic

Produis le fichier run_tests.sh complet final.
```

---

## Étape 7 — `tests/run_tests_docker.sh`

**Cette suite est indépendante — pas de dépendance aux autres suites bash.**

**Fichiers à fournir :**
- `docker-tests.md`
- `docker/entrypoint.sh`
- `tests/helpers-tap.sh`

**Prompt :**
```
Tu vas créer tests/run_tests_docker.sh pour le projet hash_tool.

Voici la spécification complète : [coller docker-tests.md]

Voici l'entrypoint à tester : [coller docker/entrypoint.sh]

Voici les helpers disponibles : [coller helpers-tap.sh]

Contraintes :
- bash >= 4, set -euo pipefail, ShellCheck zéro warning
- Skip automatique si Docker n'est pas disponible (command -v docker)
- Skip automatique si l'image hash_tool n'est pas buildée (sauf avec --build)
- Chaque test TD* crée ses propres tmpdir avec mktemp -d et les nettoie via trap EXIT
- Les tests TB* (build) sont dans une section séparée et ne tournent que si --build est passé
- Format TAP via helpers-tap.sh

Implémente tous les tests TB01–TB04, TE01–TE07, TD01–TD11.
```

**Vérification :**
```bash
shellcheck tests/run_tests_docker.sh
docker build -t hash_tool .
cd tests && ./run_tests_docker.sh --build
```

---

## Étape 8 — `.github/workflows/ci.yml`

**Dernière étape — la CI référence tous les fichiers créés précédemment.**

**Fichiers à fournir :**
- `ci-cd.md`
- La liste des fichiers de tests existants (pour vérifier les chemins)

**Prompt :**
```
Tu vas créer .github/workflows/ci.yml pour le projet hash_tool.

Voici la spécification complète : [coller ci-cd.md]

Les fichiers de tests qui existent maintenant :
- tests/helpers-tap.sh
- tests/run_tests.sh
- tests/run_tests_pipeline.sh
- tests/run_tests_core.sh
- tests/run_tests_docker.sh
- tests/fixtures/bases/reference.b3

Contraintes :
- Jobs lint, unit, integration, pipeline, non-regression en parallèle (needs: lint uniquement)
- Job docker-build conditionnel (main, develop, ou PR modifiant Dockerfile/.dockerignore/docker/)
- Job docker-arm64 avec continue-on-error: true, uniquement sur main
- Matrice ubuntu-22.04 + ubuntu-24.04 pour unit et integration
- concurrency avec cancel-in-progress pour éviter les runs redondants sur une même PR
- Upload d'artefacts TAP avec if: always() sur chaque job
- Pas de secrets requis

Produis le fichier .github/workflows/ci.yml complet.
```

**Vérification :**
```bash
# Installer actionlint si disponible
actionlint .github/workflows/ci.yml

# Ou vérifier manuellement la syntaxe YAML
python3 -c "import yaml; yaml.safe_load(open('.github/workflows/ci.yml'))" && echo "YAML valide"
```

---

## Récapitulatif de la démarche

| Étape | Livrable | Dépend de | Vérification |
|---|---|---|---|
| 1 | `helpers-tap.sh` | — | `shellcheck` + sourcing |
| 2 | `tests/fixtures/` | — | génération manuelle de `reference.b3` |
| 3a | `run_tests_core.sh` CU01–CU27 | 1, 2 | `shellcheck` + run partiel |
| 3b | `run_tests_core.sh` CU28–CU53 | 3a | run complet, 0 FAIL |
| 4 | `run_tests.sh` T15–T20 | 1 | `shellcheck` + run complet |
| 5 | `run_tests_pipeline.sh` TP13–TP15 | 1 | `shellcheck` + run complet |
| 6 | Non-régression dans `run_tests.sh` | 2, 4 | run complet, T_REG01 pass |
| 7 | `run_tests_docker.sh` | 1, image Docker | `shellcheck` + run avec `--build` |
| 8 | `ci.yml` | 1–7 tous présents | `actionlint` ou YAML lint |

**Règle absolue :** ne passer à l'étape N+1 que si l'étape N passe ShellCheck et produit zéro FAIL. Un test qui échoue dès la création est soit mal implémenté, soit révèle un bug réel dans le code — dans les deux cas, à traiter avant de continuer.

--- Fichier : hors_git/tests/TODO -- tests/ci-cd.md ---
# CI/CD — Spécification GitHub Actions

---

## Objectifs

1. **Détection automatique des régressions** : chaque push et chaque PR déclenchent les tests.
2. **Blocage des PRs cassées** : une PR ne peut pas merger si un test échoue.
3. **Feedback rapide** : les tests unitaires et d'intégration donnent un résultat en < 2 minutes.
4. **Isolation des tests lents** : les tests Docker (build arm64, QEMU) sont séparés et ne bloquent pas le feedback rapide.
5. **Artefacts accessibles** : les résultats de tests sont téléchargeables depuis l'interface GitHub même en cas d'échec.

---

## Architecture des jobs

```
push / PR
    │
    ├── [job: lint]          ShellCheck sur tous les scripts
    │       ↓
    ├── [job: unit]          run_tests_core.sh    (~30s)
    │       ↓
    ├── [job: integration]   run_tests.sh         (~60s)
    │       ↓
    ├── [job: pipeline]      run_tests_pipeline.sh (~60s)
    │
    └── [job: docker]        (déclenché sur : push main + PR modifiant Dockerfile)
            ├── docker build amd64
            ├── run_tests_docker.sh (sans --build, image en cache)
            └── docker build arm64  (QEMU, séparé, peut échouer sans bloquer)
```

Les jobs `unit`, `integration`, `pipeline` sont **indépendants et parallèles** — ils peuvent tourner simultanément. Le job `docker` est conditionnel.

---

## Fichier `.github/workflows/ci.yml`

```yaml
name: CI

on:
  push:
    branches: ["main", "develop"]
  pull_request:
    branches: ["main"]

# Annuler les runs en cours si un nouveau push arrive sur la même PR
concurrency:
  group: ${{ github.workflow }}-${{ github.ref }}
  cancel-in-progress: true

jobs:

  # ============================================================
  # Job : lint — ShellCheck sur tous les scripts
  # ============================================================
  lint:
    name: ShellCheck
    runs-on: ubuntu-latest

    steps:
      - uses: actions/checkout@v4

      - name: Installer ShellCheck
        run: sudo apt-get install -y shellcheck

      - name: ShellCheck — scripts principaux
        run: |
          shellcheck \
            src/integrity.sh \
            runner.sh \
            src/lib/core.sh \
            src/lib/ui.sh \
            src/lib/results.sh \
            src/lib/report.sh \
            docker/entrypoint.sh

      - name: ShellCheck — suites de tests
        run: |
          shellcheck \
            tests/run_tests.sh \
            tests/run_tests_pipeline.sh \
            tests/run_tests_core.sh \
            tests/run_tests_docker.sh \
            tests/helpers-tap.sh

  # ============================================================
  # Job : unit — Tests unitaires core.sh
  # ============================================================
  unit:
    name: Tests unitaires (core.sh)
    runs-on: ubuntu-latest
    needs: lint   # ne lance pas les tests si ShellCheck échoue

    strategy:
      matrix:
        os: [ubuntu-22.04, ubuntu-24.04]

    steps:
      - uses: actions/checkout@v4

      - name: Installer les dépendances
        run: sudo apt-get install -y b3sum

      - name: Lancer run_tests_core.sh
        run: |
          cd tests
          ./run_tests_core.sh 2>&1 | tee /tmp/core-results.tap
        env:
          CI: "true"

      - name: Uploader les résultats
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: unit-test-results-${{ matrix.os }}
          path: /tmp/core-results.tap
          retention-days: 7

  # ============================================================
  # Job : integration — Tests d'intégration integrity.sh
  # ============================================================
  integration:
    name: Tests d'intégration (integrity.sh)
    runs-on: ubuntu-latest
    needs: lint

    strategy:
      matrix:
        os: [ubuntu-22.04, ubuntu-24.04]

    steps:
      - uses: actions/checkout@v4

      - name: Installer les dépendances
        run: sudo apt-get install -y b3sum

      - name: Lancer run_tests.sh
        run: |
          cd tests
          ./run_tests.sh 2>&1 | tee /tmp/integration-results.tap
        env:
          CI: "true"

      - name: Uploader les résultats
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: integration-test-results-${{ matrix.os }}
          path: /tmp/integration-results.tap
          retention-days: 7

  # ============================================================
  # Job : pipeline — Tests d'intégration runner.sh
  # ============================================================
  pipeline:
    name: Tests pipeline (runner.sh)
    runs-on: ubuntu-latest
    needs: lint

    steps:
      - uses: actions/checkout@v4

      - name: Installer les dépendances
        run: sudo apt-get install -y b3sum jq

      - name: Lancer run_tests_pipeline.sh
        run: |
          cd tests
          ./run_tests_pipeline.sh 2>&1 | tee /tmp/pipeline-results.tap
        env:
          CI: "true"

      - name: Uploader les résultats
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: pipeline-test-results
          path: /tmp/pipeline-results.tap
          retention-days: 7

  # ============================================================
  # Job : non-regression — Test de non-régression format .b3
  # ============================================================
  non-regression:
    name: Non-régression format .b3
    runs-on: ubuntu-latest
    needs: lint

    steps:
      - uses: actions/checkout@v4

      - name: Installer b3sum
        run: sudo apt-get install -y b3sum

      - name: Vérifier reference.b3
        run: |
          cd tests/fixtures
          ../../src/integrity.sh compute ./data /tmp/output_reg.b3
          diff bases/reference.b3 /tmp/output_reg.b3 || {
            echo "ERREUR : régression du format .b3 détectée"
            echo "--- reference.b3 (attendu) ---"
            head -5 bases/reference.b3
            echo "--- output produit ---"
            head -5 /tmp/output_reg.b3
            exit 1
          }
          echo "Format .b3 stable"

  # ============================================================
  # Job : docker-build — Build et tests Docker (amd64)
  # ============================================================
  docker-build:
    name: Docker build + tests (amd64)
    runs-on: ubuntu-latest
    needs: lint

    # Ne tourner que sur main, develop, et les PRs modifiant Docker
    if: |
      github.ref == 'refs/heads/main' ||
      github.ref == 'refs/heads/develop' ||
      contains(github.event.pull_request.changed_files, 'Dockerfile') ||
      contains(github.event.pull_request.changed_files, '.dockerignore') ||
      contains(github.event.pull_request.changed_files, 'docker/')

    steps:
      - uses: actions/checkout@v4

      - name: Build image Docker amd64
        run: docker build --platform linux/amd64 -t hash_tool .

      - name: Vérifier la taille de l'image
        run: |
          SIZE=$(docker image inspect hash_tool --format='{{.Size}}')
          SIZE_MB=$(( SIZE / 1024 / 1024 ))
          echo "Taille image : ${SIZE_MB} Mo"
          [ "$SIZE_MB" -lt 30 ] || { echo "ERREUR : image trop lourde (${SIZE_MB} Mo)"; exit 1; }

      - name: Lancer run_tests_docker.sh
        run: |
          cd tests
          ./run_tests_docker.sh 2>&1 | tee /tmp/docker-results.tap
        env:
          CI: "true"

      - name: Uploader les résultats
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: docker-test-results
          path: /tmp/docker-results.tap
          retention-days: 7

  # ============================================================
  # Job : docker-arm64 — Build arm64 (QEMU, peut être lent)
  # ============================================================
  docker-arm64:
    name: Docker build (arm64)
    runs-on: ubuntu-latest
    needs: docker-build
    # Ce job peut échouer sans bloquer le merge (continue-on-error)
    continue-on-error: true

    if: github.ref == 'refs/heads/main'

    steps:
      - uses: actions/checkout@v4

      - name: Setup QEMU
        uses: docker/setup-qemu-action@v3

      - name: Setup Docker Buildx
        uses: docker/setup-buildx-action@v3

      - name: Build image arm64
        run: |
          docker buildx build \
            --platform linux/arm64 \
            -t hash_tool:arm64 \
            --load \
            .

      - name: Test basique arm64
        run: docker run --rm --platform linux/arm64 hash_tool version
```

---

## Conditions de blocage des PRs

Configurer dans les **Branch Protection Rules** de GitHub (`Settings > Branches > main`) :

| Check requis | Job concerné | Bloquant |
|---|---|---|
| ShellCheck | `lint` | Oui |
| Tests unitaires (ubuntu-22.04) | `unit` | Oui |
| Tests unitaires (ubuntu-24.04) | `unit` | Oui |
| Tests d'intégration (ubuntu-22.04) | `integration` | Oui |
| Tests d'intégration (ubuntu-24.04) | `integration` | Oui |
| Tests pipeline | `pipeline` | Oui |
| Non-régression .b3 | `non-regression` | Oui |
| Docker build amd64 | `docker-build` | Oui (si Dockerfile modifié) |
| Docker build arm64 | `docker-arm64` | Non (`continue-on-error: true`) |

---

## Gestion des artefacts

Chaque job uploade ses résultats TAP en artefact. Ils sont accessibles depuis l'onglet "Actions" de GitHub pendant 7 jours.

En cas d'échec, la procédure de diagnostic :
1. Cliquer sur le job échoué dans l'interface Actions.
2. Consulter les logs en ligne (résultats TAP affichés dans le terminal).
3. Télécharger l'artefact correspondant si un contexte plus détaillé est nécessaire.

---

## Déclenchement manuel

Le workflow peut être déclenché manuellement depuis l'interface GitHub Actions (`workflow_dispatch`) :

```yaml
on:
  push: ...
  pull_request: ...
  workflow_dispatch:    # ← déclenchement manuel
    inputs:
      run_docker_arm64:
        description: 'Lancer le build arm64 (lent)'
        type: boolean
        default: false
```

---

## Secrets et variables d'environnement

Aucun secret n'est requis pour la CI de base — `hash_tool` n'a pas de dépendances réseau dans ses tests (tout est local).

Si des notifications (Slack, email) sont ajoutées dans le futur :
- `SLACK_WEBHOOK_URL` → `Settings > Secrets > Actions`
- Ne jamais logger les secrets dans les steps

---

## Durée estimée par run CI

| Job | Durée estimée |
|---|---|
| lint (ShellCheck) | ~15s |
| unit (ubuntu-22.04) | ~30s |
| unit (ubuntu-24.04) | ~30s |
| integration (ubuntu-22.04) | ~60s |
| integration (ubuntu-24.04) | ~60s |
| pipeline | ~60s |
| non-regression | ~20s |
| docker-build + tests amd64 | ~3-4 min |
| docker-arm64 (QEMU) | ~8-12 min |

**Durée totale pour un push standard** (sans Docker) : ~2 minutes (jobs parallèles).  
**Durée avec Docker** : ~5 minutes (Docker build en parallèle des autres jobs).

---

## Évolutions futures

| Évolution | Priorité | Description |
|---|---|---|
| Publication TAP → rapport HTML | Basse | Utiliser `dorny/test-reporter` pour afficher les résultats dans les PR checks |
| Cache des dépendances apt | Moyenne | `actions/cache` sur `/var/cache/apt` — gain ~20s par job |
| Scheduled run nocturne | Basse | `on: schedule: cron: '0 3 * * *'` — détecte les régressions dues à des mises à jour de dépendances système |
| Notification sur échec | Basse | Webhook Slack sur `main` uniquement, pas sur les PRs |


--- Fichier : hors_git/tests/TODO -- tests/docker-tests.md ---
# Tests Docker — Spécification `run_tests_docker.sh`

---

## Périmètre

`run_tests_docker.sh` couvre trois niveaux :

1. **Build** — l'image se construit sans erreur, pour les architectures cibles
2. **Environnement** — les outils attendus sont présents dans l'image avec les bonnes versions
3. **Entrypoint** — chaque commande de `docker/entrypoint.sh` produit le résultat attendu

Cette suite est **indépendante** des autres : elle ne source aucun module bash, elle ne dépend pas de `b3sum` sur l'hôte. Elle nécessite uniquement Docker.

---

## Prérequis et skip automatique

```bash
#!/usr/bin/env bash
# run_tests_docker.sh
set -euo pipefail

# Skip si Docker n'est pas disponible
command -v docker &>/dev/null || {
    echo "SKIP - Docker non disponible sur cet hôte"
    exit 0
}

# Skip si l'image n'est pas buildée (sauf si --build passé en argument)
if [ "${1:-}" = "--build" ]; then
    echo "=== Build de l'image ==="
    docker build -t hash_tool . || { echo "ERREUR : build échoué"; exit 1; }
fi

docker image inspect hash_tool &>/dev/null || {
    echo "SKIP - image hash_tool non trouvée. Lancer avec --build ou 'docker build -t hash_tool .'"
    exit 0
}
```

---

## Tests de build (TB)

Ces tests sont séparés des tests d'entrypoint — le build est lent (~2-3 min) et ne doit pas bloquer les tests fonctionnels.

### TB01 — Build amd64 réussi

```bash
docker build --platform linux/amd64 -t hash_tool:test-amd64 .
[ $? -eq 0 ] && pass "TB01 build amd64" || fail "TB01 build amd64 échoué"
docker rmi hash_tool:test-amd64 >/dev/null 2>&1 || true
```

### TB02 — Build arm64 réussi

```bash
# Requiert Docker Buildx ou QEMU
docker build --platform linux/arm64 -t hash_tool:test-arm64 .
[ $? -eq 0 ] && pass "TB02 build arm64" || fail "TB02 build arm64 échoué"
docker rmi hash_tool:test-arm64 >/dev/null 2>&1 || true
```

**Note CI :** TB02 nécessite `docker buildx` avec `--platform linux/arm64` et l'émulation QEMU. Dans GitHub Actions, utiliser `docker/setup-qemu-action` et `docker/setup-buildx-action`.

### TB03 — Taille de l'image finale

```bash
local size
size=$(docker image inspect hash_tool --format='{{.Size}}')
local size_mb=$(( size / 1024 / 1024 ))
# Seuil : < 30 Mo (image actuelle ~14 Mo, marge pour éviter les faux positifs)
[ "$size_mb" -lt 30 ] \
    && pass "TB03 taille image OK : ${size_mb} Mo" \
    || fail "TB03 image trop lourde : ${size_mb} Mo (seuil 30 Mo)"
```

**Rationale du seuil :** l'image actuelle fait ~14 Mo. Un seuil à 30 Mo détecte une régression significative (ajout accidentel d'un package lourd) sans être trop strict.

### TB04 — Pas de données utilisateur dans l'image

```bash
# Vérifier que mon_dossier/ et les .b3 ne sont pas dans l'image (respecte .dockerignore)
local found
found=$(docker run --rm hash_tool find / -name "*.b3" -o -name "hashes_*" 2>/dev/null | grep -v "^/proc" || true)
[ -z "$found" ] \
    && pass "TB04 pas de données utilisateur dans l'image" \
    || fail "TB04 données trouvées dans l'image : $found"
```

---

## Tests d'environnement (TE)

Ces tests vérifient que les outils présents dans l'image sont les bons, aux bonnes versions.

### TE01 — `b3sum` présent et fonctionnel

```bash
local out
out=$(docker run --rm hash_tool b3sum --version 2>&1)
echo "$out" | grep -qi "b3sum" \
    && pass "TE01 b3sum présent" \
    || fail "TE01 b3sum absent ou non fonctionnel : $out"
```

### TE02 — `b3sum` produit un hash valide

```bash
local hash
hash=$(docker run --rm hash_tool bash -c 'echo "test" | b3sum')
echo "$hash" | grep -qE '^[0-9a-f]{64}' \
    && pass "TE02 b3sum produit un hash valide" \
    || fail "TE02 hash invalide : $hash"
```

### TE03 — `jq` présent et fonctionnel

```bash
local out
out=$(docker run --rm hash_tool jq --version 2>&1)
echo "$out" | grep -qi "jq" \
    && pass "TE03 jq présent" \
    || fail "TE03 jq absent : $out"
```

### TE04 — `bash` version >= 4

```bash
local version
version=$(docker run --rm hash_tool bash -c 'echo ${BASH_VERSINFO[0]}')
[ "$version" -ge 4 ] \
    && pass "TE04 bash >= 4 (version $version)" \
    || fail "TE04 bash trop ancien : $version"
```

### TE05 — Outils coreutils présents

```bash
for tool in find sort awk comm join stat du mktemp; do
    docker run --rm hash_tool command -v "$tool" >/dev/null 2>&1 \
        && pass "TE05 $tool présent" \
        || fail "TE05 $tool absent"
done
```

### TE06 — `RESULTATS_DIR` défini à `/resultats`

```bash
local val
val=$(docker run --rm hash_tool bash -c 'echo $RESULTATS_DIR')
[ "$val" = "/resultats" ] \
    && pass "TE06 RESULTATS_DIR=/resultats" \
    || fail "TE06 RESULTATS_DIR=$val (attendu /resultats)"
```

### TE07 — Scripts présents et exécutables

```bash
for f in /app/runner.sh /app/src/integrity.sh /app/src/lib/report.sh; do
    docker run --rm hash_tool test -x "$f" \
        && pass "TE07 $f exécutable" \
        || fail "TE07 $f absent ou non exécutable"
done
```

---

## Tests de l'entrypoint (TD)

### TD01 — Commande `help` : exit 0, affiche de l'aide

```bash
local out exit_code=0
out=$(docker run --rm hash_tool help 2>&1) || exit_code=$?
[ "$exit_code" -eq 0 ] && pass "TD01 help exit 0" || fail "TD01 help exit $exit_code"
echo "$out" | grep -qi "compute" && pass "TD01 help contient compute" || fail "TD01 help ne contient pas compute"
echo "$out" | grep -qi "verify"  && pass "TD01 help contient verify"  || fail "TD01 help ne contient pas verify"
```

### TD02 — Commande sans argument : affiche l'aide (CMD défaut)

```bash
local out
out=$(docker run --rm hash_tool 2>&1) || true
echo "$out" | grep -qi "usage\|compute\|verify" \
    && pass "TD02 aide par défaut" \
    || fail "TD02 pas d'aide par défaut"
```

### TD03 — Commande inconnue : exit 1, message d'erreur

```bash
local exit_code=0
local out
out=$(docker run --rm hash_tool commande_inconnue_xyz 2>&1) || exit_code=$?
[ "$exit_code" -ne 0 ] && pass "TD03 commande inconnue → exit non-zéro" || fail "TD03 doit exit 1"
echo "$out" | grep -qi "inconnue\|unknown\|ERREUR" \
    && pass "TD03 message d'erreur explicite" \
    || fail "TD03 message d'erreur absent"
```

### TD04 — Commande `version` : affiche b3sum, jq, bash

```bash
local out
out=$(docker run --rm hash_tool version 2>&1)
echo "$out" | grep -qi "b3sum" && pass "TD04 version contient b3sum" || fail "TD04 version sans b3sum"
echo "$out" | grep -qi "jq"    && pass "TD04 version contient jq"    || fail "TD04 version sans jq"
echo "$out" | grep -qi "bash"  && pass "TD04 version contient bash"   || fail "TD04 version sans bash"
```

### TD05 — Commande `compute` : produit un fichier `.b3`

```bash
local tmpdata tmpbases
tmpdata=$(mktemp -d)
tmpbases=$(mktemp -d)
echo "contenu test" > "$tmpdata/fichier.txt"

docker run --rm \
    -v "$tmpdata:/data:ro" \
    -v "$tmpbases:/bases" \
    hash_tool compute /data /bases/test.b3

[ -f "$tmpbases/test.b3" ] \
    && pass "TD05 test.b3 produit" \
    || fail "TD05 test.b3 absent"

grep -qE '^[0-9a-f]{64}  ./fichier.txt' "$tmpbases/test.b3" \
    && pass "TD05 format b3sum correct" \
    || fail "TD05 format b3sum incorrect : $(cat "$tmpbases/test.b3")"

rm -rf "$tmpdata" "$tmpbases"
```

### TD06 — Commande `verify` : OK sur base fraîche

```bash
local tmpdata tmpbases tmpres
tmpdata=$(mktemp -d); tmpbases=$(mktemp -d); tmpres=$(mktemp -d)
echo "contenu test" > "$tmpdata/fichier.txt"

docker run --rm -v "$tmpdata:/data:ro" -v "$tmpbases:/bases" \
    hash_tool compute /data /bases/test.b3 >/dev/null

local out exit_code=0
out=$(docker run --rm \
    -v "$tmpdata:/data:ro" \
    -v "$tmpbases:/bases:ro" \
    -v "$tmpres:/resultats" \
    hash_tool verify /bases/test.b3 /data 2>&1) || exit_code=$?

[ "$exit_code" -eq 0 ] && pass "TD06 verify exit 0" || fail "TD06 verify exit $exit_code"
echo "$out" | grep -qi "OK" && pass "TD06 verify affiche OK" || fail "TD06 verify n'affiche pas OK"

rm -rf "$tmpdata" "$tmpbases" "$tmpres"
```

### TD07 — Commande `verify` : détecte une corruption

```bash
local tmpdata tmpbases tmpres
tmpdata=$(mktemp -d); tmpbases=$(mktemp -d); tmpres=$(mktemp -d)
echo "contenu original" > "$tmpdata/fichier.txt"

docker run --rm -v "$tmpdata:/data:ro" -v "$tmpbases:/bases" \
    hash_tool compute /data /bases/test.b3 >/dev/null

echo "contenu corrompu" > "$tmpdata/fichier.txt"

local exit_code=0
docker run --rm \
    -v "$tmpdata:/data:ro" \
    -v "$tmpbases:/bases:ro" \
    -v "$tmpres:/resultats" \
    hash_tool verify /bases/test.b3 /data >/dev/null 2>&1 || exit_code=$?

[ "$exit_code" -ne 0 ] \
    && pass "TD07 verify détecte corruption → exit non-zéro" \
    || fail "TD07 verify aurait dû échouer"

rm -rf "$tmpdata" "$tmpbases" "$tmpres"
```

### TD08 — Commande `compare` : produit `report.html`

```bash
local tmpbases tmpres
tmpbases=$(mktemp -d); tmpres=$(mktemp -d)

# Créer deux bases différentes
local tmpdata_a tmpdata_b
tmpdata_a=$(mktemp -d); tmpdata_b=$(mktemp -d)
echo "v1" > "$tmpdata_a/f.txt"
echo "v2" > "$tmpdata_b/f.txt"

docker run --rm -v "$tmpdata_a:/data:ro" -v "$tmpbases:/bases" \
    hash_tool compute /data /bases/a.b3 >/dev/null
docker run --rm -v "$tmpdata_b:/data:ro" -v "$tmpbases:/bases" \
    hash_tool compute /data /bases/b.b3 >/dev/null

docker run --rm \
    -v "$tmpbases:/bases:ro" \
    -v "$tmpres:/resultats" \
    hash_tool compare /bases/a.b3 /bases/b.b3 >/dev/null

local report
report=$(ls "$tmpres"/resultats_a*/report.html 2>/dev/null | head -1)
[ -f "$report" ] \
    && pass "TD08 report.html produit" \
    || fail "TD08 report.html absent"

rm -rf "$tmpdata_a" "$tmpdata_b" "$tmpbases" "$tmpres"
```

### TD09 — Flag `--quiet` transmis correctement

```bash
local tmpdata tmpbases tmpres
tmpdata=$(mktemp -d); tmpbases=$(mktemp -d); tmpres=$(mktemp -d)
echo "contenu" > "$tmpdata/f.txt"

docker run --rm -v "$tmpdata:/data:ro" -v "$tmpbases:/bases" \
    hash_tool compute /data /bases/test.b3 >/dev/null

local out
out=$(docker run --rm \
    -v "$tmpdata:/data:ro" \
    -v "$tmpbases:/bases:ro" \
    -v "$tmpres:/resultats" \
    hash_tool --quiet verify /bases/test.b3 /data 2>&1)

[ -z "$out" ] \
    && pass "TD09 --quiet : stdout vide" \
    || fail "TD09 --quiet : stdout non vide : $out"

rm -rf "$tmpdata" "$tmpbases" "$tmpres"
```

### TD10 — Commande `runner` avec pipeline JSON

```bash
local tmpdata tmpbases tmpres tmppipelines
tmpdata=$(mktemp -d); tmpbases=$(mktemp -d)
tmpres=$(mktemp -d); tmppipelines=$(mktemp -d)
echo "contenu" > "$tmpdata/f.txt"

cat > "$tmppipelines/pipeline.json" <<EOF
{
    "pipeline": [
        { "op": "compute", "source": "/data", "bases": "/bases", "nom": "test.b3" }
    ]
}
EOF

docker run --rm \
    -v "$tmpdata:/data:ro" \
    -v "$tmpbases:/bases" \
    -v "$tmpres:/resultats" \
    -v "$tmppipelines/pipeline.json:/pipelines/pipeline.json:ro" \
    hash_tool runner /pipelines/pipeline.json >/dev/null

[ -f "$tmpbases/test.b3" ] \
    && pass "TD10 runner pipeline : test.b3 produit" \
    || fail "TD10 runner pipeline : test.b3 absent"

rm -rf "$tmpdata" "$tmpbases" "$tmpres" "$tmppipelines"
```

### TD11 — Commande `runner` sans pipeline.json monté : erreur explicite

```bash
local out exit_code=0
out=$(docker run --rm hash_tool runner 2>&1) || exit_code=$?
[ "$exit_code" -ne 0 ] && pass "TD11 runner sans pipeline → exit non-zéro" || fail "TD11 doit exit 1"
echo "$out" | grep -qi "introuvable\|ERREUR\|not found" \
    && pass "TD11 message d'erreur sur pipeline absent" \
    || fail "TD11 message d'erreur absent : $out"
```

---

## Structure du fichier `run_tests_docker.sh`

```bash
#!/usr/bin/env bash
# run_tests_docker.sh - Tests de l'image Docker hash_tool
# Usage : ./run_tests_docker.sh [--build]
# Prérequis : Docker

set -euo pipefail

# ... helpers pass/fail/assert identiques aux autres suites ...

echo "=== BUILD ==="
# TB01–TB04

echo "=== ENVIRONNEMENT ==="
# TE01–TE07

echo "=== ENTRYPOINT ==="
# TD01–TD11

echo "========================================"
[ "$FAIL" -eq 0 ] \
    && echo "  $PASS/$TOTAL tests passés" \
    || echo "  $PASS/$TOTAL passés - $FAIL échec(s)"
echo "========================================"
[ "$FAIL" -eq 0 ]
```

---

## Durée estimée

| Section | Durée approx. |
|---|---|
| Tests d'environnement (TE) | ~10 secondes |
| Tests entrypoint (TD) | ~60 secondes |
| Tests de build (TB01 amd64) | ~2-3 minutes |
| Tests de build (TB02 arm64 avec QEMU) | ~5-10 minutes |

**Recommandation CI :** séparer les tests de build (job `docker-build`) des tests d'entrypoint (job `docker-test`). Les tests d'entrypoint peuvent tourner sur une image pré-buildée en cache. Les tests de build ne tournent que sur les PRs modifiant `Dockerfile`, `.dockerignore` ou `docker/`.


--- Fichier : hors_git/tests/TODO -- tests/edge-cases.md ---
# Cas limites — Catalogue exhaustif

---

## Introduction

Un cas limite est une entrée qui se situe aux frontières du comportement normal. C'est là que les bugs se cachent — le code est typiquement développé et testé sur des cas "standards", et les hypothèses implicites sur les entrées ne sont jamais vérifiées.

Ce catalogue recense tous les cas limites identifiés pour `hash_tool`, classés par catégorie. Pour chaque cas : l'input, le comportement attendu, et le risque si le cas n'est pas testé.

---

## Catégorie 1 — Noms de fichiers

### 1.1 Espace dans le nom

| | |
|---|---|
| **Input** | `"fichier avec espaces.txt"` |
| **Comportement attendu** | Indexé correctement, 1 ligne dans `.b3`, verify OK |
| **Risque** | `awk '{print $2}'` fragmente le chemin — faux positif massif dans `compare` (bug historique v0.7) |
| **Testé par** | T08 (existant), CU42 (unitaire à créer) |

### 1.2 Plusieurs espaces consécutifs

| | |
|---|---|
| **Input** | `"fichier  avec  doubles  espaces.txt"` |
| **Comportement attendu** | Indexé correctement, 1 ligne, verify OK |
| **Risque** | Parsing par champ fragmente encore plus — potentiellement confondu avec le séparateur `  ` du format b3sum |
| **Testé par** | Non testé — à ajouter en T15b |

### 1.3 Newline dans le nom

| | |
|---|---|
| **Input** | `$'nom\navec\nnewline.txt'` |
| **Comportement attendu** | Indexé correctement (1 fichier = 1 ligne dans `.b3`) |
| **Risque** | `find | wc -l` compte 3 fichiers ; `xargs` sans `-0` éclate le nom ; seuls `find -print0` + `mapfile -d ''` tiennent |
| **Testé par** | T15 (à créer) |
| **Note** | Cas légal sur Linux, illégal sur Windows/macOS |

### 1.4 Tabulation dans le nom

| | |
|---|---|
| **Input** | `$'nom\tavec\ttab.txt'` |
| **Comportement attendu** | Indexé correctement |
| **Risque** | `_b3_to_path_hash` utilise `\t` comme séparateur — une tabulation dans le chemin peut corrompre le parsing |
| **Testé par** | Non testé — **cas critique à ajouter** |
| **Note** | `awk '{ print substr($0,67) "\t" substr($0,1,64) }'` — l'offset fixe 67 protège le hash, mais le chemin est copié tel quel avec sa tabulation |

### 1.5 Caractères HTML dans le nom

| | |
|---|---|
| **Input** | `"<script>alert.txt"`, `"a&b.txt"`, `"page>2.txt"` |
| **Comportement attendu** | Indexé correctement dans `.b3` (pas d'échappement dans le fichier texte) ; échappé dans `report.html` |
| **Risque** | `report.html` affiche `<script>` littéralement → injection HTML dans le rapport |
| **Testé par** | T16 (à créer) |

### 1.6 Fichier commençant par un tiret

| | |
|---|---|
| **Input** | `"-fichier.txt"` |
| **Comportement attendu** | Indexé correctement |
| **Risque** | Certains outils interprètent `-` comme un flag CLI |
| **Testé par** | Non testé — risque faible car `find` et `b3sum` reçoivent le chemin complet |

### 1.7 Nom très long (255 chars, limite ext4)

| | |
|---|---|
| **Input** | Nom de 254 caractères |
| **Comportement attendu** | Indexé correctement |
| **Risque** | Troncature silencieuse dans certains buffers |
| **Testé par** | Non testé — risque faible, `b3sum` gère les noms longs |

### 1.8 Fichier caché (commençant par `.`)

| | |
|---|---|
| **Input** | `".fichier_cache"` |
| **Comportement attendu** | Indexé par `find -type f` (find suit les fichiers cachés par défaut) |
| **Risque** | `ls` ne les montre pas — confusion si on vérifie manuellement le count |
| **Testé par** | Non testé — à ajouter dans fixtures |

---

## Catégorie 2 — Contenu de fichiers

### 2.1 Fichier de taille zéro

| | |
|---|---|
| **Input** | `touch zero.bin` |
| **Comportement attendu** | Indexé (le hash BLAKE3 d'un fichier vide est défini), `bytes_done` non modifié (branche `fsize > 0` protège le calcul ETA) |
| **Risque** | Division par zéro dans le calcul ETA si `bytes_done == total_bytes == 0` |
| **Testé par** | T18 (à créer), CU23 (unitaire) |

### 2.2 Fichier très volumineux (> 4 Go)

| | |
|---|---|
| **Input** | Fichier de 5 Go (nécessite un disque disponible) |
| **Comportement attendu** | Indexé correctement, ETA affichée |
| **Risque** | Overflow integer dans `bytes_done` si bash utilise des entiers 32 bits (bash 4+ utilise 64 bits — OK) |
| **Testé par** | Non testé — difficile en CI (espace disque, temps) |
| **Décision** | Exclus des tests automatiques. Documenté comme supporté (bash 64-bit integers) |

### 2.3 Fichier binaire avec tous les octets possibles

| | |
|---|---|
| **Input** | `printf '%b' '\x00\x01...\xff' > binary.bin` |
| **Comportement attendu** | Indexé correctement, hash stable |
| **Risque** | Traitements texte naïfs sur le contenu du fichier (aucun dans `hash_tool` — `b3sum` opère sur des octets bruts) |
| **Testé par** | Non testé — risque faible |

---

## Catégorie 3 — Structure du dossier

### 3.1 Dossier vide

| | |
|---|---|
| **Input** | `mkdir dossier_vide` sans fichiers |
| **Comportement attendu** | `core_assert_target_valid` lève une erreur "aucun fichier régulier" |
| **Risque** | Base `.b3` vide produite silencieusement, puis `core_assert_b3_valid` rejette la base vide |
| **Testé par** | T09 (existant, partiellement), CU14 (unitaire) |

### 3.2 Dossier avec uniquement des sous-dossiers vides

| | |
|---|---|
| **Input** | `mkdir -p dossier/sub1 dossier/sub2` |
| **Comportement attendu** | Même qu'un dossier vide — erreur "aucun fichier régulier" |
| **Risque** | `find -type f` retourne 0 résultat, `total_files=0`, division par zéro potentielle dans ETA |
| **Testé par** | CU16 (unitaire) |

### 3.3 Arborescence profonde

| | |
|---|---|
| **Input** | `a/b/c/d/e/f/g/h/i/j/fichier.txt` (10 niveaux) |
| **Comportement attendu** | Indexé correctement, chemin complet dans `.b3` |
| **Risque** | Limites de longueur de chemin sur certains OS (PATH_MAX = 4096 sur Linux) |
| **Testé par** | Non testé — risque faible |

### 3.4 Lien symbolique

| | |
|---|---|
| **Input** | `ln -s cible.txt lien.txt` |
| **Comportement attendu** | `find -type f` ignore le lien symbolique par défaut — lien non indexé |
| **Risque** | Comportement non documenté, surprenant pour l'utilisateur qui s'attend à voir le lien indexé |
| **Testé par** | T19 (à créer) |
| **Action** | Documenter le comportement dans `reference/integrity-sh.md` |

### 3.5 Dossier avec un seul fichier

| | |
|---|---|
| **Input** | Un seul fichier dans le dossier |
| **Comportement attendu** | Base de 1 ligne, verify OK |
| **Risque** | Comportement des algorithmes de tri et de comparaison sur des ensembles minimaux |
| **Testé par** | Partiellement par T01 — à vérifier explicitement |

---

## Catégorie 4 — Fichiers `.b3`

### 4.1 Base avec une seule ligne

| | |
|---|---|
| **Input** | `.b3` contenant exactement 1 ligne valide |
| **Comportement attendu** | `core_assert_b3_valid` accepte, `verify` fonctionne |
| **Risque** | `comm`, `join` se comportent différemment sur des fichiers à 1 ligne |
| **Testé par** | Non testé explicitement |

### 4.2 Base avec chemins contenant des espaces

| | |
|---|---|
| **Input** | `.b3` dont les chemins contiennent des espaces |
| **Comportement attendu** | `core_compare` gère correctement (offset fixe 67 dans `awk`) |
| **Risque** | Parsing par champ espace-séparé casse le join — bug historique v0.7 |
| **Testé par** | T08 (existant) + CU42/CU43 (unitaires) |

### 4.3 Base avec caractère tabulation dans un chemin

| | |
|---|---|
| **Input** | Chemin contenant `\t` dans le `.b3` |
| **Comportement attendu** | Comportement à définir — `_b3_to_path_hash` utilise `\t` comme séparateur de conversion |
| **Risque** | Corruption du parsing `chemin\thash` si le chemin contient lui-même un `\t` |
| **Testé par** | Non testé — **bug potentiel non investigué** |
| **Action** | Investiguer, documenter le comportement, ajouter un test ou une contrainte explicite |

### 4.4 Deux bases avec des ordres de tri différents

| | |
|---|---|
| **Input** | `old.b3` trié selon `LC_ALL=fr_FR`, `new.b3` trié selon `LC_ALL=C` |
| **Comportement attendu** | `comm` nécessite que les deux fichiers soient triés selon le même ordre |
| **Risque** | Faux positifs ou faux négatifs dans `compare` si les bases ont été produites avec des locales différentes |
| **Testé par** | Non testé |
| **Décision** | Documenter que `compute` doit être exécuté avec `LC_ALL=C` ou équivalent pour garantir la reproductibilité |

---

## Catégorie 5 — Environnement et configuration

### 5.1 `RESULTATS_DIR` avec espaces dans le chemin

| | |
|---|---|
| **Input** | `export RESULTATS_DIR="/tmp/mon dossier/resultats"` |
| **Comportement attendu** | Dossier créé correctement, résultats écrits |
| **Risque** | `mkdir -p` avec un chemin non quoté |
| **Testé par** | Non testé |

### 5.2 `RESULTATS_DIR` non accessible (permissions)

| | |
|---|---|
| **Input** | `RESULTATS_DIR="/root/resultats"` depuis un utilisateur non-root |
| **Comportement attendu** | `core_make_result_dir` lève une erreur explicite via `die()` |
| **Risque** | Erreur cryptique de `mkdir` sans message d'erreur lisible |
| **Testé par** | Non testé |

### 5.3 Appel depuis un répertoire différent du compute

| | |
|---|---|
| **Input** | `compute` lancé depuis `/mnt/data`, `verify` lancé depuis `/home/user` sans argument `[dossier]` |
| **Comportement attendu** | `b3sum --check` échoue (chemins relatifs résolus depuis mauvais répertoire) |
| **Risque** | Confusion utilisateur — tous les fichiers semblent manquants |
| **Testé par** | T14 (partiellement) |
| **Action** | Ajouter un message d'erreur plus explicite dans ce cas de figure |

---

## Tableau de priorité

| Cas | Priorité | Risque réel | Action |
|---|---|---|---|
| Tabulation dans le nom (1.4) | **Haute** | Bug potentiel confirmé dans `_b3_to_path_hash` | Investiguer + tester |
| Fichier taille zéro (2.1) | Haute | Division par zéro ETA | T18 + CU23 |
| Caractères HTML (1.5) | Haute | Injection dans rapport | T16 |
| Newline dans le nom (1.3) | Haute | Comptage incorrect | T15 |
| Espaces multiples (1.2) | Moyenne | Faux positifs dans compare | T15b |
| Lien symbolique (3.4) | Moyenne | Comportement surprenant non documenté | T19 + doc |
| `RESULTATS_DIR` avec espaces (5.1) | Moyenne | Crash silencieux | Test à créer |
| Fichier très volumineux (2.2) | Faible | Couvert par bash 64-bit integers | Documenté, non testé |


--- Fichier : hors_git/tests/TODO -- tests/fixtures.md ---
# Fixtures — Spécification de `tests/fixtures/`

---

## Définition

Une fixture est un ensemble de données figées dans un état connu, commitées dans le dépôt git, utilisées comme entrée reproductible pour les tests. Contrairement aux données créées dynamiquement dans `setup()`, les fixtures sont stables entre les runs et entre les machines.

---

## Arborescence cible

```
tests/fixtures/
│
├── data/                              ← jeu de données standard (4 fichiers)
│   ├── alpha.txt
│   ├── beta.txt
│   ├── gamma.txt
│   └── sub/
│       └── delta.txt
│
├── data-edge/                         ← jeu de données avec cas limites
│   ├── fichier avec espaces.txt
│   ├── fichier&special.txt
│   ├── <html>chars.txt
│   ├── .fichier_cache
│   └── zero_bytes.bin
│
├── bases/                             ← bases .b3 de référence
│   ├── reference.b3                   ← hash de data/ — non-régression format
│   └── reference-edge.b3             ← hash de data-edge/ — non-régression edge cases
│
└── reports/                           ← structures HTML de référence
    ├── reference-identiques.html      ← rapport compare sans différences
    └── reference-diff.html            ← rapport compare avec 1 modifié
```

---

## Contenu des fichiers de données

### `data/` — Jeu standard

Ces fichiers sont figés. Ne jamais les modifier sans régénérer `bases/reference.b3`.

**`data/alpha.txt`**
```
contenu alpha
```
(terminé par `\n`, encodage UTF-8, pas de BOM)

**`data/beta.txt`**
```
contenu beta
```

**`data/gamma.txt`**
```
contenu gamma
```

**`data/sub/delta.txt`**
```
contenu delta
```

**Propriétés du jeu standard :**
- 4 fichiers dans 2 niveaux d'arborescence
- Noms ASCII simples, pas de caractères spéciaux
- Contenu textuel court et déterministe
- Suffisant pour tester compute, verify, compare sans ambiguïté

---

### `data-edge/` — Jeu de cas limites

Ces fichiers couvrent les noms et contenus pathologiques.

**`data-edge/fichier avec espaces.txt`**
```
contenu avec espaces dans le nom
```
Utilisé par : T15 (intégration), CU42 (unitaire)

**`data-edge/fichier&special.txt`**
```
contenu avec esperluette dans le nom
```
Utilisé par : T16 (HTML escaping), CU43 (unitaire)

**`data-edge/<html>chars.txt`**
```
contenu avec chevrons dans le nom
```
Utilisé par : T16 (injection HTML dans report.html)

**`data-edge/.fichier_cache`**
```
contenu fichier cache
```
Utilisé par : vérification que `find -type f` indexe les fichiers cachés

**`data-edge/zero_bytes.bin`**
Fichier vide — 0 octet. Créé avec `touch`.

Utilisé par : T18 (ETA sur fichier vide), CU23 (unitaire)

---

### `bases/reference.b3`

Hash BLAKE3 de `data/`, produit par `core_compute` depuis `tests/fixtures/`.

**Procédure de génération :**
```bash
cd tests/fixtures
../../src/integrity.sh compute ./data bases/reference.b3
```

**Contenu attendu (hashes exacts à remplir lors de la génération initiale) :**
```
<hash_alpha>  ./data/alpha.txt
<hash_delta>  ./data/sub/delta.txt
<hash_beta>   ./data/beta.txt
<hash_gamma>  ./data/gamma.txt
```

**Invariants vérifiables sans connaître les hashes :**
- 4 lignes
- Triées lexicographiquement : `alpha` < `sub/delta` < `beta` < `gamma`

  **Attention :** l'ordre lexicographique binaire (LC_ALL=C) donne :
  `./data/alpha.txt` < `./data/beta.txt` < `./data/gamma.txt` < `./data/sub/delta.txt`
  
  Le tri est sur le chemin complet, pas juste le nom du fichier. `sub/delta` vient après `gamma` car `s` > `g`.

- Tous les chemins commencent par `./data/`
- Pas de ligne vide, pas de `\r`

---

### `bases/reference-edge.b3`

Hash BLAKE3 de `data-edge/`.

**Procédure de génération :**
```bash
cd tests/fixtures
../../src/integrity.sh compute ./data-edge bases/reference-edge.b3
```

**Usage :** test de non-régression sur les cas limites — vérifie que les noms de fichiers avec espaces, `&`, `<>` sont correctement traités et indexés.

---

### `reports/reference-identiques.html`

Rapport HTML produit par `compare` quand les deux bases sont identiques (aucune différence).

**Procédure de génération :**
```bash
cd tests/fixtures
# Comparer reference.b3 avec lui-même
RESULTATS_DIR=/tmp/fixtures-gen ../../src/integrity.sh compare bases/reference.b3 bases/reference.b3
cp /tmp/fixtures-gen/resultats_reference/report.html reports/reference-identiques.html
```

**Usage :** test de régression HTML — vérifier que le statut "IDENTIQUES" et les compteurs à zéro sont correctement rendus.

**Ce qui est comparé** (pas le fichier entier — la date change) :
```bash
grep -E '(status-badge|stat-value|IDENTIQUES|DIFFÉRENCES)' reports/reference-identiques.html
```

---

### `reports/reference-diff.html`

Rapport HTML produit quand il y a 1 fichier modifié, 1 disparu, 1 nouveau.

**Procédure de génération :**
```bash
cd tests/fixtures

# Créer une base modifiée
cp -r data/ data-modified/
echo "contenu modifié" > data-modified/beta.txt      # modifié
rm data-modified/gamma.txt                           # disparu
echo "contenu nouveau" > data-modified/epsilon.txt   # nouveau

../../src/integrity.sh compute ./data          bases/reference.b3
../../src/integrity.sh compute ./data-modified bases/reference-modified.b3

RESULTATS_DIR=/tmp/fixtures-gen ../../src/integrity.sh compare \
    bases/reference.b3 bases/reference-modified.b3
cp /tmp/fixtures-gen/resultats_reference/report.html reports/reference-diff.html

rm -rf data-modified bases/reference-modified.b3
```

**Usage :** test de régression HTML — vérifier que les listes de fichiers modifiés/disparus/nouveaux sont présentes et correctement formatées.

---

## Règles de nommage

| Règle | Raison |
|---|---|
| Noms de fichiers en minuscules, tirets comme séparateurs | Cohérence, compatibilité cross-platform |
| Pas d'espace dans les noms des fixtures **elles-mêmes** (dossiers, fichiers `.b3`, `.html`) | Les fixtures sont référencées dans les scripts — les espaces cassent les chemins non quotés |
| Les fichiers dans `data-edge/` peuvent avoir des noms avec caractères spéciaux | C'est leur raison d'être |
| Les fichiers `.b3` et `.html` de référence sont commitées dans git | Ils constituent la définition du comportement attendu |

---

## Procédure d'ajout d'une nouvelle fixture

1. **Identifier le besoin** : quel cas limite ou comportement doit être couvert ?
2. **Créer le fichier** dans le sous-dossier approprié (`data/`, `data-edge/`, ou nouveau sous-dossier).
3. **Documenter le fichier** dans ce document : contenu, usage, tests qui s'en servent.
4. **Régénérer les bases `.b3`** si le jeu de données standard ou edge est modifié.
5. **Commiter avec un message explicite** : `test(fixtures): add <nom> for <raison>`

---

## Ce qui ne doit PAS être dans les fixtures

| Type | Raison |
|---|---|
| Données personnelles | Commitées dans git, publiques |
| Fichiers binaires volumineux (> 1 Mo) | Alourdissent le repo sans valeur ajoutée |
| Fichiers `.b3` produits par des versions différentes de b3sum | Invalides sur d'autres machines |
| Résultats de tests (`recap.txt`, `failed.txt`) | Produits dynamiquement, ne doivent pas être fixés |

---

## Vérification de l'intégrité des fixtures elles-mêmes

Les fixtures peuvent être corrompues si un éditeur modifie les fins de ligne (`\r\n` au lieu de `\n`) ou l'encodage. Un meta-test peut vérifier leur intégrité :

```bash
# Vérifier que les fichiers de données sont en format Unix (pas de CRLF)
test_fixtures_unix_format() {
    local has_crlf=0
    while IFS= read -r -d '' f; do
        if file "$f" | grep -q "CRLF"; then
            fail "fixture en CRLF : $f"
            has_crlf=1
        fi
    done < <(find tests/fixtures/data -type f -print0)
    [ "$has_crlf" -eq 0 ] && pass "fixtures au format Unix"
}

# Vérifier que reference.b3 respecte le format b3sum
test_fixtures_reference_format() {
    local invalid
    invalid=$(grep -cvE '^[0-9a-f]{64}  .+' tests/fixtures/bases/reference.b3 || true)
    [ "$invalid" -eq 0 ] \
        && pass "reference.b3 format valide" \
        || fail "reference.b3 : $invalid ligne(s) invalide(s)"
}
```


--- Fichier : hors_git/tests/TODO -- tests/index.md ---
# Tests — Vue d'ensemble

**Scope :** documentation de la stratégie de test de `hash_tool`  
**Statut :** spécification — à implémenter  
**Référence audit :** réponse d'analyse du 24/02/2026

---

## Situation actuelle

| Suite | Fichier | Type | Cas | Statut |
|---|---|---|---|---|
| integrity.sh | `tests/run_tests.sh` | Intégration | T00–T14 | ✅ Existant |
| runner.sh + pipeline | `tests/run_tests_pipeline.sh` | Intégration | TP01–TP12b | ✅ Existant |
| core.sh (unitaires) | `tests/run_tests_core.sh` | Unitaire | — | ❌ À créer |
| Docker + entrypoint | `tests/run_tests_docker.sh` | Environnement | — | ❌ À créer |
| Non-régression .b3 | fixture `tests/fixtures/reference.b3` | Régression | — | ❌ À créer |

**Diagnostic principal :** la pyramide des tests est inversée. Les tests d'intégration sont bien couverts, mais les tests unitaires (`core.sh`) et les tests d'environnement (Docker) sont absents. La CI n'existe pas — les tests ne sont lancés que manuellement.

---

## Suites à créer

### `tests/run_tests_core.sh` — Tests unitaires

Teste chaque fonction de `src/lib/core.sh` en isolation, par sourcing direct, sans passer par `integrity.sh`. Priorité maximale : `core_compare` (algorithme complexe, bug historique en v0.7).

→ Spécification complète : [unit-tests.md](unit-tests.md)

### Extensions de `run_tests.sh` — Edge cases

Ajout des cas T15 à T20+ couvrant les noms de fichiers avec caractères spéciaux, les fichiers vides, les caractères HTML dans les chemins, le mode `--quiet` sur `compare`.

→ Spécification complète : [edge-cases.md](edge-cases.md) et [integration-tests.md](integration-tests.md)

### `tests/fixtures/` — Données de référence

Arborescence de fichiers figés commitée dans git, utilisée pour les tests de non-régression du format `.b3` et les tests de cas limites.

→ Spécification complète : [fixtures.md](fixtures.md) et [regression-tests.md](regression-tests.md)

### `tests/run_tests_docker.sh` — Tests d'environnement

Teste le build Docker, l'entrypoint commande par commande, la taille de l'image, et le comportement multi-plateforme (amd64/arm64).

→ Spécification complète : [docker-tests.md](docker-tests.md)

### CI GitHub Actions

Workflow automatique déclenché à chaque push et PR : jobs unitaires, intégration, Docker, ShellCheck, matrice OS.

→ Spécification complète : [ci-cd.md](ci-cd.md)

---

## Arborescence cible

```
tests/
├── run_tests.sh                   ← existant — intégration integrity.sh (T00–T20+)
├── run_tests_pipeline.sh          ← existant — intégration runner.sh (TP01–TP12b)
├── run_tests_core.sh              ← à créer  — unitaires core.sh
├── run_tests_docker.sh            ← à créer  — environnement Docker
└── fixtures/
    ├── data/
    │   ├── alpha.txt              ← fichier texte standard
    │   ├── beta.txt               ← fichier texte standard
    │   ├── fichier avec espaces.txt
    │   ├── fichier&special.txt
    │   ├── <html>chars.txt
    │   └── zero_bytes.bin         ← fichier de taille zéro
    └── reference.b3               ← hash de référence pour non-régression
```

---

## Ordre d'implémentation recommandé

| Priorité | Livrable | Valeur | Effort |
|---|---|---|---|
| 1 | CI GitHub Actions (squelette minimal) | Détection régression sur PR | ~2h |
| 2 | `run_tests_core.sh` | Isolation des bugs `core.sh` | ~4h |
| 3 | `tests/fixtures/` + non-régression `.b3` | Détection régression silencieuse | ~1h |
| 4 | Edge cases T15–T20 dans `run_tests.sh` | Couverture cas limites | ~2h |
| 5 | `run_tests_docker.sh` | Couverture environnement Docker | ~3h |
| 6 | Format TAP dans toutes les suites | Interopérabilité CI | ~2h |

---

## Règle d'or

> Un test n'a de valeur que s'il est lancé automatiquement à chaque modification.  
> La CI est le seul mécanisme qui garantit cette propriété.  
> Implémenter la CI en premier, avant même d'écrire de nouveaux tests.

---

## Documents de cette section

| Document | Contenu |
|---|---|
| [strategy.md](strategy.md) | Décisions, objectifs de couverture, définition de "done" |
| [unit-tests.md](unit-tests.md) | Spécification `run_tests_core.sh` |
| [integration-tests.md](integration-tests.md) | Extensions `run_tests.sh` et `run_tests_pipeline.sh` |
| [regression-tests.md](regression-tests.md) | Non-régression format `.b3`, fixtures statiques |
| [edge-cases.md](edge-cases.md) | Catalogue des cas limites |
| [docker-tests.md](docker-tests.md) | Spécification `run_tests_docker.sh` |
| [fixtures.md](fixtures.md) | Spécification `tests/fixtures/` |
| [tap-format.md](tap-format.md) | Format TAP, helpers bash |
| [ci-cd.md](ci-cd.md) | Workflow GitHub Actions |


--- Fichier : hors_git/tests/TODO -- tests/integration-tests.md ---
# Tests d'intégration — Extensions des suites existantes

---

## Périmètre

Ce document spécifie les cas à ajouter aux suites d'intégration existantes :
- `run_tests.sh` : cas T15 à T20 (extensions de la suite integrity.sh)
- `run_tests_pipeline.sh` : cas TP13 à TP15 (extensions de la suite runner.sh)

Les cas existants T00–T14 et TP01–TP12b ne sont pas modifiés.

---

## Extensions de `run_tests.sh`

### T15 — Fichier avec newline dans le nom

**Motivation :** les noms de fichiers Linux peuvent légalement contenir des newlines. `find | wc -l` ou `xargs` sans `-0` cassent sur ce cas. `mapfile -d ''` et `find -print0` sont censés tenir — ce test le vérifie.

**Précondition :**
```bash
printf "contenu\n" > "$WORKDIR/data/$'nom\navec\nnewline.txt'"
bash "$INTEGRITY" compute ./data base_t15.b3
```

**Assertions :**
- `base_t15.b3` contient exactement autant de lignes que de fichiers dans `./data` (le fichier avec newline compte pour 1)
- `bash "$INTEGRITY" verify base_t15.b3` → exit 0, aucun FAILED

**Oracle :** si le test échoue, `mapfile -d ''` ou `sort -z` ne gèrent pas correctement les newlines dans les noms — le fichier est compté plusieurs fois ou ignoré.

---

### T16 — Caractères HTML dans les noms de fichiers

**Motivation :** `report.html` est généré via `generate_compare_html`. La fonction `html_escape` est censée protéger contre l'injection HTML. Ce test vérifie que les caractères `<`, `>`, `&` dans les noms de fichiers sont bien échappés dans le rapport.

**Précondition :**
```bash
echo "v1" > "$WORKDIR/data_old/<script>alert.txt"
echo "v1" > "$WORKDIR/data_old/a&b.txt"
echo "v2" > "$WORKDIR/data_new/<script>alert.txt"   # modifié
echo "v1" > "$WORKDIR/data_new/a&b.txt"             # inchangé
bash "$INTEGRITY" compute ./data_old base_t16_old.b3
bash "$INTEGRITY" compute ./data_new base_t16_new.b3
bash "$INTEGRITY" compare base_t16_old.b3 base_t16_new.b3
```

**Assertions sur `report.html` :**
- Ne contient PAS la chaîne `<script>` littérale (serait une injection)
- Contient `&lt;script&gt;` (échappement correct)
- Contient `&amp;` pour le `&` de `a&b.txt`
- Est un HTML valide (balises ouvertes = balises fermées, au minimum)

**Oracle :** si `<script>` apparaît littéralement dans le HTML, `html_escape` ne fonctionne pas et le rapport est vulnérable à l'injection.

```bash
# Assertions spécifiques
local html_content
html_content=$(cat "$outdir/report.html")
assert_not_contains "T16 pas de <script> brut"   "<script>"      "$html_content"
assert_contains     "T16 échappement lt/gt"       "&lt;script&gt;" "$html_content"
assert_contains     "T16 échappement esperluette" "&amp;"          "$html_content"
```

---

### T17 — `--quiet` sur `compare`

**Motivation :** T12 couvre `--quiet` sur `verify` et `compute` mais pas sur `compare`. Le mode `--quiet` doit aussi supprimer la sortie de `compare`.

**Précondition :**
```bash
bash "$INTEGRITY" compute ./data base_t17a.b3
echo "contenu modifié" > data/alpha.txt
bash "$INTEGRITY" compute ./data base_t17b.b3
```

**Assertions :**
- `bash "$INTEGRITY" --quiet compare base_t17a.b3 base_t17b.b3` → stdout vide
- Les fichiers de résultats sont quand même produits (`recap.txt`, `modifies.b3`, `report.html`)
- Exit code = 0 (compare ne lève pas d'erreur sur les différences)

```bash
local out_quiet
out_quiet=$(bash "$INTEGRITY" --quiet compare base_t17a.b3 base_t17b.b3 2>&1)
assert_not_contains "T17 stdout vide en quiet"      "Résultats"  "$out_quiet"
assert_not_contains "T17 stdout vide en quiet"      "modifiés"   "$out_quiet"
local outdir
outdir=$(ls -d "${RESULTATS_DIR}/resultats_base_t17a"* 2>/dev/null | tail -1)
assert_file_exists  "T17 recap.txt produit"         "${outdir}/recap.txt"
assert_file_exists  "T17 report.html produit"       "${outdir}/report.html"
```

---

### T18 — Fichier de taille zéro dans compute

**Motivation :** dans `core_compute`, la branche `if (( fsize > 0 ))` protège le calcul ETA quand `fsize == 0`. Ce test vérifie que la présence d'un fichier vide ne plante pas le calcul et que le fichier est quand même indexé.

**Précondition :**
```bash
echo "contenu" > data/normal.txt
touch data/zero.bin    # taille zéro
bash "$INTEGRITY" compute ./data base_t18.b3
```

**Assertions :**
- `base_t18.b3` contient exactement 2 lignes
- La ligne pour `zero.bin` est au format b3sum valide (hash de contenu vide)
- `bash "$INTEGRITY" verify base_t18.b3` → exit 0

**Note :** le hash BLAKE3 d'un fichier vide est déterministe et connu — il peut être utilisé comme assertion dure si nécessaire.

---

### T19 — Lien symbolique dans le dossier source

**Motivation :** le comportement de `find -type f` sur les liens symboliques dépend de la version de `find` et des flags. Par défaut, `find -type f` ne suit pas les liens symboliques — ils sont ignorés. Ce comportement doit être documenté et vérifié.

**Précondition :**
```bash
echo "contenu cible" > data/cible.txt
ln -s data/cible.txt data/lien.txt    # lien symbolique
bash "$INTEGRITY" compute ./data base_t19.b3
```

**Assertions :**
- `base_t19.b3` contient exactement 1 ligne (le lien symbolique est ignoré par `find -type f`)
- La ligne présente correspond à `cible.txt`, pas à `lien.txt`

**Si le comportement attendu change** (décision de suivre les liens) : adapter ce test et documenter la décision dans `architecture.md`.

---

### T20 — Horodatage : deux compare successifs sur la même base

**Motivation :** T13 vérifie l'anti-écrasement pour `verify`. Ce test vérifie le même comportement pour `compare`.

**Précondition :**
```bash
bash "$INTEGRITY" compute ./data base_t20.b3
bash "$INTEGRITY" compare base_t20.b3 base_t20.b3   # compare une base avec elle-même
sleep 1
bash "$INTEGRITY" compare base_t20.b3 base_t20.b3
```

**Assertions :**
- Deux dossiers distincts existent sous `$RESULTATS_DIR` : `resultats_base_t20` et `resultats_base_t20_YYYYMMDD-HHMMSS`

```bash
local nb
nb=$(ls -d "${RESULTATS_DIR}/resultats_base_t20"* 2>/dev/null | wc -l)
[ "$nb" -ge 2 ] && pass "T20 deux dossiers distincts" || fail "T20 écrasement détecté ($nb dossier(s))"
```

---

## Extensions de `run_tests_pipeline.sh`

### TP13 — Pipeline avec verify qui échoue : les blocs suivants ne s'exécutent pas

**Motivation :** `runner.sh` utilise `set -euo pipefail`. Un `verify` qui échoue doit stopper le pipeline immédiatement. Ce comportement n'est pas explicitement testé.

**Précondition :**
```json
{
    "pipeline": [
        { "op": "compute", "source": "$WORKDIR/src_a", "bases": "$WORKDIR/bases", "nom": "tp13.b3" },
        { "op": "verify",  "source": "$WORKDIR/src_a_corrupt", "base": "$WORKDIR/bases/tp13.b3" },
        { "op": "compute", "source": "$WORKDIR/src_b", "bases": "$WORKDIR/bases", "nom": "tp13_b.b3" }
    ]
}
```

Avec `src_a_corrupt` contenant un fichier modifié par rapport à la base.

**Assertions :**
- Exit code du runner ≠ 0
- `tp13_b.b3` n'existe pas (le troisième bloc ne s'est pas exécuté)

---

### TP14 — Champ `nom` avec sous-dossier dans `bases`

**Motivation :** le champ `nom` est concaténé à `bases` via `"$bases_abs/$nom"`. Si `nom` contient un `/`, le comportement doit être défini.

**Cas testé :** `"nom": "sous/hashes.b3"`

**Assertions :**
- Le dossier `$WORKDIR/bases/sous/` est créé automatiquement (via le `mkdir -p` dans `run_compute`)
- `hashes.b3` est créé dans ce sous-dossier
- OU : erreur explicite si les sous-dossiers dans `nom` ne sont pas supportés (dans ce cas, documenter la limite)

---

### TP15 — Pipeline vide (tableau pipeline avec zéro opérations)

**Motivation :** le cas `"pipeline": []` doit être rejeté proprement.

```json
{ "pipeline": [] }
```

**Assertions :**
- Exit code ≠ 0
- Message d'erreur contient "vide" ou "absent"
- Aucun effet de bord (aucun fichier créé)

---

## Tableau de synthèse

| ID | Suite | Motivation principale | Risque si absent |
|---|---|---|---|
| T15 | run_tests.sh | Newlines dans noms | Crash silencieux sur fichiers exotiques |
| T16 | run_tests.sh | Injection HTML dans report.html | Rapport corrompu ou vulnérable |
| T17 | run_tests.sh | `--quiet` sur compare | Mode silencieux partiellement cassé |
| T18 | run_tests.sh | Fichier taille zéro | Crash ETA ou fichier non indexé |
| T19 | run_tests.sh | Liens symboliques | Comportement non documenté et non garanti |
| T20 | run_tests.sh | Anti-écrasement sur compare | Résultats précédents écrasés silencieusement |
| TP13 | run_tests_pipeline.sh | Arrêt sur verify échoué | Pipeline continue après corruption détectée |
| TP14 | run_tests_pipeline.sh | `nom` avec sous-dossier | Comportement indéfini, potentiel crash |
| TP15 | run_tests_pipeline.sh | Pipeline vide | Message d'erreur absent ou cryptique |


--- Fichier : hors_git/tests/TODO -- tests/regression-tests.md ---
# Tests de non-régression — Format `.b3` et fixtures statiques

---

## Principe

Un test de non-régression capture un comportement connu et correct, le fige comme référence, puis vérifie à chaque modification que ce comportement est inchangé.

Pour `hash_tool`, le comportement le plus critique à figer est le **format du fichier `.b3`** produit par `core_compute`. Toute modification — même accidentelle — du format de sortie invalide toutes les bases existantes des utilisateurs.

---

## Risques couverts

| Modification silencieuse | Impact utilisateur |
|---|---|
| Changement du séparateur (1 espace au lieu de 2) | Toutes les bases existantes invalides pour `b3sum --check` |
| Changement de l'ordre de tri (locale différente) | `compare` produit des faux positifs massifs |
| Ajout d'un préfixe ou suffixe dans les chemins | `verify` échoue sur toutes les bases existantes |
| Ligne vide en fin de fichier | `core_assert_b3_valid` rejette les bases existantes |
| Retour chariot `\r` introduit | `b3sum --check` échoue sur certains OS |
| Mise à jour de `b3sum` changeant le format de sortie | Rupture totale de compatibilité |

---

## Structure des fixtures

```
tests/fixtures/
├── data/
│   ├── alpha.txt          ← "contenu alpha\n"
│   ├── beta.txt           ← "contenu beta\n"
│   ├── gamma.txt          ← "contenu gamma\n"
│   └── sub/
│       └── delta.txt      ← "contenu delta\n"
└── reference.b3           ← produit par core_compute sur ./data, commité dans git
```

Le contenu de chaque fichier est **figé et documenté**. Ne jamais modifier les fichiers dans `tests/fixtures/data/` sans régénérer `reference.b3` et expliquer le changement dans la PR.

---

## Génération initiale de `reference.b3`

À faire une seule fois, sur une machine avec `b3sum` installé :

```bash
cd tests/fixtures

# Créer les fichiers de données
mkdir -p data/sub
printf "contenu alpha\n" > data/alpha.txt
printf "contenu beta\n"  > data/beta.txt
printf "contenu gamma\n" > data/gamma.txt
printf "contenu delta\n" > data/sub/delta.txt

# Générer la référence via core_compute
# (utiliser integrity.sh pour garantir le même chemin de code)
../../src/integrity.sh compute ./data reference.b3

# Vérifier le contenu
cat reference.b3
# Attendu : 4 lignes, chemins commençant par ./data/, triées, format b3sum

# Commiter
git add data/ reference.b3
git commit -m "test(fixtures): add reference.b3 for format regression tests"
```

---

## Test de non-régression — implémentation

Ce test est à ajouter dans `run_tests.sh` comme cas **T_REG01** (ou dans une section dédiée) :

```bash
echo "T_REG - Non-régression format .b3"

FIXTURES_DIR="$SCRIPT_DIR/fixtures"

# Vérifier que les fixtures existent
[ -d "$FIXTURES_DIR/data" ] || { echo "SKIP - fixtures absentes"; return; }
[ -f "$FIXTURES_DIR/reference.b3" ] || { echo "SKIP - reference.b3 absent"; return; }

# Compute sur les fixtures
( cd "$FIXTURES_DIR" && bash "$INTEGRITY" compute ./data "$WORKDIR/output_reg.b3" >/dev/null 2>&1 )

# Comparaison bit-à-bit
if diff "$FIXTURES_DIR/reference.b3" "$WORKDIR/output_reg.b3" >/dev/null 2>&1; then
    pass "T_REG01 format .b3 stable"
else
    fail "T_REG01 régression du format .b3 détectée"
    echo "  Diff :"
    diff "$FIXTURES_DIR/reference.b3" "$WORKDIR/output_reg.b3" | head -20
fi
```

---

## Contenu attendu de `reference.b3`

Exemple de contenu attendu (les hashes réels dépendent du contenu exact des fichiers) :

```
<hash_alpha_64chars>  ./data/alpha.txt
<hash_delta_64chars>  ./data/sub/delta.txt
<hash_beta_64chars>   ./data/beta.txt
<hash_gamma_64chars>  ./data/gamma.txt
```

**Invariants vérifiables sans connaître les hashes :**
- 4 lignes exactement
- Chaque ligne : 64 chars hex + `  ` (2 espaces) + chemin
- Chemins triés lexicographiquement (`alpha` < `sub/delta` car `a` < `s`)
- Pas de ligne vide
- Pas de `\r` (format Unix)
- Tous les chemins commencent par `./data/`

Ces invariants peuvent être testés indépendamment du contenu des hashes :

```bash
# Test des invariants structurels (sans dépendre de reference.b3)
local b3="$WORKDIR/output_reg.b3"

# Nombre de lignes
assert_line_count "T_REG02 4 fichiers indexés" 4 "$b3"

# Format de chaque ligne
local invalid_lines
invalid_lines=$(grep -cvE '^[0-9a-f]{64}  .+' "$b3" || true)
[ "$invalid_lines" -eq 0 ] && pass "T_REG03 format b3sum valide" || fail "T_REG03 $invalid_lines ligne(s) invalide(s)"

# Pas de retour chariot
assert_not_contains "T_REG04 pas de CRLF" $'\r' "$(cat "$b3")"

# Chemins relatifs
assert_not_contains "T_REG05 pas de chemin absolu" "$(pwd)" "$(cat "$b3")"

# Tri correct
local sorted_check
sorted_check=$(sort "$b3")
[ "$(cat "$b3")" = "$sorted_check" ] && pass "T_REG06 trié" || fail "T_REG06 non trié"
```

---

## Procédure de mise à jour de `reference.b3`

Quand une modification intentionnelle du comportement change le format de sortie :

### Étape 1 — Vérifier que le changement est délibéré

Le test `T_REG01` échoue. Avant toute mise à jour, répondre aux questions :
- Pourquoi le format a-t-il changé ?
- Est-ce documenté dans `CHANGELOG.md` ?
- Les bases `.b3` existantes des utilisateurs sont-elles impactées ?
- Faut-il fournir un outil de migration ?

### Étape 2 — Régénérer

```bash
cd tests/fixtures
../../src/integrity.sh compute ./data reference.b3
```

### Étape 3 — Valider manuellement

```bash
# Vérifier que le nouveau reference.b3 respecte les invariants
wc -l reference.b3                                  # doit afficher 4
grep -cE '^[0-9a-f]{64}  .+' reference.b3          # doit afficher 4
grep -c $'\r' reference.b3 || true                  # doit afficher 0
```

### Étape 4 — Commiter avec un message explicite

```bash
git add reference.b3
git commit -m "fix(fixtures): update reference.b3 — [raison du changement]"
```

### Étape 5 — Le diff dans la PR est un signal de revue obligatoire

Tout reviewer doit inspecter le diff de `reference.b3`. Un diff non expliqué dans le message de commit est un signal d'alerte.

---

## Fixtures supplémentaires pour les tests de régression HTML

Le rapport `report.html` est aussi sujet à régression. Une fixture statique peut capturer la structure HTML attendue :

```
tests/fixtures/
└── reports/
    └── reference_compare_empty.html    ← rapport quand modifies/disparus/nouveaux sont tous vides
    └── reference_compare_diff.html     ← rapport avec 1 modifié, 1 disparu, 1 nouveau
```

Ces fixtures sont plus difficiles à maintenir (le CSS change, la date change). La solution est de comparer uniquement les **parties structurelles** :

```bash
# Extraire et comparer uniquement le statut et les compteurs, pas le CSS ni la date
grep -E '(status-badge|stat-value|section-count)' report.html > /tmp/report_structure.txt
diff tests/fixtures/reports/reference_structure.txt /tmp/report_structure.txt
```


--- Fichier : hors_git/tests/TODO -- tests/strategy.md ---
# Stratégie de test — Décisions et objectifs

---

## Contexte

`hash_tool` est un outil de vérification d'intégrité. Une erreur non détectée dans sa logique de comparaison ou de vérification peut conduire à un faux négatif : une corruption de données passant inaperçue. Le niveau d'exigence sur la fiabilité du code est donc élevé, même si l'outil n'opère pas dans un contexte adversarial.

---

## Objectifs de couverture

### Par module

| Module | Type de test requis | Couverture cible |
|---|---|---|
| `src/lib/core.sh` | Unitaire | 100% des fonctions publiques, toutes les branches |
| `src/lib/ui.sh` | Intégration (via integrity.sh) | Chemins nominaux + mode `--quiet` |
| `src/lib/results.sh` | Intégration (via integrity.sh) | Fichiers produits, contenu, cas absent |
| `src/lib/report.sh` | Intégration + edge cases HTML | Échappement, cas vide, cas plein |
| `src/integrity.sh` | Intégration | T00–T20+, tous les modes |
| `runner.sh` | Intégration | TP01–TP12b+, tous les champs JSON |
| `docker/entrypoint.sh` | Environnement | Toutes les commandes, cas d'erreur |
| `Dockerfile` | Build | amd64, arm64, taille image |

### Par type de test

| Type | Suite | Objectif |
|---|---|---|
| Unitaire | `run_tests_core.sh` | Localiser précisément l'origine d'un bug |
| Intégration | `run_tests.sh`, `run_tests_pipeline.sh` | Valider les interfaces entre modules |
| Non-régression | fixture `reference.b3` + diff | Détecter les régressions silencieuses de format |
| Edge cases | T15–T20+ dans `run_tests.sh` | Garantir la robustesse sur les entrées limites |
| Environnement | `run_tests_docker.sh` | Valider l'image Docker et l'entrypoint |

---

## Définition de "done" pour un test

Un test est considéré complet quand :

1. **Il a un nom explicite** décrivant la condition testée et le résultat attendu.  
   Exemple : `test_compare_chemins_avec_esperluette_dans_modifies_b3`

2. **Il est isolé** : il ne dépend d'aucun autre test, d'aucun fichier extérieur au `WORKDIR`, d'aucune variable globale non initialisée localement.

3. **Il est reproductible** : relancé 10 fois dans 10 environnements différents, il donne le même résultat.

4. **Il documente l'oracle** : le commentaire ou le nom du test indique ce qui est vérifié et pourquoi c'est le bon résultat attendu.

5. **Il nettoie après lui** : tout fichier temporaire créé est supprimé, même en cas d'échec (via `trap EXIT`).

6. **Il passe ShellCheck** sans warning.

---

## Politique ShellCheck

ShellCheck zéro warning est une condition bloquante. Aucune PR ne peut merger si ShellCheck produit un warning sur les fichiers suivants :

```
src/integrity.sh
runner.sh
src/lib/core.sh
src/lib/ui.sh
src/lib/results.sh
src/lib/report.sh
docker/entrypoint.sh
tests/run_tests.sh
tests/run_tests_pipeline.sh
tests/run_tests_core.sh        ← nouveau
tests/run_tests_docker.sh      ← nouveau
```

Commande de vérification :
```bash
shellcheck src/integrity.sh runner.sh src/lib/*.sh docker/entrypoint.sh tests/*.sh
```

---

## Règles d'écriture des tests

### Isolation

```bash
# ✓ Correct : WORKDIR isolé par test ou par suite
local WORKDIR
WORKDIR=$(mktemp -d /tmp/integrity-test.XXXXXX)
trap "rm -rf '$WORKDIR'" EXIT
```

```bash
# ✓ Correct : cd isolé dans un sous-shell
( cd "$WORKDIR" && bash "$INTEGRITY" compute . base.b3 )
```

```bash
# ❌ Interdit : cd sans sous-shell
cd "$WORKDIR"
bash "$INTEGRITY" compute . base.b3
# Le répertoire courant fuit vers les tests suivants
```

### Variables d'environnement

```bash
# ✓ Correct : RESULTATS_DIR local à la suite
export RESULTATS_DIR="$WORKDIR/resultats"

# ❌ Interdit : RESULTATS_DIR global non réinitialisé entre les suites
```

### Assertions

Toute assertion doit produire un message explicite en cas d'échec :

```bash
# ✓ Correct
assert_contains "modifies.b3 contient beta.txt" "beta.txt" "$(cat modifies.b3)"

# ❌ Insuffisant
[ -s modifies.b3 ] && pass "ok" || fail "ko"
# → en cas d'échec, impossible de savoir ce qui était attendu
```

### Nettoyage garanti

```bash
# Pattern obligatoire pour tout fichier temporaire
local tmpfile
tmpfile=$(mktemp)
trap "rm -f '$tmpfile'" EXIT
# ... utilisation de tmpfile ...
# Pas besoin de rm explicite — le trap s'en charge
```

---

## Politique de mise à jour des fixtures

Quand un test de non-régression échoue suite à une modification intentionnelle du comportement :

1. Vérifier que la modification est délibérée et documentée dans `CHANGELOG.md`.
2. Regénérer la fixture : `cd tests/fixtures && ../../src/integrity.sh compute ./data reference.b3`
3. Commiter `reference.b3` avec un message explicite : `fix(fixtures): update reference.b3 after sort order change in core_compute`
4. Le diff de `reference.b3` dans la PR est un signal de revue — tout reviewer doit l'examiner.

---

## Politique de mise à jour des suites existantes

À chaque bug corrigé dans le code, un test de non-régression couvrant ce bug doit être ajouté **dans la même PR**. Référence : le changelog documente trois bugs qui auraient été détectés plus tôt avec des tests unitaires (v0.6 : `grep -c '.'`, `sort -k2` ; v0.7 : parsing `awk $2` sur chemins avec espaces).

---

## Ce qui n'est pas testé — limites acceptées

| Scénario | Raison de l'exclusion |
|---|---|
| Performances / temps d'exécution | Trop dépendant du matériel, faux positifs en CI |
| Comportement sur systèmes de fichiers exotiques (NTFS, exFAT) | Environnement CI Linux uniquement |
| Internationalisation (noms de fichiers non UTF-8) | Comportement documenté comme "octets opaques", hors scope |
| Comportement sur bash 3.x (macOS défaut) | Rejeté explicitement par `integrity.sh` au démarrage |
| Concurrence / appels parallèles | `hash_tool` est mono-processus par conception |


--- Fichier : hors_git/tests/TODO -- tests/tap-format.md ---
# Format TAP — Spécification et implémentation

---

## Qu'est-ce que TAP ?

TAP (Test Anything Protocol) est un format texte standard pour les résultats de tests. Créé en 1987 pour Perl, il est aujourd'hui supporté par la quasi-totalité des systèmes CI et des outils de test multi-langages.

**Avantage principal :** TAP est lisible par un humain ET parseable par une machine sans configuration supplémentaire. GitHub Actions, GitLab CI, Jenkins et des dizaines d'autres outils savent afficher des rapports visuels à partir de TAP.

---

## Format TAP 14 — Syntaxe

```
TAP version 14
1..N
ok 1 - description du test
not ok 2 - description du test échoué
# commentaire ou diagnostic (ignoré par les parseurs)
ok 3 - description
not ok 4 - test avec diagnostic
  ---
  message: valeur attendue
  found: valeur obtenue
  ...
```

### Règles

| Élément | Syntaxe | Obligatoire |
|---|---|---|
| Déclaration de version | `TAP version 14` | Recommandé, première ligne |
| Plan | `1..N` (N = nombre total de tests) | Oui — doit apparaître avant ou après les tests |
| Test réussi | `ok N - description` | — |
| Test échoué | `not ok N - description` | — |
| Diagnostic | `# texte libre` | Non |
| YAML block (détail d'échec) | `  ---\n  clé: valeur\n  ...` | Non |
| Test ignoré | `ok N - description # SKIP raison` | Non |
| Test attendu en échec | `not ok N - description # TODO raison` | Non |

---

## Implémentation dans les suites bash

### Helpers à inclure dans chaque suite

```bash
#!/usr/bin/env bash
# helpers-tap.sh — à sourcer dans chaque suite de tests
# Usage : source helpers-tap.sh

TAP_TOTAL=0
TAP_PASS=0
TAP_FAIL=0
TAP_TESTS=()   # tableau des résultats pour le plan final

# Déclare le plan en tête (si le nombre est connu à l'avance)
# Usage : tap_plan 42
tap_plan() {
    echo "TAP version 14"
    echo "1..$1"
}

# Enregistre un succès
# Usage : tap_ok "description du test"
tap_ok() {
    TAP_TOTAL=$(( TAP_TOTAL + 1 ))
    TAP_PASS=$(( TAP_PASS + 1 ))
    printf "ok %d - %s\n" "$TAP_TOTAL" "$1"
}

# Enregistre un échec avec diagnostic optionnel
# Usage : tap_not_ok "description" ["message de diagnostic"]
tap_not_ok() {
    TAP_TOTAL=$(( TAP_TOTAL + 1 ))
    TAP_FAIL=$(( TAP_FAIL + 1 ))
    printf "not ok %d - %s\n" "$TAP_TOTAL" "$1"
    if [ -n "${2:-}" ]; then
        printf "  ---\n  message: %s\n  ...\n" "$2"
    fi
}

# Skip un test avec raison
# Usage : tap_skip "description" "raison du skip"
tap_skip() {
    TAP_TOTAL=$(( TAP_TOTAL + 1 ))
    printf "ok %d - %s # SKIP %s\n" "$TAP_TOTAL" "$1" "$2"
}

# Affiche le résumé final (quand le plan n'est pas connu à l'avance)
tap_summary() {
    echo "1..$TAP_TOTAL"
    echo "# Tests : $TAP_TOTAL | Passés : $TAP_PASS | Échecs : $TAP_FAIL"
}

# Assertions de haut niveau construites sur tap_ok/tap_not_ok

# assert_exit_zero <label> <commande...>
assert_exit_zero() {
    local label="$1"; shift
    if "$@" >/dev/null 2>&1; then
        tap_ok "$label"
    else
        tap_not_ok "$label" "commande a retourné exit non-zéro : $*"
    fi
}

# assert_exit_nonzero <label> <commande...>
assert_exit_nonzero() {
    local label="$1"; shift
    if ! "$@" >/dev/null 2>&1; then
        tap_ok "$label"
    else
        tap_not_ok "$label" "commande aurait dû échouer : $*"
    fi
}

# assert_contains <label> <pattern> <chaine>
assert_contains() {
    local label="$1" pattern="$2" string="$3"
    if echo "$string" | grep -q "$pattern"; then
        tap_ok "$label"
    else
        tap_not_ok "$label" "pattern '$pattern' absent dans : $(echo "$string" | head -3)"
    fi
}

# assert_not_contains <label> <pattern> <chaine>
assert_not_contains() {
    local label="$1" pattern="$2" string="$3"
    if ! echo "$string" | grep -q "$pattern"; then
        tap_ok "$label"
    else
        tap_not_ok "$label" "pattern '$pattern' présent à tort dans : $(echo "$string" | head -3)"
    fi
}

# assert_file_exists <label> <fichier>
assert_file_exists() {
    local label="$1" file="$2"
    if [ -f "$file" ]; then
        tap_ok "$label"
    else
        tap_not_ok "$label" "fichier absent : $file"
    fi
}

# assert_file_absent <label> <fichier>
assert_file_absent() {
    local label="$1" file="$2"
    if [ ! -f "$file" ]; then
        tap_ok "$label"
    else
        tap_not_ok "$label" "fichier présent à tort : $file"
    fi
}

# assert_line_count <label> <expected> <fichier>
assert_line_count() {
    local label="$1" expected="$2" file="$3"
    local actual
    actual=$(wc -l < "$file")
    if [ "$actual" -eq "$expected" ]; then
        tap_ok "$label"
    else
        tap_not_ok "$label" "attendu $expected lignes, obtenu $actual"
    fi
}

# assert_eq <label> <expected> <actual>
assert_eq() {
    local label="$1" expected="$2" actual="$3"
    if [ "$expected" = "$actual" ]; then
        tap_ok "$label"
    else
        tap_not_ok "$label" "attendu '$expected', obtenu '$actual'"
    fi
}
```

---

## Exemple de sortie TAP pour `run_tests_core.sh`

```
TAP version 14
1..53
ok 1 - CU01 fichier absent → exit 1
ok 2 - CU02 chemin est un dossier → exit 1
ok 3 - CU03 fichier vide → exit 1
ok 4 - CU04 format invalide → exit 1
ok 5 - CU05 hash trop court → exit 1
ok 6 - CU06 hash trop long → exit 1
ok 7 - CU07 hash avec majuscules → exit 1
ok 8 - CU08 ligne valide unique → exit 0
ok 9 - CU09 plusieurs lignes valides → exit 0
not ok 10 - CU10 mélange valide/invalide → exit 1
  ---
  message: attendu exit 1, obtenu 0
  ...
ok 11 - CU11 label dans message d'erreur
# T_CORE02 - core_assert_target_valid
ok 12 - CU12 dossier absent → exit 1
...
```

---

## Intégration avec GitHub Actions

GitHub Actions ne parse pas TAP nativement, mais plusieurs actions le font :

### Option 1 — `dorny/test-reporter`

```yaml
- name: Run tests (TAP output)
  run: cd tests && ./run_tests_core.sh > /tmp/core-results.tap || true

- name: Publish test results
  uses: dorny/test-reporter@v1
  if: always()
  with:
    name: Unit Tests
    path: /tmp/core-results.tap
    reporter: tap
```

### Option 2 — Conversion TAP → JUnit XML (plus universelle)

```bash
# Installer tap-junit
npm install -g tap-junit

# Dans la CI
cd tests && ./run_tests_core.sh | tap-junit --name "core" > /tmp/core-junit.xml
```

```yaml
- uses: mikepenz/action-junit-report@v4
  with:
    report_paths: /tmp/*-junit.xml
```

### Option 3 — Sortie colorée en terminal, TAP en CI

Détecter si on est en CI et adapter le format :

```bash
# En tête de chaque suite
if [ -n "${CI:-}" ]; then
    # Format TAP pour la CI
    tap_ok()     { printf "ok %d - %s\n"     "$((++TAP_TOTAL))" "$1"; }
    tap_not_ok() { printf "not ok %d - %s\n" "$((++TAP_TOTAL))" "$1"; TAP_FAIL=$((TAP_FAIL+1)); }
else
    # Format coloré pour le terminal local
    GREEN='\033[0;32m'; RED='\033[0;31m'; NC='\033[0m'
    tap_ok()     { echo -e "${GREEN}  PASS${NC} - $1"; }
    tap_not_ok() { echo -e "${RED}  FAIL${NC} - $1"; TAP_FAIL=$((TAP_FAIL+1)); }
fi
```

---

## Stratégie de migration des suites existantes

Les suites `run_tests.sh` et `run_tests_pipeline.sh` utilisent actuellement des helpers `pass()`/`fail()` avec sortie colorée. La migration vers TAP se fait en deux étapes :

### Étape 1 — Compatibilité ascendante

Remplacer les helpers existants par les helpers TAP tout en conservant la sortie colorée en mode terminal. Seul le format change en CI (`CI` est défini automatiquement dans GitHub Actions).

Avant :
```bash
PASS=0; FAIL=0; TOTAL=0
pass() { echo -e "${GREEN}  PASS${NC} - $1"; ((PASS++)); ((TOTAL++)); }
fail() { echo -e "${RED}  FAIL${NC} - $1"; ((FAIL++)); ((TOTAL++)); }
```

Après (compatible backward + TAP en CI) :
```bash
source "$(dirname "$0")/helpers-tap.sh"
```

### Étape 2 — Extraction dans `tests/helpers-tap.sh`

Extraire les helpers dans un fichier commun sourcé par toutes les suites. Avantage : un seul endroit à maintenir.

```
tests/
├── helpers-tap.sh             ← helpers communs (nouveau)
├── run_tests.sh               ← source helpers-tap.sh
├── run_tests_pipeline.sh      ← source helpers-tap.sh
├── run_tests_core.sh          ← source helpers-tap.sh
└── run_tests_docker.sh        ← source helpers-tap.sh
```

---

## Plan pour `run_tests_core.sh`

Si le nombre total de tests est connu à l'avance (53 cas dans la spécification `unit-tests.md`), utiliser un plan en tête :

```bash
echo "TAP version 14"
echo "1..53"
```

Si le nombre évolue fréquemment (développement actif), utiliser un plan en queue :

```bash
# ... tous les tests ...
tap_summary   # affiche "1..N" en fin de fichier
```

TAP 14 supporte les deux positions pour le plan.


--- Fichier : hors_git/tests/TODO -- tests/test docker.md ---
Non, pas vraiment. Voici ce qui existe et ce qui manque :

**Ce qui existe :** zéro test Docker dans les suites actuelles. `entrypoint.sh` n'est jamais testé automatiquement. Le Dockerfile n'est jamais buildé en CI. La seule "vérification" Docker est manuelle : `docker run --rm hash_tool version` que l'utilisateur peut faire à la main.

**Ce qui manque concrètement :**

*Tests de build :*
- Que le `docker build` réussit (pas d'erreur de syntaxe Dockerfile, pas de package Alpine introuvable, `b3sum` bien installé)
- Que l'image produite fait bien ~14 Mo et pas 500 Mo (régression de taille)
- Que le build fonctionne en `--platform linux/arm64` (les NAS Synology)

*Tests de l'entrypoint :*
- `docker run hash_tool help` → exit 0, affiche de l'aide
- `docker run hash_tool commande_inconnue` → exit 1, message d'erreur propre
- `docker run hash_tool version` → affiche les versions de b3sum, jq, bash
- `docker run hash_tool compute /data /bases/test.b3` avec volumes montés → produit le fichier .b3
- `docker run hash_tool --quiet verify ...` → le flag `--quiet` est bien transmis à `integrity.sh`
- `docker run hash_tool runner /pipelines/pipeline.json` → pipeline exécuté

*Tests d'environnement (que les outils dans l'image sont bien ceux attendus) :*
```bash
# Vérifier que b3sum est la bonne version et fonctionne
docker run --rm hash_tool b3sum --version
# Vérifier que jq est présent
docker run --rm hash_tool jq --version
# Vérifier que bash >= 4
docker run --rm hash_tool bash -c 'echo $BASH_VERSION'
```

*Test de régression de l'image :*
```bash
# Taille de l'image — détecter une régression (ex: on ajoute python par erreur)
SIZE=$(docker image inspect hash_tool --format='{{.Size}}')
[ $SIZE -lt 20000000 ] || echo "FAIL : image trop lourde ($SIZE octets)"
```

*Tests multi-plateforme :*
```bash
docker buildx build --platform linux/amd64,linux/arm64 -t hash_tool:multiarch .
# Vérifier que les deux architectures produisent les mêmes résultats sur un même jeu de fichiers
```

Ce serait un fichier `tests/run_tests_docker.sh` séparé, conditionné à la présence de Docker (`command -v docker`), et un job distinct dans la CI GitHub Actions — parce que le build Docker est lent (~2-3 min) et ne doit pas bloquer les tests unitaires rapides.

--- Fichier : hors_git/tests/TODO -- tests/tests todo.txt ---
# === Arborescence du dossier ===

TODO -- tests
├── _audit test.md
├── _cours appliqué -- test.md
├── _cours appliqué -- test.pdf
├── _descriptif maj.md
├── _protocole maj claude.md
├── ci-cd.md
├── docker-tests.md
├── edge-cases.md
├── fixtures.md
├── index.md
├── integration-tests.md
├── regression-tests.md
├── strategy.md
├── tap-format.md
├── test docker.md
└── unit-tests.md


# === Contenu des fichiers ===

--- Fichier : _audit test.md ---
## Analyse de la situation actuelle

La suite actuelle (`run_tests.sh` T00-T14, `run_tests_pipeline.sh` TP01-TP12b) est une suite d'**intégration fonctionnelle** bash-pur. Les tests sont bien structurés mais présentent des lacunes structurelles significatives.

---

## Diagnostic des lacunes

**Ce qui manque par couche :**

**1. Tests unitaires de `core.sh`** — inexistants. Les fonctions `core_compute`, `core_verify`, `core_compare`, `core_assert_b3_valid` sont testées uniquement via le pipeline complet `integrity.sh`. Un bug dans `core_compare` est difficile à isoler.

**2. Couverture des cas limites absente :**
- Fichiers de taille 0 dans `compute` (comportement ETA sur `fsize == 0`)
- Base `.b3` avec chemins mixtes relatifs/absolus — `core_assert_b3_valid` ne le détecte pas
- Dossier source avec des milliers de fichiers (performances, comptage ETA)
- Liens symboliques — comportement non documenté, non testé
- Noms de fichiers avec newlines — `mapfile -d ''` devrait tenir mais aucun test
- Fichiers binaires larges — ETA réaliste ?

**3. Tests de régression sur le format `.b3`** — aucun test ne vérifie que le format produit par `core_compute` est **bit-à-bit compatible** avec un `b3sum` direct (T11 le fait partiellement mais pas sur les cas limites).

**4. Tests de l'output HTML** — `report.html` est vérifié uniquement par présence de fichier et présence d'un pattern. Pas de validation de structure HTML, pas de test sur l'échappement (`html_escape`), pas de test sur des chemins avec `<`, `>`, `&`.

**5. Absence totale de CI** — les tests ne tournent que localement, aucune garantie sur les PRs.

**6. Pas de test de performance / régression de temps** — aucun seuil.

**7. Pas de test de `--quiet` sur `compare`** — T12 couvre `verify` et `compute` mais pas `compare`.

**8. `entrypoint.sh` non testé** — la couche Docker est entièrement aveugle.

---

## Recommandations structurées

### Niveau 1 — Tests unitaires `core.sh` (priorité haute)

Créer `tests/run_tests_core.sh` — teste chaque fonction de `core.sh` en isolation, en sourçant directement `core.sh` sans passer par `integrity.sh`.

```bash
# Pattern : source les modules directement
QUIET=0
source "$SCRIPT_DIR/../src/lib/ui.sh"
source "$SCRIPT_DIR/../src/lib/core.sh"

# Test core_assert_b3_valid
test_assert_b3_valid_fichier_absent() {
    core_assert_b3_valid "/tmp/inexistant.b3" 2>/dev/null && fail "doit exit 1" || pass "fichier absent → exit 1"
}

test_assert_b3_valid_ligne_invalide() {
    echo "ligne_sans_format" > /tmp/bad.b3
    core_assert_b3_valid /tmp/bad.b3 2>/dev/null && fail "doit exit 1" || pass "format invalide → exit 1"
}

# Test core_compare isolation
test_compare_chemins_avec_esperluette() {
    echo "aaa...64chars...  ./a&b.txt" > "$old"
    echo "bbb...64chars...  ./a&b.txt" > "$new"
    core_compare "$old" "$new" "$outdir"
    assert_contains "chemin avec & dans modifies" "a&b.txt" "$(cat $outdir/modifies.b3)"
}
```

Cas critiques à couvrir :
- `core_assert_b3_valid` : fichier absent, dossier, vide, format invalide, lignes mixtes valides/invalides
- `core_compare` : chemins avec espaces, `&`, `<`, `>`, fichiers identiques, tous modifiés, tous disparus, tous nouveaux
- `core_make_result_dir` : collision de noms, permissions insuffisantes
- `core_compute` : dossier vide (doit lever une erreur via `core_assert_target_valid`), fichier de taille 0, lien symbolique

### Niveau 2 — Cas limites manquants dans les suites existantes

Ajouter dans `run_tests.sh` :

- **T15** : fichier avec newline dans le nom (`$'nom\nfichier.txt'`) — `mapfile -d ''` doit tenir
- **T16** : fichier avec caractères HTML (`<script>.txt`, `a&b.txt`) — vérifier l'échappement dans `report.html`
- **T17** : `compare` sans différence → `report.html` affiche "IDENTIQUES"
- **T18** : `--quiet` sur `compare` — stdout vide, fichiers produits
- **T19** : lien symbolique dans le dossier source — comportement documenté (ignoré ou suivi ?)
- **T20** : `verify` avec `[dossier]` inexistant → exit 1 (T14 couvre déjà mais pas exactement ce cas)

### Niveau 3 — Tests de non-régression du format `.b3`

Fixture figée : créer `tests/fixtures/reference.b3` contenant les hashes attendus pour `tests/fixtures/data/`. À chaque run, `core_compute` doit produire un fichier identique octet par octet. Détecte toute régression dans le format de sortie, le tri, les séparateurs.

```bash
test_compute_stable() {
    bash "$INTEGRITY" compute ./fixtures/data /tmp/output.b3
    diff tests/fixtures/reference.b3 /tmp/output.b3 || fail "régression format .b3"
    pass "format .b3 stable"
}
```

### Niveau 4 — CI GitHub Actions

```yaml
# .github/workflows/ci.yml
name: CI
on: [push, pull_request]

jobs:
  tests:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - run: sudo apt-get install -y b3sum jq shellcheck
      - run: cd tests && ./run_tests.sh
      - run: cd tests && ./run_tests_pipeline.sh
      - run: cd tests && ./run_tests_core.sh          # nouveau
      - run: shellcheck src/integrity.sh runner.sh src/lib/*.sh docker/entrypoint.sh
      - uses: actions/upload-artifact@v4
        if: always()
        with:
          name: test-results
          path: /tmp/integrity-test*/

  docker:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - run: docker build -t hash_tool .
      - run: docker run --rm hash_tool version
      - run: |
          docker run --rm \
            -v /tmp/testdata:/data:ro \
            -v /tmp/testbases:/bases \
            hash_tool compute /data /bases/test.b3
```

Ajouter une matrice pour tester sur Ubuntu 22.04 et 24.04 (versions différentes de `b3sum`, `bash`, `awk`).

### Niveau 5 — Rapport de test structuré

Modifier `run_tests.sh` pour produire un rapport TAP (Test Anything Protocol) — format standard, consommable par n'importe quel CI :

```bash
echo "TAP version 14"
echo "1..$TOTAL"
pass() { echo "ok $TOTAL - $1"; }
fail() { echo "not ok $TOTAL - $1"; }
```

Ou JSON minimal pour intégration dashboard :

```bash
# En fin de suite
cat > /tmp/test-report.json <<JSON
{
  "suite": "run_tests.sh",
  "timestamp": "$(date -Iseconds)",
  "total": $TOTAL,
  "passed": $PASS,
  "failed": $FAIL
}
JSON
```

---

## Priorisation

| Priorité | Action | Impact | Effort |
|---|---|---|---|
| 1 | CI GitHub Actions (minimal) | Détection régression sur PR | ~2h |
| 2 | `run_tests_core.sh` — tests unitaires | Isolation des bugs | ~4h |
| 3 | Fixtures de non-régression format `.b3` | Détection silencieuse | ~1h |
| 4 | Cas limites HTML escaping (T16) | Bug latent confirmé | ~1h |
| 5 | T15 newlines, T18 `--quiet compare` | Couverture lacunaire | ~1h |
| 6 | Tests `entrypoint.sh` Docker | Couverture Docker nulle | ~3h |
| 7 | Rapport TAP / JSON | Intégration dashboard | ~1h |

Le delta le plus impactant à court terme : **CI + tests unitaires `core.sh`**. La suite actuelle fonctionne mais ne détecte les régressions que si quelqu'un pense à lancer les tests manuellement.

--- Fichier : _cours appliqué -- test.md ---
# Tests logiciels — Cours appliqué à `hash_tool`

> Ce cours couvre les notions abordées dans l'analyse de la suite de tests de `hash_tool` : tests unitaires, d'intégration, de non-régression, CI/CD, rapports de tests. Chaque notion est expliquée puis illustrée avec des exemples tirés du projet.

---

## Table des matières

1. [Pourquoi tester ?](#1-pourquoi-tester-)
2. [La pyramide des tests](#2-la-pyramide-des-tests)
3. [Tests unitaires](#3-tests-unitaires)
4. [Tests d'intégration](#4-tests-dintégration)
5. [Tests de non-régression](#5-tests-de-non-régression)
6. [Tests de cas limites (edge cases)](#6-tests-de-cas-limites-edge-cases)
7. [ShellCheck — analyse statique](#7-shellcheck--analyse-statique)
8. [Le protocole TAP](#8-le-protocole-tap)
9. [CI/CD — Intégration et déploiement continus](#9-cicd--intégration-et-déploiement-continus)
10. [Isolation et reproductibilité](#10-isolation-et-reproductibilité)
11. [Couverture de tests](#11-couverture-de-tests)
12. [Fixtures et données de test](#12-fixtures-et-données-de-test)
13. [Synthèse — Appliquer tout ça à hash_tool](#13-synthèse--appliquer-tout-ça-à-hash_tool)

---

## 1. Pourquoi tester ?

Un test est une vérification automatisée qu'un comportement attendu est bien produit par le code. Sans tests :

- Une modification dans `core.sh` peut casser `compare` sans que personne s'en aperçoive avant qu'un utilisateur perde des données.
- Impossible de refactoriser avec confiance — chaque changement est un pari.
- Le debugging est lent : il faut reproduire le problème manuellement à chaque fois.

Avec des tests :

- Un test qui échoue localise immédiatement la régression.
- Le code peut être modifié, optimisé, réorganisé — les tests garantissent que le comportement observable reste stable.
- La documentation implicite : un test qui s'appelle `test_compare_chemins_avec_espaces` documente un comportement et une contrainte du système.

### Dans hash_tool

La suite `run_tests.sh` permet de valider en quelques secondes que `integrity.sh` fonctionne correctement sur 14 scénarios. Sans elle, valider manuellement chaque cas (compute, verify OK, verify après corruption, compare avec ajout/suppression, mode quiet…) prendrait 30 minutes et serait oublié à la prochaine modification.

---

## 2. La pyramide des tests

La pyramide des tests est un modèle qui décrit comment répartir les efforts de test selon le niveau d'abstraction.

```
         /\
        /  \
       / E2E\        Tests de bout en bout (End-to-End)
      /______\       Rares, lents, fragiles
     /        \
    / Intégration\   Tests d'intégration
   /______________\  Moyennement nombreux
  /                \
 /   Unitaires      \ Tests unitaires
/____________________\ Nombreux, rapides, précis
```

| Niveau | Quoi | Vitesse | Fragilité | Nb recommandé |
|---|---|---|---|---|
| Unitaire | Une fonction isolée | Milliseconde | Faible | Maximum |
| Intégration | Plusieurs modules ensemble | Secondes | Moyenne | Moyen |
| E2E | Système complet, interface réelle | Minutes | Élevée | Minimum |

### Dans hash_tool

Actuellement, `run_tests.sh` et `run_tests_pipeline.sh` sont **presque exclusivement des tests d'intégration** — ils testent `integrity.sh` et `runner.sh` comme boîtes noires, sans tester les fonctions de `core.sh` individuellement. La pyramide est inversée : le bas (unitaire) est vide, le milieu (intégration) est bien couvert.

---

## 3. Tests unitaires

Un test unitaire vérifie une seule unité de code — généralement une fonction — en isolation complète. Il ne dépend d'aucun autre module, réseau, système de fichiers (sauf si la fonction elle-même écrit des fichiers).

### Caractéristiques

- **Rapide** : pas d'I/O disque, pas de processus externes.
- **Précis** : si un test unitaire échoue, le bug est dans cette fonction, nulle part ailleurs.
- **Indépendant** : l'ordre d'exécution n'a pas d'importance.

### Exemple concret — tester `core_assert_b3_valid`

```bash
# Sans tests unitaires : on teste via integrity.sh
./src/integrity.sh verify fichier_corrompu.b3
# → si ça échoue, est-ce core_assert_b3_valid ? core_verify ? ui.sh ?

# Avec tests unitaires : on source core.sh directement
QUIET=0
source ./src/lib/ui.sh
source ./src/lib/core.sh

test_b3_valide_fichier_absent() {
    core_assert_b3_valid "/tmp/inexistant_xyz.b3" 2>/dev/null
    # Doit retourner exit code 1
    [ $? -ne 0 ] && echo "PASS" || echo "FAIL"
}

test_b3_valide_format_invalide() {
    echo "cette ligne n'est pas un hash b3sum" > /tmp/bad.b3
    core_assert_b3_valid /tmp/bad.b3 2>/dev/null
    [ $? -ne 0 ] && echo "PASS - format invalide rejeté" || echo "FAIL"
    rm -f /tmp/bad.b3
}
```

La différence clé : on **source** `core.sh` au lieu d'appeler `integrity.sh`. Les fonctions deviennent directement accessibles dans le shell courant.

### Pourquoi c'est important ici

`core.sh` contient l'algorithme central : `core_compare` utilise `awk`, `join`, `comm`. Un bug dans la conversion `hash  chemin` → `chemin\thash` produit des faux positifs massifs (comme le bug décrit dans le changelog 0.7 : 26 569 "modifiés" pour 1 seul fichier réellement changé). Un test unitaire sur `core_compare` aurait détecté ça immédiatement.

---

## 4. Tests d'intégration

Un test d'intégration vérifie que plusieurs modules fonctionnent correctement **ensemble**. Il teste les interfaces entre les composants.

### Ce qu'il détecte

- Un module A produit un format que le module B ne sait pas lire.
- Une variable d'environnement attendue par B n'est pas positionnée par A.
- Un `cd` dans A modifie le répertoire courant de B (c'est exactement le bug isolé dans `runner.sh` : les `cd` fuyaient entre les blocs du pipeline).

### Exemple — tester l'intégration `core.sh` + `results.sh`

```bash
# Test d'intégration : core_verify produit des variables
# que results_write_verify sait exploiter

source ./src/lib/ui.sh
source ./src/lib/core.sh
source ./src/lib/results.sh

OUTDIR=$(mktemp -d)
echo "contenu" > /tmp/fichier_test.txt
./src/integrity.sh compute /tmp/fichier_test.txt /tmp/base_test.b3

# core_verify positionne CORE_VERIFY_STATUS, NB_OK, etc.
core_verify /tmp/base_test.b3

# results_write_verify doit savoir lire ces variables
results_write_verify "$OUTDIR" /tmp/base_test.b3 \
    "$CORE_VERIFY_STATUS" "$CORE_VERIFY_NB_OK" "$CORE_VERIFY_NB_FAIL" \
    "$CORE_VERIFY_LINES_FAIL" "$CORE_VERIFY_LINES_ERR"

# Vérifier que recap.txt est produit avec le bon contenu
grep -q "STATUT : OK" "$OUTDIR/recap.txt" && echo "PASS" || echo "FAIL"
```

### Dans hash_tool

`run_tests.sh` est une suite d'intégration : elle appelle `integrity.sh` comme le ferait un utilisateur, et vérifie les fichiers produits et les messages affichés. C'est utile et nécessaire, mais insuffisant seul — un test d'intégration qui échoue ne dit pas *où* est le problème.

---

## 5. Tests de non-régression

Un test de non-régression (TNR) vérifie qu'une fonctionnalité qui marchait avant **marche toujours** après une modification. Il capture un comportement connu et le fige.

### Principe

1. À un instant T, le système produit un output correct → on le capture comme référence.
2. À chaque modification ultérieure, on vérifie que l'output est toujours identique à la référence.
3. Si l'output change → soit c'est un bug (la modification a cassé quelque chose), soit c'est intentionnel (il faut alors mettre à jour la référence).

### Exemple — non-régression du format `.b3`

```bash
# Étape 1 : créer la fixture (fait une seule fois, commitée dans le repo)
mkdir -p tests/fixtures/data
echo "contenu alpha" > tests/fixtures/data/alpha.txt
echo "contenu beta"  > tests/fixtures/data/beta.txt

cd tests/fixtures
../../src/integrity.sh compute ./data reference.b3
# reference.b3 est commitée dans git

# Étape 2 : test de non-régression (lancé à chaque PR)
test_format_b3_stable() {
    cd tests/fixtures
    ../../src/integrity.sh compute ./data /tmp/output_test.b3
    diff reference.b3 /tmp/output_test.b3
    [ $? -eq 0 ] && echo "PASS - format .b3 stable" || echo "FAIL - régression détectée"
}
```

Si quelqu'un modifie `core_compute` et introduit accidentellement un espace en trop dans le séparateur, ou change l'ordre de tri — le `diff` échoue immédiatement.

### Ce que le TNR détecte que les autres tests ne détectent pas

Un TNR détecte des **changements subtils de comportement** qui ne cassent pas les tests fonctionnels mais altèrent le format ou le résultat. Par exemple :
- Un `b3sum` mis à jour qui change le format de sortie.
- Un `sort` qui change de comportement selon la locale (`LC_ALL`).
- L'ajout d'une ligne vide dans le `.b3` par une nouvelle version de `find`.

---

## 6. Tests de cas limites (edge cases)

Un cas limite est une entrée qui se situe aux frontières du comportement normal — là où les bugs se cachent le plus souvent.

### Catégories de cas limites

**Valeurs vides ou nulles**
```bash
# Que se passe-t-il avec un dossier vide ?
mkdir /tmp/dossier_vide
./src/integrity.sh compute /tmp/dossier_vide /tmp/vide.b3
# core_assert_target_valid doit lever une erreur
```

**Caractères spéciaux dans les noms**

Les noms de fichiers peuvent contenir des espaces, des newlines, des caractères HTML. Chacun peut casser un traitement textuel naïf.

```bash
# Espace dans le nom
echo "contenu" > "tests/data/fichier avec espace.txt"
# Apostrophe
echo "contenu" > "tests/data/l'important.txt"
# Caractère HTML — dangereux dans report.html
echo "contenu" > "tests/data/<script>alert.txt"
# Newline dans le nom (cas extrême mais légal sur Linux)
echo "contenu" > $'tests/data/nom\navec\nnewline.txt'
```

**Taille extrême**
```bash
# Fichier de taille zéro
touch tests/data/fichier_vide.bin
# → core_compute : bytes_done += 0, ETA correcte ?
```

**Cas limites de comparaison**

```bash
# Tous les fichiers identiques → modifies.b3 vide
# Tous les fichiers supprimés → disparus.txt contient tout
# Un seul fichier dans la base → comportement sur base minimale
```

### Pourquoi les cas limites cassent souvent le code

Le code est typiquement écrit et testé sur des cas "normaux". Les cas limites exposent des hypothèses implicites :

- `awk '{print $2}'` — hypothèse : le chemin ne contient pas d'espace. Faux.
- `grep -c '.'` — hypothèse : retourne 0 sur flux vide. Faux, `grep` retourne exit code 1 sur flux vide, ce qui crash un script avec `set -e`. (C'est le bug corrigé en v0.6.)
- `sort -k2` — hypothèse : le tri sur le champ 2 s'arrête au champ 2. Faux, `sort -k2` trie du champ 2 jusqu'à la fin de ligne. (Bug corrigé en v0.6, remplacé par `sort -k2,2`.)

---

## 7. ShellCheck — analyse statique

L'analyse statique examine le code **sans l'exécuter** pour détecter des erreurs potentielles. Pour bash, l'outil de référence est **ShellCheck**.

### Ce que ShellCheck détecte

```bash
# Variable non quotée → éclate sur les espaces
for f in $(find . -type f); do     # ← SC2044 : use find -exec or while read
    echo $f                         # ← SC2086 : double quote to prevent globbing
done

# Comparaison de chaînes avec [ ] au lieu de [[ ]]
if [ $VAR == "valeur" ]; then       # ← SC2039 : use [[ ]] in bash

# Variable utilisée avant d'être définie
echo $UNDEFINED_VAR                 # ← SC2154 : variable referenced but not assigned

# Pipe dans un sous-shell
cat file | read var                 # ← SC2031 : var will be in a subshell
```

### Dans hash_tool

Le test T00 dans `run_tests.sh` lance ShellCheck sur `integrity.sh` :

```bash
# T00 - ShellCheck
if command -v shellcheck &>/dev/null; then
    assert_exit_zero "ShellCheck integrity.sh" shellcheck "$INTEGRITY"
else
    echo "  SKIP - shellcheck non installé"
fi
```

ShellCheck est la première ligne de défense — il détecte des bugs sans même exécuter les scripts. Zéro warning ShellCheck est une condition non négociable avant toute PR.

---

## 8. Le protocole TAP

TAP (Test Anything Protocol) est un format texte standard pour les résultats de tests. Il est lisible par les humains et parseable par les outils CI.

### Format

```
TAP version 14
1..5
ok 1 - core_assert_b3_valid : fichier absent → exit 1
ok 2 - core_assert_b3_valid : format invalide → exit 1
not ok 3 - core_compare : chemins avec espaces
# Expected: beta.txt in modifies.b3
# Got: (empty)
ok 4 - core_make_result_dir : horodatage anti-écrasement
ok 5 - mode --quiet : stdout vide
```

### Structure

- `1..N` : nombre total de tests annoncé en tête.
- `ok N - description` : test réussi.
- `not ok N - description` : test échoué.
- `# commentaire` : diagnostic supplémentaire (indentation sous un `not ok`).

### Implémentation dans bash

```bash
#!/usr/bin/env bash
TOTAL=0; PASS=0; FAIL=0

plan() { echo "1..$1"; }
ok()     { TOTAL=$((TOTAL+1)); PASS=$((PASS+1)); echo "ok $TOTAL - $1"; }
not_ok() { TOTAL=$((TOTAL+1)); FAIL=$((FAIL+1)); echo "not ok $TOTAL - $1"; }

plan 3

# Test 1
if core_assert_b3_valid /tmp/inexistant 2>/dev/null; then
    not_ok "fichier absent doit échouer"
else
    ok "fichier absent → exit 1"
fi

# Test 2
echo "aa  ./fichier.txt" > /tmp/valid.b3  # hash trop court
if core_assert_b3_valid /tmp/valid.b3 2>/dev/null; then
    not_ok "hash invalide doit échouer"
else
    ok "hash invalide → exit 1"
fi
```

### Avantage

Le format TAP est **interopérable** : GitHub Actions, GitLab CI, Jenkins, et des dizaines d'outils savent parser TAP et afficher des rapports visuels sans configuration supplémentaire.

---

## 9. CI/CD — Intégration et déploiement continus

### Définitions

**CI (Continuous Integration)** : à chaque push ou pull request, un serveur exécute automatiquement les tests. Si un test échoue, la modification est bloquée ou signalée.

**CD (Continuous Deployment)** : si les tests passent, le code est automatiquement déployé en production.

Pour un outil comme hash_tool, le CD n'est pas pertinent (pas de service web à déployer). La CI, en revanche, est essentielle.

### Pourquoi la CI est indispensable

Sans CI : les tests ne sont lancés que si le développeur y pense. En pratique, ils ne sont lancés qu'avant les releases, et pas systématiquement.

Avec CI : chaque modification est testée automatiquement, dans un environnement propre (pas les dépendances locales du développeur), sur les versions exactes des outils installés.

### GitHub Actions — anatomie d'un workflow

```yaml
# .github/workflows/ci.yml
name: CI

on:
  push:              # déclenché à chaque push
  pull_request:      # déclenché à chaque PR

jobs:
  tests:
    runs-on: ubuntu-latest  # environnement propre, recréé à chaque run

    steps:
      # 1. Récupérer le code
      - uses: actions/checkout@v4

      # 2. Installer les dépendances
      - run: sudo apt-get install -y b3sum jq shellcheck

      # 3. Lancer les suites de tests
      - run: cd tests && ./run_tests.sh
      - run: cd tests && ./run_tests_pipeline.sh

      # 4. ShellCheck
      - run: shellcheck src/integrity.sh runner.sh src/lib/*.sh

      # 5. Uploader les artefacts (résultats) même si les tests échouent
      - uses: actions/upload-artifact@v4
        if: always()   # ← important : s'exécute même si les steps précédents échouent
        with:
          name: test-results
          path: /tmp/integrity-test*/
          retention-days: 7
```

### Matrice de tests

Un test peut passer sur Ubuntu 22.04 et échouer sur 24.04 si la version de `b3sum` ou de `awk` a changé de comportement. La matrice permet de tester plusieurs environnements en parallèle :

```yaml
jobs:
  tests:
    strategy:
      matrix:
        os: [ubuntu-22.04, ubuntu-24.04]
        bash: ["5.1", "5.2"]

    runs-on: ${{ matrix.os }}
    steps:
      - run: bash --version
      - run: cd tests && ./run_tests.sh
```

### Test Docker dans la CI

```yaml
  docker:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - run: docker build -t hash_tool .
      - run: docker run --rm hash_tool version
      - name: Test compute dans Docker
        run: |
          mkdir -p /tmp/testdata /tmp/testbases
          echo "contenu" > /tmp/testdata/fichier.txt
          docker run --rm \
            -v /tmp/testdata:/data:ro \
            -v /tmp/testbases:/bases \
            hash_tool compute /data /bases/test.b3
          test -f /tmp/testbases/test.b3 && echo "PASS" || echo "FAIL"
```

---

## 10. Isolation et reproductibilité

Un test doit être **isolé** : son résultat ne dépend pas des autres tests, de l'état du système, ni de l'ordre d'exécution. Il doit être **reproductible** : relancé 10 fois dans 10 environnements différents, il donne le même résultat.

### Les ennemis de l'isolation

**État partagé** : une variable globale modifiée par un test affecte le suivant.

```bash
# ❌ Mauvais : RESULTATS_DIR partagé entre les tests
export RESULTATS_DIR=/tmp/resultats_partages
test_verify_ok() { ... }
test_verify_echec() { ... }   # peut lire les résultats du test précédent
```

```bash
# ✓ Correct : chaque test a son propre WORKDIR
test_verify_ok() {
    local WORKDIR=$(mktemp -d)
    export RESULTATS_DIR="$WORKDIR/resultats"
    # ... test ...
    rm -rf "$WORKDIR"   # nettoyage garanti
}
```

**Répertoire courant** : un test qui fait `cd` et ne revient pas casse le suivant.

```bash
# ❌ Mauvais
test_compute() {
    cd /tmp/montest
    ../integrity.sh compute . base.b3
    # Si le test échoue ici, le cd ne revient jamais
}

# ✓ Correct : sous-shell isolé
test_compute() {
    (
        cd /tmp/montest
        ../integrity.sh compute . base.b3
    )   # le cd est confiné dans le sous-shell
}
```

**Fichiers temporaires** : un test qui échoue à mi-chemin laisse des fichiers qui perturbent le suivant.

```bash
# ✓ Correct : trap pour nettoyage garanti même en cas d'échec
test_compute() {
    local tmpdir=$(mktemp -d)
    trap "rm -rf $tmpdir" EXIT   # nettoyage garanti
    # ... test ...
}
```

### Dans hash_tool

`run_tests.sh` utilise un `WORKDIR=$(mktemp -d /tmp/integrity-test.XXXXXX)` créé en `setup()` et détruit en `teardown()`. Tous les tests opèrent dans ce répertoire temporaire, jamais dans les fichiers du projet ou du système hôte.

---

## 11. Couverture de tests

La couverture (coverage) mesure quelle proportion du code est exercée par les tests.

### Types de couverture

**Couverture de lignes** : chaque ligne est-elle exécutée au moins une fois ?

**Couverture de branches** : chaque branche d'un `if`/`case` est-elle testée (chemin vrai ET chemin faux) ?

```bash
# Cette fonction a 2 branches
if (( fsize > 0 )); then
    bytes_done=$(( bytes_done + fsize ))
    # ← branche testée si fsize > 0
fi
# ← branche testée si fsize == 0 (fichier vide)

# Un test avec uniquement des fichiers non-vides → couverture 50% de cette condition
```

**Couverture de chemins** : chaque combinaison possible de branches est-elle testée ? (Combinatoire explosive, rare en pratique.)

### Lacunes de couverture dans hash_tool

En analysant le code, voici des branches **non testées** :

```bash
# Dans _core_file_size() — branche BSD
_core_file_size() {
    if stat -c%s "$f" 2>/dev/null; then   # ← testé sur Linux
        return
    fi
    stat -f%z "$f"   # ← jamais testé (macOS uniquement)
}

# Dans core_compute — callback vide
core_compute "$target" "$hashfile" ""   # ← jamais testé sans callback

# Dans ui_progress_callback — cas bytes_done == 0
# La branche (bytes_done > 0 && eta_seconds > 0) est testée
# Mais (bytes_done == 0) — premier fichier, juste après démarrage ?
```

### Comment mesurer la couverture en bash

Il n'existe pas d'outil de couverture natif pour bash équivalent à `coverage.py`. La méthode pragmatique est manuelle : relire chaque branche du code et vérifier qu'un test l'exerce.

Pour les projets bash critiques, `bashcov` (basé sur `xtrace`) ou simplement `set -x` avec analyse de log permettent de voir quelles lignes sont exécutées.

---

## 12. Fixtures et données de test

Une fixture est un ensemble de données préparées à l'avance, dans un état connu, utilisées comme entrée des tests.

### Types de fixtures

**Données dynamiques** : créées dans le `setup()` du test, détruites dans le `teardown()`.

```bash
setup() {
    mkdir -p "$WORKDIR/data/sub"
    echo "contenu alpha" > "$WORKDIR/data/alpha.txt"
    echo "contenu beta"  > "$WORKDIR/data/beta.txt"
}
```

C'est l'approche de `run_tests.sh` : les fichiers de test sont créés à chaque run. Avantage : pas de fichiers à maintenir dans le repo. Inconvénient : si la fixture est complexe (arborescence de 500 fichiers avec des noms spéciaux), le setup devient lui-même un code à maintenir et à tester.

**Fixtures statiques (commitées dans git)** : fichiers présents dans le repo, utilisés comme référence immuable.

```
tests/
└── fixtures/
    ├── data/
    │   ├── alpha.txt
    │   └── beta.txt
    └── reference.b3   ← résultat attendu, commité dans git
```

```bash
test_format_b3_stable() {
    cd tests/fixtures
    ../../src/integrity.sh compute ./data /tmp/output.b3 >/dev/null 2>&1
    diff reference.b3 /tmp/output.b3
    [ $? -eq 0 ] && pass "format stable" || fail "régression format"
}
```

Si `reference.b3` change dans un PR, c'est visible dans le diff git — c'est un signal fort qu'il faut examiner.

### Fixtures pour les cas limites

Certains cas limites sont difficiles à créer dynamiquement de manière fiable. Les fixtures statiques les capturent une fois pour toutes :

```
tests/fixtures/
├── edge_cases/
│   ├── fichier avec espaces.txt
│   ├── fichier&special<chars>.txt
│   └── .fichier_cache
└── reference_edge.b3
```

---

## 13. Synthèse — Appliquer tout ça à hash_tool

### Ce qui existe et fonctionne bien

`run_tests.sh` (T00-T14) et `run_tests_pipeline.sh` (TP01-TP12b) forment une suite d'intégration solide. L'isolation via `mktemp`, le `teardown()` systématique, les helpers `pass()`/`fail()` — c'est une base professionnelle.

### Ce qui manque, par ordre de priorité

**1. CI GitHub Actions** — sans CI, les tests ne sont lancés que si on y pense. Action : créer `.github/workflows/ci.yml`.

**2. Tests unitaires de `core.sh`** — créer `tests/run_tests_core.sh` qui source `core.sh` directement et teste chaque fonction en isolation. Priorité : `core_compare` (algorithme complexe, bug historique).

**3. Fixture de non-régression du format `.b3`** — commiter `tests/fixtures/reference.b3` et ajouter un test qui vérifie que `core_compute` produit exactement ce fichier.

**4. Cas limites manquants** :
- Fichier avec newline dans le nom (T15)
- Caractères HTML dans le nom de fichier → vérifier l'échappement dans `report.html` (T16)
- `--quiet` sur `compare` (T18)
- Fichier de taille zéro — comportement ETA (T19)

**5. Rapport TAP** — modifier les suites pour produire un output TAP, consommable par la CI sans configuration supplémentaire.

### Architecture cible de la suite de tests

```
tests/
├── run_tests.sh              ← intégration integrity.sh (T00-T20+)
├── run_tests_pipeline.sh     ← intégration runner.sh (TP01-TP12b+)
├── run_tests_core.sh         ← unitaires core.sh (nouveau)
├── run_tests_docker.sh       ← intégration entrypoint.sh (nouveau)
└── fixtures/
    ├── data/
    │   ├── alpha.txt
    │   ├── beta.txt
    │   ├── fichier avec espaces.txt
    │   └── <script>edge.txt
    └── reference.b3           ← non-régression format .b3
```

### Règle d'or

Un test n'a de valeur que s'il est **lancé automatiquement**. Un test dans un fichier que personne ne lance est une illusion de couverture. La CI est le seul mécanisme qui garantit que les tests sont effectivement exécutés à chaque modification.

---

*Fin du cours — toutes les notions sont illustrées avec des exemples tirés du code réel de `hash_tool`.*

--- Fichier : _cours appliqué -- test.pdf ---
[Fichier binaire ou illisible, contenu ignoré]

--- Fichier : _descriptif maj.md ---
En me basant sur l'audit complet (tests unitaires `core.sh`, non-régression format `.b3`, edge cases, CI GitHub Actions, tests Docker/environnement, protocole TAP, fixtures), voici la structure documentaire que je propose :

```
docs/development/testing/
│
├── index.md
│   Vue d'ensemble de la stratégie de test : pyramide, suites existantes,
│   suites à créer, liens vers chaque document.
│
├── strategy.md
│   Décision formelle : objectifs de couverture, règles de priorité,
│   définition de "done" pour un test, politique ShellCheck zéro warning.
│
├── unit-tests.md
│   Spécification de run_tests_core.sh : liste exhaustive des fonctions à
│   tester, cas nominal + cas d'erreur pour chaque fonction de core.sh,
│   mécanisme de sourcing direct, contrat d'isolation.
│
├── integration-tests.md
│   Spécification des extensions à run_tests.sh (T15-T20+) et
│   run_tests_pipeline.sh : cas manquants identifiés, oracle de chaque test,
│   comportement attendu documenté.
│
├── regression-tests.md
│   Spécification du mécanisme de non-régression format .b3 : création des
│   fixtures, procédure de mise à jour de reference.b3, règle de décision
│   (diff intentionnel vs bug).
│
├── edge-cases.md
│   Catalogue exhaustif des cas limites : noms avec espaces/newlines/
│   caractères HTML, fichiers vide, base .b3 minimale, locales, etc.
│   Pour chaque cas : input, comportement attendu, risque si non testé.
│
├── docker-tests.md
│   Spécification de run_tests_docker.sh : tests de build, tests
│   entrypoint.sh commande par commande, tests de taille d'image, tests
│   multi-plateforme amd64/arm64, prérequis Docker Buildx.
│
├── fixtures.md
│   Spécification de l'arborescence tests/fixtures/ : quels fichiers
│   créer, pourquoi chacun, procédure pour ajouter une nouvelle fixture,
│   règle de nommage.
│
├── tap-format.md
│   Spécification du format TAP à adopter : structure du header, format
│   ok/not ok, diagnostics, helpers bash à implémenter dans chaque suite,
│   compatibilité GitHub Actions.
│
└── ci-cd.md
    Spécification du workflow GitHub Actions : jobs (unit, integration,
    docker), matrice OS, conditions de déclenchement, gestion des
    artefacts, règles de blocage des PRs.
```

---

**Logique de la structure :**

- `index.md` + `strategy.md` sont les documents de décision — ils répondent à *pourquoi* et *quoi*.
- Les cinq fichiers `*-tests.md` + `edge-cases.md` sont les documents de spécification — ils répondent à *comment tester quoi exactement*.
- `fixtures.md` + `tap-format.md` sont des documents transversaux — ils décrivent des mécanismes utilisés par plusieurs suites.
- `ci-cd.md` est le document d'infrastructure — il décrit l'automatisation qui donne de la valeur à tout le reste.

Chaque fichier peut être rédigé et implémenté indépendamment, dans l'ordre de priorité de l'audit : `ci-cd.md` → `unit-tests.md` → `regression-tests.md` → `edge-cases.md` → `docker-tests.md`.

--- Fichier : _protocole maj claude.md ---
Bonne approche. Voici la démarche et les prompts, dans l'ordre.

---

## Principe général

Claude ne peut pas tout générer en un seul prompt — le contexte est trop large et le code produit serait non vérifiable. La bonne méthode : **une session par livrable**, avec à chaque fois le contexte minimal nécessaire et une vérification avant de passer à la suite.

L'ordre est imposé par les dépendances : `helpers-tap.sh` doit exister avant les suites qui le sourcent. Les fixtures doivent exister avant les tests de non-régression. La CI doit référencer des fichiers qui existent.

---

## Étape 1 — `helpers-tap.sh`

**Pourquoi en premier :** toutes les suites de tests le sourcent. C'est la fondation.

**Fichiers à fournir à Claude :**
- `tap-format.md`
- `tests/run_tests.sh` (pour comprendre le style et les helpers existants)

**Prompt :**
```
Tu vas créer le fichier tests/helpers-tap.sh pour le projet hash_tool.

Voici la spécification : [coller tap-format.md]

Voici la suite de tests existante pour comprendre le style du projet : [coller run_tests.sh]

Contraintes :
- bash >= 4, set -euo pipefail
- ShellCheck zéro warning
- Compatible avec la détection CI (variable $CI) : format coloré en local, format TAP en CI
- Toutes les fonctions assert_* documentées avec leur signature en commentaire
- Le fichier doit pouvoir être sourcé sans être exécuté directement (pas de logique au top-level)

Produis uniquement le fichier tests/helpers-tap.sh, complet et prêt à l'emploi.
```

**Vérification avant de continuer :**
```bash
shellcheck tests/helpers-tap.sh
bash -c 'source tests/helpers-tap.sh && echo "sourcing OK"'
```

---

## Étape 2 — `tests/fixtures/`

**Pourquoi en deuxième :** les tests de non-régression et plusieurs tests unitaires s'appuient sur les fixtures. Elles doivent exister avant d'écrire les tests qui les utilisent.

**Fichiers à fournir :**
- `fixtures.md`

**Prompt :**
```
Tu vas créer les fichiers de fixtures pour le projet hash_tool.

Voici la spécification : [coller fixtures.md]

Crée les fichiers suivants avec exactement le contenu spécifié :
- tests/fixtures/data/alpha.txt
- tests/fixtures/data/beta.txt
- tests/fixtures/data/gamma.txt
- tests/fixtures/data/sub/delta.txt
- tests/fixtures/data-edge/fichier avec espaces.txt
- tests/fixtures/data-edge/fichier&special.txt
- tests/fixtures/data-edge/zero_bytes.bin

Pour les fichiers data-edge avec des noms spéciaux (espaces, &), donne-moi les commandes bash 
exactes pour les créer, car les noms ne peuvent pas être représentés directement dans tous les contextes.

Ne génère pas encore reference.b3 — il sera généré après coup avec la commande réelle.
```

**Après la création des fichiers, générer `reference.b3` manuellement :**
```bash
cd tests/fixtures
../../src/integrity.sh compute ./data bases/reference.b3
cat bases/reference.b3   # vérifier le contenu
git add .
git commit -m "test(fixtures): add reference data and edge cases"
```

---

## Étape 3 — `tests/run_tests_core.sh`

**Pourquoi maintenant :** c'est la suite la plus importante (tests unitaires de `core.sh`), et elle ne dépend que de `helpers-tap.sh` et des fixtures.

**Fichiers à fournir :**
- `unit-tests.md` (spécification complète avec les 53 cas)
- `src/lib/core.sh` (code à tester)
- `src/lib/ui.sh` (nécessaire pour `die()`)
- `tests/helpers-tap.sh` (créé à l'étape 1)
- `tests/run_tests.sh` (pour le style)

**Prompt — partie 1 : structure + tests CU01–CU27 :**
```
Tu vas créer tests/run_tests_core.sh pour le projet hash_tool.

Voici la spécification des tests à implémenter : [coller unit-tests.md]

Voici le code à tester :
[coller src/lib/core.sh]
[coller src/lib/ui.sh]

Voici les helpers disponibles : [coller tests/helpers-tap.sh]

Contraintes :
- bash >= 4, set -euo pipefail, ShellCheck zéro warning
- Sourcer directement src/lib/ui.sh et src/lib/core.sh (pas passer par integrity.sh)
- Chaque test est isolé dans sa propre fonction, avec son propre WORKDIR local
- trap EXIT pour nettoyage garanti
- Format TAP (via helpers-tap.sh)

Pour cette première partie, implémente :
- La structure du fichier (shebang, setup, sourcing, teardown)
- Les tests CU01 à CU27 (core_assert_b3_valid, core_assert_target_valid, core_compute)

Je validerai cette partie avant de te demander la suite.
```

**Vérification intermédiaire :**
```bash
shellcheck tests/run_tests_core.sh
cd tests && ./run_tests_core.sh 2>&1 | head -40
```

**Prompt — partie 2 : tests CU28–CU53 :**
```
Voici la suite de tests run_tests_core.sh produite à l'étape précédente : [coller le fichier]

Continue en ajoutant les tests :
- CU28 à CU35 (core_verify)
- CU36 à CU48 (core_compare — la plus critique)
- CU49 à CU53 (core_make_result_dir)

Appends ces tests au fichier existant. Respecte le style et la structure déjà en place.
Fais particulièrement attention à CU42–CU44 : chemins avec espaces, &, et chevrons dans core_compare.
```

**Vérification finale :**
```bash
shellcheck tests/run_tests_core.sh
cd tests && ./run_tests_core.sh
# Tous les tests doivent passer
```

---

## Étape 4 — Extensions de `run_tests.sh` (T15–T20)

**Fichiers à fournir :**
- `integration-tests.md` (section "Extensions de run_tests.sh")
- `tests/run_tests.sh` (fichier existant à modifier)
- `tests/helpers-tap.sh`

**Prompt :**
```
Tu vas modifier tests/run_tests.sh pour y ajouter les cas T15 à T20.

Voici la spécification des nouveaux cas : [coller la section "Extensions de run_tests.sh" de integration-tests.md]

Voici le fichier actuel à modifier : [coller run_tests.sh]

Contraintes :
- Ne pas modifier les cas existants T00–T14
- Ajouter T15–T20 après T14, avant le bloc de résultats final
- Migrer les helpers pass()/fail() vers helpers-tap.sh en ajoutant : source "$(dirname "$0")/helpers-tap.sh"
- ShellCheck zéro warning
- T16 (HTML escaping) : les assertions doivent vérifier &lt; et &gt; dans report.html, pas <script>

Produis le fichier run_tests.sh complet modifié.
```

**Vérification :**
```bash
shellcheck tests/run_tests.sh
cd tests && ./run_tests.sh
```

---

## Étape 5 — Extensions de `run_tests_pipeline.sh` (TP13–TP15)

**Même approche que l'étape 4.**

**Fichiers à fournir :**
- `integration-tests.md` (section "Extensions de run_tests_pipeline.sh")
- `tests/run_tests_pipeline.sh` (fichier existant)
- `tests/helpers-tap.sh`

**Prompt :**
```
Tu vas modifier tests/run_tests_pipeline.sh pour y ajouter les cas TP13 à TP15.

Voici la spécification : [coller la section "Extensions de run_tests_pipeline.sh" de integration-tests.md]

Voici le fichier actuel : [coller run_tests_pipeline.sh]

Contraintes :
- Ne pas modifier les cas existants TP01–TP12b
- Ajouter TP13–TP15 après TP12b
- Migrer vers helpers-tap.sh
- ShellCheck zéro warning
- TP13 : créer explicitement un dossier source corrompu distinct du dossier source propre

Produis le fichier run_tests_pipeline.sh complet modifié.
```

---

## Étape 6 — Test de non-régression dans `run_tests.sh`

**Ce test dépend de `reference.b3` généré à l'étape 2.**

**Fichiers à fournir :**
- `regression-tests.md`
- `tests/run_tests.sh` (version modifiée à l'étape 4)

**Prompt :**
```
Tu vas ajouter un test de non-régression dans tests/run_tests.sh.

Voici la spécification : [coller regression-tests.md]

Voici le fichier actuel : [coller run_tests.sh modifié]

Ajoute une section "T_REG — Non-régression format .b3" avec les tests T_REG01 à T_REG06 
tels que spécifiés. 

Le test T_REG01 doit :
- Vérifier que tests/fixtures/bases/reference.b3 existe (SKIP sinon avec tap_skip)
- Lancer compute sur tests/fixtures/data/
- Faire un diff bit-à-bit avec reference.b3
- En cas d'échec, afficher le diff (limité à 20 lignes) pour faciliter le diagnostic

Produis le fichier run_tests.sh complet final.
```

---

## Étape 7 — `tests/run_tests_docker.sh`

**Cette suite est indépendante — pas de dépendance aux autres suites bash.**

**Fichiers à fournir :**
- `docker-tests.md`
- `docker/entrypoint.sh`
- `tests/helpers-tap.sh`

**Prompt :**
```
Tu vas créer tests/run_tests_docker.sh pour le projet hash_tool.

Voici la spécification complète : [coller docker-tests.md]

Voici l'entrypoint à tester : [coller docker/entrypoint.sh]

Voici les helpers disponibles : [coller helpers-tap.sh]

Contraintes :
- bash >= 4, set -euo pipefail, ShellCheck zéro warning
- Skip automatique si Docker n'est pas disponible (command -v docker)
- Skip automatique si l'image hash_tool n'est pas buildée (sauf avec --build)
- Chaque test TD* crée ses propres tmpdir avec mktemp -d et les nettoie via trap EXIT
- Les tests TB* (build) sont dans une section séparée et ne tournent que si --build est passé
- Format TAP via helpers-tap.sh

Implémente tous les tests TB01–TB04, TE01–TE07, TD01–TD11.
```

**Vérification :**
```bash
shellcheck tests/run_tests_docker.sh
docker build -t hash_tool .
cd tests && ./run_tests_docker.sh --build
```

---

## Étape 8 — `.github/workflows/ci.yml`

**Dernière étape — la CI référence tous les fichiers créés précédemment.**

**Fichiers à fournir :**
- `ci-cd.md`
- La liste des fichiers de tests existants (pour vérifier les chemins)

**Prompt :**
```
Tu vas créer .github/workflows/ci.yml pour le projet hash_tool.

Voici la spécification complète : [coller ci-cd.md]

Les fichiers de tests qui existent maintenant :
- tests/helpers-tap.sh
- tests/run_tests.sh
- tests/run_tests_pipeline.sh
- tests/run_tests_core.sh
- tests/run_tests_docker.sh
- tests/fixtures/bases/reference.b3

Contraintes :
- Jobs lint, unit, integration, pipeline, non-regression en parallèle (needs: lint uniquement)
- Job docker-build conditionnel (main, develop, ou PR modifiant Dockerfile/.dockerignore/docker/)
- Job docker-arm64 avec continue-on-error: true, uniquement sur main
- Matrice ubuntu-22.04 + ubuntu-24.04 pour unit et integration
- concurrency avec cancel-in-progress pour éviter les runs redondants sur une même PR
- Upload d'artefacts TAP avec if: always() sur chaque job
- Pas de secrets requis

Produis le fichier .github/workflows/ci.yml complet.
```

**Vérification :**
```bash
# Installer actionlint si disponible
actionlint .github/workflows/ci.yml

# Ou vérifier manuellement la syntaxe YAML
python3 -c "import yaml; yaml.safe_load(open('.github/workflows/ci.yml'))" && echo "YAML valide"
```

---

## Récapitulatif de la démarche

| Étape | Livrable | Dépend de | Vérification |
|---|---|---|---|
| 1 | `helpers-tap.sh` | — | `shellcheck` + sourcing |
| 2 | `tests/fixtures/` | — | génération manuelle de `reference.b3` |
| 3a | `run_tests_core.sh` CU01–CU27 | 1, 2 | `shellcheck` + run partiel |
| 3b | `run_tests_core.sh` CU28–CU53 | 3a | run complet, 0 FAIL |
| 4 | `run_tests.sh` T15–T20 | 1 | `shellcheck` + run complet |
| 5 | `run_tests_pipeline.sh` TP13–TP15 | 1 | `shellcheck` + run complet |
| 6 | Non-régression dans `run_tests.sh` | 2, 4 | run complet, T_REG01 pass |
| 7 | `run_tests_docker.sh` | 1, image Docker | `shellcheck` + run avec `--build` |
| 8 | `ci.yml` | 1–7 tous présents | `actionlint` ou YAML lint |

**Règle absolue :** ne passer à l'étape N+1 que si l'étape N passe ShellCheck et produit zéro FAIL. Un test qui échoue dès la création est soit mal implémenté, soit révèle un bug réel dans le code — dans les deux cas, à traiter avant de continuer.

--- Fichier : ci-cd.md ---
# CI/CD — Spécification GitHub Actions

---

## Objectifs

1. **Détection automatique des régressions** : chaque push et chaque PR déclenchent les tests.
2. **Blocage des PRs cassées** : une PR ne peut pas merger si un test échoue.
3. **Feedback rapide** : les tests unitaires et d'intégration donnent un résultat en < 2 minutes.
4. **Isolation des tests lents** : les tests Docker (build arm64, QEMU) sont séparés et ne bloquent pas le feedback rapide.
5. **Artefacts accessibles** : les résultats de tests sont téléchargeables depuis l'interface GitHub même en cas d'échec.

---

## Architecture des jobs

```
push / PR
    │
    ├── [job: lint]          ShellCheck sur tous les scripts
    │       ↓
    ├── [job: unit]          run_tests_core.sh    (~30s)
    │       ↓
    ├── [job: integration]   run_tests.sh         (~60s)
    │       ↓
    ├── [job: pipeline]      run_tests_pipeline.sh (~60s)
    │
    └── [job: docker]        (déclenché sur : push main + PR modifiant Dockerfile)
            ├── docker build amd64
            ├── run_tests_docker.sh (sans --build, image en cache)
            └── docker build arm64  (QEMU, séparé, peut échouer sans bloquer)
```

Les jobs `unit`, `integration`, `pipeline` sont **indépendants et parallèles** — ils peuvent tourner simultanément. Le job `docker` est conditionnel.

---

## Fichier `.github/workflows/ci.yml`

```yaml
name: CI

on:
  push:
    branches: ["main", "develop"]
  pull_request:
    branches: ["main"]

# Annuler les runs en cours si un nouveau push arrive sur la même PR
concurrency:
  group: ${{ github.workflow }}-${{ github.ref }}
  cancel-in-progress: true

jobs:

  # ============================================================
  # Job : lint — ShellCheck sur tous les scripts
  # ============================================================
  lint:
    name: ShellCheck
    runs-on: ubuntu-latest

    steps:
      - uses: actions/checkout@v4

      - name: Installer ShellCheck
        run: sudo apt-get install -y shellcheck

      - name: ShellCheck — scripts principaux
        run: |
          shellcheck \
            src/integrity.sh \
            runner.sh \
            src/lib/core.sh \
            src/lib/ui.sh \
            src/lib/results.sh \
            src/lib/report.sh \
            docker/entrypoint.sh

      - name: ShellCheck — suites de tests
        run: |
          shellcheck \
            tests/run_tests.sh \
            tests/run_tests_pipeline.sh \
            tests/run_tests_core.sh \
            tests/run_tests_docker.sh \
            tests/helpers-tap.sh

  # ============================================================
  # Job : unit — Tests unitaires core.sh
  # ============================================================
  unit:
    name: Tests unitaires (core.sh)
    runs-on: ubuntu-latest
    needs: lint   # ne lance pas les tests si ShellCheck échoue

    strategy:
      matrix:
        os: [ubuntu-22.04, ubuntu-24.04]

    steps:
      - uses: actions/checkout@v4

      - name: Installer les dépendances
        run: sudo apt-get install -y b3sum

      - name: Lancer run_tests_core.sh
        run: |
          cd tests
          ./run_tests_core.sh 2>&1 | tee /tmp/core-results.tap
        env:
          CI: "true"

      - name: Uploader les résultats
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: unit-test-results-${{ matrix.os }}
          path: /tmp/core-results.tap
          retention-days: 7

  # ============================================================
  # Job : integration — Tests d'intégration integrity.sh
  # ============================================================
  integration:
    name: Tests d'intégration (integrity.sh)
    runs-on: ubuntu-latest
    needs: lint

    strategy:
      matrix:
        os: [ubuntu-22.04, ubuntu-24.04]

    steps:
      - uses: actions/checkout@v4

      - name: Installer les dépendances
        run: sudo apt-get install -y b3sum

      - name: Lancer run_tests.sh
        run: |
          cd tests
          ./run_tests.sh 2>&1 | tee /tmp/integration-results.tap
        env:
          CI: "true"

      - name: Uploader les résultats
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: integration-test-results-${{ matrix.os }}
          path: /tmp/integration-results.tap
          retention-days: 7

  # ============================================================
  # Job : pipeline — Tests d'intégration runner.sh
  # ============================================================
  pipeline:
    name: Tests pipeline (runner.sh)
    runs-on: ubuntu-latest
    needs: lint

    steps:
      - uses: actions/checkout@v4

      - name: Installer les dépendances
        run: sudo apt-get install -y b3sum jq

      - name: Lancer run_tests_pipeline.sh
        run: |
          cd tests
          ./run_tests_pipeline.sh 2>&1 | tee /tmp/pipeline-results.tap
        env:
          CI: "true"

      - name: Uploader les résultats
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: pipeline-test-results
          path: /tmp/pipeline-results.tap
          retention-days: 7

  # ============================================================
  # Job : non-regression — Test de non-régression format .b3
  # ============================================================
  non-regression:
    name: Non-régression format .b3
    runs-on: ubuntu-latest
    needs: lint

    steps:
      - uses: actions/checkout@v4

      - name: Installer b3sum
        run: sudo apt-get install -y b3sum

      - name: Vérifier reference.b3
        run: |
          cd tests/fixtures
          ../../src/integrity.sh compute ./data /tmp/output_reg.b3
          diff bases/reference.b3 /tmp/output_reg.b3 || {
            echo "ERREUR : régression du format .b3 détectée"
            echo "--- reference.b3 (attendu) ---"
            head -5 bases/reference.b3
            echo "--- output produit ---"
            head -5 /tmp/output_reg.b3
            exit 1
          }
          echo "Format .b3 stable"

  # ============================================================
  # Job : docker-build — Build et tests Docker (amd64)
  # ============================================================
  docker-build:
    name: Docker build + tests (amd64)
    runs-on: ubuntu-latest
    needs: lint

    # Ne tourner que sur main, develop, et les PRs modifiant Docker
    if: |
      github.ref == 'refs/heads/main' ||
      github.ref == 'refs/heads/develop' ||
      contains(github.event.pull_request.changed_files, 'Dockerfile') ||
      contains(github.event.pull_request.changed_files, '.dockerignore') ||
      contains(github.event.pull_request.changed_files, 'docker/')

    steps:
      - uses: actions/checkout@v4

      - name: Build image Docker amd64
        run: docker build --platform linux/amd64 -t hash_tool .

      - name: Vérifier la taille de l'image
        run: |
          SIZE=$(docker image inspect hash_tool --format='{{.Size}}')
          SIZE_MB=$(( SIZE / 1024 / 1024 ))
          echo "Taille image : ${SIZE_MB} Mo"
          [ "$SIZE_MB" -lt 30 ] || { echo "ERREUR : image trop lourde (${SIZE_MB} Mo)"; exit 1; }

      - name: Lancer run_tests_docker.sh
        run: |
          cd tests
          ./run_tests_docker.sh 2>&1 | tee /tmp/docker-results.tap
        env:
          CI: "true"

      - name: Uploader les résultats
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: docker-test-results
          path: /tmp/docker-results.tap
          retention-days: 7

  # ============================================================
  # Job : docker-arm64 — Build arm64 (QEMU, peut être lent)
  # ============================================================
  docker-arm64:
    name: Docker build (arm64)
    runs-on: ubuntu-latest
    needs: docker-build
    # Ce job peut échouer sans bloquer le merge (continue-on-error)
    continue-on-error: true

    if: github.ref == 'refs/heads/main'

    steps:
      - uses: actions/checkout@v4

      - name: Setup QEMU
        uses: docker/setup-qemu-action@v3

      - name: Setup Docker Buildx
        uses: docker/setup-buildx-action@v3

      - name: Build image arm64
        run: |
          docker buildx build \
            --platform linux/arm64 \
            -t hash_tool:arm64 \
            --load \
            .

      - name: Test basique arm64
        run: docker run --rm --platform linux/arm64 hash_tool version
```

---

## Conditions de blocage des PRs

Configurer dans les **Branch Protection Rules** de GitHub (`Settings > Branches > main`) :

| Check requis | Job concerné | Bloquant |
|---|---|---|
| ShellCheck | `lint` | Oui |
| Tests unitaires (ubuntu-22.04) | `unit` | Oui |
| Tests unitaires (ubuntu-24.04) | `unit` | Oui |
| Tests d'intégration (ubuntu-22.04) | `integration` | Oui |
| Tests d'intégration (ubuntu-24.04) | `integration` | Oui |
| Tests pipeline | `pipeline` | Oui |
| Non-régression .b3 | `non-regression` | Oui |
| Docker build amd64 | `docker-build` | Oui (si Dockerfile modifié) |
| Docker build arm64 | `docker-arm64` | Non (`continue-on-error: true`) |

---

## Gestion des artefacts

Chaque job uploade ses résultats TAP en artefact. Ils sont accessibles depuis l'onglet "Actions" de GitHub pendant 7 jours.

En cas d'échec, la procédure de diagnostic :
1. Cliquer sur le job échoué dans l'interface Actions.
2. Consulter les logs en ligne (résultats TAP affichés dans le terminal).
3. Télécharger l'artefact correspondant si un contexte plus détaillé est nécessaire.

---

## Déclenchement manuel

Le workflow peut être déclenché manuellement depuis l'interface GitHub Actions (`workflow_dispatch`) :

```yaml
on:
  push: ...
  pull_request: ...
  workflow_dispatch:    # ← déclenchement manuel
    inputs:
      run_docker_arm64:
        description: 'Lancer le build arm64 (lent)'
        type: boolean
        default: false
```

---

## Secrets et variables d'environnement

Aucun secret n'est requis pour la CI de base — `hash_tool` n'a pas de dépendances réseau dans ses tests (tout est local).

Si des notifications (Slack, email) sont ajoutées dans le futur :
- `SLACK_WEBHOOK_URL` → `Settings > Secrets > Actions`
- Ne jamais logger les secrets dans les steps

---

## Durée estimée par run CI

| Job | Durée estimée |
|---|---|
| lint (ShellCheck) | ~15s |
| unit (ubuntu-22.04) | ~30s |
| unit (ubuntu-24.04) | ~30s |
| integration (ubuntu-22.04) | ~60s |
| integration (ubuntu-24.04) | ~60s |
| pipeline | ~60s |
| non-regression | ~20s |
| docker-build + tests amd64 | ~3-4 min |
| docker-arm64 (QEMU) | ~8-12 min |

**Durée totale pour un push standard** (sans Docker) : ~2 minutes (jobs parallèles).  
**Durée avec Docker** : ~5 minutes (Docker build en parallèle des autres jobs).

---

## Évolutions futures

| Évolution | Priorité | Description |
|---|---|---|
| Publication TAP → rapport HTML | Basse | Utiliser `dorny/test-reporter` pour afficher les résultats dans les PR checks |
| Cache des dépendances apt | Moyenne | `actions/cache` sur `/var/cache/apt` — gain ~20s par job |
| Scheduled run nocturne | Basse | `on: schedule: cron: '0 3 * * *'` — détecte les régressions dues à des mises à jour de dépendances système |
| Notification sur échec | Basse | Webhook Slack sur `main` uniquement, pas sur les PRs |


--- Fichier : docker-tests.md ---
# Tests Docker — Spécification `run_tests_docker.sh`

---

## Périmètre

`run_tests_docker.sh` couvre trois niveaux :

1. **Build** — l'image se construit sans erreur, pour les architectures cibles
2. **Environnement** — les outils attendus sont présents dans l'image avec les bonnes versions
3. **Entrypoint** — chaque commande de `docker/entrypoint.sh` produit le résultat attendu

Cette suite est **indépendante** des autres : elle ne source aucun module bash, elle ne dépend pas de `b3sum` sur l'hôte. Elle nécessite uniquement Docker.

---

## Prérequis et skip automatique

```bash
#!/usr/bin/env bash
# run_tests_docker.sh
set -euo pipefail

# Skip si Docker n'est pas disponible
command -v docker &>/dev/null || {
    echo "SKIP - Docker non disponible sur cet hôte"
    exit 0
}

# Skip si l'image n'est pas buildée (sauf si --build passé en argument)
if [ "${1:-}" = "--build" ]; then
    echo "=== Build de l'image ==="
    docker build -t hash_tool . || { echo "ERREUR : build échoué"; exit 1; }
fi

docker image inspect hash_tool &>/dev/null || {
    echo "SKIP - image hash_tool non trouvée. Lancer avec --build ou 'docker build -t hash_tool .'"
    exit 0
}
```

---

## Tests de build (TB)

Ces tests sont séparés des tests d'entrypoint — le build est lent (~2-3 min) et ne doit pas bloquer les tests fonctionnels.

### TB01 — Build amd64 réussi

```bash
docker build --platform linux/amd64 -t hash_tool:test-amd64 .
[ $? -eq 0 ] && pass "TB01 build amd64" || fail "TB01 build amd64 échoué"
docker rmi hash_tool:test-amd64 >/dev/null 2>&1 || true
```

### TB02 — Build arm64 réussi

```bash
# Requiert Docker Buildx ou QEMU
docker build --platform linux/arm64 -t hash_tool:test-arm64 .
[ $? -eq 0 ] && pass "TB02 build arm64" || fail "TB02 build arm64 échoué"
docker rmi hash_tool:test-arm64 >/dev/null 2>&1 || true
```

**Note CI :** TB02 nécessite `docker buildx` avec `--platform linux/arm64` et l'émulation QEMU. Dans GitHub Actions, utiliser `docker/setup-qemu-action` et `docker/setup-buildx-action`.

### TB03 — Taille de l'image finale

```bash
local size
size=$(docker image inspect hash_tool --format='{{.Size}}')
local size_mb=$(( size / 1024 / 1024 ))
# Seuil : < 30 Mo (image actuelle ~14 Mo, marge pour éviter les faux positifs)
[ "$size_mb" -lt 30 ] \
    && pass "TB03 taille image OK : ${size_mb} Mo" \
    || fail "TB03 image trop lourde : ${size_mb} Mo (seuil 30 Mo)"
```

**Rationale du seuil :** l'image actuelle fait ~14 Mo. Un seuil à 30 Mo détecte une régression significative (ajout accidentel d'un package lourd) sans être trop strict.

### TB04 — Pas de données utilisateur dans l'image

```bash
# Vérifier que mon_dossier/ et les .b3 ne sont pas dans l'image (respecte .dockerignore)
local found
found=$(docker run --rm hash_tool find / -name "*.b3" -o -name "hashes_*" 2>/dev/null | grep -v "^/proc" || true)
[ -z "$found" ] \
    && pass "TB04 pas de données utilisateur dans l'image" \
    || fail "TB04 données trouvées dans l'image : $found"
```

---

## Tests d'environnement (TE)

Ces tests vérifient que les outils présents dans l'image sont les bons, aux bonnes versions.

### TE01 — `b3sum` présent et fonctionnel

```bash
local out
out=$(docker run --rm hash_tool b3sum --version 2>&1)
echo "$out" | grep -qi "b3sum" \
    && pass "TE01 b3sum présent" \
    || fail "TE01 b3sum absent ou non fonctionnel : $out"
```

### TE02 — `b3sum` produit un hash valide

```bash
local hash
hash=$(docker run --rm hash_tool bash -c 'echo "test" | b3sum')
echo "$hash" | grep -qE '^[0-9a-f]{64}' \
    && pass "TE02 b3sum produit un hash valide" \
    || fail "TE02 hash invalide : $hash"
```

### TE03 — `jq` présent et fonctionnel

```bash
local out
out=$(docker run --rm hash_tool jq --version 2>&1)
echo "$out" | grep -qi "jq" \
    && pass "TE03 jq présent" \
    || fail "TE03 jq absent : $out"
```

### TE04 — `bash` version >= 4

```bash
local version
version=$(docker run --rm hash_tool bash -c 'echo ${BASH_VERSINFO[0]}')
[ "$version" -ge 4 ] \
    && pass "TE04 bash >= 4 (version $version)" \
    || fail "TE04 bash trop ancien : $version"
```

### TE05 — Outils coreutils présents

```bash
for tool in find sort awk comm join stat du mktemp; do
    docker run --rm hash_tool command -v "$tool" >/dev/null 2>&1 \
        && pass "TE05 $tool présent" \
        || fail "TE05 $tool absent"
done
```

### TE06 — `RESULTATS_DIR` défini à `/resultats`

```bash
local val
val=$(docker run --rm hash_tool bash -c 'echo $RESULTATS_DIR')
[ "$val" = "/resultats" ] \
    && pass "TE06 RESULTATS_DIR=/resultats" \
    || fail "TE06 RESULTATS_DIR=$val (attendu /resultats)"
```

### TE07 — Scripts présents et exécutables

```bash
for f in /app/runner.sh /app/src/integrity.sh /app/src/lib/report.sh; do
    docker run --rm hash_tool test -x "$f" \
        && pass "TE07 $f exécutable" \
        || fail "TE07 $f absent ou non exécutable"
done
```

---

## Tests de l'entrypoint (TD)

### TD01 — Commande `help` : exit 0, affiche de l'aide

```bash
local out exit_code=0
out=$(docker run --rm hash_tool help 2>&1) || exit_code=$?
[ "$exit_code" -eq 0 ] && pass "TD01 help exit 0" || fail "TD01 help exit $exit_code"
echo "$out" | grep -qi "compute" && pass "TD01 help contient compute" || fail "TD01 help ne contient pas compute"
echo "$out" | grep -qi "verify"  && pass "TD01 help contient verify"  || fail "TD01 help ne contient pas verify"
```

### TD02 — Commande sans argument : affiche l'aide (CMD défaut)

```bash
local out
out=$(docker run --rm hash_tool 2>&1) || true
echo "$out" | grep -qi "usage\|compute\|verify" \
    && pass "TD02 aide par défaut" \
    || fail "TD02 pas d'aide par défaut"
```

### TD03 — Commande inconnue : exit 1, message d'erreur

```bash
local exit_code=0
local out
out=$(docker run --rm hash_tool commande_inconnue_xyz 2>&1) || exit_code=$?
[ "$exit_code" -ne 0 ] && pass "TD03 commande inconnue → exit non-zéro" || fail "TD03 doit exit 1"
echo "$out" | grep -qi "inconnue\|unknown\|ERREUR" \
    && pass "TD03 message d'erreur explicite" \
    || fail "TD03 message d'erreur absent"
```

### TD04 — Commande `version` : affiche b3sum, jq, bash

```bash
local out
out=$(docker run --rm hash_tool version 2>&1)
echo "$out" | grep -qi "b3sum" && pass "TD04 version contient b3sum" || fail "TD04 version sans b3sum"
echo "$out" | grep -qi "jq"    && pass "TD04 version contient jq"    || fail "TD04 version sans jq"
echo "$out" | grep -qi "bash"  && pass "TD04 version contient bash"   || fail "TD04 version sans bash"
```

### TD05 — Commande `compute` : produit un fichier `.b3`

```bash
local tmpdata tmpbases
tmpdata=$(mktemp -d)
tmpbases=$(mktemp -d)
echo "contenu test" > "$tmpdata/fichier.txt"

docker run --rm \
    -v "$tmpdata:/data:ro" \
    -v "$tmpbases:/bases" \
    hash_tool compute /data /bases/test.b3

[ -f "$tmpbases/test.b3" ] \
    && pass "TD05 test.b3 produit" \
    || fail "TD05 test.b3 absent"

grep -qE '^[0-9a-f]{64}  ./fichier.txt' "$tmpbases/test.b3" \
    && pass "TD05 format b3sum correct" \
    || fail "TD05 format b3sum incorrect : $(cat "$tmpbases/test.b3")"

rm -rf "$tmpdata" "$tmpbases"
```

### TD06 — Commande `verify` : OK sur base fraîche

```bash
local tmpdata tmpbases tmpres
tmpdata=$(mktemp -d); tmpbases=$(mktemp -d); tmpres=$(mktemp -d)
echo "contenu test" > "$tmpdata/fichier.txt"

docker run --rm -v "$tmpdata:/data:ro" -v "$tmpbases:/bases" \
    hash_tool compute /data /bases/test.b3 >/dev/null

local out exit_code=0
out=$(docker run --rm \
    -v "$tmpdata:/data:ro" \
    -v "$tmpbases:/bases:ro" \
    -v "$tmpres:/resultats" \
    hash_tool verify /bases/test.b3 /data 2>&1) || exit_code=$?

[ "$exit_code" -eq 0 ] && pass "TD06 verify exit 0" || fail "TD06 verify exit $exit_code"
echo "$out" | grep -qi "OK" && pass "TD06 verify affiche OK" || fail "TD06 verify n'affiche pas OK"

rm -rf "$tmpdata" "$tmpbases" "$tmpres"
```

### TD07 — Commande `verify` : détecte une corruption

```bash
local tmpdata tmpbases tmpres
tmpdata=$(mktemp -d); tmpbases=$(mktemp -d); tmpres=$(mktemp -d)
echo "contenu original" > "$tmpdata/fichier.txt"

docker run --rm -v "$tmpdata:/data:ro" -v "$tmpbases:/bases" \
    hash_tool compute /data /bases/test.b3 >/dev/null

echo "contenu corrompu" > "$tmpdata/fichier.txt"

local exit_code=0
docker run --rm \
    -v "$tmpdata:/data:ro" \
    -v "$tmpbases:/bases:ro" \
    -v "$tmpres:/resultats" \
    hash_tool verify /bases/test.b3 /data >/dev/null 2>&1 || exit_code=$?

[ "$exit_code" -ne 0 ] \
    && pass "TD07 verify détecte corruption → exit non-zéro" \
    || fail "TD07 verify aurait dû échouer"

rm -rf "$tmpdata" "$tmpbases" "$tmpres"
```

### TD08 — Commande `compare` : produit `report.html`

```bash
local tmpbases tmpres
tmpbases=$(mktemp -d); tmpres=$(mktemp -d)

# Créer deux bases différentes
local tmpdata_a tmpdata_b
tmpdata_a=$(mktemp -d); tmpdata_b=$(mktemp -d)
echo "v1" > "$tmpdata_a/f.txt"
echo "v2" > "$tmpdata_b/f.txt"

docker run --rm -v "$tmpdata_a:/data:ro" -v "$tmpbases:/bases" \
    hash_tool compute /data /bases/a.b3 >/dev/null
docker run --rm -v "$tmpdata_b:/data:ro" -v "$tmpbases:/bases" \
    hash_tool compute /data /bases/b.b3 >/dev/null

docker run --rm \
    -v "$tmpbases:/bases:ro" \
    -v "$tmpres:/resultats" \
    hash_tool compare /bases/a.b3 /bases/b.b3 >/dev/null

local report
report=$(ls "$tmpres"/resultats_a*/report.html 2>/dev/null | head -1)
[ -f "$report" ] \
    && pass "TD08 report.html produit" \
    || fail "TD08 report.html absent"

rm -rf "$tmpdata_a" "$tmpdata_b" "$tmpbases" "$tmpres"
```

### TD09 — Flag `--quiet` transmis correctement

```bash
local tmpdata tmpbases tmpres
tmpdata=$(mktemp -d); tmpbases=$(mktemp -d); tmpres=$(mktemp -d)
echo "contenu" > "$tmpdata/f.txt"

docker run --rm -v "$tmpdata:/data:ro" -v "$tmpbases:/bases" \
    hash_tool compute /data /bases/test.b3 >/dev/null

local out
out=$(docker run --rm \
    -v "$tmpdata:/data:ro" \
    -v "$tmpbases:/bases:ro" \
    -v "$tmpres:/resultats" \
    hash_tool --quiet verify /bases/test.b3 /data 2>&1)

[ -z "$out" ] \
    && pass "TD09 --quiet : stdout vide" \
    || fail "TD09 --quiet : stdout non vide : $out"

rm -rf "$tmpdata" "$tmpbases" "$tmpres"
```

### TD10 — Commande `runner` avec pipeline JSON

```bash
local tmpdata tmpbases tmpres tmppipelines
tmpdata=$(mktemp -d); tmpbases=$(mktemp -d)
tmpres=$(mktemp -d); tmppipelines=$(mktemp -d)
echo "contenu" > "$tmpdata/f.txt"

cat > "$tmppipelines/pipeline.json" <<EOF
{
    "pipeline": [
        { "op": "compute", "source": "/data", "bases": "/bases", "nom": "test.b3" }
    ]
}
EOF

docker run --rm \
    -v "$tmpdata:/data:ro" \
    -v "$tmpbases:/bases" \
    -v "$tmpres:/resultats" \
    -v "$tmppipelines/pipeline.json:/pipelines/pipeline.json:ro" \
    hash_tool runner /pipelines/pipeline.json >/dev/null

[ -f "$tmpbases/test.b3" ] \
    && pass "TD10 runner pipeline : test.b3 produit" \
    || fail "TD10 runner pipeline : test.b3 absent"

rm -rf "$tmpdata" "$tmpbases" "$tmpres" "$tmppipelines"
```

### TD11 — Commande `runner` sans pipeline.json monté : erreur explicite

```bash
local out exit_code=0
out=$(docker run --rm hash_tool runner 2>&1) || exit_code=$?
[ "$exit_code" -ne 0 ] && pass "TD11 runner sans pipeline → exit non-zéro" || fail "TD11 doit exit 1"
echo "$out" | grep -qi "introuvable\|ERREUR\|not found" \
    && pass "TD11 message d'erreur sur pipeline absent" \
    || fail "TD11 message d'erreur absent : $out"
```

---

## Structure du fichier `run_tests_docker.sh`

```bash
#!/usr/bin/env bash
# run_tests_docker.sh - Tests de l'image Docker hash_tool
# Usage : ./run_tests_docker.sh [--build]
# Prérequis : Docker

set -euo pipefail

# ... helpers pass/fail/assert identiques aux autres suites ...

echo "=== BUILD ==="
# TB01–TB04

echo "=== ENVIRONNEMENT ==="
# TE01–TE07

echo "=== ENTRYPOINT ==="
# TD01–TD11

echo "========================================"
[ "$FAIL" -eq 0 ] \
    && echo "  $PASS/$TOTAL tests passés" \
    || echo "  $PASS/$TOTAL passés - $FAIL échec(s)"
echo "========================================"
[ "$FAIL" -eq 0 ]
```

---

## Durée estimée

| Section | Durée approx. |
|---|---|
| Tests d'environnement (TE) | ~10 secondes |
| Tests entrypoint (TD) | ~60 secondes |
| Tests de build (TB01 amd64) | ~2-3 minutes |
| Tests de build (TB02 arm64 avec QEMU) | ~5-10 minutes |

**Recommandation CI :** séparer les tests de build (job `docker-build`) des tests d'entrypoint (job `docker-test`). Les tests d'entrypoint peuvent tourner sur une image pré-buildée en cache. Les tests de build ne tournent que sur les PRs modifiant `Dockerfile`, `.dockerignore` ou `docker/`.


--- Fichier : edge-cases.md ---
# Cas limites — Catalogue exhaustif

---

## Introduction

Un cas limite est une entrée qui se situe aux frontières du comportement normal. C'est là que les bugs se cachent — le code est typiquement développé et testé sur des cas "standards", et les hypothèses implicites sur les entrées ne sont jamais vérifiées.

Ce catalogue recense tous les cas limites identifiés pour `hash_tool`, classés par catégorie. Pour chaque cas : l'input, le comportement attendu, et le risque si le cas n'est pas testé.

---

## Catégorie 1 — Noms de fichiers

### 1.1 Espace dans le nom

| | |
|---|---|
| **Input** | `"fichier avec espaces.txt"` |
| **Comportement attendu** | Indexé correctement, 1 ligne dans `.b3`, verify OK |
| **Risque** | `awk '{print $2}'` fragmente le chemin — faux positif massif dans `compare` (bug historique v0.7) |
| **Testé par** | T08 (existant), CU42 (unitaire à créer) |

### 1.2 Plusieurs espaces consécutifs

| | |
|---|---|
| **Input** | `"fichier  avec  doubles  espaces.txt"` |
| **Comportement attendu** | Indexé correctement, 1 ligne, verify OK |
| **Risque** | Parsing par champ fragmente encore plus — potentiellement confondu avec le séparateur `  ` du format b3sum |
| **Testé par** | Non testé — à ajouter en T15b |

### 1.3 Newline dans le nom

| | |
|---|---|
| **Input** | `$'nom\navec\nnewline.txt'` |
| **Comportement attendu** | Indexé correctement (1 fichier = 1 ligne dans `.b3`) |
| **Risque** | `find | wc -l` compte 3 fichiers ; `xargs` sans `-0` éclate le nom ; seuls `find -print0` + `mapfile -d ''` tiennent |
| **Testé par** | T15 (à créer) |
| **Note** | Cas légal sur Linux, illégal sur Windows/macOS |

### 1.4 Tabulation dans le nom

| | |
|---|---|
| **Input** | `$'nom\tavec\ttab.txt'` |
| **Comportement attendu** | Indexé correctement |
| **Risque** | `_b3_to_path_hash` utilise `\t` comme séparateur — une tabulation dans le chemin peut corrompre le parsing |
| **Testé par** | Non testé — **cas critique à ajouter** |
| **Note** | `awk '{ print substr($0,67) "\t" substr($0,1,64) }'` — l'offset fixe 67 protège le hash, mais le chemin est copié tel quel avec sa tabulation |

### 1.5 Caractères HTML dans le nom

| | |
|---|---|
| **Input** | `"<script>alert.txt"`, `"a&b.txt"`, `"page>2.txt"` |
| **Comportement attendu** | Indexé correctement dans `.b3` (pas d'échappement dans le fichier texte) ; échappé dans `report.html` |
| **Risque** | `report.html` affiche `<script>` littéralement → injection HTML dans le rapport |
| **Testé par** | T16 (à créer) |

### 1.6 Fichier commençant par un tiret

| | |
|---|---|
| **Input** | `"-fichier.txt"` |
| **Comportement attendu** | Indexé correctement |
| **Risque** | Certains outils interprètent `-` comme un flag CLI |
| **Testé par** | Non testé — risque faible car `find` et `b3sum` reçoivent le chemin complet |

### 1.7 Nom très long (255 chars, limite ext4)

| | |
|---|---|
| **Input** | Nom de 254 caractères |
| **Comportement attendu** | Indexé correctement |
| **Risque** | Troncature silencieuse dans certains buffers |
| **Testé par** | Non testé — risque faible, `b3sum` gère les noms longs |

### 1.8 Fichier caché (commençant par `.`)

| | |
|---|---|
| **Input** | `".fichier_cache"` |
| **Comportement attendu** | Indexé par `find -type f` (find suit les fichiers cachés par défaut) |
| **Risque** | `ls` ne les montre pas — confusion si on vérifie manuellement le count |
| **Testé par** | Non testé — à ajouter dans fixtures |

---

## Catégorie 2 — Contenu de fichiers

### 2.1 Fichier de taille zéro

| | |
|---|---|
| **Input** | `touch zero.bin` |
| **Comportement attendu** | Indexé (le hash BLAKE3 d'un fichier vide est défini), `bytes_done` non modifié (branche `fsize > 0` protège le calcul ETA) |
| **Risque** | Division par zéro dans le calcul ETA si `bytes_done == total_bytes == 0` |
| **Testé par** | T18 (à créer), CU23 (unitaire) |

### 2.2 Fichier très volumineux (> 4 Go)

| | |
|---|---|
| **Input** | Fichier de 5 Go (nécessite un disque disponible) |
| **Comportement attendu** | Indexé correctement, ETA affichée |
| **Risque** | Overflow integer dans `bytes_done` si bash utilise des entiers 32 bits (bash 4+ utilise 64 bits — OK) |
| **Testé par** | Non testé — difficile en CI (espace disque, temps) |
| **Décision** | Exclus des tests automatiques. Documenté comme supporté (bash 64-bit integers) |

### 2.3 Fichier binaire avec tous les octets possibles

| | |
|---|---|
| **Input** | `printf '%b' '\x00\x01...\xff' > binary.bin` |
| **Comportement attendu** | Indexé correctement, hash stable |
| **Risque** | Traitements texte naïfs sur le contenu du fichier (aucun dans `hash_tool` — `b3sum` opère sur des octets bruts) |
| **Testé par** | Non testé — risque faible |

---

## Catégorie 3 — Structure du dossier

### 3.1 Dossier vide

| | |
|---|---|
| **Input** | `mkdir dossier_vide` sans fichiers |
| **Comportement attendu** | `core_assert_target_valid` lève une erreur "aucun fichier régulier" |
| **Risque** | Base `.b3` vide produite silencieusement, puis `core_assert_b3_valid` rejette la base vide |
| **Testé par** | T09 (existant, partiellement), CU14 (unitaire) |

### 3.2 Dossier avec uniquement des sous-dossiers vides

| | |
|---|---|
| **Input** | `mkdir -p dossier/sub1 dossier/sub2` |
| **Comportement attendu** | Même qu'un dossier vide — erreur "aucun fichier régulier" |
| **Risque** | `find -type f` retourne 0 résultat, `total_files=0`, division par zéro potentielle dans ETA |
| **Testé par** | CU16 (unitaire) |

### 3.3 Arborescence profonde

| | |
|---|---|
| **Input** | `a/b/c/d/e/f/g/h/i/j/fichier.txt` (10 niveaux) |
| **Comportement attendu** | Indexé correctement, chemin complet dans `.b3` |
| **Risque** | Limites de longueur de chemin sur certains OS (PATH_MAX = 4096 sur Linux) |
| **Testé par** | Non testé — risque faible |

### 3.4 Lien symbolique

| | |
|---|---|
| **Input** | `ln -s cible.txt lien.txt` |
| **Comportement attendu** | `find -type f` ignore le lien symbolique par défaut — lien non indexé |
| **Risque** | Comportement non documenté, surprenant pour l'utilisateur qui s'attend à voir le lien indexé |
| **Testé par** | T19 (à créer) |
| **Action** | Documenter le comportement dans `reference/integrity-sh.md` |

### 3.5 Dossier avec un seul fichier

| | |
|---|---|
| **Input** | Un seul fichier dans le dossier |
| **Comportement attendu** | Base de 1 ligne, verify OK |
| **Risque** | Comportement des algorithmes de tri et de comparaison sur des ensembles minimaux |
| **Testé par** | Partiellement par T01 — à vérifier explicitement |

---

## Catégorie 4 — Fichiers `.b3`

### 4.1 Base avec une seule ligne

| | |
|---|---|
| **Input** | `.b3` contenant exactement 1 ligne valide |
| **Comportement attendu** | `core_assert_b3_valid` accepte, `verify` fonctionne |
| **Risque** | `comm`, `join` se comportent différemment sur des fichiers à 1 ligne |
| **Testé par** | Non testé explicitement |

### 4.2 Base avec chemins contenant des espaces

| | |
|---|---|
| **Input** | `.b3` dont les chemins contiennent des espaces |
| **Comportement attendu** | `core_compare` gère correctement (offset fixe 67 dans `awk`) |
| **Risque** | Parsing par champ espace-séparé casse le join — bug historique v0.7 |
| **Testé par** | T08 (existant) + CU42/CU43 (unitaires) |

### 4.3 Base avec caractère tabulation dans un chemin

| | |
|---|---|
| **Input** | Chemin contenant `\t` dans le `.b3` |
| **Comportement attendu** | Comportement à définir — `_b3_to_path_hash` utilise `\t` comme séparateur de conversion |
| **Risque** | Corruption du parsing `chemin\thash` si le chemin contient lui-même un `\t` |
| **Testé par** | Non testé — **bug potentiel non investigué** |
| **Action** | Investiguer, documenter le comportement, ajouter un test ou une contrainte explicite |

### 4.4 Deux bases avec des ordres de tri différents

| | |
|---|---|
| **Input** | `old.b3` trié selon `LC_ALL=fr_FR`, `new.b3` trié selon `LC_ALL=C` |
| **Comportement attendu** | `comm` nécessite que les deux fichiers soient triés selon le même ordre |
| **Risque** | Faux positifs ou faux négatifs dans `compare` si les bases ont été produites avec des locales différentes |
| **Testé par** | Non testé |
| **Décision** | Documenter que `compute` doit être exécuté avec `LC_ALL=C` ou équivalent pour garantir la reproductibilité |

---

## Catégorie 5 — Environnement et configuration

### 5.1 `RESULTATS_DIR` avec espaces dans le chemin

| | |
|---|---|
| **Input** | `export RESULTATS_DIR="/tmp/mon dossier/resultats"` |
| **Comportement attendu** | Dossier créé correctement, résultats écrits |
| **Risque** | `mkdir -p` avec un chemin non quoté |
| **Testé par** | Non testé |

### 5.2 `RESULTATS_DIR` non accessible (permissions)

| | |
|---|---|
| **Input** | `RESULTATS_DIR="/root/resultats"` depuis un utilisateur non-root |
| **Comportement attendu** | `core_make_result_dir` lève une erreur explicite via `die()` |
| **Risque** | Erreur cryptique de `mkdir` sans message d'erreur lisible |
| **Testé par** | Non testé |

### 5.3 Appel depuis un répertoire différent du compute

| | |
|---|---|
| **Input** | `compute` lancé depuis `/mnt/data`, `verify` lancé depuis `/home/user` sans argument `[dossier]` |
| **Comportement attendu** | `b3sum --check` échoue (chemins relatifs résolus depuis mauvais répertoire) |
| **Risque** | Confusion utilisateur — tous les fichiers semblent manquants |
| **Testé par** | T14 (partiellement) |
| **Action** | Ajouter un message d'erreur plus explicite dans ce cas de figure |

---

## Tableau de priorité

| Cas | Priorité | Risque réel | Action |
|---|---|---|---|
| Tabulation dans le nom (1.4) | **Haute** | Bug potentiel confirmé dans `_b3_to_path_hash` | Investiguer + tester |
| Fichier taille zéro (2.1) | Haute | Division par zéro ETA | T18 + CU23 |
| Caractères HTML (1.5) | Haute | Injection dans rapport | T16 |
| Newline dans le nom (1.3) | Haute | Comptage incorrect | T15 |
| Espaces multiples (1.2) | Moyenne | Faux positifs dans compare | T15b |
| Lien symbolique (3.4) | Moyenne | Comportement surprenant non documenté | T19 + doc |
| `RESULTATS_DIR` avec espaces (5.1) | Moyenne | Crash silencieux | Test à créer |
| Fichier très volumineux (2.2) | Faible | Couvert par bash 64-bit integers | Documenté, non testé |


--- Fichier : fixtures.md ---
# Fixtures — Spécification de `tests/fixtures/`

---

## Définition

Une fixture est un ensemble de données figées dans un état connu, commitées dans le dépôt git, utilisées comme entrée reproductible pour les tests. Contrairement aux données créées dynamiquement dans `setup()`, les fixtures sont stables entre les runs et entre les machines.

---

## Arborescence cible

```
tests/fixtures/
│
├── data/                              ← jeu de données standard (4 fichiers)
│   ├── alpha.txt
│   ├── beta.txt
│   ├── gamma.txt
│   └── sub/
│       └── delta.txt
│
├── data-edge/                         ← jeu de données avec cas limites
│   ├── fichier avec espaces.txt
│   ├── fichier&special.txt
│   ├── <html>chars.txt
│   ├── .fichier_cache
│   └── zero_bytes.bin
│
├── bases/                             ← bases .b3 de référence
│   ├── reference.b3                   ← hash de data/ — non-régression format
│   └── reference-edge.b3             ← hash de data-edge/ — non-régression edge cases
│
└── reports/                           ← structures HTML de référence
    ├── reference-identiques.html      ← rapport compare sans différences
    └── reference-diff.html            ← rapport compare avec 1 modifié
```

---

## Contenu des fichiers de données

### `data/` — Jeu standard

Ces fichiers sont figés. Ne jamais les modifier sans régénérer `bases/reference.b3`.

**`data/alpha.txt`**
```
contenu alpha
```
(terminé par `\n`, encodage UTF-8, pas de BOM)

**`data/beta.txt`**
```
contenu beta
```

**`data/gamma.txt`**
```
contenu gamma
```

**`data/sub/delta.txt`**
```
contenu delta
```

**Propriétés du jeu standard :**
- 4 fichiers dans 2 niveaux d'arborescence
- Noms ASCII simples, pas de caractères spéciaux
- Contenu textuel court et déterministe
- Suffisant pour tester compute, verify, compare sans ambiguïté

---

### `data-edge/` — Jeu de cas limites

Ces fichiers couvrent les noms et contenus pathologiques.

**`data-edge/fichier avec espaces.txt`**
```
contenu avec espaces dans le nom
```
Utilisé par : T15 (intégration), CU42 (unitaire)

**`data-edge/fichier&special.txt`**
```
contenu avec esperluette dans le nom
```
Utilisé par : T16 (HTML escaping), CU43 (unitaire)

**`data-edge/<html>chars.txt`**
```
contenu avec chevrons dans le nom
```
Utilisé par : T16 (injection HTML dans report.html)

**`data-edge/.fichier_cache`**
```
contenu fichier cache
```
Utilisé par : vérification que `find -type f` indexe les fichiers cachés

**`data-edge/zero_bytes.bin`**
Fichier vide — 0 octet. Créé avec `touch`.

Utilisé par : T18 (ETA sur fichier vide), CU23 (unitaire)

---

### `bases/reference.b3`

Hash BLAKE3 de `data/`, produit par `core_compute` depuis `tests/fixtures/`.

**Procédure de génération :**
```bash
cd tests/fixtures
../../src/integrity.sh compute ./data bases/reference.b3
```

**Contenu attendu (hashes exacts à remplir lors de la génération initiale) :**
```
<hash_alpha>  ./data/alpha.txt
<hash_delta>  ./data/sub/delta.txt
<hash_beta>   ./data/beta.txt
<hash_gamma>  ./data/gamma.txt
```

**Invariants vérifiables sans connaître les hashes :**
- 4 lignes
- Triées lexicographiquement : `alpha` < `sub/delta` < `beta` < `gamma`

  **Attention :** l'ordre lexicographique binaire (LC_ALL=C) donne :
  `./data/alpha.txt` < `./data/beta.txt` < `./data/gamma.txt` < `./data/sub/delta.txt`
  
  Le tri est sur le chemin complet, pas juste le nom du fichier. `sub/delta` vient après `gamma` car `s` > `g`.

- Tous les chemins commencent par `./data/`
- Pas de ligne vide, pas de `\r`

---

### `bases/reference-edge.b3`

Hash BLAKE3 de `data-edge/`.

**Procédure de génération :**
```bash
cd tests/fixtures
../../src/integrity.sh compute ./data-edge bases/reference-edge.b3
```

**Usage :** test de non-régression sur les cas limites — vérifie que les noms de fichiers avec espaces, `&`, `<>` sont correctement traités et indexés.

---

### `reports/reference-identiques.html`

Rapport HTML produit par `compare` quand les deux bases sont identiques (aucune différence).

**Procédure de génération :**
```bash
cd tests/fixtures
# Comparer reference.b3 avec lui-même
RESULTATS_DIR=/tmp/fixtures-gen ../../src/integrity.sh compare bases/reference.b3 bases/reference.b3
cp /tmp/fixtures-gen/resultats_reference/report.html reports/reference-identiques.html
```

**Usage :** test de régression HTML — vérifier que le statut "IDENTIQUES" et les compteurs à zéro sont correctement rendus.

**Ce qui est comparé** (pas le fichier entier — la date change) :
```bash
grep -E '(status-badge|stat-value|IDENTIQUES|DIFFÉRENCES)' reports/reference-identiques.html
```

---

### `reports/reference-diff.html`

Rapport HTML produit quand il y a 1 fichier modifié, 1 disparu, 1 nouveau.

**Procédure de génération :**
```bash
cd tests/fixtures

# Créer une base modifiée
cp -r data/ data-modified/
echo "contenu modifié" > data-modified/beta.txt      # modifié
rm data-modified/gamma.txt                           # disparu
echo "contenu nouveau" > data-modified/epsilon.txt   # nouveau

../../src/integrity.sh compute ./data          bases/reference.b3
../../src/integrity.sh compute ./data-modified bases/reference-modified.b3

RESULTATS_DIR=/tmp/fixtures-gen ../../src/integrity.sh compare \
    bases/reference.b3 bases/reference-modified.b3
cp /tmp/fixtures-gen/resultats_reference/report.html reports/reference-diff.html

rm -rf data-modified bases/reference-modified.b3
```

**Usage :** test de régression HTML — vérifier que les listes de fichiers modifiés/disparus/nouveaux sont présentes et correctement formatées.

---

## Règles de nommage

| Règle | Raison |
|---|---|
| Noms de fichiers en minuscules, tirets comme séparateurs | Cohérence, compatibilité cross-platform |
| Pas d'espace dans les noms des fixtures **elles-mêmes** (dossiers, fichiers `.b3`, `.html`) | Les fixtures sont référencées dans les scripts — les espaces cassent les chemins non quotés |
| Les fichiers dans `data-edge/` peuvent avoir des noms avec caractères spéciaux | C'est leur raison d'être |
| Les fichiers `.b3` et `.html` de référence sont commitées dans git | Ils constituent la définition du comportement attendu |

---

## Procédure d'ajout d'une nouvelle fixture

1. **Identifier le besoin** : quel cas limite ou comportement doit être couvert ?
2. **Créer le fichier** dans le sous-dossier approprié (`data/`, `data-edge/`, ou nouveau sous-dossier).
3. **Documenter le fichier** dans ce document : contenu, usage, tests qui s'en servent.
4. **Régénérer les bases `.b3`** si le jeu de données standard ou edge est modifié.
5. **Commiter avec un message explicite** : `test(fixtures): add <nom> for <raison>`

---

## Ce qui ne doit PAS être dans les fixtures

| Type | Raison |
|---|---|
| Données personnelles | Commitées dans git, publiques |
| Fichiers binaires volumineux (> 1 Mo) | Alourdissent le repo sans valeur ajoutée |
| Fichiers `.b3` produits par des versions différentes de b3sum | Invalides sur d'autres machines |
| Résultats de tests (`recap.txt`, `failed.txt`) | Produits dynamiquement, ne doivent pas être fixés |

---

## Vérification de l'intégrité des fixtures elles-mêmes

Les fixtures peuvent être corrompues si un éditeur modifie les fins de ligne (`\r\n` au lieu de `\n`) ou l'encodage. Un meta-test peut vérifier leur intégrité :

```bash
# Vérifier que les fichiers de données sont en format Unix (pas de CRLF)
test_fixtures_unix_format() {
    local has_crlf=0
    while IFS= read -r -d '' f; do
        if file "$f" | grep -q "CRLF"; then
            fail "fixture en CRLF : $f"
            has_crlf=1
        fi
    done < <(find tests/fixtures/data -type f -print0)
    [ "$has_crlf" -eq 0 ] && pass "fixtures au format Unix"
}

# Vérifier que reference.b3 respecte le format b3sum
test_fixtures_reference_format() {
    local invalid
    invalid=$(grep -cvE '^[0-9a-f]{64}  .+' tests/fixtures/bases/reference.b3 || true)
    [ "$invalid" -eq 0 ] \
        && pass "reference.b3 format valide" \
        || fail "reference.b3 : $invalid ligne(s) invalide(s)"
}
```


--- Fichier : index.md ---
# Tests — Vue d'ensemble

**Scope :** documentation de la stratégie de test de `hash_tool`  
**Statut :** spécification — à implémenter  
**Référence audit :** réponse d'analyse du 24/02/2026

---

## Situation actuelle

| Suite | Fichier | Type | Cas | Statut |
|---|---|---|---|---|
| integrity.sh | `tests/run_tests.sh` | Intégration | T00–T14 | ✅ Existant |
| runner.sh + pipeline | `tests/run_tests_pipeline.sh` | Intégration | TP01–TP12b | ✅ Existant |
| core.sh (unitaires) | `tests/run_tests_core.sh` | Unitaire | — | ❌ À créer |
| Docker + entrypoint | `tests/run_tests_docker.sh` | Environnement | — | ❌ À créer |
| Non-régression .b3 | fixture `tests/fixtures/reference.b3` | Régression | — | ❌ À créer |

**Diagnostic principal :** la pyramide des tests est inversée. Les tests d'intégration sont bien couverts, mais les tests unitaires (`core.sh`) et les tests d'environnement (Docker) sont absents. La CI n'existe pas — les tests ne sont lancés que manuellement.

---

## Suites à créer

### `tests/run_tests_core.sh` — Tests unitaires

Teste chaque fonction de `src/lib/core.sh` en isolation, par sourcing direct, sans passer par `integrity.sh`. Priorité maximale : `core_compare` (algorithme complexe, bug historique en v0.7).

→ Spécification complète : [unit-tests.md](unit-tests.md)

### Extensions de `run_tests.sh` — Edge cases

Ajout des cas T15 à T20+ couvrant les noms de fichiers avec caractères spéciaux, les fichiers vides, les caractères HTML dans les chemins, le mode `--quiet` sur `compare`.

→ Spécification complète : [edge-cases.md](edge-cases.md) et [integration-tests.md](integration-tests.md)

### `tests/fixtures/` — Données de référence

Arborescence de fichiers figés commitée dans git, utilisée pour les tests de non-régression du format `.b3` et les tests de cas limites.

→ Spécification complète : [fixtures.md](fixtures.md) et [regression-tests.md](regression-tests.md)

### `tests/run_tests_docker.sh` — Tests d'environnement

Teste le build Docker, l'entrypoint commande par commande, la taille de l'image, et le comportement multi-plateforme (amd64/arm64).

→ Spécification complète : [docker-tests.md](docker-tests.md)

### CI GitHub Actions

Workflow automatique déclenché à chaque push et PR : jobs unitaires, intégration, Docker, ShellCheck, matrice OS.

→ Spécification complète : [ci-cd.md](ci-cd.md)

---

## Arborescence cible

```
tests/
├── run_tests.sh                   ← existant — intégration integrity.sh (T00–T20+)
├── run_tests_pipeline.sh          ← existant — intégration runner.sh (TP01–TP12b)
├── run_tests_core.sh              ← à créer  — unitaires core.sh
├── run_tests_docker.sh            ← à créer  — environnement Docker
└── fixtures/
    ├── data/
    │   ├── alpha.txt              ← fichier texte standard
    │   ├── beta.txt               ← fichier texte standard
    │   ├── fichier avec espaces.txt
    │   ├── fichier&special.txt
    │   ├── <html>chars.txt
    │   └── zero_bytes.bin         ← fichier de taille zéro
    └── reference.b3               ← hash de référence pour non-régression
```

---

## Ordre d'implémentation recommandé

| Priorité | Livrable | Valeur | Effort |
|---|---|---|---|
| 1 | CI GitHub Actions (squelette minimal) | Détection régression sur PR | ~2h |
| 2 | `run_tests_core.sh` | Isolation des bugs `core.sh` | ~4h |
| 3 | `tests/fixtures/` + non-régression `.b3` | Détection régression silencieuse | ~1h |
| 4 | Edge cases T15–T20 dans `run_tests.sh` | Couverture cas limites | ~2h |
| 5 | `run_tests_docker.sh` | Couverture environnement Docker | ~3h |
| 6 | Format TAP dans toutes les suites | Interopérabilité CI | ~2h |

---

## Règle d'or

> Un test n'a de valeur que s'il est lancé automatiquement à chaque modification.  
> La CI est le seul mécanisme qui garantit cette propriété.  
> Implémenter la CI en premier, avant même d'écrire de nouveaux tests.

---

## Documents de cette section

| Document | Contenu |
|---|---|
| [strategy.md](strategy.md) | Décisions, objectifs de couverture, définition de "done" |
| [unit-tests.md](unit-tests.md) | Spécification `run_tests_core.sh` |
| [integration-tests.md](integration-tests.md) | Extensions `run_tests.sh` et `run_tests_pipeline.sh` |
| [regression-tests.md](regression-tests.md) | Non-régression format `.b3`, fixtures statiques |
| [edge-cases.md](edge-cases.md) | Catalogue des cas limites |
| [docker-tests.md](docker-tests.md) | Spécification `run_tests_docker.sh` |
| [fixtures.md](fixtures.md) | Spécification `tests/fixtures/` |
| [tap-format.md](tap-format.md) | Format TAP, helpers bash |
| [ci-cd.md](ci-cd.md) | Workflow GitHub Actions |


--- Fichier : integration-tests.md ---
# Tests d'intégration — Extensions des suites existantes

---

## Périmètre

Ce document spécifie les cas à ajouter aux suites d'intégration existantes :
- `run_tests.sh` : cas T15 à T20 (extensions de la suite integrity.sh)
- `run_tests_pipeline.sh` : cas TP13 à TP15 (extensions de la suite runner.sh)

Les cas existants T00–T14 et TP01–TP12b ne sont pas modifiés.

---

## Extensions de `run_tests.sh`

### T15 — Fichier avec newline dans le nom

**Motivation :** les noms de fichiers Linux peuvent légalement contenir des newlines. `find | wc -l` ou `xargs` sans `-0` cassent sur ce cas. `mapfile -d ''` et `find -print0` sont censés tenir — ce test le vérifie.

**Précondition :**
```bash
printf "contenu\n" > "$WORKDIR/data/$'nom\navec\nnewline.txt'"
bash "$INTEGRITY" compute ./data base_t15.b3
```

**Assertions :**
- `base_t15.b3` contient exactement autant de lignes que de fichiers dans `./data` (le fichier avec newline compte pour 1)
- `bash "$INTEGRITY" verify base_t15.b3` → exit 0, aucun FAILED

**Oracle :** si le test échoue, `mapfile -d ''` ou `sort -z` ne gèrent pas correctement les newlines dans les noms — le fichier est compté plusieurs fois ou ignoré.

---

### T16 — Caractères HTML dans les noms de fichiers

**Motivation :** `report.html` est généré via `generate_compare_html`. La fonction `html_escape` est censée protéger contre l'injection HTML. Ce test vérifie que les caractères `<`, `>`, `&` dans les noms de fichiers sont bien échappés dans le rapport.

**Précondition :**
```bash
echo "v1" > "$WORKDIR/data_old/<script>alert.txt"
echo "v1" > "$WORKDIR/data_old/a&b.txt"
echo "v2" > "$WORKDIR/data_new/<script>alert.txt"   # modifié
echo "v1" > "$WORKDIR/data_new/a&b.txt"             # inchangé
bash "$INTEGRITY" compute ./data_old base_t16_old.b3
bash "$INTEGRITY" compute ./data_new base_t16_new.b3
bash "$INTEGRITY" compare base_t16_old.b3 base_t16_new.b3
```

**Assertions sur `report.html` :**
- Ne contient PAS la chaîne `<script>` littérale (serait une injection)
- Contient `&lt;script&gt;` (échappement correct)
- Contient `&amp;` pour le `&` de `a&b.txt`
- Est un HTML valide (balises ouvertes = balises fermées, au minimum)

**Oracle :** si `<script>` apparaît littéralement dans le HTML, `html_escape` ne fonctionne pas et le rapport est vulnérable à l'injection.

```bash
# Assertions spécifiques
local html_content
html_content=$(cat "$outdir/report.html")
assert_not_contains "T16 pas de <script> brut"   "<script>"      "$html_content"
assert_contains     "T16 échappement lt/gt"       "&lt;script&gt;" "$html_content"
assert_contains     "T16 échappement esperluette" "&amp;"          "$html_content"
```

---

### T17 — `--quiet` sur `compare`

**Motivation :** T12 couvre `--quiet` sur `verify` et `compute` mais pas sur `compare`. Le mode `--quiet` doit aussi supprimer la sortie de `compare`.

**Précondition :**
```bash
bash "$INTEGRITY" compute ./data base_t17a.b3
echo "contenu modifié" > data/alpha.txt
bash "$INTEGRITY" compute ./data base_t17b.b3
```

**Assertions :**
- `bash "$INTEGRITY" --quiet compare base_t17a.b3 base_t17b.b3` → stdout vide
- Les fichiers de résultats sont quand même produits (`recap.txt`, `modifies.b3`, `report.html`)
- Exit code = 0 (compare ne lève pas d'erreur sur les différences)

```bash
local out_quiet
out_quiet=$(bash "$INTEGRITY" --quiet compare base_t17a.b3 base_t17b.b3 2>&1)
assert_not_contains "T17 stdout vide en quiet"      "Résultats"  "$out_quiet"
assert_not_contains "T17 stdout vide en quiet"      "modifiés"   "$out_quiet"
local outdir
outdir=$(ls -d "${RESULTATS_DIR}/resultats_base_t17a"* 2>/dev/null | tail -1)
assert_file_exists  "T17 recap.txt produit"         "${outdir}/recap.txt"
assert_file_exists  "T17 report.html produit"       "${outdir}/report.html"
```

---

### T18 — Fichier de taille zéro dans compute

**Motivation :** dans `core_compute`, la branche `if (( fsize > 0 ))` protège le calcul ETA quand `fsize == 0`. Ce test vérifie que la présence d'un fichier vide ne plante pas le calcul et que le fichier est quand même indexé.

**Précondition :**
```bash
echo "contenu" > data/normal.txt
touch data/zero.bin    # taille zéro
bash "$INTEGRITY" compute ./data base_t18.b3
```

**Assertions :**
- `base_t18.b3` contient exactement 2 lignes
- La ligne pour `zero.bin` est au format b3sum valide (hash de contenu vide)
- `bash "$INTEGRITY" verify base_t18.b3` → exit 0

**Note :** le hash BLAKE3 d'un fichier vide est déterministe et connu — il peut être utilisé comme assertion dure si nécessaire.

---

### T19 — Lien symbolique dans le dossier source

**Motivation :** le comportement de `find -type f` sur les liens symboliques dépend de la version de `find` et des flags. Par défaut, `find -type f` ne suit pas les liens symboliques — ils sont ignorés. Ce comportement doit être documenté et vérifié.

**Précondition :**
```bash
echo "contenu cible" > data/cible.txt
ln -s data/cible.txt data/lien.txt    # lien symbolique
bash "$INTEGRITY" compute ./data base_t19.b3
```

**Assertions :**
- `base_t19.b3` contient exactement 1 ligne (le lien symbolique est ignoré par `find -type f`)
- La ligne présente correspond à `cible.txt`, pas à `lien.txt`

**Si le comportement attendu change** (décision de suivre les liens) : adapter ce test et documenter la décision dans `architecture.md`.

---

### T20 — Horodatage : deux compare successifs sur la même base

**Motivation :** T13 vérifie l'anti-écrasement pour `verify`. Ce test vérifie le même comportement pour `compare`.

**Précondition :**
```bash
bash "$INTEGRITY" compute ./data base_t20.b3
bash "$INTEGRITY" compare base_t20.b3 base_t20.b3   # compare une base avec elle-même
sleep 1
bash "$INTEGRITY" compare base_t20.b3 base_t20.b3
```

**Assertions :**
- Deux dossiers distincts existent sous `$RESULTATS_DIR` : `resultats_base_t20` et `resultats_base_t20_YYYYMMDD-HHMMSS`

```bash
local nb
nb=$(ls -d "${RESULTATS_DIR}/resultats_base_t20"* 2>/dev/null | wc -l)
[ "$nb" -ge 2 ] && pass "T20 deux dossiers distincts" || fail "T20 écrasement détecté ($nb dossier(s))"
```

---

## Extensions de `run_tests_pipeline.sh`

### TP13 — Pipeline avec verify qui échoue : les blocs suivants ne s'exécutent pas

**Motivation :** `runner.sh` utilise `set -euo pipefail`. Un `verify` qui échoue doit stopper le pipeline immédiatement. Ce comportement n'est pas explicitement testé.

**Précondition :**
```json
{
    "pipeline": [
        { "op": "compute", "source": "$WORKDIR/src_a", "bases": "$WORKDIR/bases", "nom": "tp13.b3" },
        { "op": "verify",  "source": "$WORKDIR/src_a_corrupt", "base": "$WORKDIR/bases/tp13.b3" },
        { "op": "compute", "source": "$WORKDIR/src_b", "bases": "$WORKDIR/bases", "nom": "tp13_b.b3" }
    ]
}
```

Avec `src_a_corrupt` contenant un fichier modifié par rapport à la base.

**Assertions :**
- Exit code du runner ≠ 0
- `tp13_b.b3` n'existe pas (le troisième bloc ne s'est pas exécuté)

---

### TP14 — Champ `nom` avec sous-dossier dans `bases`

**Motivation :** le champ `nom` est concaténé à `bases` via `"$bases_abs/$nom"`. Si `nom` contient un `/`, le comportement doit être défini.

**Cas testé :** `"nom": "sous/hashes.b3"`

**Assertions :**
- Le dossier `$WORKDIR/bases/sous/` est créé automatiquement (via le `mkdir -p` dans `run_compute`)
- `hashes.b3` est créé dans ce sous-dossier
- OU : erreur explicite si les sous-dossiers dans `nom` ne sont pas supportés (dans ce cas, documenter la limite)

---

### TP15 — Pipeline vide (tableau pipeline avec zéro opérations)

**Motivation :** le cas `"pipeline": []` doit être rejeté proprement.

```json
{ "pipeline": [] }
```

**Assertions :**
- Exit code ≠ 0
- Message d'erreur contient "vide" ou "absent"
- Aucun effet de bord (aucun fichier créé)

---

## Tableau de synthèse

| ID | Suite | Motivation principale | Risque si absent |
|---|---|---|---|
| T15 | run_tests.sh | Newlines dans noms | Crash silencieux sur fichiers exotiques |
| T16 | run_tests.sh | Injection HTML dans report.html | Rapport corrompu ou vulnérable |
| T17 | run_tests.sh | `--quiet` sur compare | Mode silencieux partiellement cassé |
| T18 | run_tests.sh | Fichier taille zéro | Crash ETA ou fichier non indexé |
| T19 | run_tests.sh | Liens symboliques | Comportement non documenté et non garanti |
| T20 | run_tests.sh | Anti-écrasement sur compare | Résultats précédents écrasés silencieusement |
| TP13 | run_tests_pipeline.sh | Arrêt sur verify échoué | Pipeline continue après corruption détectée |
| TP14 | run_tests_pipeline.sh | `nom` avec sous-dossier | Comportement indéfini, potentiel crash |
| TP15 | run_tests_pipeline.sh | Pipeline vide | Message d'erreur absent ou cryptique |


--- Fichier : regression-tests.md ---
# Tests de non-régression — Format `.b3` et fixtures statiques

---

## Principe

Un test de non-régression capture un comportement connu et correct, le fige comme référence, puis vérifie à chaque modification que ce comportement est inchangé.

Pour `hash_tool`, le comportement le plus critique à figer est le **format du fichier `.b3`** produit par `core_compute`. Toute modification — même accidentelle — du format de sortie invalide toutes les bases existantes des utilisateurs.

---

## Risques couverts

| Modification silencieuse | Impact utilisateur |
|---|---|
| Changement du séparateur (1 espace au lieu de 2) | Toutes les bases existantes invalides pour `b3sum --check` |
| Changement de l'ordre de tri (locale différente) | `compare` produit des faux positifs massifs |
| Ajout d'un préfixe ou suffixe dans les chemins | `verify` échoue sur toutes les bases existantes |
| Ligne vide en fin de fichier | `core_assert_b3_valid` rejette les bases existantes |
| Retour chariot `\r` introduit | `b3sum --check` échoue sur certains OS |
| Mise à jour de `b3sum` changeant le format de sortie | Rupture totale de compatibilité |

---

## Structure des fixtures

```
tests/fixtures/
├── data/
│   ├── alpha.txt          ← "contenu alpha\n"
│   ├── beta.txt           ← "contenu beta\n"
│   ├── gamma.txt          ← "contenu gamma\n"
│   └── sub/
│       └── delta.txt      ← "contenu delta\n"
└── reference.b3           ← produit par core_compute sur ./data, commité dans git
```

Le contenu de chaque fichier est **figé et documenté**. Ne jamais modifier les fichiers dans `tests/fixtures/data/` sans régénérer `reference.b3` et expliquer le changement dans la PR.

---

## Génération initiale de `reference.b3`

À faire une seule fois, sur une machine avec `b3sum` installé :

```bash
cd tests/fixtures

# Créer les fichiers de données
mkdir -p data/sub
printf "contenu alpha\n" > data/alpha.txt
printf "contenu beta\n"  > data/beta.txt
printf "contenu gamma\n" > data/gamma.txt
printf "contenu delta\n" > data/sub/delta.txt

# Générer la référence via core_compute
# (utiliser integrity.sh pour garantir le même chemin de code)
../../src/integrity.sh compute ./data reference.b3

# Vérifier le contenu
cat reference.b3
# Attendu : 4 lignes, chemins commençant par ./data/, triées, format b3sum

# Commiter
git add data/ reference.b3
git commit -m "test(fixtures): add reference.b3 for format regression tests"
```

---

## Test de non-régression — implémentation

Ce test est à ajouter dans `run_tests.sh` comme cas **T_REG01** (ou dans une section dédiée) :

```bash
echo "T_REG - Non-régression format .b3"

FIXTURES_DIR="$SCRIPT_DIR/fixtures"

# Vérifier que les fixtures existent
[ -d "$FIXTURES_DIR/data" ] || { echo "SKIP - fixtures absentes"; return; }
[ -f "$FIXTURES_DIR/reference.b3" ] || { echo "SKIP - reference.b3 absent"; return; }

# Compute sur les fixtures
( cd "$FIXTURES_DIR" && bash "$INTEGRITY" compute ./data "$WORKDIR/output_reg.b3" >/dev/null 2>&1 )

# Comparaison bit-à-bit
if diff "$FIXTURES_DIR/reference.b3" "$WORKDIR/output_reg.b3" >/dev/null 2>&1; then
    pass "T_REG01 format .b3 stable"
else
    fail "T_REG01 régression du format .b3 détectée"
    echo "  Diff :"
    diff "$FIXTURES_DIR/reference.b3" "$WORKDIR/output_reg.b3" | head -20
fi
```

---

## Contenu attendu de `reference.b3`

Exemple de contenu attendu (les hashes réels dépendent du contenu exact des fichiers) :

```
<hash_alpha_64chars>  ./data/alpha.txt
<hash_delta_64chars>  ./data/sub/delta.txt
<hash_beta_64chars>   ./data/beta.txt
<hash_gamma_64chars>  ./data/gamma.txt
```

**Invariants vérifiables sans connaître les hashes :**
- 4 lignes exactement
- Chaque ligne : 64 chars hex + `  ` (2 espaces) + chemin
- Chemins triés lexicographiquement (`alpha` < `sub/delta` car `a` < `s`)
- Pas de ligne vide
- Pas de `\r` (format Unix)
- Tous les chemins commencent par `./data/`

Ces invariants peuvent être testés indépendamment du contenu des hashes :

```bash
# Test des invariants structurels (sans dépendre de reference.b3)
local b3="$WORKDIR/output_reg.b3"

# Nombre de lignes
assert_line_count "T_REG02 4 fichiers indexés" 4 "$b3"

# Format de chaque ligne
local invalid_lines
invalid_lines=$(grep -cvE '^[0-9a-f]{64}  .+' "$b3" || true)
[ "$invalid_lines" -eq 0 ] && pass "T_REG03 format b3sum valide" || fail "T_REG03 $invalid_lines ligne(s) invalide(s)"

# Pas de retour chariot
assert_not_contains "T_REG04 pas de CRLF" $'\r' "$(cat "$b3")"

# Chemins relatifs
assert_not_contains "T_REG05 pas de chemin absolu" "$(pwd)" "$(cat "$b3")"

# Tri correct
local sorted_check
sorted_check=$(sort "$b3")
[ "$(cat "$b3")" = "$sorted_check" ] && pass "T_REG06 trié" || fail "T_REG06 non trié"
```

---

## Procédure de mise à jour de `reference.b3`

Quand une modification intentionnelle du comportement change le format de sortie :

### Étape 1 — Vérifier que le changement est délibéré

Le test `T_REG01` échoue. Avant toute mise à jour, répondre aux questions :
- Pourquoi le format a-t-il changé ?
- Est-ce documenté dans `CHANGELOG.md` ?
- Les bases `.b3` existantes des utilisateurs sont-elles impactées ?
- Faut-il fournir un outil de migration ?

### Étape 2 — Régénérer

```bash
cd tests/fixtures
../../src/integrity.sh compute ./data reference.b3
```

### Étape 3 — Valider manuellement

```bash
# Vérifier que le nouveau reference.b3 respecte les invariants
wc -l reference.b3                                  # doit afficher 4
grep -cE '^[0-9a-f]{64}  .+' reference.b3          # doit afficher 4
grep -c $'\r' reference.b3 || true                  # doit afficher 0
```

### Étape 4 — Commiter avec un message explicite

```bash
git add reference.b3
git commit -m "fix(fixtures): update reference.b3 — [raison du changement]"
```

### Étape 5 — Le diff dans la PR est un signal de revue obligatoire

Tout reviewer doit inspecter le diff de `reference.b3`. Un diff non expliqué dans le message de commit est un signal d'alerte.

---

## Fixtures supplémentaires pour les tests de régression HTML

Le rapport `report.html` est aussi sujet à régression. Une fixture statique peut capturer la structure HTML attendue :

```
tests/fixtures/
└── reports/
    └── reference_compare_empty.html    ← rapport quand modifies/disparus/nouveaux sont tous vides
    └── reference_compare_diff.html     ← rapport avec 1 modifié, 1 disparu, 1 nouveau
```

Ces fixtures sont plus difficiles à maintenir (le CSS change, la date change). La solution est de comparer uniquement les **parties structurelles** :

```bash
# Extraire et comparer uniquement le statut et les compteurs, pas le CSS ni la date
grep -E '(status-badge|stat-value|section-count)' report.html > /tmp/report_structure.txt
diff tests/fixtures/reports/reference_structure.txt /tmp/report_structure.txt
```


--- Fichier : strategy.md ---
# Stratégie de test — Décisions et objectifs

---

## Contexte

`hash_tool` est un outil de vérification d'intégrité. Une erreur non détectée dans sa logique de comparaison ou de vérification peut conduire à un faux négatif : une corruption de données passant inaperçue. Le niveau d'exigence sur la fiabilité du code est donc élevé, même si l'outil n'opère pas dans un contexte adversarial.

---

## Objectifs de couverture

### Par module

| Module | Type de test requis | Couverture cible |
|---|---|---|
| `src/lib/core.sh` | Unitaire | 100% des fonctions publiques, toutes les branches |
| `src/lib/ui.sh` | Intégration (via integrity.sh) | Chemins nominaux + mode `--quiet` |
| `src/lib/results.sh` | Intégration (via integrity.sh) | Fichiers produits, contenu, cas absent |
| `src/lib/report.sh` | Intégration + edge cases HTML | Échappement, cas vide, cas plein |
| `src/integrity.sh` | Intégration | T00–T20+, tous les modes |
| `runner.sh` | Intégration | TP01–TP12b+, tous les champs JSON |
| `docker/entrypoint.sh` | Environnement | Toutes les commandes, cas d'erreur |
| `Dockerfile` | Build | amd64, arm64, taille image |

### Par type de test

| Type | Suite | Objectif |
|---|---|---|
| Unitaire | `run_tests_core.sh` | Localiser précisément l'origine d'un bug |
| Intégration | `run_tests.sh`, `run_tests_pipeline.sh` | Valider les interfaces entre modules |
| Non-régression | fixture `reference.b3` + diff | Détecter les régressions silencieuses de format |
| Edge cases | T15–T20+ dans `run_tests.sh` | Garantir la robustesse sur les entrées limites |
| Environnement | `run_tests_docker.sh` | Valider l'image Docker et l'entrypoint |

---

## Définition de "done" pour un test

Un test est considéré complet quand :

1. **Il a un nom explicite** décrivant la condition testée et le résultat attendu.  
   Exemple : `test_compare_chemins_avec_esperluette_dans_modifies_b3`

2. **Il est isolé** : il ne dépend d'aucun autre test, d'aucun fichier extérieur au `WORKDIR`, d'aucune variable globale non initialisée localement.

3. **Il est reproductible** : relancé 10 fois dans 10 environnements différents, il donne le même résultat.

4. **Il documente l'oracle** : le commentaire ou le nom du test indique ce qui est vérifié et pourquoi c'est le bon résultat attendu.

5. **Il nettoie après lui** : tout fichier temporaire créé est supprimé, même en cas d'échec (via `trap EXIT`).

6. **Il passe ShellCheck** sans warning.

---

## Politique ShellCheck

ShellCheck zéro warning est une condition bloquante. Aucune PR ne peut merger si ShellCheck produit un warning sur les fichiers suivants :

```
src/integrity.sh
runner.sh
src/lib/core.sh
src/lib/ui.sh
src/lib/results.sh
src/lib/report.sh
docker/entrypoint.sh
tests/run_tests.sh
tests/run_tests_pipeline.sh
tests/run_tests_core.sh        ← nouveau
tests/run_tests_docker.sh      ← nouveau
```

Commande de vérification :
```bash
shellcheck src/integrity.sh runner.sh src/lib/*.sh docker/entrypoint.sh tests/*.sh
```

---

## Règles d'écriture des tests

### Isolation

```bash
# ✓ Correct : WORKDIR isolé par test ou par suite
local WORKDIR
WORKDIR=$(mktemp -d /tmp/integrity-test.XXXXXX)
trap "rm -rf '$WORKDIR'" EXIT
```

```bash
# ✓ Correct : cd isolé dans un sous-shell
( cd "$WORKDIR" && bash "$INTEGRITY" compute . base.b3 )
```

```bash
# ❌ Interdit : cd sans sous-shell
cd "$WORKDIR"
bash "$INTEGRITY" compute . base.b3
# Le répertoire courant fuit vers les tests suivants
```

### Variables d'environnement

```bash
# ✓ Correct : RESULTATS_DIR local à la suite
export RESULTATS_DIR="$WORKDIR/resultats"

# ❌ Interdit : RESULTATS_DIR global non réinitialisé entre les suites
```

### Assertions

Toute assertion doit produire un message explicite en cas d'échec :

```bash
# ✓ Correct
assert_contains "modifies.b3 contient beta.txt" "beta.txt" "$(cat modifies.b3)"

# ❌ Insuffisant
[ -s modifies.b3 ] && pass "ok" || fail "ko"
# → en cas d'échec, impossible de savoir ce qui était attendu
```

### Nettoyage garanti

```bash
# Pattern obligatoire pour tout fichier temporaire
local tmpfile
tmpfile=$(mktemp)
trap "rm -f '$tmpfile'" EXIT
# ... utilisation de tmpfile ...
# Pas besoin de rm explicite — le trap s'en charge
```

---

## Politique de mise à jour des fixtures

Quand un test de non-régression échoue suite à une modification intentionnelle du comportement :

1. Vérifier que la modification est délibérée et documentée dans `CHANGELOG.md`.
2. Regénérer la fixture : `cd tests/fixtures && ../../src/integrity.sh compute ./data reference.b3`
3. Commiter `reference.b3` avec un message explicite : `fix(fixtures): update reference.b3 after sort order change in core_compute`
4. Le diff de `reference.b3` dans la PR est un signal de revue — tout reviewer doit l'examiner.

---

## Politique de mise à jour des suites existantes

À chaque bug corrigé dans le code, un test de non-régression couvrant ce bug doit être ajouté **dans la même PR**. Référence : le changelog documente trois bugs qui auraient été détectés plus tôt avec des tests unitaires (v0.6 : `grep -c '.'`, `sort -k2` ; v0.7 : parsing `awk $2` sur chemins avec espaces).

---

## Ce qui n'est pas testé — limites acceptées

| Scénario | Raison de l'exclusion |
|---|---|
| Performances / temps d'exécution | Trop dépendant du matériel, faux positifs en CI |
| Comportement sur systèmes de fichiers exotiques (NTFS, exFAT) | Environnement CI Linux uniquement |
| Internationalisation (noms de fichiers non UTF-8) | Comportement documenté comme "octets opaques", hors scope |
| Comportement sur bash 3.x (macOS défaut) | Rejeté explicitement par `integrity.sh` au démarrage |
| Concurrence / appels parallèles | `hash_tool` est mono-processus par conception |


--- Fichier : tap-format.md ---
# Format TAP — Spécification et implémentation

---

## Qu'est-ce que TAP ?

TAP (Test Anything Protocol) est un format texte standard pour les résultats de tests. Créé en 1987 pour Perl, il est aujourd'hui supporté par la quasi-totalité des systèmes CI et des outils de test multi-langages.

**Avantage principal :** TAP est lisible par un humain ET parseable par une machine sans configuration supplémentaire. GitHub Actions, GitLab CI, Jenkins et des dizaines d'autres outils savent afficher des rapports visuels à partir de TAP.

---

## Format TAP 14 — Syntaxe

```
TAP version 14
1..N
ok 1 - description du test
not ok 2 - description du test échoué
# commentaire ou diagnostic (ignoré par les parseurs)
ok 3 - description
not ok 4 - test avec diagnostic
  ---
  message: valeur attendue
  found: valeur obtenue
  ...
```

### Règles

| Élément | Syntaxe | Obligatoire |
|---|---|---|
| Déclaration de version | `TAP version 14` | Recommandé, première ligne |
| Plan | `1..N` (N = nombre total de tests) | Oui — doit apparaître avant ou après les tests |
| Test réussi | `ok N - description` | — |
| Test échoué | `not ok N - description` | — |
| Diagnostic | `# texte libre` | Non |
| YAML block (détail d'échec) | `  ---\n  clé: valeur\n  ...` | Non |
| Test ignoré | `ok N - description # SKIP raison` | Non |
| Test attendu en échec | `not ok N - description # TODO raison` | Non |

---

## Implémentation dans les suites bash

### Helpers à inclure dans chaque suite

```bash
#!/usr/bin/env bash
# helpers-tap.sh — à sourcer dans chaque suite de tests
# Usage : source helpers-tap.sh

TAP_TOTAL=0
TAP_PASS=0
TAP_FAIL=0
TAP_TESTS=()   # tableau des résultats pour le plan final

# Déclare le plan en tête (si le nombre est connu à l'avance)
# Usage : tap_plan 42
tap_plan() {
    echo "TAP version 14"
    echo "1..$1"
}

# Enregistre un succès
# Usage : tap_ok "description du test"
tap_ok() {
    TAP_TOTAL=$(( TAP_TOTAL + 1 ))
    TAP_PASS=$(( TAP_PASS + 1 ))
    printf "ok %d - %s\n" "$TAP_TOTAL" "$1"
}

# Enregistre un échec avec diagnostic optionnel
# Usage : tap_not_ok "description" ["message de diagnostic"]
tap_not_ok() {
    TAP_TOTAL=$(( TAP_TOTAL + 1 ))
    TAP_FAIL=$(( TAP_FAIL + 1 ))
    printf "not ok %d - %s\n" "$TAP_TOTAL" "$1"
    if [ -n "${2:-}" ]; then
        printf "  ---\n  message: %s\n  ...\n" "$2"
    fi
}

# Skip un test avec raison
# Usage : tap_skip "description" "raison du skip"
tap_skip() {
    TAP_TOTAL=$(( TAP_TOTAL + 1 ))
    printf "ok %d - %s # SKIP %s\n" "$TAP_TOTAL" "$1" "$2"
}

# Affiche le résumé final (quand le plan n'est pas connu à l'avance)
tap_summary() {
    echo "1..$TAP_TOTAL"
    echo "# Tests : $TAP_TOTAL | Passés : $TAP_PASS | Échecs : $TAP_FAIL"
}

# Assertions de haut niveau construites sur tap_ok/tap_not_ok

# assert_exit_zero <label> <commande...>
assert_exit_zero() {
    local label="$1"; shift
    if "$@" >/dev/null 2>&1; then
        tap_ok "$label"
    else
        tap_not_ok "$label" "commande a retourné exit non-zéro : $*"
    fi
}

# assert_exit_nonzero <label> <commande...>
assert_exit_nonzero() {
    local label="$1"; shift
    if ! "$@" >/dev/null 2>&1; then
        tap_ok "$label"
    else
        tap_not_ok "$label" "commande aurait dû échouer : $*"
    fi
}

# assert_contains <label> <pattern> <chaine>
assert_contains() {
    local label="$1" pattern="$2" string="$3"
    if echo "$string" | grep -q "$pattern"; then
        tap_ok "$label"
    else
        tap_not_ok "$label" "pattern '$pattern' absent dans : $(echo "$string" | head -3)"
    fi
}

# assert_not_contains <label> <pattern> <chaine>
assert_not_contains() {
    local label="$1" pattern="$2" string="$3"
    if ! echo "$string" | grep -q "$pattern"; then
        tap_ok "$label"
    else
        tap_not_ok "$label" "pattern '$pattern' présent à tort dans : $(echo "$string" | head -3)"
    fi
}

# assert_file_exists <label> <fichier>
assert_file_exists() {
    local label="$1" file="$2"
    if [ -f "$file" ]; then
        tap_ok "$label"
    else
        tap_not_ok "$label" "fichier absent : $file"
    fi
}

# assert_file_absent <label> <fichier>
assert_file_absent() {
    local label="$1" file="$2"
    if [ ! -f "$file" ]; then
        tap_ok "$label"
    else
        tap_not_ok "$label" "fichier présent à tort : $file"
    fi
}

# assert_line_count <label> <expected> <fichier>
assert_line_count() {
    local label="$1" expected="$2" file="$3"
    local actual
    actual=$(wc -l < "$file")
    if [ "$actual" -eq "$expected" ]; then
        tap_ok "$label"
    else
        tap_not_ok "$label" "attendu $expected lignes, obtenu $actual"
    fi
}

# assert_eq <label> <expected> <actual>
assert_eq() {
    local label="$1" expected="$2" actual="$3"
    if [ "$expected" = "$actual" ]; then
        tap_ok "$label"
    else
        tap_not_ok "$label" "attendu '$expected', obtenu '$actual'"
    fi
}
```

---

## Exemple de sortie TAP pour `run_tests_core.sh`

```
TAP version 14
1..53
ok 1 - CU01 fichier absent → exit 1
ok 2 - CU02 chemin est un dossier → exit 1
ok 3 - CU03 fichier vide → exit 1
ok 4 - CU04 format invalide → exit 1
ok 5 - CU05 hash trop court → exit 1
ok 6 - CU06 hash trop long → exit 1
ok 7 - CU07 hash avec majuscules → exit 1
ok 8 - CU08 ligne valide unique → exit 0
ok 9 - CU09 plusieurs lignes valides → exit 0
not ok 10 - CU10 mélange valide/invalide → exit 1
  ---
  message: attendu exit 1, obtenu 0
  ...
ok 11 - CU11 label dans message d'erreur
# T_CORE02 - core_assert_target_valid
ok 12 - CU12 dossier absent → exit 1
...
```

---

## Intégration avec GitHub Actions

GitHub Actions ne parse pas TAP nativement, mais plusieurs actions le font :

### Option 1 — `dorny/test-reporter`

```yaml
- name: Run tests (TAP output)
  run: cd tests && ./run_tests_core.sh > /tmp/core-results.tap || true

- name: Publish test results
  uses: dorny/test-reporter@v1
  if: always()
  with:
    name: Unit Tests
    path: /tmp/core-results.tap
    reporter: tap
```

### Option 2 — Conversion TAP → JUnit XML (plus universelle)

```bash
# Installer tap-junit
npm install -g tap-junit

# Dans la CI
cd tests && ./run_tests_core.sh | tap-junit --name "core" > /tmp/core-junit.xml
```

```yaml
- uses: mikepenz/action-junit-report@v4
  with:
    report_paths: /tmp/*-junit.xml
```

### Option 3 — Sortie colorée en terminal, TAP en CI

Détecter si on est en CI et adapter le format :

```bash
# En tête de chaque suite
if [ -n "${CI:-}" ]; then
    # Format TAP pour la CI
    tap_ok()     { printf "ok %d - %s\n"     "$((++TAP_TOTAL))" "$1"; }
    tap_not_ok() { printf "not ok %d - %s\n" "$((++TAP_TOTAL))" "$1"; TAP_FAIL=$((TAP_FAIL+1)); }
else
    # Format coloré pour le terminal local
    GREEN='\033[0;32m'; RED='\033[0;31m'; NC='\033[0m'
    tap_ok()     { echo -e "${GREEN}  PASS${NC} - $1"; }
    tap_not_ok() { echo -e "${RED}  FAIL${NC} - $1"; TAP_FAIL=$((TAP_FAIL+1)); }
fi
```

---

## Stratégie de migration des suites existantes

Les suites `run_tests.sh` et `run_tests_pipeline.sh` utilisent actuellement des helpers `pass()`/`fail()` avec sortie colorée. La migration vers TAP se fait en deux étapes :

### Étape 1 — Compatibilité ascendante

Remplacer les helpers existants par les helpers TAP tout en conservant la sortie colorée en mode terminal. Seul le format change en CI (`CI` est défini automatiquement dans GitHub Actions).

Avant :
```bash
PASS=0; FAIL=0; TOTAL=0
pass() { echo -e "${GREEN}  PASS${NC} - $1"; ((PASS++)); ((TOTAL++)); }
fail() { echo -e "${RED}  FAIL${NC} - $1"; ((FAIL++)); ((TOTAL++)); }
```

Après (compatible backward + TAP en CI) :
```bash
source "$(dirname "$0")/helpers-tap.sh"
```

### Étape 2 — Extraction dans `tests/helpers-tap.sh`

Extraire les helpers dans un fichier commun sourcé par toutes les suites. Avantage : un seul endroit à maintenir.

```
tests/
├── helpers-tap.sh             ← helpers communs (nouveau)
├── run_tests.sh               ← source helpers-tap.sh
├── run_tests_pipeline.sh      ← source helpers-tap.sh
├── run_tests_core.sh          ← source helpers-tap.sh
└── run_tests_docker.sh        ← source helpers-tap.sh
```

---

## Plan pour `run_tests_core.sh`

Si le nombre total de tests est connu à l'avance (53 cas dans la spécification `unit-tests.md`), utiliser un plan en tête :

```bash
echo "TAP version 14"
echo "1..53"
```

Si le nombre évolue fréquemment (développement actif), utiliser un plan en queue :

```bash
# ... tous les tests ...
tap_summary   # affiche "1..N" en fin de fichier
```

TAP 14 supporte les deux positions pour le plan.


--- Fichier : test docker.md ---
Non, pas vraiment. Voici ce qui existe et ce qui manque :

**Ce qui existe :** zéro test Docker dans les suites actuelles. `entrypoint.sh` n'est jamais testé automatiquement. Le Dockerfile n'est jamais buildé en CI. La seule "vérification" Docker est manuelle : `docker run --rm hash_tool version` que l'utilisateur peut faire à la main.

**Ce qui manque concrètement :**

*Tests de build :*
- Que le `docker build` réussit (pas d'erreur de syntaxe Dockerfile, pas de package Alpine introuvable, `b3sum` bien installé)
- Que l'image produite fait bien ~14 Mo et pas 500 Mo (régression de taille)
- Que le build fonctionne en `--platform linux/arm64` (les NAS Synology)

*Tests de l'entrypoint :*
- `docker run hash_tool help` → exit 0, affiche de l'aide
- `docker run hash_tool commande_inconnue` → exit 1, message d'erreur propre
- `docker run hash_tool version` → affiche les versions de b3sum, jq, bash
- `docker run hash_tool compute /data /bases/test.b3` avec volumes montés → produit le fichier .b3
- `docker run hash_tool --quiet verify ...` → le flag `--quiet` est bien transmis à `integrity.sh`
- `docker run hash_tool runner /pipelines/pipeline.json` → pipeline exécuté

*Tests d'environnement (que les outils dans l'image sont bien ceux attendus) :*
```bash
# Vérifier que b3sum est la bonne version et fonctionne
docker run --rm hash_tool b3sum --version
# Vérifier que jq est présent
docker run --rm hash_tool jq --version
# Vérifier que bash >= 4
docker run --rm hash_tool bash -c 'echo $BASH_VERSION'
```

*Test de régression de l'image :*
```bash
# Taille de l'image — détecter une régression (ex: on ajoute python par erreur)
SIZE=$(docker image inspect hash_tool --format='{{.Size}}')
[ $SIZE -lt 20000000 ] || echo "FAIL : image trop lourde ($SIZE octets)"
```

*Tests multi-plateforme :*
```bash
docker buildx build --platform linux/amd64,linux/arm64 -t hash_tool:multiarch .
# Vérifier que les deux architectures produisent les mêmes résultats sur un même jeu de fichiers
```

Ce serait un fichier `tests/run_tests_docker.sh` séparé, conditionné à la présence de Docker (`command -v docker`), et un job distinct dans la CI GitHub Actions — parce que le build Docker est lent (~2-3 min) et ne doit pas bloquer les tests unitaires rapides.

--- Fichier : unit-tests.md ---
# Tests unitaires — Spécification `run_tests_core.sh`

---

## Principe

`run_tests_core.sh` source directement `src/lib/core.sh` (et `src/lib/ui.sh` pour `die()`) sans passer par `integrity.sh`. Chaque fonction de `core.sh` est testée en isolation.

```bash
#!/usr/bin/env bash
set -euo pipefail

SCRIPT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"
WORKDIR="$(mktemp -d /tmp/integrity-core-test.XXXXXX)"
export RESULTATS_DIR="$WORKDIR/resultats"
QUIET=0

# Sourcing direct — pas d'appel à integrity.sh
source "$SCRIPT_DIR/../src/lib/ui.sh"
source "$SCRIPT_DIR/../src/lib/core.sh"

teardown() { rm -rf "$WORKDIR"; }
trap teardown EXIT
```

---

## Fonctions à tester

### `core_assert_b3_valid`

**Signature :** `core_assert_b3_valid <fichier> [label]`

| ID | Cas | Input | Résultat attendu |
|---|---|---|---|
| CU01 | Fichier absent | `/tmp/inexistant_xyz.b3` | exit 1, message "introuvable" sur stderr |
| CU02 | Chemin est un dossier | `mkdir /tmp/un_dossier` | exit 1, message "est un dossier" |
| CU03 | Fichier vide | `touch /tmp/vide.b3` | exit 1, message "fichier vide" |
| CU04 | Ligne au format invalide | `echo "pas_un_hash  chemin"` | exit 1, message "format invalide" |
| CU05 | Hash trop court (63 chars) | `echo "abc...63chars  ./f.txt"` | exit 1 |
| CU06 | Hash trop long (65 chars) | `echo "abc...65chars  ./f.txt"` | exit 1 |
| CU07 | Hash avec majuscules | `echo "ABC...64chars  ./f.txt"` | exit 1 — format b3sum est minuscule |
| CU08 | Ligne valide unique | `echo "aaa...64zeros  ./f.txt"` | exit 0 |
| CU09 | Plusieurs lignes valides | 4 lignes correctes | exit 0 |
| CU10 | Mélange valide + invalide | 3 valides + 1 invalide | exit 1, message "ligne(s) ne respectent pas" |
| CU11 | Label personnalisé dans message d'erreur | `core_assert_b3_valid /tmp/vide.b3 "ma base"` | stderr contient "ma base" |

```bash
# Exemple d'implémentation — CU04
test_cu04_format_invalide() {
    local f="$WORKDIR/bad.b3"
    echo "pas_un_hash  ./fichier.txt" > "$f"
    local out
    out=$(core_assert_b3_valid "$f" 2>&1) && fail "CU04 doit exit 1" || {
        assert_contains "CU04 message format invalide" "format invalide" "$out"
    }
}
```

---

### `core_assert_target_valid`

**Signature :** `core_assert_target_valid <dossier>`

| ID | Cas | Input | Résultat attendu |
|---|---|---|---|
| CU12 | Dossier absent | `/tmp/inexistant_xyz/` | exit 1, message "introuvable" |
| CU13 | Chemin est un fichier | `touch /tmp/unfichier` | exit 1, message "n'est pas un dossier" |
| CU14 | Dossier vide | `mkdir /tmp/vide` | exit 1, message "aucun fichier régulier" |
| CU15 | Dossier avec un fichier | `echo "x" > /tmp/d/f.txt` | exit 0 |
| CU16 | Dossier avec sous-dossiers uniquement vides | `mkdir /tmp/d/sub` | exit 1 — aucun fichier régulier |
| CU17 | Dossier avec fichiers dans sous-dossiers | `echo "x" > /tmp/d/sub/f.txt` | exit 0 |

---

### `core_compute`

**Signature :** `core_compute <dossier> <fichier_sortie> [callback]`

| ID | Cas | Condition | Résultat attendu |
|---|---|---|---|
| CU18 | Cas nominal sans callback | 3 fichiers, callback="" | hashfile produit, 3 lignes, format correct |
| CU19 | Format des lignes | 1 fichier connu | ligne = `[0-9a-f]{64}  <chemin>` |
| CU20 | Tri des chemins | 3 fichiers désordonnés | lignes triées par chemin (ordre lexicographique) |
| CU21 | Chemin relatif préservé | `compute ./data base.b3` depuis `/tmp` | chemins commencent par `./data/` |
| CU22 | Fichier avec espace dans le nom | `"fichier test.txt"` | une seule ligne, chemin correct |
| CU23 | Fichier de taille zéro | `touch zero.bin` | ligne présente, bytes_done non affecté |
| CU24 | Callback appelé N fois | 5 fichiers, callback compteur | callback appelé exactement 5 fois |
| CU25 | Callback reçoit les bons arguments | 1 fichier, callback loggeur | args (i, total, bytes_done, total_bytes, eta) cohérents |
| CU26 | Aucune ligne ETA dans hashfile | compute avec callback actif | hashfile ne contient pas "ETA" ni `\r` |
| CU27 | Idempotence | compute 2× sur même dossier | les deux hashfiles sont identiques |

```bash
# Exemple — CU24 : callback appelé N fois
test_cu24_callback_count() {
    local dir="$WORKDIR/data_cu24"
    mkdir -p "$dir"
    for i in 1 2 3 4 5; do echo "contenu $i" > "$dir/f$i.txt"; done

    local count=0
    _counter_callback() { count=$((count + 1)); }

    core_compute "$dir" "$WORKDIR/base_cu24.b3" "_counter_callback"
    [ "$count" -eq 5 ] && pass "CU24 callback appelé 5 fois" || fail "CU24 callback appelé $count fois (attendu 5)"
}
```

---

### `core_verify`

**Signature :** `core_verify <fichier_b3_absolu>`

Le répertoire courant doit être celui d'origine du compute avant l'appel.

| ID | Cas | Condition | Résultat attendu |
|---|---|---|---|
| CU28 | Tous les fichiers intègres | base correcte, fichiers inchangés | exit 0, CORE_VERIFY_STATUS="OK" |
| CU29 | Un fichier corrompu | contenu modifié après compute | exit 1, STATUS="ECHEC", NB_FAIL=1 |
| CU30 | Plusieurs fichiers corrompus | 2 fichiers modifiés | exit 1, NB_FAIL=2 |
| CU31 | Un fichier supprimé | rm après compute | exit 1, LINES_FAIL contient le chemin |
| CU32 | Variables CORE_VERIFY_* positionnées | cas nominal | toutes les variables sont non nulles et cohérentes |
| CU33 | CORE_VERIFY_NB_OK correct | 4 fichiers intègres | NB_OK=4 |
| CU34 | CORE_VERIFY_LINES_FAIL contient les bons chemins | 1 corruption sur beta.txt | LINES_FAIL contient "beta.txt" |
| CU35 | STATUS="ERREUR" si b3sum rapporte une erreur | fichier illisible (chmod 000) | STATUS="ERREUR" |

```bash
# Exemple — CU29
test_cu29_corruption_detectee() {
    local dir="$WORKDIR/data_cu29"
    mkdir -p "$dir"
    echo "contenu original" > "$dir/alpha.txt"
    local base="$WORKDIR/base_cu29.b3"

    ( cd "$dir" && core_compute . "$base" "" )

    echo "contenu corrompu" > "$dir/alpha.txt"

    local exit_code=0
    ( cd "$dir" && core_verify "$(cd "$WORKDIR" && pwd)/base_cu29.b3" ) || exit_code=$?

    [ "$exit_code" -ne 0 ] && pass "CU29 exit code non-zéro" || fail "CU29 doit détecter la corruption"
    [ "$CORE_VERIFY_STATUS" = "ECHEC" ] && pass "CU29 STATUS=ECHEC" || fail "CU29 STATUS=$CORE_VERIFY_STATUS"
}
```

---

### `core_compare`

**Signature :** `core_compare <old> <new> <outdir>`

C'est la fonction la plus critique — un bug ici produit de faux positifs massifs (cf. v0.7).

| ID | Cas | Condition | Résultat attendu |
|---|---|---|---|
| CU36 | Bases identiques | même contenu | modifies.b3 vide, disparus.txt vide, nouveaux.txt vide |
| CU37 | Un fichier modifié | beta.txt changé | modifies.b3 contient beta.txt, NB_MOD=1 |
| CU38 | Plusieurs fichiers modifiés | 3 fichiers changés | NB_MOD=3, les 3 chemins dans modifies.b3 |
| CU39 | Un fichier disparu | alpha.txt supprimé dans new | disparus.txt contient alpha.txt, NB_DIS=1 |
| CU40 | Un fichier nouveau | epsilon.txt ajouté dans new | nouveaux.txt contient epsilon.txt, NB_NOU=1 |
| CU41 | Combinaison modifié + disparu + nouveau | — | les 3 fichiers dans les 3 listes correctes |
| CU42 | Chemin avec espace | `"fichier test.txt"` modifié | modifies.b3 contient le chemin complet avec espace |
| CU43 | Chemin avec `&` | `"a&b.txt"` modifié | chemin correct dans modifies.b3 |
| CU44 | Chemin avec `<` et `>` | `"<script>.txt"` modifié | chemin correct (pas d'échappement HTML dans .b3) |
| CU45 | Format de modifies.b3 | 1 fichier modifié | ligne = `nouveau_hash  chemin` (format b3sum) |
| CU46 | Variables CORE_COMPARE_NB_* | — | NB_MOD, NB_DIS, NB_NOU corrects |
| CU47 | Fichiers tmp nettoyés | après appel | aucun fichier dans /tmp commençant par le pattern mktemp |
| CU48 | outdir doit exister avant l'appel | outdir absent | comportement défini (mkdir requis par l'appelant) |

```bash
# Exemple — CU42 : chemin avec espace
test_cu42_chemin_avec_espace() {
    local dir_old="$WORKDIR/old_cu42"
    local dir_new="$WORKDIR/new_cu42"
    mkdir -p "$dir_old" "$dir_new"

    echo "contenu v1" > "$dir_old/fichier avec espace.txt"
    echo "contenu v2" > "$dir_new/fichier avec espace.txt"

    ( cd "$dir_old" && core_compute . "$WORKDIR/old_cu42.b3" "" )
    ( cd "$dir_new" && core_compute . "$WORKDIR/new_cu42.b3" "" )

    local outdir="$WORKDIR/result_cu42"
    mkdir -p "$outdir"
    core_compare "$WORKDIR/old_cu42.b3" "$WORKDIR/new_cu42.b3" "$outdir"

    assert_contains "CU42 chemin avec espace dans modifies.b3" \
        "fichier avec espace.txt" \
        "$(cat "$outdir/modifies.b3")"
    [ "$CORE_COMPARE_NB_MOD" -eq 1 ] && pass "CU42 NB_MOD=1" || fail "CU42 NB_MOD=$CORE_COMPARE_NB_MOD"
}
```

---

### `core_make_result_dir`

**Signature :** `core_make_result_dir <fichier_b3> <resultats_dir>`

| ID | Cas | Condition | Résultat attendu |
|---|---|---|---|
| CU49 | Création normale | dossier parent existe, pas de collision | dossier `resultats_<nom>` créé, chemin retourné sur stdout |
| CU50 | Anti-collision — dossier existant | `resultats_<nom>` déjà présent | nouveau dossier `resultats_<nom>_YYYYMMDD-HHMMSS` créé |
| CU51 | Deux appels successifs | sleep 1 entre les deux | deux dossiers distincts |
| CU52 | Nom sans extension .b3 | fichier nommé `base` (sans .b3) | dossier `resultats_base` |
| CU53 | Nom avec chemin imbriqué | `/chemin/vers/hashes.b3` | dossier `resultats_hashes` (basename only) |

---

## Structure du fichier `run_tests_core.sh`

```bash
#!/usr/bin/env bash
# run_tests_core.sh - Tests unitaires de src/lib/core.sh
# Usage : cd tests && ./run_tests_core.sh
# Prérequis : bash >= 4, b3sum

set -euo pipefail

SCRIPT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"
WORKDIR="$(mktemp -d /tmp/integrity-core-test.XXXXXX)"
export RESULTATS_DIR="$WORKDIR/resultats"
QUIET=0

source "$SCRIPT_DIR/../src/lib/ui.sh"
source "$SCRIPT_DIR/../src/lib/core.sh"

# Helpers identiques à run_tests.sh
PASS=0; FAIL=0; TOTAL=0
pass() { ... }
fail() { ... }
assert_contains() { ... }
assert_exit_nonzero() { ... }

teardown() { rm -rf "$WORKDIR"; }
trap teardown EXIT

# == Tests =====================================================================

echo "T_CORE01 - core_assert_b3_valid"
# ... cas CU01 à CU11

echo "T_CORE02 - core_assert_target_valid"
# ... cas CU12 à CU17

echo "T_CORE03 - core_compute"
# ... cas CU18 à CU27

echo "T_CORE04 - core_verify"
# ... cas CU28 à CU35

echo "T_CORE05 - core_compare"
# ... cas CU36 à CU48

echo "T_CORE06 - core_make_result_dir"
# ... cas CU49 à CU53

# == Résultats =================================================================
echo "========================================"
[ "$FAIL" -eq 0 ] \
    && echo "  $PASS/$TOTAL tests passés" \
    || echo "  $PASS/$TOTAL passés - $FAIL échec(s)"
echo "========================================"
[ "$FAIL" -eq 0 ]
```

---

## Précautions spécifiques au sourcing

Quand `core.sh` est sourcé directement, les fonctions internes `_b3_to_path_hash` et `_core_file_size` sont aussi accessibles. Elles peuvent être testées unitairement si nécessaire :

```bash
# Test de la fonction interne _b3_to_path_hash
test_b3_to_path_hash_format() {
    local f="$WORKDIR/sample.b3"
    printf '%0.s0' {1..64} > /tmp/hash64  # 64 zéros
    echo "$(cat /tmp/hash64)  ./dossier/fichier.txt" > "$f"

    local result
    result=$(_b3_to_path_hash "$f")
    # Attendu : "./dossier/fichier.txt\t0000...64zeros"
    echo "$result" | grep -q $'./dossier/fichier.txt\t' \
        && pass "_b3_to_path_hash format correct" \
        || fail "_b3_to_path_hash format incorrect : $result"
}
```




--- Fichier : hors_git/tests/TODO -- tests/unit-tests.md ---
# Tests unitaires — Spécification `run_tests_core.sh`

---

## Principe

`run_tests_core.sh` source directement `src/lib/core.sh` (et `src/lib/ui.sh` pour `die()`) sans passer par `integrity.sh`. Chaque fonction de `core.sh` est testée en isolation.

```bash
#!/usr/bin/env bash
set -euo pipefail

SCRIPT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"
WORKDIR="$(mktemp -d /tmp/integrity-core-test.XXXXXX)"
export RESULTATS_DIR="$WORKDIR/resultats"
QUIET=0

# Sourcing direct — pas d'appel à integrity.sh
source "$SCRIPT_DIR/../src/lib/ui.sh"
source "$SCRIPT_DIR/../src/lib/core.sh"

teardown() { rm -rf "$WORKDIR"; }
trap teardown EXIT
```

---

## Fonctions à tester

### `core_assert_b3_valid`

**Signature :** `core_assert_b3_valid <fichier> [label]`

| ID | Cas | Input | Résultat attendu |
|---|---|---|---|
| CU01 | Fichier absent | `/tmp/inexistant_xyz.b3` | exit 1, message "introuvable" sur stderr |
| CU02 | Chemin est un dossier | `mkdir /tmp/un_dossier` | exit 1, message "est un dossier" |
| CU03 | Fichier vide | `touch /tmp/vide.b3` | exit 1, message "fichier vide" |
| CU04 | Ligne au format invalide | `echo "pas_un_hash  chemin"` | exit 1, message "format invalide" |
| CU05 | Hash trop court (63 chars) | `echo "abc...63chars  ./f.txt"` | exit 1 |
| CU06 | Hash trop long (65 chars) | `echo "abc...65chars  ./f.txt"` | exit 1 |
| CU07 | Hash avec majuscules | `echo "ABC...64chars  ./f.txt"` | exit 1 — format b3sum est minuscule |
| CU08 | Ligne valide unique | `echo "aaa...64zeros  ./f.txt"` | exit 0 |
| CU09 | Plusieurs lignes valides | 4 lignes correctes | exit 0 |
| CU10 | Mélange valide + invalide | 3 valides + 1 invalide | exit 1, message "ligne(s) ne respectent pas" |
| CU11 | Label personnalisé dans message d'erreur | `core_assert_b3_valid /tmp/vide.b3 "ma base"` | stderr contient "ma base" |

```bash
# Exemple d'implémentation — CU04
test_cu04_format_invalide() {
    local f="$WORKDIR/bad.b3"
    echo "pas_un_hash  ./fichier.txt" > "$f"
    local out
    out=$(core_assert_b3_valid "$f" 2>&1) && fail "CU04 doit exit 1" || {
        assert_contains "CU04 message format invalide" "format invalide" "$out"
    }
}
```

---

### `core_assert_target_valid`

**Signature :** `core_assert_target_valid <dossier>`

| ID | Cas | Input | Résultat attendu |
|---|---|---|---|
| CU12 | Dossier absent | `/tmp/inexistant_xyz/` | exit 1, message "introuvable" |
| CU13 | Chemin est un fichier | `touch /tmp/unfichier` | exit 1, message "n'est pas un dossier" |
| CU14 | Dossier vide | `mkdir /tmp/vide` | exit 1, message "aucun fichier régulier" |
| CU15 | Dossier avec un fichier | `echo "x" > /tmp/d/f.txt` | exit 0 |
| CU16 | Dossier avec sous-dossiers uniquement vides | `mkdir /tmp/d/sub` | exit 1 — aucun fichier régulier |
| CU17 | Dossier avec fichiers dans sous-dossiers | `echo "x" > /tmp/d/sub/f.txt` | exit 0 |

---

### `core_compute`

**Signature :** `core_compute <dossier> <fichier_sortie> [callback]`

| ID | Cas | Condition | Résultat attendu |
|---|---|---|---|
| CU18 | Cas nominal sans callback | 3 fichiers, callback="" | hashfile produit, 3 lignes, format correct |
| CU19 | Format des lignes | 1 fichier connu | ligne = `[0-9a-f]{64}  <chemin>` |
| CU20 | Tri des chemins | 3 fichiers désordonnés | lignes triées par chemin (ordre lexicographique) |
| CU21 | Chemin relatif préservé | `compute ./data base.b3` depuis `/tmp` | chemins commencent par `./data/` |
| CU22 | Fichier avec espace dans le nom | `"fichier test.txt"` | une seule ligne, chemin correct |
| CU23 | Fichier de taille zéro | `touch zero.bin` | ligne présente, bytes_done non affecté |
| CU24 | Callback appelé N fois | 5 fichiers, callback compteur | callback appelé exactement 5 fois |
| CU25 | Callback reçoit les bons arguments | 1 fichier, callback loggeur | args (i, total, bytes_done, total_bytes, eta) cohérents |
| CU26 | Aucune ligne ETA dans hashfile | compute avec callback actif | hashfile ne contient pas "ETA" ni `\r` |
| CU27 | Idempotence | compute 2× sur même dossier | les deux hashfiles sont identiques |

```bash
# Exemple — CU24 : callback appelé N fois
test_cu24_callback_count() {
    local dir="$WORKDIR/data_cu24"
    mkdir -p "$dir"
    for i in 1 2 3 4 5; do echo "contenu $i" > "$dir/f$i.txt"; done

    local count=0
    _counter_callback() { count=$((count + 1)); }

    core_compute "$dir" "$WORKDIR/base_cu24.b3" "_counter_callback"
    [ "$count" -eq 5 ] && pass "CU24 callback appelé 5 fois" || fail "CU24 callback appelé $count fois (attendu 5)"
}
```

---

### `core_verify`

**Signature :** `core_verify <fichier_b3_absolu>`

Le répertoire courant doit être celui d'origine du compute avant l'appel.

| ID | Cas | Condition | Résultat attendu |
|---|---|---|---|
| CU28 | Tous les fichiers intègres | base correcte, fichiers inchangés | exit 0, CORE_VERIFY_STATUS="OK" |
| CU29 | Un fichier corrompu | contenu modifié après compute | exit 1, STATUS="ECHEC", NB_FAIL=1 |
| CU30 | Plusieurs fichiers corrompus | 2 fichiers modifiés | exit 1, NB_FAIL=2 |
| CU31 | Un fichier supprimé | rm après compute | exit 1, LINES_FAIL contient le chemin |
| CU32 | Variables CORE_VERIFY_* positionnées | cas nominal | toutes les variables sont non nulles et cohérentes |
| CU33 | CORE_VERIFY_NB_OK correct | 4 fichiers intègres | NB_OK=4 |
| CU34 | CORE_VERIFY_LINES_FAIL contient les bons chemins | 1 corruption sur beta.txt | LINES_FAIL contient "beta.txt" |
| CU35 | STATUS="ERREUR" si b3sum rapporte une erreur | fichier illisible (chmod 000) | STATUS="ERREUR" |

```bash
# Exemple — CU29
test_cu29_corruption_detectee() {
    local dir="$WORKDIR/data_cu29"
    mkdir -p "$dir"
    echo "contenu original" > "$dir/alpha.txt"
    local base="$WORKDIR/base_cu29.b3"

    ( cd "$dir" && core_compute . "$base" "" )

    echo "contenu corrompu" > "$dir/alpha.txt"

    local exit_code=0
    ( cd "$dir" && core_verify "$(cd "$WORKDIR" && pwd)/base_cu29.b3" ) || exit_code=$?

    [ "$exit_code" -ne 0 ] && pass "CU29 exit code non-zéro" || fail "CU29 doit détecter la corruption"
    [ "$CORE_VERIFY_STATUS" = "ECHEC" ] && pass "CU29 STATUS=ECHEC" || fail "CU29 STATUS=$CORE_VERIFY_STATUS"
}
```

---

### `core_compare`

**Signature :** `core_compare <old> <new> <outdir>`

C'est la fonction la plus critique — un bug ici produit de faux positifs massifs (cf. v0.7).

| ID | Cas | Condition | Résultat attendu |
|---|---|---|---|
| CU36 | Bases identiques | même contenu | modifies.b3 vide, disparus.txt vide, nouveaux.txt vide |
| CU37 | Un fichier modifié | beta.txt changé | modifies.b3 contient beta.txt, NB_MOD=1 |
| CU38 | Plusieurs fichiers modifiés | 3 fichiers changés | NB_MOD=3, les 3 chemins dans modifies.b3 |
| CU39 | Un fichier disparu | alpha.txt supprimé dans new | disparus.txt contient alpha.txt, NB_DIS=1 |
| CU40 | Un fichier nouveau | epsilon.txt ajouté dans new | nouveaux.txt contient epsilon.txt, NB_NOU=1 |
| CU41 | Combinaison modifié + disparu + nouveau | — | les 3 fichiers dans les 3 listes correctes |
| CU42 | Chemin avec espace | `"fichier test.txt"` modifié | modifies.b3 contient le chemin complet avec espace |
| CU43 | Chemin avec `&` | `"a&b.txt"` modifié | chemin correct dans modifies.b3 |
| CU44 | Chemin avec `<` et `>` | `"<script>.txt"` modifié | chemin correct (pas d'échappement HTML dans .b3) |
| CU45 | Format de modifies.b3 | 1 fichier modifié | ligne = `nouveau_hash  chemin` (format b3sum) |
| CU46 | Variables CORE_COMPARE_NB_* | — | NB_MOD, NB_DIS, NB_NOU corrects |
| CU47 | Fichiers tmp nettoyés | après appel | aucun fichier dans /tmp commençant par le pattern mktemp |
| CU48 | outdir doit exister avant l'appel | outdir absent | comportement défini (mkdir requis par l'appelant) |

```bash
# Exemple — CU42 : chemin avec espace
test_cu42_chemin_avec_espace() {
    local dir_old="$WORKDIR/old_cu42"
    local dir_new="$WORKDIR/new_cu42"
    mkdir -p "$dir_old" "$dir_new"

    echo "contenu v1" > "$dir_old/fichier avec espace.txt"
    echo "contenu v2" > "$dir_new/fichier avec espace.txt"

    ( cd "$dir_old" && core_compute . "$WORKDIR/old_cu42.b3" "" )
    ( cd "$dir_new" && core_compute . "$WORKDIR/new_cu42.b3" "" )

    local outdir="$WORKDIR/result_cu42"
    mkdir -p "$outdir"
    core_compare "$WORKDIR/old_cu42.b3" "$WORKDIR/new_cu42.b3" "$outdir"

    assert_contains "CU42 chemin avec espace dans modifies.b3" \
        "fichier avec espace.txt" \
        "$(cat "$outdir/modifies.b3")"
    [ "$CORE_COMPARE_NB_MOD" -eq 1 ] && pass "CU42 NB_MOD=1" || fail "CU42 NB_MOD=$CORE_COMPARE_NB_MOD"
}
```

---

### `core_make_result_dir`

**Signature :** `core_make_result_dir <fichier_b3> <resultats_dir>`

| ID | Cas | Condition | Résultat attendu |
|---|---|---|---|
| CU49 | Création normale | dossier parent existe, pas de collision | dossier `resultats_<nom>` créé, chemin retourné sur stdout |
| CU50 | Anti-collision — dossier existant | `resultats_<nom>` déjà présent | nouveau dossier `resultats_<nom>_YYYYMMDD-HHMMSS` créé |
| CU51 | Deux appels successifs | sleep 1 entre les deux | deux dossiers distincts |
| CU52 | Nom sans extension .b3 | fichier nommé `base` (sans .b3) | dossier `resultats_base` |
| CU53 | Nom avec chemin imbriqué | `/chemin/vers/hashes.b3` | dossier `resultats_hashes` (basename only) |

---

## Structure du fichier `run_tests_core.sh`

```bash
#!/usr/bin/env bash
# run_tests_core.sh - Tests unitaires de src/lib/core.sh
# Usage : cd tests && ./run_tests_core.sh
# Prérequis : bash >= 4, b3sum

set -euo pipefail

SCRIPT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"
WORKDIR="$(mktemp -d /tmp/integrity-core-test.XXXXXX)"
export RESULTATS_DIR="$WORKDIR/resultats"
QUIET=0

source "$SCRIPT_DIR/../src/lib/ui.sh"
source "$SCRIPT_DIR/../src/lib/core.sh"

# Helpers identiques à run_tests.sh
PASS=0; FAIL=0; TOTAL=0
pass() { ... }
fail() { ... }
assert_contains() { ... }
assert_exit_nonzero() { ... }

teardown() { rm -rf "$WORKDIR"; }
trap teardown EXIT

# == Tests =====================================================================

echo "T_CORE01 - core_assert_b3_valid"
# ... cas CU01 à CU11

echo "T_CORE02 - core_assert_target_valid"
# ... cas CU12 à CU17

echo "T_CORE03 - core_compute"
# ... cas CU18 à CU27

echo "T_CORE04 - core_verify"
# ... cas CU28 à CU35

echo "T_CORE05 - core_compare"
# ... cas CU36 à CU48

echo "T_CORE06 - core_make_result_dir"
# ... cas CU49 à CU53

# == Résultats =================================================================
echo "========================================"
[ "$FAIL" -eq 0 ] \
    && echo "  $PASS/$TOTAL tests passés" \
    || echo "  $PASS/$TOTAL passés - $FAIL échec(s)"
echo "========================================"
[ "$FAIL" -eq 0 ]
```

---

## Précautions spécifiques au sourcing

Quand `core.sh` est sourcé directement, les fonctions internes `_b3_to_path_hash` et `_core_file_size` sont aussi accessibles. Elles peuvent être testées unitairement si nécessaire :

```bash
# Test de la fonction interne _b3_to_path_hash
test_b3_to_path_hash_format() {
    local f="$WORKDIR/sample.b3"
    printf '%0.s0' {1..64} > /tmp/hash64  # 64 zéros
    echo "$(cat /tmp/hash64)  ./dossier/fichier.txt" > "$f"

    local result
    result=$(_b3_to_path_hash "$f")
    # Attendu : "./dossier/fichier.txt\t0000...64zeros"
    echo "$result" | grep -q $'./dossier/fichier.txt\t' \
        && pass "_b3_to_path_hash format correct" \
        || fail "_b3_to_path_hash format incorrect : $result"
}
```


--- Fichier : hors_git/TODO - améliorations/ameliorations - audit.md ---

Pour élever ce projet au niveau d’un projet professionnel (production-ready), les améliorations attendues se situent sur plusieurs plans : ingénierie logicielle, qualité, sécurité, documentation et gouvernance.

Sur le plan de l’architecture logicielle, il est recommandé de séparer strictement la logique métier (hachage, comparaison, vérification) de la logique d’interface (CLI, affichage, ETA). Une organisation en modules clairement identifiés permettrait une meilleure testabilité et une éventuelle réutilisation comme bibliothèque. Il serait également pertinent de définir une API interne stable (fonctions clairement spécifiées avec contrats d’entrée/sortie) et de documenter formellement les invariants (format `.b3`, hypothèses sur les chemins, encodage, locale).

Concernant la robustesse et la fiabilité, il faudrait renforcer la gestion des erreurs : distinction systématique entre erreurs utilisateur (chemin invalide, base absente), erreurs système (I/O, permissions) et erreurs logiques (base incohérente). Les codes de retour devraient être normalisés et documentés. La gestion des cas limites (liens symboliques, fichiers très volumineux, changements pendant le scan, caractères non UTF-8) doit être explicitement définie et testée.

Sur le plan des performances, une analyse reproductible est attendue : benchmarks documentés (temps de calcul, débit disque, coût CPU) selon différents scénarios (HDD, SSD, NVMe, petits fichiers vs gros fichiers). Les résultats doivent distinguer données observées et choix d’implémentation. Il serait également pertinent d’introduire une stratégie adaptative formalisée (séquentiel vs parallèle) fondée sur des critères mesurables, et non uniquement heuristiques.

Pour la qualité logicielle, une couverture de tests mesurable est requise. Il faut inclure des tests unitaires (fonctions de parsing, comparaison), des tests d’intégration (workflows complets) et des tests de non-régression automatisés en CI. Les tests doivent être reproductibles, indépendants de l’environnement local, et documentés (préconditions, oracle de test). Un rapport de couverture (même approximatif en bash) renforcerait la crédibilité du projet.

Du point de vue de la sécurité, il est nécessaire de préciser le modèle de menace. Aujourd’hui, le projet vise la détection d’erreurs accidentelles ; cela doit être explicitement formulé. Si l’usage évolue vers un contexte adversarial, il faudra justifier formellement l’usage de BLAKE3, documenter les propriétés cryptographiques attendues (résistance aux collisions, à la pré-image) et éviter toute ambiguïté avec un mécanisme d’authentification (MAC ou signature). La surface d’attaque (injection de chemins, exécution de commandes externes) doit être auditée.

En matière de documentation, une documentation professionnelle doit distinguer :  
– une documentation utilisateur (installation, exemples, erreurs fréquentes),  
– une documentation développeur (architecture, flux de données, choix techniques),  
– une documentation de référence (spécification du format `.b3`, description formelle des commandes).  
Chaque choix non trivial (chemins relatifs, ETA, tri, format) doit être justifié par une section « rationale ».

Sur le plan de l’industrialisation, il est nécessaire d’ajouter un véritable pipeline CI/CD : linting systématique, exécution automatique des tests, vérification de style, génération d’artefacts (release taguée, checksum du binaire ou du script). La version du projet doit suivre une sémantique explicite (par exemple SemVer) et un changelog normé.

Enfin, pour la gouvernance du projet, un projet professionnel requiert : une licence clairement choisie et cohérente avec l’objectif (MIT, GPL, Apache…), des règles de contribution (processus de revue, format des commits), et une feuille de route explicite (fonctionnalités prévues, limites connues, axes de recherche).

En synthèse, le projet est techniquement fonctionnel, mais pour devenir professionnel, il doit passer d’un script robuste à un système spécifié, testé, documenté et gouverné. La valeur professionnelle ne vient pas seulement de l’algorithme, mais de la traçabilité des choix, de la reproductibilité des résultats et de la maîtrise des risques.


--- Fichier : hors_git/TODO - améliorations/ameliorations - roadmap.md ---


## roadmap amélioration 



### Jalon 2 - Robustesse du code 

Objectif : corriger les défauts identifiés dans le code

Délivrables :
- Fix `run_compare()` : `trap - EXIT` déplacé dans un bloc `finally` simulé ou restructuration pour garantir l'exécution sur tout chemin de sortie
- Fix `assert_b3_valid()` : vérification d'au moins N lignes au bon format (pas seulement la première), rejection si taux d'erreur > seuil configurable
- Fix `compute_with_progress()` : gestion explicite du cas `file_size = 0` (skip de la mise à jour de `bytes_done`, ou log en mode debug)
- Définition et documentation du comportement sur liens symboliques (ignorer, suivre, ou erreur explicite) - choix à documenter dans `architecture.md`
- Gestion explicite du cas `RESULTATS_DIR` non accessible en écriture : message d'erreur propre au lieu d'un crash `mkdir` opaque


### Jalon 5 - Documentation et gouvernance

Objectif : formaliser ce qui est implicite

Délivrables :
- `SECURITY.md` : modèle de menace explicite (périmètre : erreurs accidentelles uniquement), propriétés BLAKE3 utilisées, surface d'attaque auditée (injection de chemins dans `pipeline.json`, comportement sur chemins avec `..`), procédure de signalement
- `docs/architecture.md` : section "Limites de conception" ajoutée (liens symboliques, fichiers 0 octet, non UTF-8, comportement en écriture concurrente)
- `docs/development/contributing.md` : convention Conventional Commits, processus de release en 5 étapes (branch → test → tag → release → changelog), format attendu des PRs
- `ROADMAP.md` : fonctionnalités prévues, limites connues non corrigeables (clone bit-à-bit, métadonnées), axes d'évolution potentiels (notifications natives, export JSON des résultats, `--verify-base` pour auto-protéger le `.b3`)




--- Fichier : hors_git/documentation /llm -- Intégration Read the Docs.md ---
# Intégration Read the Docs

**User:** Anonymous (mapellecorentin@gmail.com)  
**Created:** 2/26/2026 12:32:43  
**Updated:** 2/26/2026 12:35:00  
**Exported:** 2/26/2026 12:43:56  
**Link:** [https://chatgpt.com/c/69a02f51-fd78-8327-b599-9f5bd04b2a93](https://chatgpt.com/c/69a02f51-fd78-8327-b599-9f5bd04b2a93)  

## Prompt:
j'ai un read the docs mkdir dans un projet, comment il est intégré dans un répo github ?

## Response:
Dans un projet hébergé sur GitHub, un répertoire associé à Read the Docs (souvent nommé `docs/`) n’est **pas automatiquement créé ni injecté** par la plateforme. Il fait partie intégrante du dépôt si — et seulement si — le développeur l’a **versionné** dans le répertoire Git.

Concrètement, l’intégration se fait ainsi :

1.  Le dépôt GitHub contient un répertoire de documentation, typiquement `docs/`, avec une structure de type Sphinx (par exemple `conf.py`, `index.rst` ou `index.md`, sous-répertoires, etc.).  
    Ce répertoire est géré comme n’importe quel autre dossier du projet (`git add docs/`, puis commit).
2.  À la racine du dépôt, on trouve généralement un fichier de configuration `.readthedocs.yml`.  
    Ce fichier indique à Read the Docs :  
    – où se trouve la documentation (souvent `docs/`),  
    – quel outil utiliser (Sphinx, MkDocs…),  
    – quelle version de Python et quelles dépendances installer.

Exemple conceptuel (schématique) :

```
project/
├── src/
├── docs/
│   ├── conf.py
│   └── index.rst
├── .readthedocs.yml
└── pyproject.toml / requirements.txt
```

3.  Sur le site Read the Docs, on lie le projet à un dépôt GitHub.  
    À chaque commit ou tag, Read the Docs :  
    – clone le dépôt,  
    – lit `.readthedocs.yml`,  
    – construit la documentation à partir du dossier `docs/`,  
    – publie le HTML généré sur son propre serveur.

Point important :  
le dossier `docs/` (ou équivalent) est **dans le dépôt GitHub**,  
mais le HTML final (le site web) **n’est pas stocké dans le dépôt** ; il est généré par Read the Docs à partir de ce dossier.

Donc, pour répondre directement à ta question :  
un “read the docs mkdir” est intégré dans un repo GitHub simplement comme un répertoire versionné (`docs/`), référencé par `.readthedocs.yml`, et exploité automatiquement par Read the Docs lors du build.

## Prompt:
il faut que je crée un compte sur read the docs ?

## Response:
Oui. Pour publier une documentation avec **Read the Docs**, il faut créer un compte sur la plateforme.

Distinction importante :

– **Sans compte Read the Docs** :  
tu peux avoir un dossier `docs/` dans ton dépôt GitHub, mais rien ne sera automatiquement construit ni publié en ligne.

– **Avec un compte Read the Docs** :  
tu relies ton compte GitHub à Read the Docs, tu importes ton dépôt, et la plateforme :  
• clone ton dépôt,  
• lit le fichier `.readthedocs.yml`,  
• génère la documentation,  
• l’héberge (ex. `https://ton-projet.readthedocs.io`).

Le compte est donc nécessaire pour :

1.  autoriser Read the Docs à accéder à ton dépôt GitHub,
2.  configurer le projet,
3.  déclencher les builds automatiques à chaque commit ou tag.

En résumé :  
GitHub seul stocke la documentation source (`docs/`),  
Read the Docs (avec un compte) est requis pour la construire et la publier comme site web.

## Prompt:
github ne propose pas une alternative interne ?

## Response:
Oui. **GitHub** propose une alternative interne à Read the Docs : **GitHub Pages**.

Principe : GitHub Pages permet d’héberger gratuitement un site statique directement depuis un dépôt GitHub. On peut donc y publier une documentation sans passer par Read the Docs.

Deux approches courantes :

1.  Site statique simple  
    Tu mets ta documentation en HTML (ou Markdown) dans un dépôt ou une branche dédiée (`gh-pages`).  
    GitHub Pages sert directement ces fichiers comme site web.
2.  Génération automatique (équivalent fonctionnel de Read the Docs)  
    Tu peux écrire la doc en Markdown ou reStructuredText (avec Sphinx, MkDocs, etc.), puis utiliser :  
    – un générateur de site (Sphinx, MkDocs, Jekyll),  
    – et une action GitHub (GitHub Actions) pour :  
    • builder la doc à chaque commit,  
    • publier le HTML généré sur GitHub Pages.

Différence conceptuelle avec Read the Docs :

– Read the Docs :  
service spécialisé « documentation », avec configuration dédiée (`.readthedocs.yml`), gestion native des versions, moteur de recherche intégré.

– GitHub Pages :  
hébergement statique générique ;  
la logique de build (Sphinx/MkDocs) est à ta charge via GitHub Actions.

Conclusion :  
Oui, GitHub a une alternative interne via GitHub Pages, mais elle est plus bas niveau.  
Read the Docs est une solution clé en main pour la documentation ;  
GitHub Pages est une brique d’hébergement qu’il faut combiner avec un outil de génération et une pipeline CI.



---
Powered by [ChatGPT Exporter](https://www.chatgptexporter.com)

--- Fichier : hors_git/documentation /llm -- Test FDP et Commandes Hash-Tool.md ---
# Test FDP et Commandes Hash-Tool

**Exported:** 2/26/2026 16:50:03  
**Link:** [https://gemini.google.com/app/cbe608c1fddd4e40?hl=fr](https://gemini.google.com/app/cbe608c1fddd4e40?hl=fr)

## Prompt:
> gentxt - TXT

test fdp

## Response:
Gemini a dit
------------

L'expression « test fdp » semble être un test de saisie rapide. En tant que développeur informatique, je me tiens prêt à vous aider sur le projet **hash-tool** décrit dans vos documents.

Voici un rappel des commandes principales de l'outil que vous pouvez tester ou intégrer dans vos développements :

### Commandes de base de `hash-tool`

*   **`compute`** : Calcule les empreintes BLAKE3 d'un dossier et génère un fichier `.b3` accompagné d'un sidecar `.meta.json`.
    +1
*   **`verify`** : Vérifie l'intégrité d'un dossier par rapport à une base existante.
    +1
*   **`compare`** : Compare deux bases d'empreintes et génère un rapport de différences.
    +1
*   **`runner`** : Exécute une suite d'opérations définies dans un fichier JSON (pipeline).
    +1

### Outils de diagnostic

*   **`check-env`** : Vérifie si votre environnement possède les dépendances nécessaires (`b3sum`, `jq`, `bash >= 4`) ou si l'exécution doit basculer sur Docker.
    +1
*   **`stats`** : Affiche des statistiques détaillées sur une base `.b3` (nombre de fichiers, extensions, métadonnées).
    +1

### Structure du projet

Le projet est organisé pour supporter une exécution native ou via Docker:

+1

*   `src/integrity.sh` : Le moteur de calcul.
    +1
*   `runner.sh` : Le gestionnaire de pipelines.
*   `Dockerfile` : Pour l'isolation dans une image Alpine légère.

N'hésitez pas à me soumettre un problème spécifique ou une demande de modification de code, je vous fournirai le fichier complet conformément à vos instructions.

## Prompt:
j'ai mis ça sur github, commetn je fais pour afficher la doc ? je dois créer un compte read the docs ?

## Response:
Gemini a dit
------------

Pas besoin de créer un compte **Read the Docs** dans un premier temps. Comme ton projet possède déjà une structure de documentation (`/docs`), tu as deux options simples et gratuites directement intégrées à GitHub.

Voici les deux méthodes recommandées pour ton projet **hash-tool**.

* * *

1\. GitHub Pages (La plus propre)
---------------------------------

C'est la méthode idéale car elle transforme tes fichiers Markdown en un véritable site web.

1.  Va sur le dépôt de ton projet sur GitHub.
2.  Clique sur l'onglet **Settings** (Paramètres).
3.  Dans le menu à gauche, clique sur **Pages**.
4.  Sous **Build and deployment** \> **Branch** :
    *   Sélectionne la branche `main`.
    *   Sélectionne le dossier `/docs` (au lieu de `root`).
5.  Clique sur **Save**.

GitHub va te donner une URL du type `https://ton-pseudo.github.io/hash-tool/`. Ton fichier `docs/index.md` deviendra automatiquement ta page d'accueil.

* * *

2\. Navigation native GitHub (La plus rapide)
---------------------------------------------

GitHub sait déjà rendre les fichiers `.md`. Tu n'as techniquement rien à faire, mais pour que ce soit ergonomique pour les utilisateurs, je te conseille de modifier ton `README.md` à la racine pour qu'il serve de portail.

### Modification du README.md

Voici le code complet du `README.md` que je te suggère d'utiliser pour lier toute ta documentation de manière pro :

```
# Hash-Tool

Outil de vérification d'intégrité basé sur BLAKE3.

## 📚 Documentation

Vous trouverez l'ensemble de la documentation technique dans le dossier `/docs` :

### 🚀 Démarrage
* [Guide de démarrage rapide](docs/getting-started.md)
* [Installation avec Docker](docs/reference/docker.md)

### 🛠 Référence Technique
* [Utilisation de integrity.sh](docs/reference/integrity-sh.md)
* [Utilisation du runner (Pipelines)](docs/reference/runner-sh.md)
* [Spécification du format .b3](docs/spec/b3-format.md)

### 📖 Guides spécifiques
* [Utilisation sur NAS Synology](docs/guides/nas-synology.md)
* [Vérification de volumes VeraCrypt](docs/guides/veracrypt.md)

---

## Architecture du projet
Pour comprendre l'organisation des fichiers et le fonctionnement interne, consultez le document d'[Architecture](docs/development/architecture.md).
```

* * *

Pourquoi pas Read the Docs ?
----------------------------

**Read the Docs** est excellent pour les très gros projets (souvent en Python avec Sphinx), mais il nécessite un fichier de configuration (`.readthedocs.yaml`). Pour ton projet shell/bash, **GitHub Pages** est beaucoup plus léger et suffisant car il gère nativement le Markdown via Jekyll (le moteur par défaut de GitHub).

**Ma recommandation :** Utilise la **Méthode 1** avec le dossier `/docs`. C'est ce qui donnera l'aspect le plus "professionnel" sans aucun service tiers.

Souhaites-tu que je t'aide à rédiger le fichier de configuration Jekyll (`_config.yml`) pour personnaliser l'apparence de ta doc sur GitHub Pages ?

## Prompt:
github pages en ligne de commande

## Response:
Gemini a dit
------------

Pour mettre à jour ou déployer votre documentation **GitHub Pages** directement en ligne de commande, vous avez deux approches selon l'outil que vous utilisez.

Votre projet contient un fichier `mkdocs.yml` , ce qui indique que vous utilisez probablement **MkDocs** (avec le thème Material ).

### 1\. La méthode "MkDocs" (Recommandée)

Si MkDocs est installé sur votre machine, une seule commande suffit pour compiler la documentation et l'envoyer sur la branche `gh-pages` de votre dépôt GitHub.

```
# À la racine de votre projet hash-tool
mkdocs gh-deploy
```

**Ce que fait cette commande :**

1.  Elle lit votre configuration `mkdocs.yml` et vos fichiers dans `/docs`.
2.  Elle génère le site statique (HTML/CSS).
3.  Elle crée (ou met à jour) une branche nommée `gh-pages` sur GitHub et y pousse le site.

### 2\. La méthode "Git manuel" (Sans MkDocs)

Si vous n'avez pas MkDocs installé localement et que vous voulez simplement pousser vos fichiers Markdown pour que GitHub les affiche via son système natif :

```
git add docs/
git commit -m "Mise à jour de la documentation"
git push origin main
```

Ensuite, dans l'interface GitHub : **Settings \> Pages**, choisissez la branche `main` et le dossier `/docs` comme source.

### 3\. Automatisation via GitHub Actions

Pour ne plus avoir à taper de commande, vous pouvez automatiser le déploiement à chaque `push`. Créez un fichier `.github/workflows/docs.yml` :

```
name: Deploy Docs
on:
  push:
    branches:
      - main
jobs:
  deploy:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - uses: actions/setup-python@v4
        with:
          python-version: 3.x
      - run: pip install mkdocs-material
      - run: mkdocs gh-deploy --force
```

### Rappel de votre structure actuelle

Votre documentation est déjà très bien organisée dans le dossier `docs/` avec les sections suivantes:

*   **Référence technique** : `integrity-sh.md`, `runner-sh.md`.
*   **Guides** : `veracrypt.md`, `nas-synology.md`.
*   **Spécifications** : `b3-format.md`.

**Conseil de développeur :** Utilisez la **méthode 1** (`mkdocs gh-deploy`). C'est la plus propre pour un projet comme le vôtre qui possède déjà un fichier `mkdocs.yml` configuré avec le thème Material et des extensions comme `pymdownx.superfences`.

## Prompt:
(conda\_env\_hash\_tool) me-dell@desktop-dell:/media/veracrypt1/partition\_laptop/divers/config ordinateur/2 en cours -- 2025-00-00 -- backup/d11 installation/hash\_tool\$ mkdocs gh-deploy

Traceback (most recent call last):

  File "/home/me-dell/.conda/envs/conda\_env\_hash\_tool/bin/mkdocs", line 10, in \<module\>

    sys.exit(cli())

             ~~~^^

  File "/home/me-dell/.conda/envs/conda\_env\_hash\_tool/lib/python3.14/site-packages/click/core.py", line 1485, in \_\_call\_\_

    return self.main(\*args, \*\*kwargs)

           ~~~~~~~~~^^^^^^^^^^^^^^^^^

  File "/home/me-dell/.conda/envs/conda\_env\_hash\_tool/lib/python3.14/site-packages/click/core.py", line 1406, in main

    rv = self.invoke(ctx)

  File "/home/me-dell/.conda/envs/conda\_env\_hash\_tool/lib/python3.14/site-packages/click/core.py", line 1873, in invoke

    return \_process\_result(sub\_ctx.command.invoke(sub\_ctx))

                           ~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^

  File "/home/me-dell/.conda/envs/conda\_env\_hash\_tool/lib/python3.14/site-packages/click/core.py", line 1269, in invoke

    return ctx.invoke(self.callback, \*\*ctx.params)

           ~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

  File "/home/me-dell/.conda/envs/conda\_env\_hash\_tool/lib/python3.14/site-packages/click/core.py", line 824, in invoke

    return callback(\*args, \*\*kwargs)

  File "/home/me-dell/.conda/envs/conda\_env\_hash\_tool/lib/python3.14/site-packages/mkdocs/\_\_main\_\_.py", line 309, in gh\_deploy\_command

    from mkdocs.commands import build, gh\_deploy

  File "/home/me-dell/.conda/envs/conda\_env\_hash\_tool/lib/python3.14/site-packages/mkdocs/commands/gh\_deploy.py", line 10, in \<module\>

    from packaging import version

ModuleNotFoundError: No module named 'packaging'

(conda\_env\_hash\_tool) me-dell@desktop-dell:/media/veracrypt1/partition\_laptop/divers/config ordinateur/2 en cours -- 2025-00-00 -- backup/d11 installation/hash\_tool\$

## Response:
Gemini a dit
------------

L'erreur `ModuleNotFoundError: No module named 'packaging'` indique qu'une dépendance essentielle de MkDocs est manquante dans votre environnement Conda `conda_env_hash_tool`. Cela arrive parfois lors d'installations minimales ou de mises à jour d'environnements.

Voici comment résoudre ce problème et déployer votre documentation.

### 1\. Correction de l'environnement Conda

Vous devez installer le paquet `packaging`. Étant donné que vous utilisez Python 3.14 (une version très récente), il est préférable d'utiliser `pip` à l'intérieur de votre environnement activé pour garantir la compatibilité avec MkDocs.

Exécutez cette commande dans votre terminal :

```
pip install packaging
```

### 2\. Vérification et Déploiement

Une fois l'installation terminée, relancez la commande de déploiement :

```
mkdocs gh-deploy
```

### Si d'autres erreurs apparaissent

Avec Python 3.14, il est possible que d'autres dépendances manquent ou soient incompatibles. Si vous rencontrez une autre erreur `ModuleNotFoundError` (par exemple pour `ghp-import` qui est nécessaire pour le déploiement GitHub), installez les composants recommandés pour votre configuration :

```
pip install mkdocs-material ghp-import
```

Puis réessayez :

```
mkdocs gh-deploy
```

### Pourquoi cela a échoué ?

Le paquet `packaging` est utilisé par MkDocs pour vérifier les versions des plugins. Dans les versions récentes de Python, certains outils de base qui étaient inclus par défaut sont parfois séparés, ou le processus d'installation de MkDocs via Conda n'a pas correctement résolu cette dépendance.

**Note sur GitHub Pages :** Une fois que la commande `mkdocs gh-deploy` réussit, elle crée une branche `gh-pages` sur votre dépôt distant. GitHub détecte généralement cela automatiquement. Si votre site ne s'affiche pas après quelques minutes, allez dans **Settings \> Pages** sur GitHub et vérifiez que la source est bien configurée sur la branche **gh-pages**.

## Prompt:
et maintenant ?

(conda\_env\_hash\_tool) me-dell@desktop-dell:/media/veracrypt1/partition\_laptop/divers/config ordinateur/2 en cours -- 2025-00-00 -- backup/d11 installation/hash\_tool\$ mkdocs gh-deploy

 │ ⚠ WARNING – MkDocs 2.0 is incompatible with Material for MkDocs

 │ 

 │   MkDocs 1.x is unmaintained. We recommend switching to Zensical, our

 │   new static site generator, as soon as possible. We're providing an

 │   analysis of the situation in this article:

 │   

 │   https://squidfunk.github.io/mkdocs-material/blog/2026/02/18/mkdocs-2.0/

INFO    -  Cleaning site directory

INFO    -  Building documentation to directory: /media/veracrypt1/partition\_laptop/divers/config ordinateur/2 en

           cours -- 2025-00-00 -- backup/d11 installation/hash\_tool/site

INFO    -  The following pages exist in the docs directory, but are not included in the "nav" configuration:

             - development/ROADMAP.md

             - troubleshooting /troubleshooting\_1.md

WARNING -  A reference to 'development/roadmap.md' is included in the 'nav' configuration, which is not found in the

           documentation files.

INFO    -  Doc file 'getting-started.md' contains a link '#docker-démarrage-rapide', but there is no such anchor on

           this page.

INFO    -  Documentation built in 2.47 seconds

WARNING -  Version check skipped: No version specified in previous deployment.

INFO    -  Copying '/media/veracrypt1/partition\_laptop/divers/config ordinateur/2 en cours -- 2025-00-00 --

           backup/d11 installation/hash\_tool/site' to 'gh-pages' branch and pushing to GitHub.

Énumération des objets: 92, fait.

Décompte des objets: 100% (92/92), fait.

Compression par delta en utilisant jusqu'à 4 fils d'exécution

Compression des objets: 100% (73/73), fait.

Écriture des objets: 100% (92/92), 692.71 Kio | 989.00 Kio/s, fait.

Total 92 (delta 16), réutilisés 0 (delta 0), réutilisés du pack 0

remote: Resolving deltas: 100% (16/16), done.

remote: 

remote: Create a pull request for 'gh-pages' on GitHub by visiting:

remote:      https://github.com/Alan45678/hash-tool/pull/new/gh-pages

remote: 

To https://github.com/Alan45678/hash-tool.git

 \* \[new branch\]      gh-pages -\> gh-pages

INFO    -  Your documentation should shortly be available at: https://Alan45678.github.io/hash-tool/

## Response:
Gemini a dit
------------

C'est parfait ! Ton déploiement a réussi. La branche `gh-pages` a été créée et envoyée sur GitHub.

Il ne reste plus qu'une toute petite étape de configuration sur l'interface de GitHub pour que le site s'affiche réellement à l'adresse indiquée.

* * *

1\. Activer l'affichage sur GitHub
----------------------------------

1.  Ouvre ton navigateur sur ton dépôt : `https://github.com/Alan45678/hash-tool`.
2.  Va dans l'onglet **Settings** (en haut à droite).
3.  Dans le menu latéral gauche, clique sur **Pages**.
4.  Sous la section **Build and deployment** \> **Branch** :
    *   Vérifie que la branche sélectionnée est bien **`gh-pages`**.
    *   Vérifie que le dossier est bien **`/(root)`**.
5.  Si ce n'est pas déjà fait, clique sur **Save**.

D'ici 1 à 2 minutes, ta doc sera visible ici : 
[https://Alan45678.github.io/hash-tool/](https://Alan45678.github.io/hash-tool/)

* * *

2\. Nettoyage de la configuration (Optionnel mais recommandé)
-------------------------------------------------------------

Ton log montre quelques avertissements (Warnings) que tu devrais corriger dans ton fichier `mkdocs.yml` pour avoir une doc propre :

*   **Le casier (Case sensitivity) :** Dans ta navigation (`nav`), tu as écrit `development/roadmap.md` (minuscule), mais ton fichier réel s'appelle `development/ROADMAP.md` (majuscule). Linux et MkDocs y sont sensibles.
*   **Fichiers orphelins :** Tu as des fichiers comme `troubleshooting_1.md` qui ne sont pas listés dans ton menu `nav`.

### Le code corrigé de ton `mkdocs.yml`

Voici une version propre qui corrige ces erreurs de liens :

```
site_name: Hash-Tool
theme:
  name: material

nav:
  - Accueil: index.md
  - Démarrage: getting-started.md
  - Référence Technique:
      - Docker: reference/docker.md
      - Integrity.sh: reference/integrity-sh.md
      - Runner.sh: reference/runner-sh.md
  - Guides:
      - NAS Synology: guides/nas-synology.md
      - VeraCrypt: guides/veracrypt.md
      - Automatisation (Cron): guides/cron-ci.md
  - Spécifications:
      - Format .b3: spec/b3-format.md
      - API Interne: spec/api-interne.md
  - Développement:
      - Roadmap: development/ROADMAP.md
      - Architecture: development/architecture.md
      - Changelog: development/changelog.md
      - Contribuer: development/contributing.md
  - Aide:
      - Troubleshooting: troubleshooting /troubleshooting_1.md

plugins:
  - search

markdown_extensions:
  - pymdownx.superfences
  - pymdownx.highlight:
      anchor_linenums: true
  - admonition
  - details
```

* * *

Et pour la suite ?
------------------

Maintenant que la machine est lancée, dès que tu modifies un fichier dans `/docs` sur ton ordinateur, il te suffit de retaper :

```
mkdocs gh-deploy
```

Cela mettra à jour ton site web instantanément.

**Une question sur l'avertissement concernant MkDocs 2.0 ?** Ne t'inquiète pas, c'est une annonce très récente (février 2026). Ton installation actuelle fonctionne parfaitement, tu pourras envisager la migration vers "Zensical" plus tard si tu veux rester à la pointe.

Est-ce que le lien fonctionne bien de ton côté après l'activation dans les réglages ?

## Prompt:
en cli

1\. Activer l'affichage sur GitHub

Ouvre ton navigateur sur ton dépôt : https://github.com/Alan45678/hash-tool.

Va dans l'onglet Settings (en haut à droite).

Dans le menu latéral gauche, clique sur Pages.

Sous la section Build and deployment \> Branch :

Vérifie que la branche sélectionnée est bien gh-pages.

Vérifie que le dossier est bien /(root).

Si ce n'est pas déjà fait, clique sur Save.

D'ici 1 à 2 minutes, ta doc sera visible ici : https://Alan45678.github.io/hash-tool/

## Response:
Gemini a dit
------------

Je comprends parfaitement : tu veux éviter de toucher à la souris et tout piloter depuis ton terminal.

Pour activer **GitHub Pages** en ligne de commande (CLI), tu dois utiliser l'outil officiel **GitHub CLI** (`gh`). Si tu ne l'as pas encore, il s'installe très facilement (ex: `sudo apt install gh` ou via Conda).

Voici la procédure complète pour configurer le déploiement sur la branche `gh-pages` sans ouvrir ton navigateur :

* * *

### 1\. Connexion à GitHub CLI

Si ce n'est pas déjà fait, connecte-toi à ton compte :

```
gh auth login
```

_(Suis les instructions, choisis HTTPS et connecte-toi via le navigateur une seule fois ou avec un token)._

### 2\. Configuration de GitHub Pages via CLI

Exécute la commande suivante à la racine de ton projet pour dire à GitHub : "Utilise la branche `gh-pages` (dossier racine) pour servir mon site" :

```
gh api repos/Alan45678/hash-tool/pages \
  --method POST \
  -f source='{"branch":"gh-pages","path":"/"}'
```

### 3\. Vérifier le statut du déploiement

Pour savoir si GitHub a fini de compiler et de mettre en ligne ta doc, utilise cette commande :

```
gh run list --workflow "pages-build-deployment"
```

Une fois que le statut est `completed` et `success`, ton site est en ligne.

### 4\. Récupérer l'URL de ta doc

Pour obtenir l'URL finale directement dans ton terminal :

```
gh api repos/Alan45678/hash-tool/pages --template '{{.html_url}}'
```

* * *

### Résumé de ton workflow "Full CLI" pour la doc :

Désormais, quand tu modifies tes fichiers dans `/docs`, tu n'as plus qu'à faire ceci :

1.  **Mise à jour et déploiement :**
    ```
    mkdocs gh-deploy
    ```
2.  **Vérification (optionnel) :**
    ```
    gh api repos/Alan45678/hash-tool/pages --template 'Statut: {{.status}} - URL: {{.html_url}}'
    ```

C'est beaucoup plus efficace pour un développeur. Est-ce que tu veux que je t'aide à automatiser la correction des "Warnings" de ton fichier `mkdocs.yml` pour que le déploiement soit 100% propre ?

## Prompt:
comment rendre un github public ?

## Response:
Gemini a dit
------------

Pour rendre ton dépôt **hash-tool** public via la ligne de commande (CLI), tu as deux options : utiliser l'outil `gh` (GitHub CLI) ou passer par une requête API manuelle si tu n'as pas l'outil.

### 1\. La méthode simple (avec GitHub CLI)

Si tu as déjà installé `gh` et que tu es connecté, c'est une seule commande :

```
gh repo edit Alan45678/hash-tool --visibility public
```

_GitHub te demandera peut-être une confirmation, il suffit de valider._

* * *

### 2\. La méthode API (si tu n'as pas GitHub CLI)

Si tu préfères utiliser `curl` avec un jeton d'accès (PAT), voici la commande :

```
curl -L \
  -X PATCH \
  -H "Accept: application/vnd.github+json" \
  -H "Authorization: Bearer TON_TOKEN_GITHUB" \
  -H "X-GitHub-Api-Version: 2022-11-28" \
  https://api.github.com/repos/Alan45678/hash-tool \
  -d '{"visibility":"public"}'
```

* * *

### ⚠️ Choses importantes à vérifier avant de passer en public

Comme ton projet semble lié à des sauvegardes et à des configurations personnelles (on voit des chemins comme `/media/veracrypt1/...` dans tes logs), assure-toi de deux choses :

1.  **Le fichier `.gitignore`** : Vérifie que tu n'envoies pas par erreur tes fichiers `.b3` contenant des listes de tes fichiers personnels, ou des fichiers de résultats.
2.  **Les données sensibles** : Assure-toi qu'aucun mot de passe ou chemin trop explicite ne figure dans tes scripts ou tes fichiers de config.

### Pourquoi le faire ?

Une fois le dépôt public :

*   Ton site **GitHub Pages** sera accessible à tout le monde sans authentification.
*   N'importe qui pourra cloner ton outil `hash-tool` pour l'utiliser.

Souhaites-tu que je te génère un fichier `.gitignore` complet et optimisé pour ton projet afin d'éviter d'exposer des données privées lors du passage en public ?

## Prompt:
"The custom domain \`hashh-tool\` is not properly formatted. See https://docs.github.com/articles/troubleshooting-custom-domains/#github-repository-setup-errors for more information."

## Response:
Gemini a dit
------------

Cette erreur provient du fait que vous avez probablement essayé de définir `hash-tool` comme un **domaine personnalisé** (Custom Domain) au lieu de l'utiliser comme le **nom du dépôt**.

Sur GitHub Pages, si vous n'avez pas acheté votre propre nom de domaine (comme `mon-outil.com`), vous ne devez pas remplir le champ "Custom Domain". Par défaut, votre site sera `https://Alan45678.github.io/hash-tool/`.

Voici comment corriger cela en ligne de commande avec `gh` pour revenir à la configuration standard.

### 1\. Supprimer le domaine mal formaté

Exécutez cette commande pour vider le champ "custom\_domain" qui cause l'erreur :

```
gh api repos/Alan45678/hash-tool/pages \
  --method PATCH \
  -f cname=null
```

### 2\. S'assurer que la source est correcte

Assurez-vous que GitHub Pages pointe bien sur la branche `gh-pages` :

```
gh api repos/Alan45678/hash-tool/pages \
  --method PUT \
  -f source='{"branch":"gh-pages","path":"/"}'
```

### 3\. Pourquoi avez-vous eu cette erreur ?

L'erreur "not properly formatted" survient parce que GitHub attend un nom de domaine avec une extension (ex: `.com`, `.fr`, `.io`) dans ce champ. En y mettant juste `hash-tool`, il pense que c'est un nom de domaine invalide.

### 4\. Vérifier le résultat

Attendez environ 30 secondes, puis vérifiez le statut avec :

```
gh api repos/Alan45678/hash-tool/pages --template 'URL du site : {{.html_url}}{{"\n"}}Statut : {{.status}}'
```

Si tout est correct, vous devriez obtenir :

*   **URL du site :** `https://Alan45678.github.io/hash-tool/`
*   **Statut :** `built` (ou `building`)

* * *

### Conseil pour votre `mkdocs.yml`

Puisque votre site est dans un sous-dossier du domaine principal (le dossier `/hash-tool/`), assurez-vous que votre fichier `mkdocs.yml` ne force pas une URL racine. Vous pouvez ajouter cette ligne si elle manque :

```
site_url: https://Alan45678.github.io/hash-tool/
```

Ensuite, refaites un petit déploiement pour valider :

```
mkdocs gh-deploy
```



---
Powered by [Gemini Exporter](https://www.ai-chat-exporter.com)

--- Fichier : hors_git/documentation /requirements-docs.txt ---
mkdocs 
mkdocs-material

conda activate conda_env_hash_tool 

mkdocs serve 



--- Fichier : hors_git/presentation hash tool/hash_tool-presentation.docx ---
[Fichier binaire ou illisible, contenu ignoré]

--- Fichier : hors_git/presentation hash tool/hash_tool-presentation.pdf ---
[Fichier binaire ou illisible, contenu ignoré]

--- Fichier : hors_git/presentation hash tool/manuel.md ---
# Manuel technique — Vérification d'intégrité de données

**Périmètre :** détection d'erreurs de transfert et de corruption silencieuse sur disque, sans adversaire.  
**Outils couverts :** b3sum (BLAKE3) · xxHash3 · find · diff · bash · jq

---

## Table des matières

1. [Algorithmes de hachage](#1-algorithmes-de-hachage)
2. [Structure du fichier .b3](#2-structure-du-fichier-b3)
3. [Workflow : calcul, stockage, comparaison](#3-workflow--calcul-stockage-comparaison)
4. [Explication du script integrity.sh](#4-explication-du-script-integritysh)
5. [Pipeline batch : runner.sh + pipeline.json](#5-pipeline-batch--runnersh--pipelinejson)
6. [Performances et optimisation disque](#6-performances-et-optimisation-disque)
7. [Limites et angles morts](#7-limites-et-angles-morts)
8. [Référence rapide](#8-référence-rapide)
9. [Annexe — Alternatives et extensions](#9-annexe--alternatives-et-extensions)

---

## 1. Algorithmes de hachage

### Taxonomie

Deux familles distinctes, usages mutuellement exclusifs :

| Propriété | Cryptographique (BLAKE3) | Non-cryptographique (xxHash3) |
|---|---|---|
| Résistance collision intentionnelle | Oui — infaisable calculatoirement | Non — collisions construisibles |
| Résistance préimage | Oui | Non |
| Débit CPU (1 cœur) | ~1 Go/s | ~50 Go/s |
| Débit sur HDD (150 Mo/s) | Identique — disque impose le rythme | Identique |
| Débit sur SATA SSD (500 Mo/s) | Identique | Identique |
| Détection corruption accidentelle | Oui | Oui |
| Utilisable en sécurité | Oui | Non |

### Pourquoi BLAKE3 plutôt que xxHash3

xxHash3 est techniquement suffisant pour détecter des erreurs accidentelles. BLAKE3 est recommandé pour une seule raison : **le coût marginal sur disque est nul** — les deux sont limités par l'I/O. BLAKE3 reste utilisable si le besoin évolue vers un contexte de sécurité. Headroom gratuit.

```bash
# Si xxHash3 est préféré — workflow identique à b3sum
find ./dossier -type f -print0 | sort -z | xargs -0 xxh128sum > base.xxh
```

### Limitations spécifiques à ce workflow

- Ne hache pas les métadonnées (mtime, permissions).
- Ne hache pas les dossiers vides : `find -type f` ne remonte que les fichiers réguliers.
- Sensible aux chemins : chemin absolu vs relatif → deux bases incompatibles pour la même donnée.

---

## 2. Structure du fichier .b3

b3sum produit un format texte simple, une ligne par fichier :

```
# Format : <hash>  <chemin>
# Deux espaces séparent le hash du chemin (convention b3sum/sha256sum)

a1b2c3d4e5f6a7b8c9d0e1f2a3b4c5d6e7f8a9b0c1d2e3f4a5b6c7d8e9f0a1b2  ./dossier/fichier.txt
e5f6a7b8c9d0e1f2a3b4c5d6e7f8a9b0c1d2e3f4a5b6c7d8e9f0a1b2c3d4e5f6  ./dossier/sous/autre.bin
```

| Nombre de fichiers | Taille approximative |
|---|---|
| 10 000 | ~2 Mo |
| 100 000 | ~20 Mo |
| 1 000 000 | ~200 Mo |

> **Règle absolue : chemins relatifs.** Toujours `find ./dossier`, jamais `find /chemin/absolu`. Un chemin absolu rend la base inutilisable après déplacement ou remontage.

---

## 3. Workflow : calcul, stockage, comparaison

### Calcul et enregistrement de la base

```bash
find ./mon_dossier -type f -print0 \
  | sort -z \
  | xargs -0 b3sum \
  > hashes_2024-01-15.b3

wc -l hashes_2024-01-15.b3
```

**`sort -z`** : `find` ne garantit pas un ordre déterministe. Sans tri, `diff` entre deux bases est inutilisable.

**`-print0` / `-0`** : robuste aux noms de fichiers avec espaces ou caractères spéciaux.

### Vérification directe

```bash
b3sum --check hashes_2024-01-15.b3

# Sortie OK :
# ./mon_dossier/fichier.txt: OK

# Sortie ECHEC :
# ./mon_dossier/sous/corrompu.bin: FAILED
# b3sum: WARNING: 1 computed checksum did NOT match

b3sum --check hashes_2024-01-15.b3 2>&1 | grep FAILED
```

> **Contrainte critique : répertoire de travail.** `b3sum --check` résout les chemins relatifs depuis `pwd`. Toujours exécuter depuis le répertoire où `compute` a été lancé.

### Comparaison de deux bases .b3

```bash
diff <(sort hashes_2024-01-15.b3) <(sort hashes_2024-02-01.b3)
```

`run_compare()` dans `integrity.sh` automatise cette comparaison avec `join`, `comm`, et un rapport structuré.

---

## 4. Explication du script integrity.sh

### En-tête et mode strict

```bash
#!/usr/bin/env bash
set -euo pipefail
```

- `-e` : arrêt sur échec de commande.
- `-u` : erreur sur variable non initialisée.
- `-o pipefail` : échec du pipeline si une commande intermédiaire échoue.

### Parsing des arguments

```bash
QUIET=0
ARGS=()
for arg in "$@"; do
  case "$arg" in
    --quiet) QUIET=1 ;;
    *)       ARGS+=("$arg") ;;
  esac
done
MODE="${ARGS[0]:-}"
ARG2="${ARGS[1]:-}"
ARG3="${ARGS[2]:-}"
```

`--quiet` filtré avant la lecture positionnelle. `:-` donne une valeur vide par défaut en mode `-u`.

### Mode compute

```bash
compute_with_progress() {
  local -a files
  mapfile -d '' files < <(find "$target" -type f -print0 | sort -z)

  for file in "${files[@]}"; do
    b3sum "$file" >> "$hashfile"
    # ETA calculé et affiché sur /dev/tty — jamais dans le pipe
    printf "\r[%d/%d] ETA : %dm %02ds   " ... > /dev/tty
  done
}
```

**`mapfile -d ''`** : charge les chemins en tableau depuis flux nul-séparé. Robuste aux espaces et caractères spéciaux.

**`> /dev/tty`** : progression écrite directement sur le terminal, ne peut pas polluer la base `.b3`.

### Mode verify

```bash
hashfile_abs=$(realpath "$ARG2")
[ -n "${ARG3:-}" ] && cd "$ARG3"
run_verify "$hashfile_abs"
```

Le chemin absolu est résolu **avant** le `cd` — un chemin relatif deviendrait invalide après changement de répertoire.

### Mode compare

`run_compare()` convertit `hash  chemin` → `chemin\thash` via `awk` (offset fixe 64 chars pour le hash), puis utilise `sort`, `join`, `comm` avec `-t $'\t'` — robuste aux chemins avec espaces.

---

## 5. Pipeline batch : runner.sh + pipeline.json

### Problème résolu

Lancer `integrity.sh` manuellement sur plusieurs dossiers depuis des partitions différentes (VeraCrypt, disques externes) est error-prone : répertoire de travail incorrect, chemins absolus dans les bases, oubli de `cd`. `runner.sh` automatise et sécurise ces étapes.

**Dépendance supplémentaire :** `jq` (`apt install jq` dans WSL).

### pipeline.json — format

```json
{
    "pipeline": [

        {
            "op":     "compute",
            "source": "/mnt/a/dossier_disque_1",
            "bases":  "/mnt/c/Users/TonNom/Desktop/bases",
            "nom":    "hashes_dossier_1.b3"
        },

        {
            "op":     "compute",
            "source": "/mnt/i/dossier_disque_2",
            "bases":  "/mnt/c/Users/TonNom/Desktop/bases",
            "nom":    "hashes_dossier_2.b3"
        },

        {
            "op":     "verify",
            "source": "/mnt/a/dossier_disque_1",
            "base":   "/mnt/c/Users/TonNom/Desktop/bases/hashes_dossier_1.b3"
        },

        {
            "op":     "compare",
            "base_a": "/mnt/c/Users/TonNom/Desktop/bases/hashes_dossier_1.b3",
            "base_b": "/mnt/c/Users/TonNom/Desktop/bases/hashes_dossier_2.b3"
        }

    ]
}
```

Champs requis par opération :

| `op` | Champs |
|---|---|
| `compute` | `source` — dossier à hacher · `bases` — dossier de destination · `nom` — nom du `.b3` |
| `verify` | `source` — répertoire de travail d'origine · `base` — chemin complet du `.b3` |
| `compare` | `base_a` — ancienne base · `base_b` — nouvelle base |

### runner.sh — comportement

**compute** : `cd "$source"` puis `integrity.sh compute . "$bases/$nom"`. Le `.` garantit des chemins relatifs dans la base.

**verify** : `cd "$source"` puis `integrity.sh verify "$base"`. Le `cd` reproduit le répertoire de travail d'origine du compute.

**compare** : appel direct sans `cd`. `base_a` et `base_b` sont des chemins absolus vers les `.b3`.

**Validation** : `jq empty` vérifie la syntaxe JSON à l'entrée. Champs manquants et opérations inconnues produisent un message `ERREUR` avec numéro de bloc, sans stacktrace `jq`.

### Lancement Windows (double-clic)

```bat
@echo off
wsl bash /mnt/c/Users/TonNom/Desktop/runner.sh
pause
```

### Chemins WSL — partitions VeraCrypt

| Windows | WSL |
|---|---|
| `A:\` | `/mnt/a/` |
| `C:\` | `/mnt/c/` |
| `H:\` | `/mnt/h/` |
| `I:\` | `/mnt/i/` |

Si VeraCrypt remonte une partition sur une lettre différente, seul le champ `source` dans `pipeline.json` est à modifier. La base `.b3` reste valide car ses chemins sont relatifs.

---

## 6. Performances et optimisation disque

Sur HDD (150 Mo/s), SSD SATA (500 Mo/s) ou SSD NVMe séquentiel, le disque est systématiquement le goulot. b3sum à 1 Go/s sur un cœur ne sera jamais le facteur limitant.

La boucle séquentielle de `compute_with_progress` est légèrement moins efficace que `xargs -P 4` sur SSD NVMe avec de nombreux petits fichiers, mais identique sur HDD — cas principal pour gros volumes. Le gain ETA justifie le choix.

Pour SSD NVMe + pas besoin d'ETA :

```bash
find ./dossier -type f -print0 | sort -z | xargs -0 -P 4 b3sum > base.b3
```

---

## 7. Limites et angles morts

| Scénario | Détecté ? | Explication |
|---|---|---|
| Fichier corrompu | **Oui** | Hash différent → FAILED ou divergence compare |
| Fichier manquant | **Oui** | FAILED (No such file) ou section DISPARUS |
| Fichier ajouté | **Oui** (compare) | Section NOUVEAUX |
| Dossier vide | **Non** | `find -type f` ignore les dossiers vides |
| Permissions/timestamps | **Non** | b3sum ne hache que le contenu binaire |
| Clone identique | **Non** | Hash identique — indétectable par définition |
| Corruption de la base .b3 | **Non** | La base n'est pas auto-protégée |

### Protéger la base

```bash
b3sum hashes_2024-01-15.b3 > hashes_2024-01-15.b3.check
b3sum --check hashes_2024-01-15.b3.check
```

Stocker la base sur un support distinct. Sur VeraCrypt : stocker les `.b3` sur `C:`, jamais sur la partition vérifiée.

### Renommages et changements de chemin

`b3sum --check` compare les chemins littéralement. Tout renommage de dossier produit des FAILED sur tous les fichiers, même si le contenu est intact.

```bash
sed 's|./ancien_nom/|./nouveau_nom/|g' base.b3 > base_corrigee.b3
b3sum --check base_corrigee.b3
```

---

## 8. Référence rapide

```bash
# Calcul
find ./dossier -type f -print0 | sort -z | xargs -0 b3sum > base.b3

# Vérification
./integrity.sh verify base.b3

# Comparaison
./integrity.sh compare ancienne.b3 nouvelle.b3

# Pipeline multi-dossiers
./runner.sh                        # lit pipeline.json dans le même dossier
./runner.sh /chemin/pipeline.json  # config explicite

# Compter les fichiers indexés
wc -l base.b3

# Fichier unique
b3sum fichier.bin

# Protéger la base
b3sum base.b3 > base.b3.check
```

| Situation | Mode | Commande |
|---|---|---|
| Première indexation | compute | `./integrity.sh compute ./dossier base.b3` |
| Multi-dossiers / VeraCrypt | runner | `./runner.sh` |
| Vérifier après transfert | verify | `./integrity.sh verify base.b3` |
| Comparer deux archives | compare | `./integrity.sh compare old.b3 new.b3` |
| Fichier unique | ad hoc | `b3sum fichier.bin` |

---

## 9. Annexe — Alternatives et extensions

### A.1 Outils FIM

| Outil | Usage | Complexité | Pertinent si… |
|---|---|---|---|
| Tripwire | Audit système local | Moyenne | Serveur Linux, conformité PCI-DSS/HIPAA |
| Samhain | FIM distribué, alertes SIEM | Élevée | Infrastructure d'entreprise |
| AIDE | Alternative open source à Tripwire | Moyenne | Remplacement direct de Tripwire |
| ZFS | Checksum natif sur chaque bloc | Faible (si migration possible) | Protection transparente |

b3sum/xxHash3 sont des **primitives**. Tripwire et Samhain sont des **systèmes** qui maintiennent un état de référence et détectent les dérives.

### A.2 Intégration automatisée

```bash
# Crontab — vérification hebdomadaire
0 2 * * 0 /opt/integrity.sh --quiet verify /var/lib/integrity/base.b3 >> /var/log/integrity.log 2>&1

# Post-transfert rsync
rsync -av source/ dest/ && b3sum --check base.b3

# Alerte email
b3sum --check base.b3 2>&1 | grep FAILED | mail -s 'Alerte intégrité' admin@example.com
```

--- Fichier : hors_git/TODO - messages exceptions/message d'erreur.md ---

Des messages d'erreurs humainement compréhensibles. 
Il faut ajouter des commentaires dans le code pour qu'ils apparaissent. 

TODO


des exceptions 


--- Fichier : hors_git/[terminé] -- TODO - CLI/ameliorations todo.txt ---
# === Arborescence du dossier ===

TODO - CLI
├── cli unique.md
├── commandes_prevues.md
├── helpers_commandes.md
├── pipeline-amelioree.json
├── pipeline_json.md
└── sidecar file for metadata.md


# === Contenu des fichiers ===

--- Fichier : cli unique.md ---

**Rapport — Spécification conceptuelle de l’interface CLI de `hash-tool` (version mise à jour)**

**1. Objectif général**

Le logiciel `hash-tool` propose une interface en ligne de commande unique, indépendante du mode d’exécution réel (natif ou conteneurisé). L’utilisateur interagit exclusivement avec une grammaire de commandes stable, sans référence explicite à l’environnement d’exécution. Le logiciel choisit automatiquement le mode d’exécution (natif ou conteneurisé) selon les capacités détectées.

Ce principe correspond à une abstraction de la couche d’exécution : la CLI constitue un contrat stable entre l’utilisateur et le logiciel, tandis que l’implémentation peut varier selon l’environnement.

---

**2. Principe d’interface de commande unique**

La propriété centrale reste l’« unicité de l’interface » :

– L’utilisateur invoque toujours `hash-tool` avec la même syntaxe,
– Le logiciel détecte en interne les capacités de l’environnement,
– Si l’exécution native est possible, elle est utilisée,
– Sinon, le programme délègue l’exécution à un conteneur (Docker), invisible pour l’utilisateur.

Docker ou tout autre conteneur devient un **détail d’implémentation**. La CLI reste stable et intuitive.

---

**3. Support des pipelines JSON (conceptuel)**

Le logiciel prend en charge un **fichier pipeline JSON** définissant une suite d’opérations à exécuter automatiquement. Chaque opération (`op`) correspond à une commande CLI (`compute`, `verify`, `compare`). Le runner (`hash-tool runner -pipeline <chemin>`) parcourt le JSON et exécute chaque étape dans l’ordre, en respectant la logique métier.

Exemple conceptuel :

```json
{
  "pipeline": [
    { "op": "compute", "source": "...", "bases": "...", "nom": "..." },
    { "op": "verify", "source": "...", "base": "..." },
    { "op": "compare", "base_a": "...", "base_b": "...", "resultats": "..." }
  ]
}
````

**Description fonctionnelle :**

– Les chemins et noms dans le JSON reflètent les arguments de la CLI.
– Les opérations sont cumulables et répétables sur plusieurs dossiers et bases sans intervention manuelle.
– Cette approche rend la CLI plus puissante et adaptée à l’automatisation tout en conservant l’interface unique et cohérente.

---

**4. Support des métadonnées avec Sidecar File (conceptuel)**

Le logiciel peut générer un fichier **sidecar** associé à chaque `.b3` produit, contenant des métadonnées et commentaires. Cela permet de conserver des informations supplémentaires sans altérer le fichier `.b3` natif.

Exemple d’usage conceptuel :

```bash
hash-tool compute -data ./donnees -save ./bases -meta "Snapshot initial"
```

Cette commande génère :

* `hashes_donnees.b3` → hash des fichiers
* `hashes_donnees.b3.meta.json` → sidecar avec métadonnées (date, version, paramètres, commentaire)

---

**5. Conclusion**

Le modèle CLI conceptuel final :

– Interface homogène et stable pour toutes les opérations
– Détection automatique du mode d’exécution (natif ou Docker)
– Support conceptuel des pipelines JSON pour automatisation
– Gestion des métadonnées via sidecar file
– Détail d’implémentation masqué à l’utilisateur
– Maximisation de lisibilité, portabilité et ergonomie




--- Fichier : commandes_prevues.md ---

**Rapport — Commandes prévues de `hash-tool`**

---

**1. Principe général**

Toutes les commandes suivent le schéma unique :

````

hash-tool <commande> [options]

````

L’utilisateur n’a pas besoin de connaître le mode d’exécution (natif ou Docker), qui est détecté automatiquement.

---

**2. Commandes principales et usage rapide**

| Commande    | Description courte                                                 |
| ----------- | ------------------------------------------------------------------ |
| `compute`   | Calcule les empreintes des fichiers d’un dossier.                  |
| `verify`    | Vérifie l’intégrité d’un dossier à partir d’une base d’empreintes. |
| `compare`   | Compare deux bases d’empreintes (snapshots).                       |
| `runner`    | Exécute un pipeline défini dans un fichier JSON.                   |
| `list`      | Liste les bases d’empreintes disponibles dans un dossier.          |
| `diff`      | Affiche les différences entre une base et un dossier courant.      |
| `stats`     | Affiche des statistiques sur une base d’empreintes.                |
| `check-env` | Analyse l’environnement d’exécution (natif ou conteneur).          |
| `version`   | Affiche la version du logiciel.                                    |
| `help`      | Affiche le help global ou spécifique à une commande.               |

---

**3. Options génériques principales**

| Option               | Description                                                            |
| -------------------- | ---------------------------------------------------------------------- |
| `-data <chemin>`     | Chemin vers le dossier de données à analyser.                          |
| `-base <chemin>`     | Chemin vers un fichier base d’empreintes (.b3) ou un dossier de bases. |
| `-old <chemin>`      | Chemin vers l’ancienne base (pour `compare`).                          |
| `-new <chemin>`      | Chemin vers la nouvelle base (pour `compare`).                         |
| `-pipeline <chemin>` | Chemin vers un fichier pipeline JSON.                                  |
| `-save <chemin>`     | Dossier de sortie pour les résultats.                                  |
| `-readonly`          | Force l’ouverture des données en lecture seule.                        |
| `-verbose`           | Mode verbeux.                                                          |
| `-quiet`             | Mode silencieux.                                                       |
| `-help`              | Affiche le help spécifique.                                            |
| `-version`           | Affiche la version.                                                    |
| `-meta <texte>`      | Commentaire ou note à inclure dans le sidecar JSON associé au `.b3`.   |

---

**4. Exemples d’utilisation rapide**

```bash
# Calculer les empreintes d’un dossier
hash-tool compute -data ./donnees -save ./bases -meta "Snapshot initial"

# Vérifier l’intégrité d’un dossier à partir d’une base
hash-tool verify -data ./donnees -base ./bases/hashes.b3 -save ./resultats

# Comparer deux bases
hash-tool compare -old ancien.b3 -new nouveau.b3 -save ./resultats

# Exécuter un pipeline JSON
hash-tool runner -pipeline ./pipeline.json -save ./resultats

# Vérifier l’environnement
hash-tool check-env
````

---

**5. Objectif de ce fichier**

* Fournir un **référentiel rapide et clair** des commandes disponibles.
* Permettre à l’utilisateur de comprendre la syntaxe générale sans consulter tous les helps détaillés.
* Complémentaire à `helpers_commandes.md` pour les détails par sous-commande et la gestion des métadonnées via sidecar file.




--- Fichier : helpers_commandes.md ---

**Rapport — Helps spécifiques des sous-commandes de `hash-tool`**

---

### 1. Help global

```bash
hash-tool help
````

**Usage :**
`hash-tool <commande> [options]`

**Commandes principales :**

* `compute`        Calcule les empreintes d’un dossier.
* `verify`         Vérifie l’intégrité d’un dossier à partir d’une base.
* `compare`        Compare deux bases d’empreintes.
* `runner`         Exécute un pipeline JSON.
* `list`           Liste les bases d’empreintes disponibles.
* `diff`           Affiche les différences entre une base et un dossier.
* `stats`          Affiche des statistiques sur une base.
* `check-env`      Analyse l’environnement d’exécution.
* `version`        Affiche la version.
* `help`           Affiche cette aide.

**Options générales :**

* `-data <chemin>`        Dossier à analyser.
* `-base <chemin>`        Fichier base d’empreintes (.b3).
* `-old <chemin>`         Ancienne base (pour `compare`).
* `-new <chemin>`         Nouvelle base (pour `compare`).
* `-pipeline <chemin>`    Fichier pipeline JSON.
* `-save <chemin>`        Dossier de sortie pour les résultats.
* `-readonly`             Lecture seule.
* `-verbose`              Mode verbeux.
* `-quiet`                Mode silencieux.
* `-help`                 Affiche le help spécifique.
* `-version`              Affiche la version.
* `-meta <texte>`         Commentaire à inclure dans le sidecar JSON.

---

### 2. Helps spécifiques par sous-commande

#### 2.1 Compute

```bash
hash-tool compute -help
```

**Usage :**
`hash-tool compute -data <chemin dossier> -save <chemin sortie> [options]`

**Options :**

* `-data <chemin>`      Dossier contenant les fichiers à hacher.
* `-save <chemin>`      Dossier où enregistrer la base d’empreintes.
* `-verbose`            Mode verbeux.
* `-readonly`           Analyse en lecture seule.
* `-quiet`              Mode silencieux.
* `-meta <texte>`       Commentaire à inclure dans le sidecar JSON.

**Exemple :**
`hash-tool compute -data ./donnees -save ./bases -meta "Snapshot initial"`

---

#### 2.2 Verify

```bash
hash-tool verify -help
```

**Usage :**
`hash-tool verify -data <chemin dossier> -base <chemin base.b3> -save <chemin sortie> [options]`

**Options :**

* `-data <chemin>`      Dossier à vérifier.
* `-base <chemin>`      Base d’empreintes de référence.
* `-save <chemin>`      Dossier de sortie pour le rapport de vérification.
* `-verbose`            Mode verbeux.
* `-quiet`              Mode silencieux.

**Exemple :**
`hash-tool verify -data ./donnees -base ./bases/hashes.b3 -save ./resultats`

---

#### 2.3 Compare

```bash
hash-tool compare -help
```

**Usage :**
`hash-tool compare -old <chemin ancien.b3> -new <chemin nouveau.b3> -save <chemin sortie> [options]`

**Options :**

* `-old <chemin>`       Ancienne base d’empreintes.
* `-new <chemin>`       Nouvelle base d’empreintes.
* `-save <chemin>`      Dossier de sortie pour le rapport de comparaison.
* `-verbose`            Mode verbeux.
* `-quiet`              Mode silencieux.

**Exemple :**
`hash-tool compare -old ancien.b3 -new nouveau.b3 -save ./resultats`

---

#### 2.4 Runner (pipeline JSON)

```bash
hash-tool runner -help
```

**Usage :**
`hash-tool runner -pipeline <chemin pipeline.json> -save <chemin sortie> [options]`

**Options :**

* `-pipeline <chemin>`  Fichier JSON définissant le pipeline.
* `-save <chemin>`      Dossier de sortie pour les résultats du pipeline.
* `-verbose`            Mode verbeux.
* `-quiet`              Mode silencieux.

**Exemple :**
`hash-tool runner -pipeline ./pipeline.json -save ./resultats`

---

#### 2.5 List

```bash
hash-tool list -help
```

**Usage :**
`hash-tool list -base <chemin dossier> [options]`

**Options :**

* `-base <chemin>`      Dossier contenant les snapshots à lister.
* `-verbose`            Mode verbeux.

**Exemple :**
`hash-tool list -base ./bases`

---

#### 2.6 Diff

```bash
hash-tool diff -help
```

**Usage :**
`hash-tool diff -base <chemin base.b3> -data <chemin dossier> [options]`

**Options :**

* `-base <chemin>`      Base d’empreintes de référence.
* `-data <chemin>`      Dossier à comparer.
* `-verbose`            Mode verbeux.

**Exemple :**
`hash-tool diff -base ./bases/hashes.b3 -data ./donnees`

---

#### 2.7 Stats

```bash
hash-tool stats -help
```

**Usage :**
`hash-tool stats -base <chemin base.b3> [options]`

**Options :**

* `-base <chemin>`      Base d’empreintes pour calculer les statistiques.
* `-verbose`            Mode verbeux.

**Exemple :**
`hash-tool stats -base ./bases/hashes.b3`

---

#### 2.8 Check-env

```bash
hash-tool check-env -help
```

**Usage :**
`hash-tool check-env`

**Description :**
Analyse l’environnement d’exécution et indique si le programme peut s’exécuter nativement ou doit utiliser Docker.

---

#### 2.9 Version

```bash
hash-tool version -help
```

**Usage :**
`hash-tool version`

**Description :**
Affiche la version du logiciel.

---

**3. Conclusion**

* Chaque sous-commande dispose d’un help dédié pour détailler ses options et arguments.
* Le help global résume les commandes principales et sert de point d’entrée.
* La structure prend en charge la génération et l’exploitation de sidecar files pour les métadonnées.


--- Fichier : pipeline-amelioree.json ---

{
  "pipeline": [
    {
      "type": "compute",
      "params": {
        "input": "/mnt/data/dossier_exemple",
        "output_dir": "/mnt/bases",
        "filename": "hashes_exemple.b3",
        "meta": "Snapshot initial"
      },
      "options": {
        "verbose": true
      },
      "description": "Calcul des empreintes pour un dossier exemple"
    },
    {
      "type": "verify",
      "params": {
        "input": "/mnt/data/dossier_exemple",
        "reference": "/mnt/bases/hashes_exemple.b3",
        "output_dir": "/mnt/resultats/verify_exemple"
      },
      "options": {},
      "description": "Vérification de l’intégrité du dossier exemple"
    },
    {
      "type": "compare",
      "params": {
        "input": "/mnt/bases/hashes_exemple.b3",
        "reference": "/mnt/bases/hashes_autre.b3",
        "output_dir": "/mnt/resultats/compare_exemple"
      },
      "options": {},
      "description": "Comparaison de deux bases d’empreintes"
    },
    {
      "type": "runner",
      "params": {
        "pipeline_file": "/mnt/pipelines/pipeline_secondaire.json",
        "output_dir": "/mnt/resultats/runner_exemple"
      },
      "options": {
        "verbose": true
      },
      "description": "Exécution d’un pipeline JSON secondaire"
    },
    {
      "type": "list",
      "params": {
        "input_dir": "/mnt/bases"
      },
      "options": {},
      "description": "Lister les bases d’empreintes disponibles"
    },
    {
      "type": "diff",
      "params": {
        "input": "/mnt/bases/hashes_exemple.b3",
        "reference_dir": "/mnt/data/dossier_exemple"
      },
      "options": {},
      "description": "Afficher les différences entre la base et le dossier"
    },
    {
      "type": "stats",
      "params": {
        "input": "/mnt/bases/hashes_exemple.b3"
      },
      "options": {},
      "description": "Afficher les statistiques de la base d’empreintes"
    },
    {
      "type": "check-env",
      "params": {},
      "options": {},
      "description": "Vérifier si l’exécution native ou Docker est possible"
    },
    {
      "type": "version",
      "params": {},
      "options": {},
      "description": "Afficher la version du logiciel"
    }
  ]
}




--- Fichier : pipeline_json.md ---



### Fichier : pipeline_json.md

**Rapport — Documentation du pipeline JSON pour `hash-tool`**

---

**1. Objectif**

Le pipeline JSON permet de définir une suite d’opérations à exécuter automatiquement avec `hash-tool runner`. Chaque étape correspond à une commande CLI (`compute`, `verify`, `compare`, etc.) et inclut les chemins, paramètres et options nécessaires.

Le fichier `pipeline-amelioree.json` fournit un exemple représentatif, suffisant pour couvrir toutes les commandes principales et illustrer la structure uniforme du pipeline.

---

**2. Structure générale**

Chaque étape du pipeline utilise une structure uniforme :

* `type` : commande à exécuter (`compute`, `verify`, `compare`, `runner`, `list`, `diff`, `stats`, `check-env`, `version`).
* `params` : arguments spécifiques à la commande (`input`, `reference`, `output_dir`, etc.).
* `options` : flags optionnels (`verbose`, `quiet`, `readonly`, etc.).
* `meta` : métadonnées optionnelles pour enrichir la documentation et suivi (ex. `comment`).
* `description` : texte explicatif décrivant l’étape.

Cette uniformité permet au runner de **parcourir toutes les étapes dans l’ordre** et d’exécuter automatiquement les commandes, tout en conservant un format homogène, clair et validable.

---

**3. Référence du fichier pipeline**

Le pipeline complet est disponible dans :

```
pipeline-amelioree.json
```

Ce fichier contient un exemple pertinent, couvrant toutes les commandes principales et utilisant la structure uniforme `type` / `params` / `options` / `meta` avec `description`.

---

**4. Description fonctionnelle**

* Chaque étape correspond à une commande CLI.
* `params` et `options` sont standardisés pour toutes les commandes, facilitant l’automatisation.
* `meta` permet d’associer des informations complémentaires à chaque étape, exploitables par les pipelines ou le sidecar file.
* Le champ `description` fournit une documentation lisible directement dans le JSON.
* Le runner exécute chaque étape dans l’ordre défini.

---

**5. Bonnes pratiques**

1. Toujours vérifier les chemins et permissions avant exécution.
2. Utiliser des noms explicites pour les fichiers de base (`filename`) et dossiers de sortie (`output_dir`).
3. Ajouter les options (`verbose`, `quiet`, `readonly`) au niveau de chaque étape si nécessaire.
4. Compléter le champ `description` pour documenter le rôle de chaque étape, facilitant la lecture et le suivi du pipeline.
5. Exploiter le champ `meta` pour des commentaires, version de snapshot ou paramètres spécifiques.
6. Utiliser le fichier `pipeline-amelioree.json` comme référence pour créer de nouveaux pipelines cohérents et homogènes.

---

**6. Avantages du format**

* Pertinent et compréhensible pour l’utilisateur.
* Suffisamment descriptif pour illustrer toutes les commandes principales.
* Uniforme, extensible et facile à valider avec JSON Schema.
* Permet l’automatisation et la documentation simultanément.
* Intégrable avec le sidecar file pour enrichir les métadonnées associées aux fichiers `.b3`.




--- Fichier : sidecar file for metadata.md ---



### Note — Feature « Sidecar File » pour `hash-tool`

**Objet :** ajout de la possibilité de stocker des métadonnées et commentaires associés aux fichiers `.b3` générés par `hash-tool`.

---

#### 1. Contexte

Les fichiers `.b3` générés par `hash-tool` contiennent uniquement les hash Blake3 des fichiers d’un dossier. Actuellement, il n’existe aucun espace prévu pour des commentaires ou des informations complémentaires (ex. date de snapshot, paramètres utilisés, version de l’outil).

Pour enrichir l’information sans modifier le format `.b3` natif ni perdre la compatibilité avec d’autres outils Blake3, l’introduction d’un **sidecar file** est proposée.

---

#### 2. Principe

Un **sidecar file** est un fichier annexe, créé à côté du fichier `.b3` correspondant, contenant des métadonnées structurées.

* Extension suggérée : `.meta.json` ou `.b3.json` (ex. `hashes_exemple.b3.meta.json`).
* Format : JSON, pour lisibilité et compatibilité avec les pipelines existants.
* Contenu typique : informations descriptives, date de création, paramètres d’exécution, version de `hash-tool`.

---

#### 3. Structure du sidecar

Exemple minimal de fichier sidecar :

```json
{
  "created_by": "hash-tool v1.2",
  "date": "2026-02-24T14:30:00Z",
  "comment": "Snapshot avant migration",
  "parameters": {
    "readonly": true,
    "directory": "/mnt/data/dossier_exemple",
    "hash_algo": "blake3"
  }
}
```

**Champs principaux :**

| Champ        | Description                                                                   |
| ------------ | ----------------------------------------------------------------------------- |
| `created_by` | Version de l’outil ayant généré le snapshot.                                  |
| `date`       | Date et heure du calcul des hash.                                             |
| `comment`    | Texte libre pour des informations contextuelles.                              |
| `parameters` | Paramètres utilisés pour le calcul des hash (répertoires, flags, algorithme). |

---

#### 4. Avantages

1. **Compatibilité** : le fichier `.b3` reste inchangé, donc compatible avec Blake3 standard.
2. **Extensible** : possibilité d’ajouter de nouveaux champs sans modifier le moteur de hash.
3. **Synchronisation** : le sidecar est lié au fichier `.b3` correspondant et peut être automatiquement créé par `hash-tool`.
4. **Automatisation** : les pipelines (`runner`) peuvent lire et utiliser les métadonnées pour documentation ou suivi.

---

#### 5. Intégration dans `hash-tool`

* **Création automatique** : lors de `hash-tool compute`, un sidecar peut être généré dans le même répertoire que le `.b3`.
* **Lecture et affichage** : les commandes `verify`, `compare`, `stats` peuvent afficher ou exploiter les métadonnées.
* **Mise à jour optionnelle** : possibilité d’ajouter un commentaire postérieur au snapshot sans toucher au `.b3`.

* `params.meta` dans le pipeline JSON peut être utilisé pour remplir le sidecar automatiquement.

**Exemple d’usage :**

```bash
hash-tool compute -data ./donnees -save ./bases -meta "Snapshot initial"
```

Cette commande générerait :

* `hashes_donnees.b3` → hash des fichiers
* `hashes_donnees.b3.meta.json` → métadonnées contenant la note “Snapshot initial” et autres informations automatiques (date, version, paramètres).

---

#### 6. Conclusion

Le sidecar file est une solution simple et robuste pour enrichir les fichiers `.b3` avec des métadonnées :

* Aucun impact sur le format binaire existant.
* Permet la documentation, l’automatisation et le suivi des snapshots.
* Compatible avec les pipelines et l’interface CLI unique de `hash-tool`.




--- Fichier : hors_git/[terminé] -- TODO - CLI/cli unique.md ---

**Rapport — Spécification conceptuelle de l’interface CLI de `hash-tool` (version mise à jour)**

**1. Objectif général**

Le logiciel `hash-tool` propose une interface en ligne de commande unique, indépendante du mode d’exécution réel (natif ou conteneurisé). L’utilisateur interagit exclusivement avec une grammaire de commandes stable, sans référence explicite à l’environnement d’exécution. Le logiciel choisit automatiquement le mode d’exécution (natif ou conteneurisé) selon les capacités détectées.

Ce principe correspond à une abstraction de la couche d’exécution : la CLI constitue un contrat stable entre l’utilisateur et le logiciel, tandis que l’implémentation peut varier selon l’environnement.

---

**2. Principe d’interface de commande unique**

La propriété centrale reste l’« unicité de l’interface » :

– L’utilisateur invoque toujours `hash-tool` avec la même syntaxe,
– Le logiciel détecte en interne les capacités de l’environnement,
– Si l’exécution native est possible, elle est utilisée,
– Sinon, le programme délègue l’exécution à un conteneur (Docker), invisible pour l’utilisateur.

Docker ou tout autre conteneur devient un **détail d’implémentation**. La CLI reste stable et intuitive.

---

**3. Support des pipelines JSON (conceptuel)**

Le logiciel prend en charge un **fichier pipeline JSON** définissant une suite d’opérations à exécuter automatiquement. Chaque opération (`op`) correspond à une commande CLI (`compute`, `verify`, `compare`). Le runner (`hash-tool runner -pipeline <chemin>`) parcourt le JSON et exécute chaque étape dans l’ordre, en respectant la logique métier.

Exemple conceptuel :

```json
{
  "pipeline": [
    { "op": "compute", "source": "...", "bases": "...", "nom": "..." },
    { "op": "verify", "source": "...", "base": "..." },
    { "op": "compare", "base_a": "...", "base_b": "...", "resultats": "..." }
  ]
}
````

**Description fonctionnelle :**

– Les chemins et noms dans le JSON reflètent les arguments de la CLI.
– Les opérations sont cumulables et répétables sur plusieurs dossiers et bases sans intervention manuelle.
– Cette approche rend la CLI plus puissante et adaptée à l’automatisation tout en conservant l’interface unique et cohérente.

---

**4. Support des métadonnées avec Sidecar File (conceptuel)**

Le logiciel peut générer un fichier **sidecar** associé à chaque `.b3` produit, contenant des métadonnées et commentaires. Cela permet de conserver des informations supplémentaires sans altérer le fichier `.b3` natif.

Exemple d’usage conceptuel :

```bash
hash-tool compute -data ./donnees -save ./bases -meta "Snapshot initial"
```

Cette commande génère :

* `hashes_donnees.b3` → hash des fichiers
* `hashes_donnees.b3.meta.json` → sidecar avec métadonnées (date, version, paramètres, commentaire)

---

**5. Conclusion**

Le modèle CLI conceptuel final :

– Interface homogène et stable pour toutes les opérations
– Détection automatique du mode d’exécution (natif ou Docker)
– Support conceptuel des pipelines JSON pour automatisation
– Gestion des métadonnées via sidecar file
– Détail d’implémentation masqué à l’utilisateur
– Maximisation de lisibilité, portabilité et ergonomie




--- Fichier : hors_git/[terminé] -- TODO - CLI/commandes_prevues.md ---

**Rapport — Commandes prévues de `hash-tool`**

---

**1. Principe général**

Toutes les commandes suivent le schéma unique :

````

hash-tool <commande> [options]

````

L’utilisateur n’a pas besoin de connaître le mode d’exécution (natif ou Docker), qui est détecté automatiquement.

---

**2. Commandes principales et usage rapide**

| Commande    | Description courte                                                 |
| ----------- | ------------------------------------------------------------------ |
| `compute`   | Calcule les empreintes des fichiers d’un dossier.                  |
| `verify`    | Vérifie l’intégrité d’un dossier à partir d’une base d’empreintes. |
| `compare`   | Compare deux bases d’empreintes (snapshots).                       |
| `runner`    | Exécute un pipeline défini dans un fichier JSON.                   |
| `list`      | Liste les bases d’empreintes disponibles dans un dossier.          |
| `diff`      | Affiche les différences entre une base et un dossier courant.      |
| `stats`     | Affiche des statistiques sur une base d’empreintes.                |
| `check-env` | Analyse l’environnement d’exécution (natif ou conteneur).          |
| `version`   | Affiche la version du logiciel.                                    |
| `help`      | Affiche le help global ou spécifique à une commande.               |

---

**3. Options génériques principales**

| Option               | Description                                                            |
| -------------------- | ---------------------------------------------------------------------- |
| `-data <chemin>`     | Chemin vers le dossier de données à analyser.                          |
| `-base <chemin>`     | Chemin vers un fichier base d’empreintes (.b3) ou un dossier de bases. |
| `-old <chemin>`      | Chemin vers l’ancienne base (pour `compare`).                          |
| `-new <chemin>`      | Chemin vers la nouvelle base (pour `compare`).                         |
| `-pipeline <chemin>` | Chemin vers un fichier pipeline JSON.                                  |
| `-save <chemin>`     | Dossier de sortie pour les résultats.                                  |
| `-readonly`          | Force l’ouverture des données en lecture seule.                        |
| `-verbose`           | Mode verbeux.                                                          |
| `-quiet`             | Mode silencieux.                                                       |
| `-help`              | Affiche le help spécifique.                                            |
| `-version`           | Affiche la version.                                                    |
| `-meta <texte>`      | Commentaire ou note à inclure dans le sidecar JSON associé au `.b3`.   |

---

**4. Exemples d’utilisation rapide**

```bash
# Calculer les empreintes d’un dossier
hash-tool compute -data ./donnees -save ./bases -meta "Snapshot initial"

# Vérifier l’intégrité d’un dossier à partir d’une base
hash-tool verify -data ./donnees -base ./bases/hashes.b3 -save ./resultats

# Comparer deux bases
hash-tool compare -old ancien.b3 -new nouveau.b3 -save ./resultats

# Exécuter un pipeline JSON
hash-tool runner -pipeline ./pipeline.json -save ./resultats

# Vérifier l’environnement
hash-tool check-env
````

---

**5. Objectif de ce fichier**

* Fournir un **référentiel rapide et clair** des commandes disponibles.
* Permettre à l’utilisateur de comprendre la syntaxe générale sans consulter tous les helps détaillés.
* Complémentaire à `helpers_commandes.md` pour les détails par sous-commande et la gestion des métadonnées via sidecar file.




--- Fichier : hors_git/[terminé] -- TODO - CLI/helpers_commandes.md ---

**Rapport — Helps spécifiques des sous-commandes de `hash-tool`**

---

### 1. Help global

```bash
hash-tool help
````

**Usage :**
`hash-tool <commande> [options]`

**Commandes principales :**

* `compute`        Calcule les empreintes d’un dossier.
* `verify`         Vérifie l’intégrité d’un dossier à partir d’une base.
* `compare`        Compare deux bases d’empreintes.
* `runner`         Exécute un pipeline JSON.
* `list`           Liste les bases d’empreintes disponibles.
* `diff`           Affiche les différences entre une base et un dossier.
* `stats`          Affiche des statistiques sur une base.
* `check-env`      Analyse l’environnement d’exécution.
* `version`        Affiche la version.
* `help`           Affiche cette aide.

**Options générales :**

* `-data <chemin>`        Dossier à analyser.
* `-base <chemin>`        Fichier base d’empreintes (.b3).
* `-old <chemin>`         Ancienne base (pour `compare`).
* `-new <chemin>`         Nouvelle base (pour `compare`).
* `-pipeline <chemin>`    Fichier pipeline JSON.
* `-save <chemin>`        Dossier de sortie pour les résultats.
* `-readonly`             Lecture seule.
* `-verbose`              Mode verbeux.
* `-quiet`                Mode silencieux.
* `-help`                 Affiche le help spécifique.
* `-version`              Affiche la version.
* `-meta <texte>`         Commentaire à inclure dans le sidecar JSON.

---

### 2. Helps spécifiques par sous-commande

#### 2.1 Compute

```bash
hash-tool compute -help
```

**Usage :**
`hash-tool compute -data <chemin dossier> -save <chemin sortie> [options]`

**Options :**

* `-data <chemin>`      Dossier contenant les fichiers à hacher.
* `-save <chemin>`      Dossier où enregistrer la base d’empreintes.
* `-verbose`            Mode verbeux.
* `-readonly`           Analyse en lecture seule.
* `-quiet`              Mode silencieux.
* `-meta <texte>`       Commentaire à inclure dans le sidecar JSON.

**Exemple :**
`hash-tool compute -data ./donnees -save ./bases -meta "Snapshot initial"`

---

#### 2.2 Verify

```bash
hash-tool verify -help
```

**Usage :**
`hash-tool verify -data <chemin dossier> -base <chemin base.b3> -save <chemin sortie> [options]`

**Options :**

* `-data <chemin>`      Dossier à vérifier.
* `-base <chemin>`      Base d’empreintes de référence.
* `-save <chemin>`      Dossier de sortie pour le rapport de vérification.
* `-verbose`            Mode verbeux.
* `-quiet`              Mode silencieux.

**Exemple :**
`hash-tool verify -data ./donnees -base ./bases/hashes.b3 -save ./resultats`

---

#### 2.3 Compare

```bash
hash-tool compare -help
```

**Usage :**
`hash-tool compare -old <chemin ancien.b3> -new <chemin nouveau.b3> -save <chemin sortie> [options]`

**Options :**

* `-old <chemin>`       Ancienne base d’empreintes.
* `-new <chemin>`       Nouvelle base d’empreintes.
* `-save <chemin>`      Dossier de sortie pour le rapport de comparaison.
* `-verbose`            Mode verbeux.
* `-quiet`              Mode silencieux.

**Exemple :**
`hash-tool compare -old ancien.b3 -new nouveau.b3 -save ./resultats`

---

#### 2.4 Runner (pipeline JSON)

```bash
hash-tool runner -help
```

**Usage :**
`hash-tool runner -pipeline <chemin pipeline.json> -save <chemin sortie> [options]`

**Options :**

* `-pipeline <chemin>`  Fichier JSON définissant le pipeline.
* `-save <chemin>`      Dossier de sortie pour les résultats du pipeline.
* `-verbose`            Mode verbeux.
* `-quiet`              Mode silencieux.

**Exemple :**
`hash-tool runner -pipeline ./pipeline.json -save ./resultats`

---

#### 2.5 List

```bash
hash-tool list -help
```

**Usage :**
`hash-tool list -base <chemin dossier> [options]`

**Options :**

* `-base <chemin>`      Dossier contenant les snapshots à lister.
* `-verbose`            Mode verbeux.

**Exemple :**
`hash-tool list -base ./bases`

---

#### 2.6 Diff

```bash
hash-tool diff -help
```

**Usage :**
`hash-tool diff -base <chemin base.b3> -data <chemin dossier> [options]`

**Options :**

* `-base <chemin>`      Base d’empreintes de référence.
* `-data <chemin>`      Dossier à comparer.
* `-verbose`            Mode verbeux.

**Exemple :**
`hash-tool diff -base ./bases/hashes.b3 -data ./donnees`

---

#### 2.7 Stats

```bash
hash-tool stats -help
```

**Usage :**
`hash-tool stats -base <chemin base.b3> [options]`

**Options :**

* `-base <chemin>`      Base d’empreintes pour calculer les statistiques.
* `-verbose`            Mode verbeux.

**Exemple :**
`hash-tool stats -base ./bases/hashes.b3`

---

#### 2.8 Check-env

```bash
hash-tool check-env -help
```

**Usage :**
`hash-tool check-env`

**Description :**
Analyse l’environnement d’exécution et indique si le programme peut s’exécuter nativement ou doit utiliser Docker.

---

#### 2.9 Version

```bash
hash-tool version -help
```

**Usage :**
`hash-tool version`

**Description :**
Affiche la version du logiciel.

---

**3. Conclusion**

* Chaque sous-commande dispose d’un help dédié pour détailler ses options et arguments.
* Le help global résume les commandes principales et sert de point d’entrée.
* La structure prend en charge la génération et l’exploitation de sidecar files pour les métadonnées.


--- Fichier : hors_git/[terminé] -- TODO - CLI/pipeline-amelioree.json ---

{
  "pipeline": [
    {
      "type": "compute",
      "params": {
        "input": "/mnt/data/dossier_exemple",
        "output_dir": "/mnt/bases",
        "filename": "hashes_exemple.b3",
        "meta": "Snapshot initial"
      },
      "options": {
        "verbose": true
      },
      "description": "Calcul des empreintes pour un dossier exemple"
    },
    {
      "type": "verify",
      "params": {
        "input": "/mnt/data/dossier_exemple",
        "reference": "/mnt/bases/hashes_exemple.b3",
        "output_dir": "/mnt/resultats/verify_exemple"
      },
      "options": {},
      "description": "Vérification de l’intégrité du dossier exemple"
    },
    {
      "type": "compare",
      "params": {
        "input": "/mnt/bases/hashes_exemple.b3",
        "reference": "/mnt/bases/hashes_autre.b3",
        "output_dir": "/mnt/resultats/compare_exemple"
      },
      "options": {},
      "description": "Comparaison de deux bases d’empreintes"
    },
    {
      "type": "runner",
      "params": {
        "pipeline_file": "/mnt/pipelines/pipeline_secondaire.json",
        "output_dir": "/mnt/resultats/runner_exemple"
      },
      "options": {
        "verbose": true
      },
      "description": "Exécution d’un pipeline JSON secondaire"
    },
    {
      "type": "list",
      "params": {
        "input_dir": "/mnt/bases"
      },
      "options": {},
      "description": "Lister les bases d’empreintes disponibles"
    },
    {
      "type": "diff",
      "params": {
        "input": "/mnt/bases/hashes_exemple.b3",
        "reference_dir": "/mnt/data/dossier_exemple"
      },
      "options": {},
      "description": "Afficher les différences entre la base et le dossier"
    },
    {
      "type": "stats",
      "params": {
        "input": "/mnt/bases/hashes_exemple.b3"
      },
      "options": {},
      "description": "Afficher les statistiques de la base d’empreintes"
    },
    {
      "type": "check-env",
      "params": {},
      "options": {},
      "description": "Vérifier si l’exécution native ou Docker est possible"
    },
    {
      "type": "version",
      "params": {},
      "options": {},
      "description": "Afficher la version du logiciel"
    }
  ]
}




--- Fichier : hors_git/[terminé] -- TODO - CLI/pipeline_json.md ---



### Fichier : pipeline_json.md

**Rapport — Documentation du pipeline JSON pour `hash-tool`**

---

**1. Objectif**

Le pipeline JSON permet de définir une suite d’opérations à exécuter automatiquement avec `hash-tool runner`. Chaque étape correspond à une commande CLI (`compute`, `verify`, `compare`, etc.) et inclut les chemins, paramètres et options nécessaires.

Le fichier `pipeline-amelioree.json` fournit un exemple représentatif, suffisant pour couvrir toutes les commandes principales et illustrer la structure uniforme du pipeline.

---

**2. Structure générale**

Chaque étape du pipeline utilise une structure uniforme :

* `type` : commande à exécuter (`compute`, `verify`, `compare`, `runner`, `list`, `diff`, `stats`, `check-env`, `version`).
* `params` : arguments spécifiques à la commande (`input`, `reference`, `output_dir`, etc.).
* `options` : flags optionnels (`verbose`, `quiet`, `readonly`, etc.).
* `meta` : métadonnées optionnelles pour enrichir la documentation et suivi (ex. `comment`).
* `description` : texte explicatif décrivant l’étape.

Cette uniformité permet au runner de **parcourir toutes les étapes dans l’ordre** et d’exécuter automatiquement les commandes, tout en conservant un format homogène, clair et validable.

---

**3. Référence du fichier pipeline**

Le pipeline complet est disponible dans :

```
pipeline-amelioree.json
```

Ce fichier contient un exemple pertinent, couvrant toutes les commandes principales et utilisant la structure uniforme `type` / `params` / `options` / `meta` avec `description`.

---

**4. Description fonctionnelle**

* Chaque étape correspond à une commande CLI.
* `params` et `options` sont standardisés pour toutes les commandes, facilitant l’automatisation.
* `meta` permet d’associer des informations complémentaires à chaque étape, exploitables par les pipelines ou le sidecar file.
* Le champ `description` fournit une documentation lisible directement dans le JSON.
* Le runner exécute chaque étape dans l’ordre défini.

---

**5. Bonnes pratiques**

1. Toujours vérifier les chemins et permissions avant exécution.
2. Utiliser des noms explicites pour les fichiers de base (`filename`) et dossiers de sortie (`output_dir`).
3. Ajouter les options (`verbose`, `quiet`, `readonly`) au niveau de chaque étape si nécessaire.
4. Compléter le champ `description` pour documenter le rôle de chaque étape, facilitant la lecture et le suivi du pipeline.
5. Exploiter le champ `meta` pour des commentaires, version de snapshot ou paramètres spécifiques.
6. Utiliser le fichier `pipeline-amelioree.json` comme référence pour créer de nouveaux pipelines cohérents et homogènes.

---

**6. Avantages du format**

* Pertinent et compréhensible pour l’utilisateur.
* Suffisamment descriptif pour illustrer toutes les commandes principales.
* Uniforme, extensible et facile à valider avec JSON Schema.
* Permet l’automatisation et la documentation simultanément.
* Intégrable avec le sidecar file pour enrichir les métadonnées associées aux fichiers `.b3`.




--- Fichier : hors_git/[terminé] -- TODO - CLI/sidecar file for metadata.md ---



### Note — Feature « Sidecar File » pour `hash-tool`

**Objet :** ajout de la possibilité de stocker des métadonnées et commentaires associés aux fichiers `.b3` générés par `hash-tool`.

---

#### 1. Contexte

Les fichiers `.b3` générés par `hash-tool` contiennent uniquement les hash Blake3 des fichiers d’un dossier. Actuellement, il n’existe aucun espace prévu pour des commentaires ou des informations complémentaires (ex. date de snapshot, paramètres utilisés, version de l’outil).

Pour enrichir l’information sans modifier le format `.b3` natif ni perdre la compatibilité avec d’autres outils Blake3, l’introduction d’un **sidecar file** est proposée.

---

#### 2. Principe

Un **sidecar file** est un fichier annexe, créé à côté du fichier `.b3` correspondant, contenant des métadonnées structurées.

* Extension suggérée : `.meta.json` ou `.b3.json` (ex. `hashes_exemple.b3.meta.json`).
* Format : JSON, pour lisibilité et compatibilité avec les pipelines existants.
* Contenu typique : informations descriptives, date de création, paramètres d’exécution, version de `hash-tool`.

---

#### 3. Structure du sidecar

Exemple minimal de fichier sidecar :

```json
{
  "created_by": "hash-tool v1.2",
  "date": "2026-02-24T14:30:00Z",
  "comment": "Snapshot avant migration",
  "parameters": {
    "readonly": true,
    "directory": "/mnt/data/dossier_exemple",
    "hash_algo": "blake3"
  }
}
```

**Champs principaux :**

| Champ        | Description                                                                   |
| ------------ | ----------------------------------------------------------------------------- |
| `created_by` | Version de l’outil ayant généré le snapshot.                                  |
| `date`       | Date et heure du calcul des hash.                                             |
| `comment`    | Texte libre pour des informations contextuelles.                              |
| `parameters` | Paramètres utilisés pour le calcul des hash (répertoires, flags, algorithme). |

---

#### 4. Avantages

1. **Compatibilité** : le fichier `.b3` reste inchangé, donc compatible avec Blake3 standard.
2. **Extensible** : possibilité d’ajouter de nouveaux champs sans modifier le moteur de hash.
3. **Synchronisation** : le sidecar est lié au fichier `.b3` correspondant et peut être automatiquement créé par `hash-tool`.
4. **Automatisation** : les pipelines (`runner`) peuvent lire et utiliser les métadonnées pour documentation ou suivi.

---

#### 5. Intégration dans `hash-tool`

* **Création automatique** : lors de `hash-tool compute`, un sidecar peut être généré dans le même répertoire que le `.b3`.
* **Lecture et affichage** : les commandes `verify`, `compare`, `stats` peuvent afficher ou exploiter les métadonnées.
* **Mise à jour optionnelle** : possibilité d’ajouter un commentaire postérieur au snapshot sans toucher au `.b3`.

* `params.meta` dans le pipeline JSON peut être utilisé pour remplir le sidecar automatiquement.

**Exemple d’usage :**

```bash
hash-tool compute -data ./donnees -save ./bases -meta "Snapshot initial"
```

Cette commande générerait :

* `hashes_donnees.b3` → hash des fichiers
* `hashes_donnees.b3.meta.json` → métadonnées contenant la note “Snapshot initial” et autres informations automatiques (date, version, paramètres).

---

#### 6. Conclusion

Le sidecar file est une solution simple et robuste pour enrichir les fichiers `.b3` avec des métadonnées :

* Aucun impact sur le format binaire existant.
* Permet la documentation, l’automatisation et le suivi des snapshots.
* Compatible avec les pipelines et l’interface CLI unique de `hash-tool`.


--- Fichier : hors_git/interet du projet/blabla ---


File Integrity Monitor, Intrusion Detection Environment, et Security Information and Event Management
FIM/HIDS/SIEM

threat detection
surveillance active

OSSEC, Wazuh, AIDE, Tripwire

Ne se positionne pas sur ce secteur car : 

Surveillance en temps réel (pas de daemon, pas d'inotify/fsevents/kernel hooks)
Alertes automatiques / intégration SIEM
Détection de qui a modifié quoi (who-data avancé)
Protection contre rootkits ou attaques actives
Gestion de base de données signée/chiffrée
Scalabilité sur des centaines de machines
Règles de compliance mapping

Mias c'est léger et intéressant pour cette raison 

ça fait peu de choses mais ça les fait correctement  




--- Fichier : hors_git/interet du projet/hash_tool-positionnement-open-source.docx ---
[Fichier binaire ou illisible, contenu ignoré]

--- Fichier : hors_git/interet du projet/hash_tool-positionnement-open-source.pdf ---
[Fichier binaire ou illisible, contenu ignoré]

--- Fichier : hors_git/changelog/2026-02-22-11-39 -- CHANGELOG.md ---
# Changelog — hash_tool / integrity.sh

## [0.12] — Dockerisation

### Ajouté

- `Dockerfile` : image multi-stage basée sur Alpine 3.19.
  - Stage `fetcher` : télécharge le binaire officiel `b3sum` musl depuis GitHub Releases, le vérifie (auto-vérification via `b3sum --check`). Supporte `amd64`, `arm64`, `armv7`.
  - Stage final : Alpine + `bash` + `jq` + `coreutils` + `findutils` + binaire `b3sum` copié. Image finale ~14 Mo sans toolchain Rust.
  - `ARG B3SUM_VERSION` : version b3sum paramétrable au build.

- `docker/entrypoint.sh` : dispatcher des commandes.
  - `compute`, `verify`, `compare` → délégués à `src/integrity.sh`.
  - `runner [pipeline.json]` → délégué à `runner.sh` (défaut : `/pipelines/pipeline.json`).
  - `shell` / `bash` → shell interactif debug.
  - `help`, `version` → affichage inline.
  - `--quiet` supporté en premier argument.

- `docker-compose.yml` : trois services.
  - `integrity` : commandes ponctuelles (compute/verify/compare).
  - `pipeline` : exécution de `runner.sh` avec `pipeline.json` monté.
  - `cron` : profil optionnel (`--profile cron`) pour vérification périodique.
  - Section `x-volumes` : chemins à adapter en un seul endroit.

- `.dockerignore` : exclut données, résultats, tests, docs du contexte de build.

- `docs/docker.md` : guide complet — build, commandes, volumes, NAS Synology, cron Debian, taille image, mise à jour b3sum.

### Volumes conventionnels

| Volume conteneur | Usage |
|---|---|
| `/data` | Données à hacher (`:ro` recommandé) |
| `/bases` | Fichiers `.b3` |
| `/pipelines` | Fichiers `pipeline.json` |
| `/resultats` | Résultats compare/verify |

`RESULTATS_DIR=/resultats` est défini par défaut dans l'image.

---

 — Restructuration + rapport HTML compare

### Restructuration du projet

```
hash_tool/
├── runner.sh                  ← inchangé (point d'entrée)
├── src/
│   ├── integrity.sh           ← déplacé depuis la racine
│   └── lib/
│       └── report.sh          ← nouveau, extrait de integrity.sh
├── pipelines/
│   ├── pipeline.json          ← déplacé depuis la racine
│   └── pipeline-full.json     ← renommé depuis "pipeline full.json"
└── reports/
    └── template.html          ← nouveau, barebone HTML de référence
```

Motivations :
- `src/` isole le code des fichiers de configuration et de données.
- `src/lib/` prépare l'extension à d'autres modules (ex. `notify.sh`, `export.sh`).
- `pipelines/` centralise les configurations de pipeline, évite la pollution de la racine.
- `reports/` documente la structure HTML attendue, sert de référence pour la personnalisation.

### Modifié

- `runner.sh`
  - Chemin `INTEGRITY` mis à jour : `$SCRIPT_DIR/src/integrity.sh`.
  - Chemin `CONFIG` par défaut mis à jour : `$SCRIPT_DIR/pipelines/pipeline.json`.
  - `run_compare()` : lecture du champ optionnel `resultats` dans le bloc JSON. Si présent, exporte `RESULTATS_DIR` avec cette valeur pour le seul appel à `integrity.sh compare`. Isolation par sous-shell : le `RESULTATS_DIR` global du processus parent n'est pas modifié.
  - `run_compute()` et `run_verify()` : isolation du `cd` dans un sous-shell `( )` — le répertoire courant ne fuite plus vers les blocs suivants du pipeline.

- `src/integrity.sh`
  - Chargement de `src/lib/report.sh` via `source` au démarrage.
  - `run_compare()` : délègue la génération HTML à `generate_compare_html()` (définie dans `lib/report.sh`).

### Ajouté

- `src/lib/report.sh` : bibliothèque de génération de rapports.
  - `generate_compare_html()` : produit `report.html` autonome (CSS inline, sans dépendance externe) à partir des fichiers `modifies.b3`, `disparus.txt`, `nouveaux.txt`. Thème sombre, police monospace, compteurs par catégorie, badge statut IDENTIQUES / DIFFÉRENCES DÉTECTÉES.

- `reports/template.html` : barebone HTML statique de référence. Documente les placeholders injectés par `generate_compare_html()` et la structure attendue du dossier de résultats.

- `pipeline.json` (et `pipeline-full.json`) : champ optionnel `"resultats"` sur les blocs `compare`.

  ```json
  {
      "op":       "compare",
      "base_a":   "/chemin/hashes_1.b3",
      "base_b":   "/chemin/hashes_2.b3",
      "resultats": "/chemin/vers/dossier_resultats"
  }
  ```

  Sans ce champ, comportement inchangé : résultats dans `RESULTATS_DIR` (défaut `~/integrity_resultats`).

- `tests/run_tests_pipeline.sh` : cas TP10b — vérifie que le champ `resultats` redirige bien les résultats dans le dossier personnalisé et n'écrit rien dans `RESULTATS_DIR` par défaut.

### Couverture tests mise à jour

| Suite | Cas | Description |
|---|---|---|
| `run_tests.sh` | T00–T14 | Inchangée — `INTEGRITY` mis à jour vers `../src/integrity.sh` |
| `run_tests_pipeline.sh` | TP01–TP12 | Inchangée dans la logique |
| `run_tests_pipeline.sh` | **TP10b** | Nouveau — champ `resultats` personnalisé et isolation |

---


## [0.11] — Restructuration + rapport HTML compare

### Restructuration du projet

```
hash_tool/
├── runner.sh                  ← inchangé (point d'entrée)
├── src/
│   ├── integrity.sh           ← déplacé depuis la racine
│   └── lib/
│       └── report.sh          ← nouveau, extrait de integrity.sh
├── pipelines/
│   ├── pipeline.json          ← déplacé depuis la racine
│   └── pipeline-full.json     ← renommé depuis "pipeline full.json"
└── reports/
    └── template.html          ← nouveau, barebone HTML de référence
```

Motivations :
- `src/` isole le code des fichiers de configuration et de données.
- `src/lib/` prépare l'extension à d'autres modules (ex. `notify.sh`, `export.sh`).
- `pipelines/` centralise les configurations de pipeline, évite la pollution de la racine.
- `reports/` documente la structure HTML attendue, sert de référence pour la personnalisation.

### Modifié

- `runner.sh`
  - Chemin `INTEGRITY` mis à jour : `$SCRIPT_DIR/src/integrity.sh`.
  - Chemin `CONFIG` par défaut mis à jour : `$SCRIPT_DIR/pipelines/pipeline.json`.
  - `run_compare()` : lecture du champ optionnel `resultats` dans le bloc JSON. Si présent, exporte `RESULTATS_DIR` avec cette valeur pour le seul appel à `integrity.sh compare`. Isolation par sous-shell : le `RESULTATS_DIR` global du processus parent n'est pas modifié.
  - `run_compute()` et `run_verify()` : isolation du `cd` dans un sous-shell `( )` — le répertoire courant ne fuite plus vers les blocs suivants du pipeline.

- `src/integrity.sh`
  - Chargement de `src/lib/report.sh` via `source` au démarrage.
  - `run_compare()` : délègue la génération HTML à `generate_compare_html()` (définie dans `lib/report.sh`).

### Ajouté

- `src/lib/report.sh` : bibliothèque de génération de rapports.
  - `generate_compare_html()` : produit `report.html` autonome (CSS inline, sans dépendance externe) à partir des fichiers `modifies.b3`, `disparus.txt`, `nouveaux.txt`. Thème sombre, police monospace, compteurs par catégorie, badge statut IDENTIQUES / DIFFÉRENCES DÉTECTÉES.

- `reports/template.html` : barebone HTML statique de référence. Documente les placeholders injectés par `generate_compare_html()` et la structure attendue du dossier de résultats.

- `pipeline.json` (et `pipeline-full.json`) : champ optionnel `"resultats"` sur les blocs `compare`.

  ```json
  {
      "op":       "compare",
      "base_a":   "/chemin/hashes_1.b3",
      "base_b":   "/chemin/hashes_2.b3",
      "resultats": "/chemin/vers/dossier_resultats"
  }
  ```

  Sans ce champ, comportement inchangé : résultats dans `RESULTATS_DIR` (défaut `~/integrity_resultats`).

- `tests/run_tests_pipeline.sh` : cas TP10b — vérifie que le champ `resultats` redirige bien les résultats dans le dossier personnalisé et n'écrit rien dans `RESULTATS_DIR` par défaut.

### Couverture tests mise à jour

| Suite | Cas | Description |
|---|---|---|
| `run_tests.sh` | T00–T14 | Inchangée — `INTEGRITY` mis à jour vers `../src/integrity.sh` |
| `run_tests_pipeline.sh` | TP01–TP12 | Inchangée dans la logique |
| `run_tests_pipeline.sh` | **TP10b** | Nouveau — champ `resultats` personnalisé et isolation |

---



## [0.10] — Pipeline JSON + tests pipeline

### Modifié

- `pipeline.json` (ex `config.txt`) : format migré de la syntaxe custom vers JSON standard. Champ `op` remplace les noms de blocs. Parsé par `jq` — validation syntaxique native, interopérable avec tout outil JSON.
- `runner.sh` : réécriture du parser. Suppression du parser bash custom (`IFS`, regex, `local -n`). Remplacement par `jq` pour l'extraction des champs. Validation JSON en entrée (`jq empty`), détection des champs manquants et des opérations inconnues avec messages d'erreur explicites incluant le numéro de bloc.

### Ajouté

- `tests/run_tests_pipeline.sh` : suite de tests dédiée au pipeline. 12 cas TP01–TP12.

### Format pipeline.json

```json
{
    "pipeline": [
        {
            "op":     "compute",
            "source": "/mnt/a/dossier",
            "bases":  "/mnt/c/bases",
            "nom":    "hashes.b3"
        },
        {
            "op":     "verify",
            "source": "/mnt/a/dossier",
            "base":   "/mnt/c/bases/hashes.b3"
        },
        {
            "op":     "compare",
            "base_a": "/mnt/c/bases/hashes_1.b3",
            "base_b": "/mnt/c/bases/hashes_2.b3"
        }
    ]
}
```

### Couverture run_tests_pipeline.sh

| Cas | Description |
|---|---|
| TP01 | JSON invalide — erreur propre sans stacktrace jq |
| TP02 | Clé `.pipeline` absente |
| TP03 | Champ manquant dans un bloc (`nom`) |
| TP04 | Opération inconnue |
| TP05 | Compute — cd correct, chemins relatifs dans la base, comptage fichiers |
| TP06 | Compute — dossier source absent |
| TP07 | Verify — bon répertoire de travail, OK détecté |
| TP08 | Verify — corruption détectée |
| TP09 | Verify — base .b3 absente |
| TP10 | Compare — fichiers de résultats produits |
| TP11 | Compare — base_a absente |
| TP12 | Pipeline complet compute + verify + compare |

---


## [0.9] — Pipeline batch : runner.sh + config.txt

### Ajouté

- `runner.sh` : exécuteur de pipeline batch. Lit `config.txt`, parse les blocs `compute`, `verify`, `compare` et appelle `integrity.sh` avec les arguments corrects. Gère le `cd` automatique avant chaque `compute` et `verify` pour garantir des chemins relatifs dans les bases `.b3`.
- `config.txt` : déclaration du pipeline au format structuré `pipeline = { ... }`. Chaque opération est un bloc nommé avec des champs `clé = "valeur"`. Supporte les commentaires `#` et les lignes vides.
- `runner.bat` : lanceur Windows pour double-clic depuis le bureau. Appelle `runner.sh` via WSL. Paramètre `pause` final pour garder la fenêtre ouverte.

### Format config.txt

```
pipeline = {

    compute {
        source = "/mnt/a/dossier",
        bases  = "/mnt/c/bases",
        nom    = "hashes.b3"
    }

    verify {
        source = "/mnt/a/dossier",
        base   = "/mnt/c/bases/hashes.b3"
    }

    compare {
        base_a = "/mnt/c/bases/hashes_1.b3",
        base_b = "/mnt/c/bases/hashes_2.b3"
    }

}
```

### Comportement runner.sh

- `compute` : `cd` dans `source`, puis `integrity.sh compute . bases/nom` — chemin relatif garanti.
- `verify` : `cd` dans `source`, puis `integrity.sh verify base` — répertoire de travail correct.
- `compare` : appel direct `integrity.sh compare base_a base_b`.
- Crée `bases/` automatiquement si inexistant (`mkdir -p`).
- `set -e` : arrêt immédiat sur toute erreur.

---

## [0.8] — Fonctionnalité batch_compute.sh

### Ajouté

- `batch_compute.sh` : permet de lancer plusieurs commandes `compute` avec un seul script. Remplacé par `runner.sh` + `config.txt` dans la version 0.9.


---

## [0.7] — Robustesse compare : chemins avec espaces

### Corrigé
- `integrity.sh`
  - Bug critique dans `run_compare()` : `sort -k2,2`, `join -1 2 -2 2` et `awk '{print $2}'` utilisent le blanc comme séparateur de champ. Un chemin contenant des espaces est fragmenté en plusieurs champs, ce qui corrompt le tri, le join et l'extraction — produisant des faux positifs massifs (ex. 26569 modifiés pour 163 fichiers dont 1 seul a changé).
  - Correction : conversion préalable de chaque ligne en `chemin\thash` via `awk '{ print substr($0,67) "\t" substr($0,1,64) }'` — le hash b3sum étant toujours exactement 64 caractères, l'offset 67 est garanti par le format. Toutes les opérations suivantes utilisent `-t $'\t'` comme séparateur explicite : `sort -t $'\t' -k1,1`, `join -t $'\t' -1 1 -2 1`, `cut -f1`.
  - `modifies.b3` : format de sortie préservé (`hash  chemin`) via `awk -F $'\t' '$2 != $3 { print $3 "  " $1 }'`.

## [0.6] — Robustesse et mode silencieux

### Ajouté
- `integrity.sh`
  - Flag `--quiet` : supprime toute sortie terminal, écrit uniquement dans les fichiers de résultats (`recap.txt`, `failed.txt`). Exit code propagé pour usage CI/cron.
  - Fonction `say()` : point d'entrée unique pour toute sortie terminal, désactivée si `--quiet`.
  - Fonction `file_size()` : abstraction portable `stat -c%s` (GNU/Linux) / `stat -f%z` (BSD/macOS).
  - Vérification version bash en tête de script : `bash >= 4` requis, exit explicite avec message si non respecté.
  - `make_result_dir()` : horodatage automatique des dossiers de résultats en cas de collision (`_YYYYMMDD-HHMMSS`), plus d'écrasement silencieux.
  - `trap EXIT` dans `run_compare()` : nettoyage garanti des fichiers temporaires même en cas d'erreur intermédiaire.
  - Redirection ETA sur `/dev/tty` dans `compute_with_progress()` : garantit que la progression n'est jamais écrite dans le fichier `.b3`.
- `tests/run_tests.sh`
  - `set -euo pipefail` : mode strict complet activé (ajout de `-e`).
  - Fonction `assert_file_absent()` : helper dédié pour les assertions d'absence de fichier.
  - T00 : ShellCheck sur `integrity.sh` et `run_tests.sh` (SKIP propre si non installé).
  - T12 : couverture exhaustive du mode `--quiet` (stdout vide, fichiers produits, exit code propagé).
  - T13 : vérifie l'horodatage automatique des dossiers de résultats sur collision.
  - T14 : détection d'un argument `[dossier]` invalide pour `verify`.
- `README.md`
  - Section `--quiet` avec exemples CI/cron.
  - Section Tests avec instructions d'exécution et comptage des cas (14 tests).
  - Mention horodatage automatique dans l'arborescence des résultats.

### Modifié
- `integrity.sh`
  - `assert_target_valid()` : `find -print0 | grep -zc ''` au lieu de `find | wc -l` — robuste aux noms de fichiers contenant des newlines.
  - `run_verify()` : comptage de lignes via `grep -c '^'` au lieu de `grep -c '.'` — correction du bug de comptage sur flux vide.
  - `run_compare()` : `sort -k2,2` au lieu de `sort -k2` — clé de tri limitée strictement au champ chemin, sans déborder sur le hash.
  - `run_verify()` : propagation de l'exit code de `b3sum --check` via `return $exit_code` — utilisable en scripting avec `|| alert`.
  - `failed.txt` : suppression explicite via `rm -f` si `nb_failed == 0` après une vérification OK suivant un échec précédent.
- `tests/run_tests.sh`
  - Résolution dynamique des `outdir` via `ls -d ... | tail -1` : compatible avec l'horodatage des dossiers de résultats.
  - T02, T03, T05, T06, T07 : assertions adaptées à la résolution dynamique des dossiers.
- `README.md`
  - Dépendances : mention explicite de `bash >= 4`.
  - Usage : exemple `--quiet` ajouté.

### Corrigé
- `integrity.sh`
  - Bug comptage lignes dans `run_verify()` : `grep -c '.'` sur flux vide retournait 0 mais ne capturait pas correctement les lignes non vides. Remplacé par `grep -c '^'`.
  - Bug tri ambigü dans `run_compare()` : `sort -k2` triait du champ 2 à la fin de ligne, incluant potentiellement le hash. `sort -k2,2` limite la clé au seul champ 2.
  - Bug nettoyage tmpfiles : `run_compare()` laissait des fichiers temporaires en cas d'erreur intermédiaire. Ajout de `trap 'rm -f ...' EXIT`.
  - Bug portabilité `stat` : `stat -c%s` est GNU-only. Ajout de `file_size()` avec fallback BSD `stat -f%z`.
  - Bug comptage fichiers avec newlines : `assert_target_valid()` utilisait `find | wc -l`. Corrigé avec `find -print0 | grep -zc ''`.
- `tests/run_tests.sh`
  - T10 : pattern `"^/"` remplacé par `"  /"` — `grep` opérait sur une chaîne, l'ancre `^` ne matchait pas la deuxième colonne.

---

## [0.5] — Documentation

### Modifié
- `README.md` — règle répertoire de travail pour `verify` précisée : l'argument `[dossier]` est le répertoire d'origine du compute, pas le dossier haché. Exemples correct/incorrect ajoutés.
- `docs/manuel.md` — section `verify` mise à jour avec le même avertissement et les exemples.

---

## [0.4] — Gardes-fous et signalisation des erreurs

### Modifié
- `integrity.sh`
  - Ajout de `die()` : point de sortie unique pour toutes les erreurs, message sur stderr.
  - Ajout de `assert_b3_valid()` : vérifie existence, type fichier, non-vide, format b3sum valide.
  - Ajout de `assert_target_valid()` : vérifie existence du dossier cible et présence d'au moins un fichier.
  - Validation explicite des arguments dans chaque branche du `case` avant tout traitement.
  - `verify` accepte un argument optionnel `[dossier]` : fait `cd` avant `b3sum --check`.
  - Résolution du chemin absolu du `.b3` avant `cd` (correction bug : chemin relatif invalide après changement de répertoire).
  - `RESULTATS_DIR` : `${RESULTATS_DIR:-...}` au lieu d'assignation inconditionnelle — respecte la valeur exportée par l'environnement (fix tests).
  - Suppression de `local hashfile_abs` hors fonction (illégal en bash hors contexte fonction).
  - `run_verify()` : refonte de la signalisation.
    - Trois états distincts : `OK`, `ECHEC`, `ERREUR`.
    - Terminal : affichage sobre si OK, bloc `████` visible si échec ou erreur.
    - `recap.txt` : compteur `FAILED` affiché uniquement si > 0 ; section erreurs b3sum séparée.
    - `failed.txt` : créé uniquement si `nb_failed > 0` ou erreurs b3sum présentes. Supprimé si tout est OK.
- `tests/run_tests.sh`
  - T02 : assertion `failed.txt absent si 0 échec` (logique inversée par rapport à l'ancienne version).
  - T03 : patterns mis à jour (`ECHEC`, `FAILED`) alignés sur le nouveau format de sortie.

---

## [0.3] — Dossiers de résultats (verify et compare)

### Modifié
- `integrity.sh`
  - Ajout de `RESULTATS_DIR` (configurable, défaut `~/integrity_resultats`).
  - Ajout de `make_result_dir()` : crée `resultats_<nom_base>/` sous `RESULTATS_DIR`.
  - `verify` : délègue à `run_verify()` — produit `recap.txt` et `failed.txt`.
  - `compare` : délègue à `run_compare()` — produit `recap.txt`, `modifies.b3`, `disparus.txt`, `nouveaux.txt`.
  - Fichiers temporaires de `compare` passent par `mktemp` (plus de `/tmp/_old.b3` en dur).
  - Signature `verify` simplifiée : `<base.b3>` uniquement (le dossier n'était pas utilisé par `b3sum --check`).
- `README.md` — usage `verify` et `compare` mis à jour ; section Configuration ajoutée avec arbre des fichiers produits.
- `docs/manuel.md` — sections `verify` et `compare` mises à jour ; arbre de décision et référence rapide alignés.
- `tests/run_tests.sh`
  - `RESULTATS_DIR` exporté vers `WORKDIR` pour isoler les résultats des tests.
  - Ajout de `assert_file_exists()`.
  - T02–T07 : assertions sur la présence et le contenu des fichiers de résultats.

---

## [0.2] — Intégration ETA et tests automatisés

### Modifié
- `integrity.sh`
  - Suppression de `detect_parallelism()` et de la logique SSD/parallélisme (hors périmètre HDD gros volumes).
  - Mode `compute` : délègue à `compute_with_progress()`.
  - Ajout de `compute_with_progress()` : boucle fichier par fichier avec affichage progression et ETA.
    - `mapfile -d ''` remplace `FILES=($(find ...))` — gestion correcte des noms avec espaces.
    - `printf "\r%*s\r"` efface proprement la ligne de progression avant le message final.
  - `df` retiré des dépendances.
- `README.md` — dépendances mises à jour (`df` supprimé, `stat` et `du` ajoutés).
- `docs/manuel.md`
  - Section `detect_parallelism` supprimée.
  - Section `compute` réécrite autour de `compute_with_progress`.
  - Section performances : stratégie SSD/NVMe retirée, focus HDD séquentiel.
- `docs/progression-eta.md` — implémentation finale documentée ; note `mapfile -d ''` vs substitution de commande.
- `tests/run_tests.sh` — T11 ajouté : vérifie que la base produite par `compute_with_progress` est bit-à-bit identique à une base de référence, sans artefact ETA ni `\r`.
- `docs/explication-run-tests.md` — comptage corrigé (10 → 11 cas) ; section T11 ajoutée.

### Corrigé
- `tests/run_tests.sh` T10 : pattern `"^/"` remplacé par `"  /"` — `grep` opère sur une chaîne, pas un fichier, l'ancre `^` ne matchait pas la deuxième colonne.

---

## [0.1] — Structure initiale du projet

### Ajouté
- `integrity.sh` — script principal BLAKE3 avec trois modes : `compute`, `verify`, `compare`.
  - `set -euo pipefail` — mode strict.
  - `detect_parallelism()` — détection SSD/HDD via `/sys/block/.../queue/rotational`.
  - Mode `compute` : pipeline `find | sort -z | xargs b3sum`, parallélisme `-P 4` sur SSD.
  - Mode `verify` : délègue à `b3sum --check`.
  - Mode `compare` : tri sur colonne 2, `join` pour les modifiés, `comm` pour disparus/nouveaux, rapport `tee`.
- `README.md` — point d'entrée : dépendances, usage en 3 commandes, arbre de décision, règles critiques.
- `docs/manuel.md` — référence technique complète : algorithmes, structure `.b3`, workflow, explication du script, performances, limites, référence rapide, annexe FIM.
- `docs/progression-eta.md` — analyse du problème ETA sur pipeline `xargs`, deux approches (`pv` invalide, boucle bash), mécanique de l'estimation, tableau de comparaison des performances.
- `docs/explication-run-tests.md` — documentation du code `run_tests.sh` : chemins, compteurs, assertions, setup/teardown, structure d'un cas de test, prérequis, exit code CI.
- `tests/run_tests.sh` — suite de tests automatisée bash pur, 11 cas T01–T11, isolation via `mktemp`, teardown systématique, exit code CI-compatible.
- `tests/validation.md` — protocole de test manuel : 10 cas T01–T10 avec commandes exactes et résultats attendus, critères de qualité globaux.


--- Fichier : hors_git/changelog/2026-02-26-12-03 -- changelog.md ---
# Changelog - hash_tool / integrity.sh

## [2.0] — CLI unique, nouvelles commandes, sidecar, pipeline étendu

### Ajouté

**`hash-tool` — CLI unique (nouveau fichier à la racine)**

- Interface CLI unifiée. L'utilisateur invoque toujours `hash-tool <commande>`, indépendamment du mode d'exécution réel.
- Détection automatique du mode d'exécution : natif (`b3sum` + `jq` disponibles) ou Docker (`hash_tool` image disponible). Aucune intervention utilisateur requise.
- Parser d'arguments uniforme : `-data`, `-base`, `-old`, `-new`, `-pipeline`, `-save`, `-meta`, `-quiet`, `-verbose`, `-readonly`.
- Nouvelles commandes : `list`, `diff`, `stats`, `check-env`, `version`, `help` (global + par sous-commande).
- Variable d'environnement `HASH_TOOL_DOCKER_IMAGE` pour spécifier l'image Docker à utiliser (défaut : `hash_tool`).

**Sidecar file (`.meta.json`)**

- `compute` génère automatiquement `<base.b3>.meta.json` à côté du fichier `.b3`.
- Champs : `created_by`, `date` (ISO 8601 UTC), `comment` (depuis `-meta`), `parameters` (répertoire, algorithme, nb_fichiers, readonly).
- `verify`, `compare`, `stats` affichent le sidecar si présent.
- Le runner (format étendu) génère également le sidecar via `meta.comment` dans le pipeline JSON.

**Commande `list`**

- `hash-tool list -data <dossier>` : parcourt le dossier sur 2 niveaux, liste toutes les bases `.b3` avec leur nombre de fichiers, taille, et commentaire sidecar si présent.
- Indicateur `[+meta]` si un sidecar est associé.

**Commande `diff`**

- `hash-tool diff -base <fichier.b3> [-data <dossier>]` : compare les chemins de la base avec l'état actuel du dossier.
- Ne recalcule pas les hashes — uniquement comparaison des chemins.
- Affiche les fichiers disparus et les nouveaux fichiers non indexés.

**Commande `stats`**

- `hash-tool stats -base <fichier.b3>` : affiche le chemin absolu, la taille du fichier `.b3`, le nombre de fichiers indexés, la distribution des extensions (top 10), et le sidecar si présent.

**Commande `check-env`**

- `hash-tool check-env` : vérifie la disponibilité de `b3sum`, `jq`, `bash >= 4`, `integrity.sh`, `runner.sh`, Docker et l'image Docker.
- Indique le mode d'exécution sélectionné : `native`, `docker`, ou `none`.

**Commande `version`**

- `hash-tool version` : affiche la version `hash-tool` et la version `b3sum`.

**Commande `help`**

- `hash-tool help` : aide globale avec toutes les commandes et options.
- `hash-tool help <commande>` : aide détaillée par sous-commande.

**`runner.sh` — format pipeline étendu**

- Nouveau format `type / params / options / meta / description` — rétrocompatible avec le format legacy `op / source / bases / nom`.
- Détection automatique du format par la présence de `"op"` (legacy) ou `"type"` (étendu).
- Support des nouvelles opérations dans le pipeline : `list`, `diff`, `stats`, `check-env`, `version`.
- Génération du sidecar dans les blocs `compute` (format étendu) si `meta.comment` est fourni.
- Champ `options` par bloc : `quiet`, `verbose`, `readonly`.
- Champ `description` : documentation lisible directement dans le JSON.

**`pipelines/pipeline-amelioree.json`**

- Nouveau fichier pipeline de référence au format étendu, couvrant toutes les commandes disponibles.

### Modifié

- `runner.sh` : ajout de la fonction `dispatch_bloc()` qui détecte le format (legacy/étendu) et route vers la bonne implémentation. Fonctions `run_*_legacy()` et `run_*_extended()` séparées pour chaque opération.

### Non modifié

- `src/integrity.sh` : inchangé — les nouvelles commandes sont intégralement gérées dans `hash-tool`.
- `src/lib/core.sh`, `src/lib/ui.sh`, `src/lib/results.sh`, `src/lib/report.sh` : inchangés.
- Tous les pipelines existants (format legacy) : rétrocompatibles sans modification.

### Installation

```bash
chmod +x hash-tool runner.sh src/integrity.sh
# Optionnel : accès global
sudo ln -s "$(pwd)/hash-tool" /usr/local/bin/hash-tool
```

---

## [0.18] - debug 

### Ajoutée 

- dans "brouillon_non_prod" j'ai ajouté des documents .md décrivant les prochains travaux à effectuer pour avoir une architecture de test ainsi qu'une CLI améliorée. 


## [0.17] - debug 

### Ajoutée 

- ajout de "autre" ou "brouillon_non_prod" au git, c'est des documents de travail qui n'a pas à être dans le délivrable mais qui est intéressant de mettre dans le git parce qu'ils sont importants.

## [0.16] - debug 

### Ajoutée 

- dossier "troubleshooting" et le fichier "troubleshooting_1" 
- dossier qu'il faudra compléter avec les bugs courants. 

## [0.15] - Documentation restructurée

maj de la doc 

## [0.14] - Documentation restructurée

### Ajouté
- `docs/` : documentation complète au format MkDocs Material.
  - `index.md` : page d'accueil, vue d'ensemble, structure du projet.
  - `getting-started.md` : installation, prérequis, premier usage pas à pas.
  - `reference/integrity-sh.md` : référence exhaustive - modes, arguments, variables, exit codes, limites.
  - `reference/runner-sh.md` : schéma complet pipeline.json, comportements, messages d'erreur.
  - `reference/docker.md` : build, volumes, Compose, cron, Synology, ARM64.
  - `guides/veracrypt.md` : workflow multi-disques, lanceur Windows `.bat`.
  - `guides/cron-ci.md` : cron Linux, GitHub Actions, GitLab CI, hooks Git, patterns de notification.
  - `guides/nas-synology.md` : DSM 7, Container Manager, planificateur de tâches.
  - `development/architecture.md` : décisions techniques documentées (BLAKE3, chemins relatifs, ETA, CSS inline, etc.).
  - `development/contributing.md` : couverture tests, conventions, processus de release.
  - `development/changelog.md` : historique reformaté Keep a Changelog.
- `mkdocs.yml` : configuration MkDocs Material, navigation, extensions pymdownx, thème sombre/clair.
- `CONTRIBUTING.md` : guide de contribution à la racine du projet.
- README-docker.md : readme juste pour docker. 
- README-docs.md : readme juste pour la documentation. 
- README-tests.md : readme juste pour les tests. 

### Supprimé
- `docs/*.docx`, `docs/*.pdf` : binaires non diffables retirés du repo. Générer depuis le markdown via `pandoc` si nécessaire.
- `temp.txt` : ajouté au `.gitignore`.

### Modifié
- `pipelines/pipeline full.json` → `pipelines/pipeline-full.json` : suppression de l'espace dans le nom de fichier.

## [0.13] - Débug de la dockerisation et documentation 

### Ajouté

- `hash_tool-positionnement-open-source.docx` : positionnement du projet dans l'environnement open source actuel, preuve de valeur du projet.
- `hash_tool-presentation.docx` : présentation macro du projet, sans rentrer dans les details de l'implémentation. 

### Modifié

- Modification du `Dockerfile` pour debug : Installer b3sum depuis Alpine community. b3sum est disponible dans les packages Alpine Linux Alpine Linux, ce qui est plus propre et évite le wget GitHub. Plus de multi-stage, plus de wget, plus de problème de nom. La version fournie par Alpine 3.19 est stable et maintenue. C'est la solution la plus robuste.


## [0.12] - Dockerisation

### Ajouté

- `Dockerfile` : image multi-stage basée sur Alpine 3.19.
  - Stage `fetcher` : télécharge le binaire officiel `b3sum` musl depuis GitHub Releases, le vérifie (auto-vérification via `b3sum --check`). Supporte `amd64`, `arm64`, `armv7`.
  - Stage final : Alpine + `bash` + `jq` + `coreutils` + `findutils` + binaire `b3sum` copié. Image finale ~14 Mo sans toolchain Rust.
  - `ARG B3SUM_VERSION` : version b3sum paramétrable au build.

- `docker/entrypoint.sh` : dispatcher des commandes.
  - `compute`, `verify`, `compare` → délégués à `src/integrity.sh`.
  - `runner [pipeline.json]` → délégué à `runner.sh` (défaut : `/pipelines/pipeline.json`).
  - `shell` / `bash` → shell interactif debug.
  - `help`, `version` → affichage inline.
  - `--quiet` supporté en premier argument.

- `docker-compose.yml` : trois services.
  - `integrity` : commandes ponctuelles (compute/verify/compare).
  - `pipeline` : exécution de `runner.sh` avec `pipeline.json` monté.
  - `cron` : profil optionnel (`--profile cron`) pour vérification périodique.
  - Section `x-volumes` : chemins à adapter en un seul endroit.

- `.dockerignore` : exclut données, résultats, tests, docs du contexte de build.

- `docs/docker.md` : guide complet - build, commandes, volumes, NAS Synology, cron Debian, taille image, mise à jour b3sum.

### Volumes conventionnels

| Volume conteneur | Usage |
|---|---|
| `/data` | Données à hacher (`:ro` recommandé) |
| `/bases` | Fichiers `.b3` |
| `/pipelines` | Fichiers `pipeline.json` |
| `/resultats` | Résultats compare/verify |

`RESULTATS_DIR=/resultats` est défini par défaut dans l'image.

---

 - Restructuration + rapport HTML compare

### Restructuration du projet

```
hash_tool/
├== runner.sh                  ← inchangé (point d'entrée)
├== src/
│   ├== integrity.sh           ← déplacé depuis la racine
│   └== lib/
│       └== report.sh          ← nouveau, extrait de integrity.sh
├== pipelines/
│   ├== pipeline.json          ← déplacé depuis la racine
│   └== pipeline-full.json     ← renommé depuis "pipeline full.json"
└== reports/
    └== template.html          ← nouveau, barebone HTML de référence
```

Motivations :
- `src/` isole le code des fichiers de configuration et de données.
- `src/lib/` prépare l'extension à d'autres modules (ex. `notify.sh`, `export.sh`).
- `pipelines/` centralise les configurations de pipeline, évite la pollution de la racine.
- `reports/` documente la structure HTML attendue, sert de référence pour la personnalisation.

### Modifié

- `runner.sh`
  - Chemin `INTEGRITY` mis à jour : `$SCRIPT_DIR/src/integrity.sh`.
  - Chemin `CONFIG` par défaut mis à jour : `$SCRIPT_DIR/pipelines/pipeline.json`.
  - `run_compare()` : lecture du champ optionnel `resultats` dans le bloc JSON. Si présent, exporte `RESULTATS_DIR` avec cette valeur pour le seul appel à `integrity.sh compare`. Isolation par sous-shell : le `RESULTATS_DIR` global du processus parent n'est pas modifié.
  - `run_compute()` et `run_verify()` : isolation du `cd` dans un sous-shell `( )` - le répertoire courant ne fuite plus vers les blocs suivants du pipeline.

- `src/integrity.sh`
  - Chargement de `src/lib/report.sh` via `source` au démarrage.
  - `run_compare()` : délègue la génération HTML à `generate_compare_html()` (définie dans `lib/report.sh`).

### Ajouté

- `src/lib/report.sh` : bibliothèque de génération de rapports.
  - `generate_compare_html()` : produit `report.html` autonome (CSS inline, sans dépendance externe) à partir des fichiers `modifies.b3`, `disparus.txt`, `nouveaux.txt`. Thème sombre, police monospace, compteurs par catégorie, badge statut IDENTIQUES / DIFFÉRENCES DÉTECTÉES.

- `reports/template.html` : barebone HTML statique de référence. Documente les placeholders injectés par `generate_compare_html()` et la structure attendue du dossier de résultats.

- `pipeline.json` (et `pipeline-full.json`) : champ optionnel `"resultats"` sur les blocs `compare`.

  ```json
  {
      "op":       "compare",
      "base_a":   "/chemin/hashes_1.b3",
      "base_b":   "/chemin/hashes_2.b3",
      "resultats": "/chemin/vers/dossier_resultats"
  }
  ```

  Sans ce champ, comportement inchangé : résultats dans `RESULTATS_DIR` (défaut `~/integrity_resultats`).

- `tests/run_tests_pipeline.sh` : cas TP10b - vérifie que le champ `resultats` redirige bien les résultats dans le dossier personnalisé et n'écrit rien dans `RESULTATS_DIR` par défaut.

### Couverture tests mise à jour

| Suite | Cas | Description |
|---|---|---|
| `run_tests.sh` | T00–T14 | Inchangée - `INTEGRITY` mis à jour vers `../src/integrity.sh` |
| `run_tests_pipeline.sh` | TP01–TP12 | Inchangée dans la logique |
| `run_tests_pipeline.sh` | **TP10b** | Nouveau - champ `resultats` personnalisé et isolation |

---


## [0.11] - Restructuration + rapport HTML compare

### Restructuration du projet

```
hash_tool/
├== runner.sh                  ← inchangé (point d'entrée)
├== src/
│   ├== integrity.sh           ← déplacé depuis la racine
│   └== lib/
│       └== report.sh          ← nouveau, extrait de integrity.sh
├== pipelines/
│   ├== pipeline.json          ← déplacé depuis la racine
│   └== pipeline-full.json     ← renommé depuis "pipeline full.json"
└== reports/
    └== template.html          ← nouveau, barebone HTML de référence
```

Motivations :
- `src/` isole le code des fichiers de configuration et de données.
- `src/lib/` prépare l'extension à d'autres modules (ex. `notify.sh`, `export.sh`).
- `pipelines/` centralise les configurations de pipeline, évite la pollution de la racine.
- `reports/` documente la structure HTML attendue, sert de référence pour la personnalisation.

### Modifié

- `runner.sh`
  - Chemin `INTEGRITY` mis à jour : `$SCRIPT_DIR/src/integrity.sh`.
  - Chemin `CONFIG` par défaut mis à jour : `$SCRIPT_DIR/pipelines/pipeline.json`.
  - `run_compare()` : lecture du champ optionnel `resultats` dans le bloc JSON. Si présent, exporte `RESULTATS_DIR` avec cette valeur pour le seul appel à `integrity.sh compare`. Isolation par sous-shell : le `RESULTATS_DIR` global du processus parent n'est pas modifié.
  - `run_compute()` et `run_verify()` : isolation du `cd` dans un sous-shell `( )` - le répertoire courant ne fuite plus vers les blocs suivants du pipeline.

- `src/integrity.sh`
  - Chargement de `src/lib/report.sh` via `source` au démarrage.
  - `run_compare()` : délègue la génération HTML à `generate_compare_html()` (définie dans `lib/report.sh`).

### Ajouté

- `src/lib/report.sh` : bibliothèque de génération de rapports.
  - `generate_compare_html()` : produit `report.html` autonome (CSS inline, sans dépendance externe) à partir des fichiers `modifies.b3`, `disparus.txt`, `nouveaux.txt`. Thème sombre, police monospace, compteurs par catégorie, badge statut IDENTIQUES / DIFFÉRENCES DÉTECTÉES.

- `reports/template.html` : barebone HTML statique de référence. Documente les placeholders injectés par `generate_compare_html()` et la structure attendue du dossier de résultats.

- `pipeline.json` (et `pipeline-full.json`) : champ optionnel `"resultats"` sur les blocs `compare`.

  ```json
  {
      "op":       "compare",
      "base_a":   "/chemin/hashes_1.b3",
      "base_b":   "/chemin/hashes_2.b3",
      "resultats": "/chemin/vers/dossier_resultats"
  }
  ```

  Sans ce champ, comportement inchangé : résultats dans `RESULTATS_DIR` (défaut `~/integrity_resultats`).

- `tests/run_tests_pipeline.sh` : cas TP10b - vérifie que le champ `resultats` redirige bien les résultats dans le dossier personnalisé et n'écrit rien dans `RESULTATS_DIR` par défaut.

### Couverture tests mise à jour

| Suite | Cas | Description |
|---|---|---|
| `run_tests.sh` | T00–T14 | Inchangée - `INTEGRITY` mis à jour vers `../src/integrity.sh` |
| `run_tests_pipeline.sh` | TP01–TP12 | Inchangée dans la logique |
| `run_tests_pipeline.sh` | **TP10b** | Nouveau - champ `resultats` personnalisé et isolation |

---



## [0.10] - Pipeline JSON + tests pipeline

### Modifié

- `pipeline.json` (ex `config.txt`) : format migré de la syntaxe custom vers JSON standard. Champ `op` remplace les noms de blocs. Parsé par `jq` - validation syntaxique native, interopérable avec tout outil JSON.
- `runner.sh` : réécriture du parser. Suppression du parser bash custom (`IFS`, regex, `local -n`). Remplacement par `jq` pour l'extraction des champs. Validation JSON en entrée (`jq empty`), détection des champs manquants et des opérations inconnues avec messages d'erreur explicites incluant le numéro de bloc.

### Ajouté

- `tests/run_tests_pipeline.sh` : suite de tests dédiée au pipeline. 12 cas TP01–TP12.

### Format pipeline.json

```json
{
    "pipeline": [
        {
            "op":     "compute",
            "source": "/mnt/a/dossier",
            "bases":  "/mnt/c/bases",
            "nom":    "hashes.b3"
        },
        {
            "op":     "verify",
            "source": "/mnt/a/dossier",
            "base":   "/mnt/c/bases/hashes.b3"
        },
        {
            "op":     "compare",
            "base_a": "/mnt/c/bases/hashes_1.b3",
            "base_b": "/mnt/c/bases/hashes_2.b3"
        }
    ]
}
```

### Couverture run_tests_pipeline.sh

| Cas | Description |
|---|---|
| TP01 | JSON invalide - erreur propre sans stacktrace jq |
| TP02 | Clé `.pipeline` absente |
| TP03 | Champ manquant dans un bloc (`nom`) |
| TP04 | Opération inconnue |
| TP05 | Compute - cd correct, chemins relatifs dans la base, comptage fichiers |
| TP06 | Compute - dossier source absent |
| TP07 | Verify - bon répertoire de travail, OK détecté |
| TP08 | Verify - corruption détectée |
| TP09 | Verify - base .b3 absente |
| TP10 | Compare - fichiers de résultats produits |
| TP11 | Compare - base_a absente |
| TP12 | Pipeline complet compute + verify + compare |

---


## [0.9] - Pipeline batch : runner.sh + config.txt

### Ajouté

- `runner.sh` : exécuteur de pipeline batch. Lit `config.txt`, parse les blocs `compute`, `verify`, `compare` et appelle `integrity.sh` avec les arguments corrects. Gère le `cd` automatique avant chaque `compute` et `verify` pour garantir des chemins relatifs dans les bases `.b3`.
- `config.txt` : déclaration du pipeline au format structuré `pipeline = { ... }`. Chaque opération est un bloc nommé avec des champs `clé = "valeur"`. Supporte les commentaires `#` et les lignes vides.
- `runner.bat` : lanceur Windows pour double-clic depuis le bureau. Appelle `runner.sh` via WSL. Paramètre `pause` final pour garder la fenêtre ouverte.

### Format config.txt

```
pipeline = {

    compute {
        source = "/mnt/a/dossier",
        bases  = "/mnt/c/bases",
        nom    = "hashes.b3"
    }

    verify {
        source = "/mnt/a/dossier",
        base   = "/mnt/c/bases/hashes.b3"
    }

    compare {
        base_a = "/mnt/c/bases/hashes_1.b3",
        base_b = "/mnt/c/bases/hashes_2.b3"
    }

}
```

### Comportement runner.sh

- `compute` : `cd` dans `source`, puis `integrity.sh compute . bases/nom` - chemin relatif garanti.
- `verify` : `cd` dans `source`, puis `integrity.sh verify base` - répertoire de travail correct.
- `compare` : appel direct `integrity.sh compare base_a base_b`.
- Crée `bases/` automatiquement si inexistant (`mkdir -p`).
- `set -e` : arrêt immédiat sur toute erreur.

---

## [0.8] - Fonctionnalité batch_compute.sh

### Ajouté

- `batch_compute.sh` : permet de lancer plusieurs commandes `compute` avec un seul script. Remplacé par `runner.sh` + `config.txt` dans la version 0.9.


---

## [0.7] - Robustesse compare : chemins avec espaces

### Corrigé
- `integrity.sh`
  - Bug critique dans `run_compare()` : `sort -k2,2`, `join -1 2 -2 2` et `awk '{print $2}'` utilisent le blanc comme séparateur de champ. Un chemin contenant des espaces est fragmenté en plusieurs champs, ce qui corrompt le tri, le join et l'extraction - produisant des faux positifs massifs (ex. 26569 modifiés pour 163 fichiers dont 1 seul a changé).
  - Correction : conversion préalable de chaque ligne en `chemin\thash` via `awk '{ print substr($0,67) "\t" substr($0,1,64) }'` - le hash b3sum étant toujours exactement 64 caractères, l'offset 67 est garanti par le format. Toutes les opérations suivantes utilisent `-t $'\t'` comme séparateur explicite : `sort -t $'\t' -k1,1`, `join -t $'\t' -1 1 -2 1`, `cut -f1`.
  - `modifies.b3` : format de sortie préservé (`hash  chemin`) via `awk -F $'\t' '$2 != $3 { print $3 "  " $1 }'`.

## [0.6] - Robustesse et mode silencieux

### Ajouté
- `integrity.sh`
  - Flag `--quiet` : supprime toute sortie terminal, écrit uniquement dans les fichiers de résultats (`recap.txt`, `failed.txt`). Exit code propagé pour usage CI/cron.
  - Fonction `say()` : point d'entrée unique pour toute sortie terminal, désactivée si `--quiet`.
  - Fonction `file_size()` : abstraction portable `stat -c%s` (GNU/Linux) / `stat -f%z` (BSD/macOS).
  - Vérification version bash en tête de script : `bash >= 4` requis, exit explicite avec message si non respecté.
  - `make_result_dir()` : horodatage automatique des dossiers de résultats en cas de collision (`_YYYYMMDD-HHMMSS`), plus d'écrasement silencieux.
  - `trap EXIT` dans `run_compare()` : nettoyage garanti des fichiers temporaires même en cas d'erreur intermédiaire.
  - Redirection ETA sur `/dev/tty` dans `compute_with_progress()` : garantit que la progression n'est jamais écrite dans le fichier `.b3`.
- `tests/run_tests.sh`
  - `set -euo pipefail` : mode strict complet activé (ajout de `-e`).
  - Fonction `assert_file_absent()` : helper dédié pour les assertions d'absence de fichier.
  - T00 : ShellCheck sur `integrity.sh` et `run_tests.sh` (SKIP propre si non installé).
  - T12 : couverture exhaustive du mode `--quiet` (stdout vide, fichiers produits, exit code propagé).
  - T13 : vérifie l'horodatage automatique des dossiers de résultats sur collision.
  - T14 : détection d'un argument `[dossier]` invalide pour `verify`.
- `README.md`
  - Section `--quiet` avec exemples CI/cron.
  - Section Tests avec instructions d'exécution et comptage des cas (14 tests).
  - Mention horodatage automatique dans l'arborescence des résultats.

### Modifié
- `integrity.sh`
  - `assert_target_valid()` : `find -print0 | grep -zc ''` au lieu de `find | wc -l` - robuste aux noms de fichiers contenant des newlines.
  - `run_verify()` : comptage de lignes via `grep -c '^'` au lieu de `grep -c '.'` - correction du bug de comptage sur flux vide.
  - `run_compare()` : `sort -k2,2` au lieu de `sort -k2` - clé de tri limitée strictement au champ chemin, sans déborder sur le hash.
  - `run_verify()` : propagation de l'exit code de `b3sum --check` via `return $exit_code` - utilisable en scripting avec `|| alert`.
  - `failed.txt` : suppression explicite via `rm -f` si `nb_failed == 0` après une vérification OK suivant un échec précédent.
- `tests/run_tests.sh`
  - Résolution dynamique des `outdir` via `ls -d ... | tail -1` : compatible avec l'horodatage des dossiers de résultats.
  - T02, T03, T05, T06, T07 : assertions adaptées à la résolution dynamique des dossiers.
- `README.md`
  - Dépendances : mention explicite de `bash >= 4`.
  - Usage : exemple `--quiet` ajouté.

### Corrigé
- `integrity.sh`
  - Bug comptage lignes dans `run_verify()` : `grep -c '.'` sur flux vide retournait 0 mais ne capturait pas correctement les lignes non vides. Remplacé par `grep -c '^'`.
  - Bug tri ambigü dans `run_compare()` : `sort -k2` triait du champ 2 à la fin de ligne, incluant potentiellement le hash. `sort -k2,2` limite la clé au seul champ 2.
  - Bug nettoyage tmpfiles : `run_compare()` laissait des fichiers temporaires en cas d'erreur intermédiaire. Ajout de `trap 'rm -f ...' EXIT`.
  - Bug portabilité `stat` : `stat -c%s` est GNU-only. Ajout de `file_size()` avec fallback BSD `stat -f%z`.
  - Bug comptage fichiers avec newlines : `assert_target_valid()` utilisait `find | wc -l`. Corrigé avec `find -print0 | grep -zc ''`.
- `tests/run_tests.sh`
  - T10 : pattern `"^/"` remplacé par `"  /"` - `grep` opérait sur une chaîne, l'ancre `^` ne matchait pas la deuxième colonne.

---

## [0.5] - Documentation

### Modifié
- `README.md` - règle répertoire de travail pour `verify` précisée : l'argument `[dossier]` est le répertoire d'origine du compute, pas le dossier haché. Exemples correct/incorrect ajoutés.
- `docs/manuel.md` - section `verify` mise à jour avec le même avertissement et les exemples.

---

## [0.4] - Gardes-fous et signalisation des erreurs

### Modifié
- `integrity.sh`
  - Ajout de `die()` : point de sortie unique pour toutes les erreurs, message sur stderr.
  - Ajout de `assert_b3_valid()` : vérifie existence, type fichier, non-vide, format b3sum valide.
  - Ajout de `assert_target_valid()` : vérifie existence du dossier cible et présence d'au moins un fichier.
  - Validation explicite des arguments dans chaque branche du `case` avant tout traitement.
  - `verify` accepte un argument optionnel `[dossier]` : fait `cd` avant `b3sum --check`.
  - Résolution du chemin absolu du `.b3` avant `cd` (correction bug : chemin relatif invalide après changement de répertoire).
  - `RESULTATS_DIR` : `${RESULTATS_DIR:-...}` au lieu d'assignation inconditionnelle - respecte la valeur exportée par l'environnement (fix tests).
  - Suppression de `local hashfile_abs` hors fonction (illégal en bash hors contexte fonction).
  - `run_verify()` : refonte de la signalisation.
    - Trois états distincts : `OK`, `ECHEC`, `ERREUR`.
    - Terminal : affichage sobre si OK, bloc `████` visible si échec ou erreur.
    - `recap.txt` : compteur `FAILED` affiché uniquement si > 0 ; section erreurs b3sum séparée.
    - `failed.txt` : créé uniquement si `nb_failed > 0` ou erreurs b3sum présentes. Supprimé si tout est OK.
- `tests/run_tests.sh`
  - T02 : assertion `failed.txt absent si 0 échec` (logique inversée par rapport à l'ancienne version).
  - T03 : patterns mis à jour (`ECHEC`, `FAILED`) alignés sur le nouveau format de sortie.

---

## [0.3] - Dossiers de résultats (verify et compare)

### Modifié
- `integrity.sh`
  - Ajout de `RESULTATS_DIR` (configurable, défaut `~/integrity_resultats`).
  - Ajout de `make_result_dir()` : crée `resultats_<nom_base>/` sous `RESULTATS_DIR`.
  - `verify` : délègue à `run_verify()` - produit `recap.txt` et `failed.txt`.
  - `compare` : délègue à `run_compare()` - produit `recap.txt`, `modifies.b3`, `disparus.txt`, `nouveaux.txt`.
  - Fichiers temporaires de `compare` passent par `mktemp` (plus de `/tmp/_old.b3` en dur).
  - Signature `verify` simplifiée : `<base.b3>` uniquement (le dossier n'était pas utilisé par `b3sum --check`).
- `README.md` - usage `verify` et `compare` mis à jour ; section Configuration ajoutée avec arbre des fichiers produits.
- `docs/manuel.md` - sections `verify` et `compare` mises à jour ; arbre de décision et référence rapide alignés.
- `tests/run_tests.sh`
  - `RESULTATS_DIR` exporté vers `WORKDIR` pour isoler les résultats des tests.
  - Ajout de `assert_file_exists()`.
  - T02–T07 : assertions sur la présence et le contenu des fichiers de résultats.

---

## [0.2] - Intégration ETA et tests automatisés

### Modifié
- `integrity.sh`
  - Suppression de `detect_parallelism()` et de la logique SSD/parallélisme (hors périmètre HDD gros volumes).
  - Mode `compute` : délègue à `compute_with_progress()`.
  - Ajout de `compute_with_progress()` : boucle fichier par fichier avec affichage progression et ETA.
    - `mapfile -d ''` remplace `FILES=($(find ...))` - gestion correcte des noms avec espaces.
    - `printf "\r%*s\r"` efface proprement la ligne de progression avant le message final.
  - `df` retiré des dépendances.
- `README.md` - dépendances mises à jour (`df` supprimé, `stat` et `du` ajoutés).
- `docs/manuel.md`
  - Section `detect_parallelism` supprimée.
  - Section `compute` réécrite autour de `compute_with_progress`.
  - Section performances : stratégie SSD/NVMe retirée, focus HDD séquentiel.
- `docs/progression-eta.md` - implémentation finale documentée ; note `mapfile -d ''` vs substitution de commande.
- `tests/run_tests.sh` - T11 ajouté : vérifie que la base produite par `compute_with_progress` est bit-à-bit identique à une base de référence, sans artefact ETA ni `\r`.
- `docs/explication-run-tests.md` - comptage corrigé (10 → 11 cas) ; section T11 ajoutée.

### Corrigé
- `tests/run_tests.sh` T10 : pattern `"^/"` remplacé par `"  /"` - `grep` opère sur une chaîne, pas un fichier, l'ancre `^` ne matchait pas la deuxième colonne.

---

## [0.1] - Structure initiale du projet

### Ajouté
- `integrity.sh` - script principal BLAKE3 avec trois modes : `compute`, `verify`, `compare`.
  - `set -euo pipefail` - mode strict.
  - `detect_parallelism()` - détection SSD/HDD via `/sys/block/.../queue/rotational`.
  - Mode `compute` : pipeline `find | sort -z | xargs b3sum`, parallélisme `-P 4` sur SSD.
  - Mode `verify` : délègue à `b3sum --check`.
  - Mode `compare` : tri sur colonne 2, `join` pour les modifiés, `comm` pour disparus/nouveaux, rapport `tee`.
- `README.md` - point d'entrée : dépendances, usage en 3 commandes, arbre de décision, règles critiques.
- `docs/manuel.md` - référence technique complète : algorithmes, structure `.b3`, workflow, explication du script, performances, limites, référence rapide, annexe FIM.
- `docs/progression-eta.md` - analyse du problème ETA sur pipeline `xargs`, deux approches (`pv` invalide, boucle bash), mécanique de l'estimation, tableau de comparaison des performances.
- `docs/explication-run-tests.md` - documentation du code `run_tests.sh` : chemins, compteurs, assertions, setup/teardown, structure d'un cas de test, prérequis, exit code CI.
- `tests/run_tests.sh` - suite de tests automatisée bash pur, 11 cas T01–T11, isolation via `mktemp`, teardown systématique, exit code CI-compatible.
- `tests/validation.md` - protocole de test manuel : 10 cas T01–T10 avec commandes exactes et résultats attendus, critères de qualité globaux.


--- Fichier : hors_git/documentation dev/guide - changelog - bonne pratique.md ---
La réponse courte est : **On ne liste pas les fichiers modifiés, on liste les changements apportés à l'utilisateur.**

Le `changelog` n'est pas un journal technique des commits Git, c'est un document destiné aux humains pour comprendre l'évolution de l'outil. Voici les règles de la convention **Keep a Changelog**.

---

### 1. La règle d'or : "Le quoi, pas le comment"

On ne s'occupe pas du nombre de fichiers modifiés.

* **Mauvais exemple :** "Modifié le fichier `hash-tool` et le fichier `utils.py`." (C'est le rôle de `git log`).
* **Bon exemple :** "Amélioration de la gestion des espaces dans les noms de dossiers."

### 2. Les 6 catégories standard

Pour chaque version, vous devez classer vos modifications sous ces titres (n'utilisez que ceux dont vous avez besoin) :

* **Added** : Pour les nouvelles fonctionnalités.
* **Changed** : Pour les modifications de fonctionnalités existantes.
* **Deprecated** : Pour les fonctionnalités qui vont bientôt être supprimées.
* **Removed** : Pour les fonctionnalités supprimées.
* **Fixed** : Pour les corrections de bugs.
* **Security** : En cas de vulnérabilités corrigées.

---

### 3. Si je modifie un seul fichier, je le note ?

Cela dépend de **l'impact** de la modification :

| Type de modification | On le met dans le Changelog ? | Catégorie |
| --- | --- | --- |
| **Correction d'une faute d'orthographe** dans un commentaire de code. | **NON** (Trop insignifiant). | / |
| **Optimisation interne** qui ne change rien pour l'utilisateur. | **NON** (Sauf si le script devient 10x plus rapide). | `Changed` |
| **Correction d'un bug** qui faisait planter le script. | **OUI** (Même si c'est une seule virgule changée). | `Fixed` |
| **Ajout d'un nouveau paramètre** (ex: `-save`). | **OUI** (Indispensable). | `Added` |

---

### 4. Exemple concret pour votre projet

Si vous avez modifié votre fichier unique `hash-tool` pour mieux gérer les dossiers temporaires, votre entrée de changelog ressemblera à ceci :

```markdown
## [1.1.0] - 2026-02-26

### Added
- Nouveau paramètre `-save` pour automatiser l'emplacement de la base.

### Fixed
- Problème de gestion des chemins contenant des espaces.
- Erreur lors de l'accès aux dossiers en lecture seule.

### Changed
- Amélioration du format d'affichage des résultats en console.

```

---

### 5. Intégration dans votre documentation

Vous pouvez ajouter ce petit rappel à la fin de votre guide de gestion de projet :

> **Note sur le Changelog :**
> * Ne listez pas les noms de fichiers techniques.
> * Regroupez vos changements par type (`Added`, `Fixed`, `Changed`).
> * Un changement = une ligne commençant par un tiret.
> * Si un changement n'a aucun impact sur l'utilisation du script, ne le notez pas.
> 
>


--- Fichier : hors_git/documentation dev/guide - git - convention message.md ---

La convention la plus utilisée aujourd'hui par les développeurs (et celle que je vous recommande pour `hash-tool`) est celle des **Conventional Commits**.

Cette norme permet de générer automatiquement des changelogs et de comprendre l'historique en un coup d'œil.

---

## 1. Structure d'un message de commit

Un message bien formaté suit cette structure :
`<type>: <description courte>`

### Les types principaux :

* **feat**: (feature) Une nouvelle fonctionnalité pour l'utilisateur (ex: le paramètre `-save`).
* **fix**: Une correction de bug.
* **docs**: Modifications de la documentation (README, guides, commentaires).
* **style**: Changements qui n'affectent pas le sens du code (espaces, formatage, virgules oubliées).
* **refactor**: Modification du code qui ne corrige ni bug ni n'ajoute de fonction (nettoyage).
* **chore**: Tâches ingrates ou maintenance (mise à jour de `.gitignore`, changement de nom de dossier).

---

## 2. Exemples concrets pour votre projet

| Mauvais message | Message "Conventional" |
| --- | --- |
| "ajout de save" | `feat: ajout de l'option -save pour l'export auto` |
| "bug fix" | `fix: gestion des noms de fichiers avec espaces` |
| "maj doc" | `docs: mise à jour du guide d'installation gh` |
| "nettoyage" | `refactor: simplification de la boucle de hachage` |

---

## 3. Les règles d'écriture (Style)

1. **Utilisez l'impératif ou le présent** : "ajoute" au lieu de "ajouté" ou "en train d'ajouter".
2. **Pas de majuscule au début de la description** : Après le `:`, on commence souvent en minuscule.
3. **Pas de point à la fin** : Le titre doit être court et percutant.
4. **Limitez à 50 caractères** : Pour que le message soit lisible sur GitHub ou dans un terminal.

---

## 4. Pourquoi utiliser des types ?

C'est ici que tout se recoupe avec votre **Changelog** :

* Tous vos commits **feat** iront dans la section `Added` du changelog.
* Tous vos commits **fix** iront dans la section `Fixed` du changelog.

---


**Règle d'or :** Si un commit contient un "breaking change" (changement majeur qui casse la compatibilité), on ajoute un point d'exclamation : `feat!: changement complet du format de base .b3`.



--- Fichier : hors_git/documentation dev/guide - git - gestion des branches - niveau avancé.md ---



## 1. La nomenclature des branches (Naming Convention)

Au lieu de nommer vos branches de test au hasard, adoptez un préfixe. Cela permet de savoir immédiatement de quoi traite une branche quand vous en avez plusieurs.

* **`feature/`** : Pour l'ajout d'une nouvelle fonctionnalité (ex: `feature/stats-export`).
* **`fix/`** : Pour la correction d'un bug (ex: `fix/spaces-in-path`).
* **`docs/`** : Pour les modifications de documentation uniquement.
* **`refactor/`** : Pour le nettoyage du code sans changement de fonctionnalité.

**Exemple :** `git checkout -b feature/sidecar-json`

---

## 2. Le "Merge" vs le "Rebase"

C'est un grand débat dans Git, mais voici la règle simple :

* **Merge (Fusion)** : Crée un "commit de fusion". On voit visuellement que deux branches se sont rejointes. C'est parfait pour garder une trace de "quand" une fonctionnalité a été intégrée à `main`.
* **Rebase** : Réécrit l'historique pour qu'il soit bien droit, comme si vous aviez travaillé sur une seule ligne.
* *Conseil :* Utilisez le **Rebase** sur votre branche `dev` pour la garder propre, mais utilisez toujours le **Merge** pour envoyer `dev` vers `main`.



---

## 3. Le "Stash" (Le placard temporaire)

Imaginez : vous travaillez sur une grosse modification dans `dev`, ce n'est pas fini, mais vous devez *absolument* retourner sur `main` pour vérifier une sauvegarde. Git vous interdira de changer de branche si vous avez des fichiers modifiés non commités.

* **`git stash`** : Met vos modifications de côté dans un placard temporaire. Votre dossier redeviens "propre".
* **`git checkout main`** : Vous faites votre vérification.
* **`git checkout dev`** : Vous revenez.
* **`git stash pop`** : Vous ressortez vos modifications du placard et reprenez le travail là où vous en étiez.

---

## 4. Le "Cherry-pick" (Cueillir une cerise)

Parfois, vous avez fait 10 commits sur `dev`, mais il y en a **un seul** (un petit correctif génial) que vous voulez ramener sur `main` immédiatement sans ramener tout le reste du chantier.

* **Commande** : `git cherry-pick <ID_DU_COMMIT>`
* Cela permet de copier-coller un commit spécifique d'une branche à l'autre.

---

## 5. La protection de branche (Sur GitHub)

Puisque vous avez maintenant un dépôt sur GitHub, vous pouvez activer une option dans les réglages du dépôt (*Settings > Branches > Add rule*) :

* **Require a pull request before merging** : Vous force à passer par l'interface web pour valider le passage de `dev` vers `main`.
* **Lock branch** : Empêche toute suppression accidentelle de la branche `main`.
* C'est une sécurité "anti-fatigue" pour éviter de faire une bêtise un soir de fatigue.

---

## 6. Les Pull Requests (PR) / Merge Requests

Même seul, créer une **Pull Request** sur GitHub pour fusionner `dev` vers `main` est utile car :

1. Cela vous permet de **relire votre propre code** dans une interface claire avant de valider.
2. Cela crée une trace propre dans GitHub avec la liste des changements.
3. Vous pouvez y lier des captures d'écran ou des notes pour votre "futur vous".

---




--- Fichier : hors_git/documentation dev/guide - git - gestion des branches.md ---


# Guide : Stratégie de Branches Git pour `hash-tool`

L'objectif de cette stratégie est de séparer le **code stable** (utilisé pour vos vraies opérations de hachage) du **code en développement** (où vous testez de nouvelles fonctions ou corrections).

## 1. Structure des branches

Nous utilisons deux branches permanentes :

* **`main` (Production)** : Contient uniquement le code validé. C'est la référence. Chaque commit sur cette branche correspond généralement à une version du `changelog` (v1.0, v1.1, etc.).
* **`dev` (Développement)** : C'est ici que vous travaillez au quotidien. Vous y ajoutez des fonctionnalités, corrigez des bugs et testez vos scripts.

---

## 2. Mise en place initiale

Si vous n'avez actuellement qu'une branche `main`, créez la branche `dev` :

```bash
# 1. Se placer sur main
git checkout main

# 2. Créer la branche dev et basculer dessus
git checkout -b dev

# 3. Envoyer la branche dev sur GitHub
git push -u origin dev

```

---

## 3. Cycle de travail quotidien

Désormais, ne travaillez plus jamais directement sur `main`.

### Étape A : Travailler sur `dev`

Faites vos modifications dans votre code.

```bash
git add .
git commit -m "feat: ajout de la gestion des chemins absolus pour -save"
git push origin dev

```

### Étape B : Valider et Fusionner (Mise en production)

Une fois que vos modifications sur `dev` fonctionnent parfaitement et que vous avez mis à jour le `changelog.md` :

```bash
# 1. Basculer sur la branche stable
git checkout main

# 2. Récupérer les nouveautés de dev
git merge dev

# 3. Marquer la version officielle (Tag)
git tag -a v1.1.0 -m "Version 1.1.0 : gestion robuste du dossier -save"

# 4. Envoyer vers GitHub
git push origin main --tags

```

### Étape C : Reprendre le développement

Repartez sur votre branche de travail :

```bash
git checkout dev

```

---

## 4. Cas d'urgence : Le "Hotfix"

Si vous découvrez un bug critique en plein milieu d'une utilisation réelle de `hash-tool` alors que votre branche `dev` est en plein chantier (code instable) :

1. Revenez sur `main` : `git checkout main`.
2. Créez une branche temporaire : `git checkout -b fix-bug-urgent`.
3. Réparer le bug, faites un `commit`.
4. Fusionnez sur `main` et supprimez la branche de fix.
5. N'oubliez pas de fusionner aussi ce correctif dans `dev` pour ne pas perdre la réparation !

---

## 5. Résumé des commandes de navigation

| Action | Commande |
| --- | --- |
| **Savoir sur quelle branche je suis** | `git branch` |
| **Passer sur la branche dev** | `git checkout dev` |
| **Passer sur la branche main** | `git checkout main` |
| **Voir l'historique de toutes les branches** | `git log --oneline --graph --all` |

---

## Pourquoi cette méthode est-elle pertinente ?

Pour un outil comme `hash-tool`, la branche `main` devient votre **assurance sécurité**. Si un jour vous faites une erreur de script catastrophique (ex: un `rm -rf` mal placé dans vos tests), vos données réelles ne risquent rien car vous pourrez toujours revenir instantanément à la version saine présente sur `main`.

--- Fichier : hors_git/documentation dev/guide - git - quand faire un commit.md ---
La règle d'or pour un commit est la suivante : **"Faites un commit pour chaque unité de changement logique."**

Un commit ne doit pas forcément représenter une heure de travail ou un fichier entier, mais une **idée complète**.

---

## 1. Les 3 règles d'or du "Quand ?"

### A. Le principe atomique (Atomic Commits)

Un commit doit être "atomique" : il fait une seule chose, mais il la fait complètement.

* **Pourquoi ?** Si vous découvrez que votre modification de ce matin casse tout, vous pouvez l'annuler (`revert`) sans perdre le reste de votre travail de l'après-midi.
* **Exemple :** Ne mélangez pas "Correction faute d'orthographe" et "Nouvel algorithme de hachage" dans le même commit.

### B. "Commit early, commit often" (Commiter tôt et souvent)

N'attendez pas la fin de la journée. Faites un commit dès que vous avez :

* Fini une petite sous-fonctionnalité.
* Corrigé un bug précis.
* Mis à jour la documentation d'une partie que vous venez de coder.

### C. Ne jamais commiter du code qui ne "compile" pas

Même si vous êtes sur la branche `dev`, essayez de ne pas commiter un script qui contient une erreur de syntaxe empêchant son lancement. Si vous devez arrêter votre travail au milieu d'une modification, utilisez plutôt le **`git stash`** (le placard) dont nous avons parlé.

---

## 2. Le test du "Parce que"

Pour savoir si vous devez faire un commit, essayez de compléter cette phrase :

> *"Si j'applique ce commit, cela va [votre message de commit]"*

* **Bon commit** : "...cela va **ajouter l'option -save au script**." (C'est clair).
* **Mauvais commit** : "...cela va **faire plein de trucs et corriger deux-trois trucs**." (C'est trop large).

---

## 3. Rythme type d'une session de dev (Exemple `hash-tool`)

Voici comment vous pourriez découper vos commits sur 2 heures de travail :

1. **Commit 1** : `docs: ajout des paramètres de version dans le README`
2. **Commit 2** : `feat: ajout de la vérification de l'existence du dossier -save`
3. **Commit 3** : `fix: gestion des erreurs si le disque est plein lors du hachage`
4. **Commit 4** : `chore: mise à jour du changelog pour la v1.1.0`

---

## 4. Ce qu'il ne faut JAMAIS commiter

Même si vous faites des commits souvent, certains fichiers ne doivent jamais y figurer :

* **Données sensibles** : Mots de passe, clés d'API, chemins d'accès personnels (d'où l'importance du `.gitignore`).
* **Gros fichiers binaires de données** : Vos fichiers `.b3` (Git n'est pas fait pour stocker des bases de données volumineuses).
* **Fichiers temporaires** : Les fichiers `temp.txt` que nous avons exclus précédemment.

---

## 5. Résumé pour votre guide

Vous pouvez ajouter ce paragraphe à votre documentation :

> ### Stratégie de Commits
> 
> 
> * **Fréquence** : 1 commit = 1 action logique (ex: une fonction créée, un bug fixé).
> * **Qualité** : Ne jamais commiter de code qui casse le lancement du script.
> * **Messages** : Utilisez des verbes d'action au présent (ex: `feat: ajoute...`, `fix: corrige...`).
> * **Avant le Push** : Relisez vos modifications avec `git status` pour vérifier que vous n'envoyez pas de fichiers inutiles.
> 
> 

Souhaitez-vous que je vous montre comment utiliser des **"Conventional Commits"** (le système de préfixes `feat:`, `fix:`, `docs:`) pour rendre votre historique encore plus professionnel ?

--- Fichier : hors_git/documentation dev/guide - github - config.md ---


# Guide : Configurer GitHub CLI et l'identité Git

Ce guide explique comment installer l'outil `gh`, configurer votre identité de développeur et créer un dépôt privé pour votre projet.

## 1. Installation de GitHub CLI (`gh`)

Le paquet `gh` n'est pas présent par défaut dans les dépôts standards. Il faut ajouter le dépôt officiel pour garantir une version à jour.

```bash
# 1. Préparation du dossier des clés
sudo mkdir -p -m 755 /etc/apt/keyrings

# 2. Ajout de la clé de confiance GitHub
wget -qO- https://cli.github.com/packages/githubcli-archive-keyring.gpg | sudo tee /etc/apt/keyrings/githubcli-archive-keyring.gpg > /dev/null
sudo chmod go+r /etc/apt/keyrings/githubcli-archive-keyring.gpg

# 3. Ajout du dépôt officiel
echo "deb [arch=$(dpkg --print-architecture) signed-by=/etc/apt/keyrings/githubcli-archive-keyring.gpg] https://cli.github.com/packages stable main" | sudo tee /etc/apt/sources.list.d/github-cli.list > /dev/null

# 4. Installation
sudo apt update
sudo apt install gh -y

```

---

## 2. Configuration de l'identité (Nom & Email)

Avant de vous connecter à GitHub, vous devez indiquer à Git qui vous êtes. Ces informations seront inscrites dans chaque commit (historique).

### Configuration Globale (Recommandé)

Ceci s'appliquera à tous vos projets sur cet ordinateur.

```bash
# L'email peut être différent de celui du compte GitHub, mais 
# utilisez celui de GitHub pour lier vos commits à votre profil.
git config --global user.name "Votre Nom ou Pseudo"
git config --global user.email "votre-email@exemple.com"

```

### Configuration Locale (Optionnel)

Si vous voulez utiliser un nom ou un email différent **uniquement pour ce projet** (ex: pseudo spécifique), lancez ceci à l'intérieur du dossier du projet :

```bash
git config user.name "Mon Pseudo Projet"
git config user.email "email-prive@projet.com"

```

*Note : La configuration locale est prioritaire sur la globale pour le dossier en cours.*

---

## 3. Authentification avec `gh auth login`

Liez votre terminal à votre compte GitHub de manière sécurisée.

1. Lancez : `gh auth login`
2. **What account?** `GitHub.com`
3. **Protocol?** `HTTPS`
4. **Authenticate Git?** `Yes` (Important pour automatiser les futurs push)
5. **How to authenticate?** `Login with a web browser`
6. **Action :** Copiez le code à 8 caractères affiché, appuyez sur Entrée, collez-le dans la page web qui s'ouvre et validez.

---

## 4. Création du dépôt privé et Push

Une fois authentifié, préparez votre envoi.

### Étape A : Créer le fichier `.gitignore`

Indispensable pour ne pas envoyer vos données de test ou bases volumineuses. Créez un fichier `.gitignore` à la racine :

```text
*.b3
*.meta.json
mon_dossier/source/
mon_dossier/destination/

```

### Étape B : Création et premier envoi

```bash
# Crée le repo sur GitHub, lie le dossier local et envoie tout (y compris les tags)
gh repo create hash-tool --private --source=. --remote=origin --push

```

---

## 5. Résumé et Astuces

| Commande | Utilité |
| --- | --- |
| `git config --list` | Vérifier l'identité configurée (nom/email). |
| `gh auth status` | Vérifier si vous êtes bien connecté. |
| `gh repo view --web` | Ouvrir votre projet GitHub dans le navigateur. |
| `git push origin --tags` | Envoyer vos nouveaux tags de version (ex: v1.1.0). |

**Astuce GitHub :** Si vous utilisez un email différent de celui de votre compte, vous pouvez l'ajouter dans vos paramètres GitHub (*Settings > Emails*) pour que vos commits soient quand même reliés à votre profil et comptabilisés dans vos statistiques.


--- Fichier : hors_git/documentation dev/guide- git - pratique - dev et master.md ---
Voici la procédure exacte pour fusionner votre travail de la branche `dev` vers `master` et tout envoyer sur GitHub de manière propre.

### 1. Sécuriser votre branche `dev`

Assurez-vous que tout est bien enregistré sur votre branche actuelle avant de changer de branche.

```bash
# Vérifier que vous êtes bien sur dev
git checkout dev

# Ajouter et commiter vos dernières modifs si ce n'est pas fait
git add .
git commit -m "feat: description de vos dernières modifications"
git push origin dev

```

---

### 2. Fusionner vers `master` (Le "Merge")

C'est ici que vous ramenez votre travail vers la branche stable.

```bash
# 1. Basculer sur la branche principale
git checkout master

# 2. Récupérer les modifs de dev
git merge dev

```

*Note : Si Git ouvre un éditeur de texte (souvent `nano`) pour le message de fusion, appuyez sur `Ctrl+O`, `Entrée` puis `Ctrl+X` pour valider.*

---

### 3. Marquer la version et envoyer (Le "Push")

C'est l'étape finale pour mettre à jour votre dépôt distant.

```bash
# 1. Créer le tag de version (ex: v1.2.0)
git tag -a v1.2.0 -m "Release v1.2.0 : description synthétique"

# 2. Envoyer le code de la branche master vers GitHub
git push origin master

# 3. Envoyer les tags (très important pour que GitHub affiche la version)
git push origin --tags

```

---

### Résumé visuel de ce que vous venez de faire

### 4. Revenir au travail

Une fois que tout est en ligne et sécurisé, n'oubliez pas de vous remettre sur votre branche de travail pour la suite :

```bash
git checkout dev

```

---

### En cas de conflit (si vous avez modifié `master` par erreur)

Si Git affiche un message disant `CONFLICT`, ne paniquez pas :

1. VS Code affichera les fichiers en rouge.
2. Choisissez "Accept Incoming Change" (ce qui vient de dev) ou "Accept Current Change".
3. Refaites un `git add .` et `git commit` pour finaliser la fusion.




--- Fichier : hors_git/docker/docker.md ---
# Docker — hash_tool

Utilisation de hash_tool via Docker — aucune dépendance à installer sur l'hôte.

---

## Prérequis

- Docker >= 20.10 (support multi-platform)
- Optionnel : Docker Compose v2

---

## Build

```bash
# Build standard (amd64)
docker build -t hash_tool .

# Build pour ARM64 (NAS Synology DS923+, Raspberry Pi, Apple Silicon)
docker build --platform linux/arm64 -t hash_tool:arm64 .

# Build avec version b3sum spécifique
docker build --build-arg B3SUM_VERSION=1.5.4 -t hash_tool .
```

---

## Commandes disponibles

```
docker run [--rm] [-v ...] hash_tool <commande> [args]

  compute <dossier> <base.b3>           Calcule les hashes
  verify  <base.b3> [dossier]           Vérifie l'intégrité
  compare <ancienne.b3> <nouvelle.b3>   Compare deux bases
  runner  [pipeline.json]               Exécute un pipeline JSON
  shell                                 Shell bash interactif (debug)
  help                                  Aide
  version                               Versions des outils
```

---

## Exemples d'utilisation

### Compute — indexer un dossier

```bash
docker run --rm \
  -v /mes/donnees:/data:ro \
  -v /mes/bases:/bases \
  hash_tool compute /data /bases/hashes_$(date +%Y-%m-%d).b3
```

### Verify — vérifier l'intégrité

```bash
# Depuis le répertoire d'origine (même montage /data qu'au compute)
docker run --rm \
  -v /mes/donnees:/data:ro \
  -v /mes/bases:/bases:ro \
  -v /mes/resultats:/resultats \
  hash_tool verify /bases/hashes_2024-01-15.b3 /data
```

Le résultat (`recap.txt`, `failed.txt` si échec) est écrit dans `/resultats` sur l'hôte.

### Compare — deux snapshots

```bash
docker run --rm \
  -v /mes/bases:/bases:ro \
  -v /mes/resultats:/resultats \
  hash_tool compare /bases/hashes_2024-01-15.b3 /bases/hashes_2024-02-01.b3
```

Produit `recap.txt`, `modifies.b3`, `disparus.txt`, `nouveaux.txt`, `report.html`.

### Pipeline JSON complet

```bash
docker run --rm \
  -v /mes/donnees:/data:ro \
  -v /mes/bases:/bases \
  -v /mes/resultats:/resultats \
  -v /chemin/vers/pipeline.json:/pipelines/pipeline.json:ro \
  hash_tool runner
```

### Mode silencieux — CI/cron

```bash
# Exit code 0 si OK, non-nul si FAILED
docker run --rm \
  -v /mes/donnees:/data:ro \
  -v /mes/bases:/bases:ro \
  -v /mes/resultats:/resultats \
  hash_tool --quiet verify /bases/hashes.b3 /data \
  || echo "ALERTE : corruption détectée"
```

### Debug interactif

```bash
docker run --rm -it \
  -v /mes/donnees:/data \
  -v /mes/bases:/bases \
  hash_tool shell
```

---

## Volumes

| Volume | Usage | Recommandation |
|---|---|---|
| `/data` | Données à hacher | `:ro` (lecture seule) |
| `/bases` | Fichiers `.b3` | Lecture/écriture pour `compute` |
| `/pipelines` | Fichiers `pipeline.json` | `:ro` |
| `/resultats` | Résultats `verify`/`compare` | Lecture/écriture |

---

## Variable d'environnement

`RESULTATS_DIR` — dossier de résultats dans le conteneur (défaut : `/resultats`).

```bash
docker run --rm \
  -v /mes/resultats:/mon_dossier_custom \
  -e RESULTATS_DIR=/mon_dossier_custom \
  hash_tool verify /bases/hashes.b3
```

---

## Docker Compose

Adapter les chemins dans `docker-compose.yml` (section `x-volumes`), puis :

```bash
# Commande ponctuelle
docker compose run --rm integrity verify /bases/hashes.b3 /data
docker compose run --rm integrity compute /data /bases/hashes.b3

# Pipeline complet
docker compose run --rm pipeline

# Build et run pipeline
docker compose build && docker compose run --rm pipeline
```

---

## NAS Synology

Sur DSM 7.x avec Docker Manager ou Portainer :

```bash
# Chemin type sur Synology
docker run --rm \
  -v /volume1/data:/data:ro \
  -v /volume1/bases:/bases \
  -v /volume1/resultats:/resultats \
  hash_tool verify /bases/hashes.b3 /data
```

Pour ARM64 (DS220+, DS923+) : builder avec `--platform linux/arm64` ou utiliser une image pré-buildée.

---

## Cron sur serveur Debian

```bash
# /etc/cron.d/hash-integrity
0 3 * * * root docker run --rm \
  -v /srv/data:/data:ro \
  -v /srv/bases:/bases:ro \
  -v /srv/resultats:/resultats \
  hash_tool --quiet verify /bases/hashes.b3 /data \
  >> /var/log/hash-integrity.log 2>&1 \
  || mail -s "ALERTE intégrité $(hostname)" admin@example.com
```

---

## Taille de l'image

| Couche | Taille approx. |
|---|---|
| Alpine 3.19 base | ~7 Mo |
| bash + jq + coreutils + findutils | ~5 Mo |
| b3sum binaire musl | ~2 Mo |
| Scripts hash_tool | <100 Ko |
| **Total** | **~14 Mo** |

L'utilisation d'un binaire musl pré-compilé (stage `fetcher`) évite d'embarquer la toolchain Rust (~700 Mo) dans l'image finale.

---

## Mise à jour de b3sum

Modifier `ARG B3SUM_VERSION` dans le `Dockerfile` et rebuilder :

```bash
docker build --build-arg B3SUM_VERSION=1.6.0 -t hash_tool .
```

Les URLs de release suivent le pattern :
```
https://github.com/BLAKE3-team/BLAKE3/releases/download/<version>/b3sum_linux_amd64_musl
https://github.com/BLAKE3-team/BLAKE3/releases/download/<version>/b3sum_linux_aarch64_musl
```

La signature `.b3` est vérifiée automatiquement au build (le binaire se vérifie lui-même).


--- Fichier : hors_git/docker/hash_tool-docker-documentation.docx ---
[Fichier binaire ou illisible, contenu ignoré]

--- Fichier : hors_git/docker/hash_tool-docker-documentation.pdf ---
[Fichier binaire ou illisible, contenu ignoré]

--- Fichier : hors_git/chemin relatif et absolu/chemins relatifs et absolu.md ---



**Problématique : comparaison de dossiers sur différents volumes**

Lorsqu’on utilise `hash-tool` pour comparer des dossiers situés sur des volumes différents (ex. `A:/disque_1/musique` vs `Z:/disque_3/musique`), une limitation apparaît : les bases `.b3` actuelles stockent des chemins **absolus**. Ainsi, même si les fichiers ont un contenu identique, `compare` ou `verify` peut signaler des différences, car les chemins absolus diffèrent (`A:/…` ≠ `Z:/…`).

Ce comportement n’est pas un bug : l’outil compare en réalité des fonctions `chemin → hash`. Toute divergence dans les chemins rend la comparaison invalide.

---

**Feature proposée : support des chemins relatifs**

Pour résoudre ce problème, il est nécessaire d’introduire le concept de **chemins relatifs à une racine logique**.

* Lors de l’indexation (`compute`), le chemin enregistré dans la base `.b3` serait **relatif à la racine du dossier analysé** (ex. `musique/album1/piste1.flac`).
* Lors de la vérification ou de la comparaison (`verify` / `diff`), ces chemins relatifs seraient appliqués à la racine du dossier cible, quelle que soit sa localisation sur le système de fichiers.

**Avantages attendus :**

1. Comparer deux copies identiques de dossiers sur différents volumes sans générer de faux positifs liés aux chemins absolus.
2. Détecter précisément : fichiers modifiés, manquants ou ajoutés, indépendamment du point de montage ou de la lettre de disque.
3. Maintenir l’intégrité logique du workflow actuel, sans changer la méthode de calcul des hash.

**Exemple :**

* Base générée sur : `A:/disque_1/musique` → enregistre `album1/piste1.flac`
* Vérification sur : `Z:/disque_3/musique` → applique le même chemin relatif, détection correcte des écarts.

En résumé, le support des chemins relatifs permet une **comparaison robuste des contenus**, indépendamment des chemins physiques, tout en conservant la puissance et la granularité du modèle `chemin → hash`.




--- Fichier : hors_git/chemin relatif et absolu/llm -- feature chemin relatif - presentation du pb.md ---
# Comparer fichiers hash BLAKE3

**User:** Anonymous (mapellecorentin@gmail.com)  
**Created:** 2/26/2026 12:58:14  
**Updated:** 2/26/2026 13:08:17  
**Exported:** 2/26/2026 13:09:03  
**Link:** [https://chatgpt.com/c/69a03554-9190-8332-8704-25040dca6d73](https://chatgpt.com/c/69a03554-9190-8332-8704-25040dca6d73)  

## Prompt:
Je suis à l'adresse "/media/veracrypt1/partition_laptop/divers/config ordinateur/2 en cours -- 2025-00-00 -- backup/d11 installation/hash_tool" , je lance les commandes suivantes : 

bash \
hash-tool \
compute \
-data "/media/veracrypt1/partition_laptop/divers/config ordinateur/2 en cours -- 2025-00-00 -- backup/d11 installation/hash_tool/mon_dossier/source" \
-save "/media/veracrypt1/partition_laptop/divers/config ordinateur/2 en cours -- 2025-00-00 -- backup/d11 installation/hash_tool/mon_dossier/destination" \
-meta "source, base initiale"

et

bash \
hash-tool \
compute \
-data "/home/me-dell/Bureau/dossier bureau/destination" \
-save "/home/me-dell/Bureau/dossier bureau/bases" \
-meta "destination, base initiale" 

j'obtiens les fichiers .b3 suivants : 

096fc1aadff334e739da7bde4bca5116735c85e097ec459c9765382656073b18  /media/veracrypt1/partition_laptop/divers/config ordinateur/2 en cours -- 2025-00-00 -- backup/d11 installation/hash_tool/mon_dossier/source/fichier (1).txt
0f6591514285c2e48ce58e71cc34879e345b7414dba9201ba2c8c9bb812b7924  /media/veracrypt1/partition_laptop/divers/config ordinateur/2 en cours -- 2025-00-00 -- backup/d11 installation/hash_tool/mon_dossier/source/fichier (2).txt
7bb238792d6ba450e3d9cb1b4bc2de6c8dc8210a6011282b7df2c3772b462df9  /media/veracrypt1/partition_laptop/divers/config ordinateur/2 en cours -- 2025-00-00 -- backup/d11 installation/hash_tool/mon_dossier/source/fichier (3).txt
b4d63a7ac21e4e40ade16322470f8ad99cc6e8f8ec8c11471a988732983e8d59  /media/veracrypt1/partition_laptop/divers/config ordinateur/2 en cours -- 2025-00-00 -- backup/d11 installation/hash_tool/mon_dossier/source/fichier (4).txt

et

9ad9dd9635080df19e5f10c6844d325dd059607981f214c43889f44d2b71e3c4  /home/me-dell/Bureau/dossier bureau/destination/fichier (1).txt
0f6591514285c2e48ce58e71cc34879e345b7414dba9201ba2c8c9bb812b7924  /home/me-dell/Bureau/dossier bureau/destination/fichier (2).txt
7bb238792d6ba450e3d9cb1b4bc2de6c8dc8210a6011282b7df2c3772b462df9  /home/me-dell/Bureau/dossier bureau/destination/fichier (3).txt
b4d63a7ac21e4e40ade16322470f8ad99cc6e8f8ec8c11471a988732983e8d59  /home/me-dell/Bureau/dossier bureau/destination/fichier (4).txt

Problème : comment comparer étant donné que les chemins sont différents?

## Response:
Le problème n’est pas le hash, mais le **champ “chemin”** : ton outil compare des lignes complètes, alors que seul le **digest BLAKE3** (première colonne) est pertinent pour l’intégrité.

Il y a trois solutions robustes.

1.  Comparer uniquement les colonnes de hash (recommandé).

Extrait uniquement la première colonne de chaque fichier `.b3`, puis compare-les :

```
cut -d' ' -f1 source.b3 | sort > source.hash
cut -d' ' -f1 destination.b3 | sort > destination.hash
diff source.hash destination.hash
```

Si `diff` ne renvoie rien, alors les ensembles de fichiers sont identiques au sens du contenu.

2.  Neutraliser les chemins en les remplaçant par des noms relatifs.

Par exemple, si les fichiers ont les mêmes noms :

```
sed 's#.*/##' source.b3 > source_rel.b3
sed 's#.*/##' destination.b3 > destination_rel.b3
diff source_rel.b3 destination_rel.b3
```

Cela supprime tout ce qui précède le nom de fichier.

3.  Comparaison par jointure (méthode formelle).

Pour voir précisément quels fichiers diffèrent :

```
sort source.b3 > s1
sort destination.b3 > s2
join s1 s2
```

ou, pour lister ceux qui ne correspondent pas :

```
comm -3 <(sort source.b3) <(sort destination.b3)
```

Interprétation scientifique :

– Donnée observée : tes sorties montrent que  
_fichier (2), (3), (4)_ ont des hashs identiques → contenus identiques.  
_fichier (1)_ a un hash différent → contenu différent.

Donc le problème n’est pas lié aux chemins, mais à la logique de comparaison : il faut comparer les **empreintes cryptographiques**, pas les chemins absolus.

Si tu veux, je peux te proposer un script minimal (bash ou Python) qui compare deux `.b3` proprement et te sort :  
– fichiers identiques  
– fichiers différents  
– fichiers manquants.

## Prompt:
est-ce qu'il faudrait pas que je lance le script au bon endroit ?

## Response:
Non. Le répertoire courant n’a **aucune importance** pour la validité de la comparaison, tant que tu fournis les **bons chemins vers les fichiers `.b3`**.

Deux cas distincts :

1.  Si tu utilises des **chemins absolus** (comme dans tes exemples `/media/veracrypt1/...` et `/home/me-dell/...`)

Alors tu peux lancer la commande depuis n’importe quel répertoire :

```
diff /chemin/vers/source.b3 /chemin/vers/destination.b3
```

Le résultat sera identique quel que soit l’endroit d’où tu lances la commande.  
Le problème ne vient donc pas du “mauvais dossier”, mais du fait que les lignes contiennent des chemins différents.

2.  Si tu utilises des **chemins relatifs** (ex. `source.b3`)

Alors oui, il faut être dans le bon répertoire :

```
cd "/media/veracrypt1/partition_laptop/divers/config ordinateur/2 en cours -- 2025-00-00 -- backup/d11 installation/hash_tool"
diff source.b3 destination.b3
```

Mais ce n’est qu’une question de résolution de nom de fichier, pas de logique de comparaison.

Conclusion rigoureuse :

– La comparaison correcte doit porter sur la **colonne des hash**, pas sur le chemin.  
– Le répertoire courant n’influence pas le résultat **si tu passes des chemins explicites**.  
– Ton écart observé sur `fichier (1)` est un écart réel de contenu, pas un artefact de chemin.

Si tu veux une réponse opérationnelle en une ligne :

```
cut -d' ' -f1 source.b3 | sort > a
cut -d' ' -f1 destination.b3 | sort > b
diff a b
```

Cela élimine totalement la dépendance au répertoire et aux chemins.

## Prompt:
non mais si je garde que la colonne des hashes et que un seul fichier est absent dans le dossier 2, alors  je vais pas pouvoir le voir

## Response:
Exact. Si tu compares **uniquement l’ensemble des hash**, tu perds l’information de correspondance avec les fichiers.  
Deux situations deviennent indiscernables :

– un fichier manquant  
– un fichier présent mais remplacé par un autre de même taille (hash différent mais “compensé” par un autre)

Donc ta remarque est **correcte** : comparer seulement la colonne des hash est insuffisant pour un contrôle d’intégrité structurel.

Il faut comparer des couples **(nom de fichier, hash)**, mais en neutralisant la partie variable du chemin.

Solution rigoureuse : ramener les chemins à des chemins relatifs (ou au nom de fichier seul), puis comparer.

Par exemple avec le nom de fichier uniquement :

```
sed 's#.*/##' source.b3 | sort > source_norm.b3
sed 's#.*/##' destination.b3 | sort > destination_norm.b3
diff source_norm.b3 destination_norm.b3
```

Ici chaque ligne reste de la forme :

```
HASH  fichier (1).txt
```

Donc tu détectes :  
– fichier absent  
– fichier en plus  
– fichier présent mais modifié  
– fichier identique

Alternative plus formelle (diagnostic explicite) :

```
comm -3 source_norm.b3 destination_norm.b3
```

Interprétation scientifique (à partir de tes données observées) :

Tu as :

source :

```
096fc1aa…  fichier (1).txt
```

destination :

```
9ad9dd96…  fichier (1).txt
```

Donc même nom, hash différent → **modification réelle du contenu**.

Si un fichier était absent du dossier 2, tu aurais une ligne :  
– présente uniquement dans `source_norm.b3`  
→ détectée par `comm` ou `diff`.

Conclusion méthodologique :

– Comparer seulement les hash ⇒ test d’égalité d’ensembles (perte d’information).  
– Comparer (nom relatif, hash) ⇒ test d’isomorphie de répertoires (structure + contenu).  
– C’est cette seconde approche qui est correcte pour un backup.

Si tu veux, je peux te donner un script minimal qui classe automatiquement en :

1.  identiques
2.  modifiés
3.  absents dans destination
4.  présents en trop dans destination.

## Prompt:
En fait mon outil est bien à condition de fonctionner sur un seul dossier et un seul chemin à la fois : # Démarrage rapide

---

## Prérequis

| Dépendance | Usage | Installation |
|---|---|---|
| bash >= 4 | Interpréteur shell | Linux natif ; macOS via brew install bash ; WSL |
| b3sum | Calcul des empreintes BLAKE3 | apt install b3sum / brew install b3sum |
| jq | Pipelines JSON + sidecar | apt install jq / brew install jq |
| find, sort, awk, comm, join, stat, du | Outils internes | GNU coreutils (natifs sur toute distribution) |

!!! note "macOS"
    bash est en version 3.x par défaut sur macOS. hash_tool requiert bash >= 4.
    bash
    brew install bash b3sum jq
    # Vérifier : /usr/local/bin/bash --version

!!! note "Docker (alternative)"
    Si les dépendances ne peuvent pas être installées sur l'hôte, hash-tool bascule automatiquement sur Docker. Voir [Démarrage rapide Docker](#docker-démarrage-rapide).

---

## Installation

bash
git clone https://github.com/hash_tool/hash_tool.git
cd hash_tool
chmod +x hash-tool src/integrity.sh runner.sh

Aucune compilation, aucune dépendance système au-delà des outils listés ci-dessus.

### Rendre hash-tool accessible globalement (optionnel)

bash
sudo ln -s "$(pwd)/hash-tool" /usr/local/bin/hash-tool
# Ou : ajouter le dossier hash_tool/ au PATH

---

## Environnements supportés

| Environnement | Méthode | Notes |
|---|---|---|
| Linux (Debian, Ubuntu, Alpine, Arch…) | Natif | Environnement de référence |
| macOS | Natif avec bash 4+ via Homebrew | brew install bash b3sum jq |
| Windows | Via WSL2 | Distributions Ubuntu ou Debian recommandées |
| NAS Synology | Via Docker (image arm64) | Voir [guide NAS](guides/nas-synology.md) |
| Serveur headless | Mode -quiet + cron | Voir [guide CI/Cron](guides/cron-ci.md) |

---

## Vérifier l'environnement

Avant toute utilisation, diagnostiquer l'environnement :

bash
hash-tool check-env

Sortie attendue :

=== check-env : Analyse de l'environnement ===

  [OK] b3sum disponible : b3sum 1.5.4
  [OK] jq disponible : jq-1.7
  [OK] bash 5.2.15(1)-release
  [OK] integrity.sh présent et exécutable : /opt/hash_tool/src/integrity.sh
  [OK] runner.sh présent et exécutable : /opt/hash_tool/runner.sh
  [--] Docker non disponible (optionnel)

  Mode d'exécution sélectionné : native
  → Exécution native active

---

## Workflow typique

| Étape | Commande | Moment |
|---|---|---|
| 1. Indexer | hash-tool compute -data ./dossier -save ./bases -meta "..." | Données saines connues |
| 2. Vérifier | hash-tool verify -base ./bases/hashes_dossier.b3 | Après transfert / stockage |
| 3. Comparer | hash-tool compare -old avant.b3 -new apres.b3 | Entre deux états |
| 4. Inspecter | hash-tool diff -base ./bases/hashes_dossier.b3 -data ./dossier | Contrôle rapide (sans recalcul) |
| 5. Pipeline | hash-tool runner -pipeline ./pipelines/pipeline-amelioree.json | Automatisation multi-étapes |

### Exemple concret — archivage sur disque externe

bash
# Disque monté sur /mnt/archive

# 1. Première indexation — données saines à J0
hash-tool compute \
  -data /mnt/archive \
  -save /mnt/c/bases \
  -meta "Snapshot initial archive 2024-01-15"

# 2. Vérification après chaque session — J+30, J+90, etc.
hash-tool verify \
  -base /mnt/c/bases/hashes_archive.b3 \
  -data /mnt/archive

# 3. Après ajout de fichiers — voir ce qui a changé sans recalculer
hash-tool diff \
  -base /mnt/c/bases/hashes_archive.b3 \
  -data /mnt/archive

# 4. Nouveau snapshot puis comparaison
hash-tool compute \
  -data /mnt/archive \
  -save /mnt/c/bases \
  -meta "Snapshot après ajout collection 2024-02-15"

hash-tool compare \
  -old /mnt/c/bases/hashes_archive_avant.b3 \
  -new /mnt/c/bases/hashes_archive_apres.b3 \
  -save /mnt/c/rapports

---

## Sidecar file — métadonnées associées aux bases

Chaque compute génère automatiquement un fichier .meta.json à côté du .b3 :

bash
hash-tool compute -data ./donnees -save ./bases -meta "Snapshot initial"

Produit :

./bases/
├── hashes_donnees.b3           ← empreintes BLAKE3
└── hashes_donnees.b3.meta.json ← métadonnées (date, commentaire, paramètres)

Contenu du sidecar :

json
{
  "created_by": "hash-tool v2.0.0",
  "date": "2026-02-26T14:30:00Z",
  "comment": "Snapshot initial",
  "parameters": {
    "directory": "./donnees",
    "hash_algo": "blake3",
    "readonly": false,
    "nb_files": 1247
  }
}

Les commandes verify, compare et stats affichent automatiquement les métadonnées sidecar si le fichier est présent.

---

## Lire les résultats

Chaque opération verify ou compare produit un dossier horodaté dans ~/integrity_resultats/ :

~/integrity_resultats/
└── resultats_hashes_archive/
    ├── recap.txt      ← statut global, compteurs
    ├── failed.txt     ← fichiers en échec (si applicable)
    ├── modifies.b3    ← fichiers modifiés (compare uniquement)
    ├── disparus.txt   ← fichiers disparus (compare uniquement)
    ├── nouveaux.txt   ← nouveaux fichiers (compare uniquement)
    └── report.html    ← rapport visuel autonome

Ouvrir report.html directement dans un navigateur — aucune connexion requise, aucun serveur.

---

## Docker — démarrage rapide

Si les dépendances ne peuvent pas être installées sur l'hôte, hash-tool détecte Docker automatiquement et l'utilise en fallback :

bash
# Build une fois
docker build -t hash_tool .

# Ensuite, hash-tool fonctionne identiquement
# (le mode d'exécution est sélectionné automatiquement)
hash-tool check-env   # affichera : Mode d'exécution : docker

Ou directement via Docker :

bash
docker run --rm \
  -v /mes/donnees:/data:ro \
  -v /mes/bases:/bases \
  hash_tool compute /data /bases/hashes_$(date +%Y-%m-%d).b3

Voir la [référence Docker complète](reference/docker.md) pour les volumes, les environnements Synology, et les options Compose.

---

## Commandes disponibles

hash-tool compute     Calcule les empreintes d'un dossier.
hash-tool verify      Vérifie l'intégrité d'un dossier à partir d'une base.
hash-tool compare     Compare deux bases d'empreintes.
hash-tool runner      Exécute un pipeline JSON.
hash-tool list        Liste les bases d'empreintes disponibles.
hash-tool diff        Affiche les différences entre une base et un dossier.
hash-tool stats       Affiche des statistiques sur une base.
hash-tool check-env   Analyse l'environnement d'exécution.
hash-tool version     Affiche la version.
hash-tool help        Affiche l'aide (ou 'help <commande>' pour le détail).

Aide détaillée par commande :

bash
hash-tool help compute
hash-tool help verify
hash-tool help runner
# etc.

## Response:
Oui. Ton diagnostic est correct : **ton outil est cohérent à condition qu’une base corresponde toujours au même arbre de fichiers (même racine logique)**.

Structurellement, `hash-tool compute` enregistre des couples :

```
(hash, chemin)
```

où le _chemin est absolu ou ancré dans un dossier donné_.  
Donc une base est **indexée par le chemin**, pas seulement par le contenu.

Conséquence formelle :

– `compare` est valide si  
_old_ et _new_ proviennent **du même dossier racine** (ou d’une copie à l’identique du même arbre).  
– `compare` est invalide si  
_old_ = snapshot de `/media/veracrypt1/.../source`  
_new_ = snapshot de `/home/.../destination`  
car l’espace des clés (les chemins) est différent, même si les fichiers sont identiques.

Autrement dit, ton outil vérifie l’égalité d’une fonction :

```
f : chemin → hash
```

et non l’égalité d’un multiensemble de contenus.

Donc ton workflow correct est :

1.  `compute` sur un dossier D (référence)
2.  copie de D ailleurs
3.  `compute` sur le dossier copié
4.  `compare` entre les deux bases  
    → valide **si et seulement si** la structure de chemins est isomorphe.

Si tu veux comparer deux dossiers situés à des emplacements différents, il faut soit :

– imposer la même racine logique (ex : toujours travailler avec des chemins relatifs),  
– soit ajouter une normalisation (`strip_prefix`) dans ton outil,  
– soit utiliser `verify` / `diff` au lieu de `compare`.

En résumé :

Ton outil n’est pas “faux”.  
Il est **défini sur un espace de chemins**, pas sur un ensemble de fichiers abstraits.  
Ton cas d’échec vient d’un changement de repère (racine différente), pas d’un bug de hash.

## Prompt:
– soit utiliser \`verify\` / \`diff\` au lieu de \`compare\`.

c'est à dire ?

## Response:
Concrètement :

`compare` sert à comparer **deux bases d’empreintes** qui ont été calculées sur **le même dossier racine logique**.  
Il suppose que les chemins stockés dans les deux fichiers `.b3` sont comparables tels quels.  
Dans ton cas, ce n’est pas vrai :  
– base 1 → `/media/veracrypt1/.../source/...`  
– base 2 → `/home/.../destination/...`  
Les contenus peuvent être identiques, mais les clés (les chemins) sont différentes, donc `compare` conclut à tort qu’il y a des écarts structurels.

À l’inverse :

`verify` et `diff` ne comparent pas deux bases entre elles.  
Ils comparent **une base** avec **un dossier réel**.

Formellement :

– `verify` teste :  
“le contenu actuel de ce dossier correspond-il à la base ?”  
– `diff` teste :  
“qu’est-ce qui diffère entre cette base et ce dossier ?”

Exemple adapté à ton cas :

Tu fais une base sur la source :

```
hash-tool compute -data /media/veracrypt1/.../source -save ./bases
```

Puis tu copies ce dossier vers :

```
/home/me-dell/Bureau/dossier bureau/destination
```

Ensuite tu vérifies la copie avec la base d’origine :

```
hash-tool verify \
  -base ./bases/hashes_source.b3 \
  -data "/home/me-dell/Bureau/dossier bureau/destination"
```

ou pour voir les écarts :

```
hash-tool diff \
  -base ./bases/hashes_source.b3 \
  -data "/home/me-dell/Bureau/dossier bureau/destination"
```

Ici, la base contient toujours les chemins relatifs internes (ex. `fichier (1).txt`), et l’outil les applique au nouveau dossier racine.  
Donc :  
– fichier manquant → détecté  
– fichier modifié → détecté  
– fichier en plus → détecté  
sans exiger que `/media/...` = `/home/...`.

En résumé :

– `compare` = comparaison **historique** entre deux snapshots du _même_ dossier.  
– `verify` / `diff` = comparaison **logique** entre un snapshot et une _copie ailleurs_.

Ton cas d’usage (source vs destination à des chemins différents) relève de `verify` ou `diff`, pas de `compare`.

## Prompt:
oui mais il faut que le b3 utilisé ait la même arboresscence que le dossier

## Response:
Oui — et c’est une contrainte **structurelle**, pas accidentelle.

Une base `.b3` n’est pas un simple ensemble de hash.  
C’est une table de correspondance :

```
chemin_relatif → hash
```

Donc, pour que `verify` ou `diff` fonctionne correctement, il faut que :

> **le dossier vérifié ait la même arborescence relative que celle enregistrée dans la base**

Concrètement :

Si ta base a été construite sur :

```
source/
 ├── fichier (1).txt
 ├── fichier (2).txt
 └── subdir/
     └── fichier (3).txt
```

alors le dossier cible doit être :

```
destination/
 ├── fichier (1).txt
 ├── fichier (2).txt
 └── subdir/
     └── fichier (3).txt
```

Peu importe que `source` soit :

```
/media/veracrypt1/.../source
```

et `destination` :

```
/home/me-dell/.../destination
```

ce qui compte est que **le chemin relatif interne soit identique** :

```
fichier (1).txt
subdir/fichier (3).txt
```

Sinon, logiquement :

– si le fichier existe mais pas au même endroit → vu comme “manquant”  
– si un fichier est déplacé → vu comme “disparu + nouveau”  
– si l’arborescence est différente → la base ne peut plus être appliquée

Ce n’est pas une limitation technique arbitraire, c’est une propriété mathématique du modèle utilisé :  
tu compares deux fonctions `chemin → hash`.  
Si l’ensemble des chemins diffère, il n’existe plus de bijection évidente entre les fichiers.

Donc :

✔️ valable :

```
compute sur A
verify sur copie exacte de A ailleurs
```

❌ non valable :

```
compute sur A
verify sur B où les fichiers ont été déplacés ou renommés
```

Si ton besoin est :  
« comparer deux dossiers qui ont le même contenu mais pas la même arborescence »,  
alors ce n’est **plus un test d’intégrité**, c’est un problème d’**équivalence d’ensembles de fichiers**,  
et il faut un autre modèle (par hash seul, ou par contenu + taille, sans chemin).

En résumé :

– ton outil est correct pour : _intégrité d’un arbre de fichiers_  
– il suppose : _arborescence conservée_  
– si l’arborescence change, la comparaison n’a plus de sens au sens strict de l’outil.

## Prompt:
moi j'aimerais comparer "A:/disque_1/musique" et "Z:/disque_3/musique", il faut donc passer à des chemins relatifs c'est ça ?

## Response:
Oui. Pour ton cas d’usage — comparer  
`A:/disque_1/musique`  
et  
`Z:/disque_3/musique` —  
il faut raisonner en **chemins relatifs à la racine “musique”**, pas en chemins absolus.

Ce que tu veux comparer, ce n’est pas :

```
A:/disque_1/musique/album1/piste1.flac
Z:/disque_3/musique/album1/piste1.flac
```

mais :

```
album1/piste1.flac
```

Autrement dit, la fonction pertinente est :

```
chemin_relatif → hash
```

et non :

```
chemin_absolu → hash
```

Donc, logiquement, ton outil doit :

1.  prendre comme racine logique `musique`,
2.  stocker uniquement les chemins **relatifs à cette racine** dans le `.b3`,
3.  appliquer ces chemins relatifs à l’autre dossier racine lors de la vérification/comparaison.

Workflow correct dans ton cas :

```
hash-tool compute -data "A:/disque_1/musique" -save ./bases
```

puis :

```
hash-tool verify -base ./bases/hashes_musique.b3 -data "Z:/disque_3/musique"
```

À condition que l’arborescence interne soit la même :

```
musique/
 ├── album1/
 │    └── piste1.flac
 └── album2/
      └── piste3.flac
```

Si tu restes en chemins absolus, alors mathématiquement tu compares deux ensembles disjoints de clés :  
`A:/…` ≠ `Z:/…`, même si les contenus sont identiques.

Conclusion :

Oui, tu dois passer à des **chemins relatifs à la racine logique commune** (`musique`).  
Sinon, ton outil compare des emplacements, pas des fichiers homologues.



---
Powered by [ChatGPT Exporter](https://www.chatgptexporter.com)

--- Fichier : hors_git/_misc/environment.md ---
Aucun des deux n'est pertinent ici — ce sont des fichiers Python (`pip`/`conda`).

**hash_tool est un projet bash pur.** Les dépendances sont des binaires système, pas des packages Python. Le fichier équivalent existe déjà dans le projet : `requirements-docs.txt` qui gère uniquement MkDocs (la doc), pas le code.

**Pour les dépendances runtime du projet lui-même**, les conventions bash sont :

Le plus courant et le plus adapté à votre cas est de documenter dans un script de vérification ou directement dans `check-env`. Vous avez déjà `hash-tool check-env` qui joue exactement ce rôle. C'est la solution idiomatique pour un projet shell.

Si vous voulez quand même un fichier déclaratif formel pour l'intégration CI ou les contributeurs, la convention bash est un fichier texte simple à la racine :

```
# dependencies — hash_tool
# Binaires système requis (installables via apt / brew / apk)

bash>=4
b3sum
jq
find        # GNU coreutils
sort        # GNU coreutils
awk         # GNU coreutils
comm        # GNU coreutils
join        # GNU coreutils
stat        # GNU coreutils
du          # GNU coreutils
mktemp      # GNU coreutils

# Documentation uniquement (pip)
# pip install -r requirements-docs.txt
```

Nommé `DEPENDENCIES` ou `dependencies.txt`. Pas de standard universel — c'est purement informatif.

**Verdict : non, ce n'est pas grave.** `hash-tool check-env` est la vraie source de vérité. Un `DEPENDENCIES` textuel est un plus pour les contributeurs, pas une nécessité opérationnelle.

--- Fichier : hors_git/_misc/progression-eta.md ---
# Progression temps réel et estimation ETA

## Le problème

Le pipeline `find | sort | xargs b3sum` est une boîte noire : `b3sum` ne remonte aucune progression. Par défaut, le mode `compute` s'exécute en silence jusqu'à complétion - aucun indicateur de durée ni d'avancement.

---

## Pourquoi l'ETA nécessite de casser le pipeline `xargs`

Intercaler `pv` dans le pipeline existant est techniquement possible mais inutilisable ici : mesurer le débit sur un flux `cat | pv | b3sum` produit un hash global du flux concaténé, pas une ligne par fichier. Le fichier `.b3` résultant est invalide pour `--check` ou `compare`.

```bash
# Cette approche est invalide - ne pas utiliser
TOTAL=$(find "$TARGET" -type f -print0 | xargs -0 du -sb | awk '{sum+=$1} END {print sum}')
find "$TARGET" -type f -print0 | sort -z \
  | xargs -0 cat \
  | pv -s "$TOTAL" \
  | b3sum \
  > "$HASHFILE"
# Produit un hash unique du flux concaténé - inutilisable
```

La seule approche compatible avec le format `.b3` : remplacer `xargs` par une boucle bash explicite, fichier par fichier. Le contrôle de progression devient trivial. Le coût en performance est négligeable - le disque est le goulot, pas le shell.

---

## Implémentation finale : `compute_with_progress`

```bash
compute_with_progress() {
  local target="$1"
  local hashfile="$2"

  local -a files
  mapfile -d '' files < <(find "$target" -type f -print0 | sort -z)

  local total_files=${#files[@]}
  local total_bytes
  total_bytes=$(du -sb "$target" | awk '{print $1}')

  local bytes_done=0
  local t_start
  t_start=$(date +%s)

  local i=0
  for file in "${files[@]}"; do
    b3sum "$file" >> "$hashfile"

    bytes_done=$(( bytes_done + $(stat -c%s "$file") ))
    i=$(( i + 1 ))

    local t_now elapsed
    t_now=$(date +%s)
    elapsed=$(( t_now - t_start ))

    if (( bytes_done > 0 && elapsed > 0 )); then
      local speed remaining
      speed=$(( bytes_done / elapsed ))
      remaining=$(( (total_bytes - bytes_done) / speed ))
      printf "\r[%d/%d] ETA : %dm %02ds   " \
        "$i" "$total_files" $(( remaining / 60 )) $(( remaining % 60 ))
    fi
  done

  printf "\r%*s\r" 40 ""  # effacer la ligne de progression
}
```

**`mapfile -d ''`** au lieu de `FILES=($(find ...))` : la substitution de commande `$(...)` découpe sur les espaces et les retours à la ligne - les noms de fichiers avec espaces seraient cassés en plusieurs éléments. `mapfile -d ''` lit le flux nul-séparé produit par `-print0` et charge chaque chemin comme un élément distinct du tableau, sans ambiguïté.

---

## Mécanique de l'estimation

L'ETA repose sur trois mesures :

- **octets traités** - cumulés après chaque fichier via `stat -c%s`
- **octets totaux** - calculés une fois avant la boucle via `du -sb`
- **débit instantané** - `octets_traités / secondes_écoulées`

```
ETA = (octets_restants) / débit_moyen
    = (total - fait) / (fait / elapsed)
```

Le débit moyen converge après ~10–20 secondes de traitement. Avant ce seuil, l'ETA est instable - comportement identique à `rsync`, `cp --progress`, ou tout outil du même type. Ce n'est pas un défaut d'implémentation, c'est une contrainte statistique inhérente à toute estimation par extrapolation linéaire sur fenêtre courte.

---

## Coût du changement de stratégie

| | Pipeline `xargs` | Boucle bash (avec progression) |
|---|---|---|
| Débit sur HDD | Optimal | Identique - I/O impose le rythme |
| Débit sur SSD séquentiel | Optimal | Identique |
| Débit sur SSD `-P 4` | +20–40 % | Non applicable - boucle séquentielle |
| Progression temps réel | Non | Oui |
| ETA | Non | Oui |

**Cas où la boucle dégrade les performances :** SSD avec `-P 4`. Le parallélisme par `xargs` n'est pas reproductible en boucle bash sans complexité significative. Sur HDD - cas le plus courant pour de gros volumes - la différence est nulle.


--- Fichier : .github/workflows/ci.yml ---
name: CI

on:
  push:
    branches: ["**"]
  pull_request:
    branches: ["**"]

jobs:
  # ===========================================================================
  # Tests fonctionnels + unitaires
  # ===========================================================================
  tests:
    name: Tests (${{ matrix.os }})
    runs-on: ${{ matrix.os }}

    strategy:
      fail-fast: false
      matrix:
        os: [ubuntu-22.04, ubuntu-24.04]

    steps:
      - uses: actions/checkout@v4

      - name: Installer les dépendances
        run: |
          sudo apt-get update -qq
          sudo apt-get install -y b3sum jq shellcheck

      - name: Vérifier les prérequis
        run: |
          b3sum --version
          jq --version
          shellcheck --version
          bash --version

      - name: T00-T20 - integrity.sh (run_tests.sh)
        run: |
          chmod +x tests/run_tests.sh
          cd tests && ./run_tests.sh

      - name: TP01-TP12 - pipeline (run_tests_pipeline.sh)
        run: |
          chmod +x tests/run_tests_pipeline.sh
          cd tests && ./run_tests_pipeline.sh

      - name: CU01-CU53 - tests unitaires core.sh (run_tests_core.sh)
        run: |
          chmod +x tests/run_tests_core.sh
          cd tests && ./run_tests_core.sh

      - name: ShellCheck - tous les scripts
        run: |
          shellcheck src/integrity.sh
          shellcheck runner.sh
          shellcheck src/lib/core.sh
          shellcheck src/lib/ui.sh
          shellcheck src/lib/report.sh
          shellcheck src/lib/results.sh
          shellcheck docker/entrypoint.sh
          shellcheck tests/run_tests.sh
          shellcheck tests/run_tests_pipeline.sh
          shellcheck tests/run_tests_core.sh

      - name: Upload artefacts de test
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: test-results-${{ matrix.os }}
          path: /tmp/integrity-test*/
          retention-days: 7

  # ===========================================================================
  # Tests Docker
  # ===========================================================================
  docker:
    name: Docker build & smoke tests
    runs-on: ubuntu-latest

    steps:
      - uses: actions/checkout@v4

      - name: Build de l'image
        run: docker build -t hash_tool .

      - name: Smoke test - version
        run: docker run --rm hash_tool version

      - name: Smoke test - help
        run: docker run --rm hash_tool help

      - name: Smoke test - check-env
        run: docker run --rm hash_tool check-env

      - name: Smoke test - compute via volume
        run: |
          mkdir -p /tmp/testdata /tmp/testbases
          echo "contenu alpha" > /tmp/testdata/alpha.txt
          echo "contenu beta"  > /tmp/testdata/beta.txt
          docker run --rm \
            -v /tmp/testdata:/data:ro \
            -v /tmp/testbases:/bases \
            hash_tool compute /data /bases/test.b3
          # Vérifie que le fichier .b3 est produit et non vide
          [ -s /tmp/testbases/test.b3 ] || (echo "ERREUR : test.b3 vide ou absent" && exit 1)
          echo "test.b3 produit : $(wc -l < /tmp/testbases/test.b3) ligne(s)"

      - name: Smoke test - verify via volume
        run: |
          docker run --rm \
            -v /tmp/testdata:/data:ro \
            -v /tmp/testbases:/bases:ro \
            -v /tmp/testresultats:/resultats \
            -e RESULTATS_DIR=/resultats \
            hash_tool verify /bases/test.b3 /data

      - name: Entrypoint - commande inconnue → exit non-zéro
        run: |
          docker run --rm hash_tool commande_inexistante && exit 1 || true


--- Fichier : reports/template.html ---
<!DOCTYPE html>
<html lang="fr">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Rapport - [BASE_A] vs [BASE_B]</title>
  <!--
    ══════════════════════════════════════════════════════════════════
    reports/template.html - Barebone rapport de comparaison hash_tool
    ══════════════════════════════════════════════════════════════════

    Ce fichier est un template statique de référence.
    Le rapport réel est généré automatiquement par src/lib/report.sh
    dans le dossier "resultats" défini dans pipeline.json.

    Structure du rapport généré :
      <resultats>/
        ├== report.html      ← rapport visuel (ce template rempli)
        ├== recap.txt        ← résumé texte
        ├== modifies.b3      ← fichiers avec hash différent
        ├== disparus.txt     ← fichiers présents dans A, absents de B
        └== nouveaux.txt     ← fichiers absents de A, présents dans B

    Pour personnaliser le rendu HTML : modifier src/lib/report.sh
    (fonction generate_compare_html).

    Placeholders utilisés dans report.sh :
      [BASE_A]       nom du fichier .b3 ancienne base
      [BASE_B]       nom du fichier .b3 nouvelle base
      [DATE]         date de génération
      [STATUT]       IDENTIQUES | DIFFÉRENCES DÉTECTÉES
      [NB_MODIFIES]  nombre de fichiers modifiés
      [NB_DISPARUS]  nombre de fichiers disparus
      [NB_NOUVEAUX]  nombre de nouveaux fichiers
      [LIST_*]       listes HTML injectées par _render_file_list()
    ══════════════════════════════════════════════════════════════════
  -->
  <style>
    /* → Voir src/lib/report.sh pour le CSS complet injecté dans les rapports générés */

    :root {
      --bg:       #0f1117;
      --bg-card:  #161b27;
      --border:   #252d3f;
      --text:     #c8d4e8;
      --text-dim: #5a6a85;
      --mono:     monospace;
      --sans:     system-ui, sans-serif;
    }

    body {
      background: var(--bg);
      color: var(--text);
      font-family: var(--sans);
      font-size: 14px;
      display: flex;
      align-items: center;
      justify-content: center;
      min-height: 100vh;
      padding: 40px;
    }

    .placeholder {
      max-width: 560px;
      text-align: center;
    }

    .placeholder h1 {
      font-family: var(--mono);
      font-size: 12px;
      letter-spacing: .1em;
      text-transform: uppercase;
      color: var(--text-dim);
      margin-bottom: 24px;
    }

    .placeholder p {
      color: var(--text-dim);
      line-height: 1.7;
      font-size: 13px;
      margin-bottom: 12px;
    }

    code {
      font-family: var(--mono);
      font-size: 12px;
      background: var(--bg-card);
      border: 1px solid var(--border);
      border-radius: 4px;
      padding: 2px 6px;
      color: var(--text);
    }
  </style>
</head>
<body>
  <div class="placeholder">
    <h1>hash_tool · template.html</h1>
    <p>Ce fichier est le template de référence du rapport de comparaison.</p>
    <p>
      Les rapports réels sont générés automatiquement dans le dossier
      <code>resultats</code> défini par le champ
      <code>"resultats"</code> dans <code>pipeline.json</code>.
    </p>
    <p>
      Pour personnaliser le rendu : modifier
      <code>src/lib/report.sh</code> → fonction
      <code>generate_compare_html()</code>.
    </p>
  </div>
</body>
</html>

--- Fichier : src/integrity.sh ---
#!/usr/bin/env bash
# integrity.sh - Vérification d'intégrité par hachage BLAKE3
#
# Point d'entrée CLI interne. Orchestre les modules :
#   src/lib/core.sh    - logique métier (hachage, vérification, comparaison, sidecar)
#   src/lib/ui.sh      - interface terminal (affichage, ETA, progression)
#   src/lib/results.sh - écriture des fichiers de résultats
#   src/lib/report.sh  - génération des rapports HTML
#
# Usage :
#   ./integrity.sh [--quiet] compute <dossier> <base.b3> [commentaire_sidecar]
#   ./integrity.sh [--quiet] verify  <base.b3> [dossier]
#   ./integrity.sh [--quiet] compare <ancienne.b3> <nouvelle.b3>
#
# Options :
#   --quiet   Supprime toute sortie terminal. Écrit uniquement dans les
#             fichiers de résultats. Exit code propagé sans modification.
#
# Sidecar :
#   compute génère automatiquement <base.b3>.meta.json si jq est disponible.
#   Le troisième argument optionnel de compute est un commentaire libre.
#   verify et compare affichent le sidecar si présent (sauf --quiet).
#
# Dépendances : b3sum, bash >= 4, find, sort, awk, comm, join, stat, du, mktemp
#               jq (optionnel - requis pour la génération du sidecar)
#
# Exit codes :
#   0 - succès (voir contrat de chaque mode dans src/lib/core.sh)
#   1 - erreur (argument manquant, fichier introuvable, corruption détectée)

set -euo pipefail

# == Version ====================================================================

INTEGRITY_VERSION="2.0.0"

# == Prérequis bash =============================================================

(( BASH_VERSINFO[0] >= 4 )) || {
  echo "ERREUR : bash >= 4 requis (actuel : $BASH_VERSION)" >&2
  exit 1
}

# == Résolution des chemins =====================================================

SCRIPT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"

# == Chargement des modules =====================================================

for _module in ui core results report; do
  _path="$SCRIPT_DIR/lib/${_module}.sh"
  [ -f "$_path" ] || { echo "ERREUR : module introuvable : $_path" >&2; exit 1; }
  # shellcheck source=/dev/null
  source "$_path"
done
unset _module _path

# == Parsing des arguments ======================================================

QUIET=0
ARGS=()

for arg in "$@"; do
  case "$arg" in
    --quiet) QUIET=1 ;;
    *)       ARGS+=("$arg") ;;
  esac
done

MODE="${ARGS[0]:-}"
ARG2="${ARGS[1]:-}"
ARG3="${ARGS[2]:-}"
ARG4="${ARGS[3]:-}"   # commentaire sidecar optionnel pour compute

# == Configuration ==============================================================

# Dossier racine des résultats. Peut être surchargé par variable d'environnement.
# runner.sh surcharge cette valeur via export pour isoler les runs de pipeline.
RESULTATS_DIR="${RESULTATS_DIR:-${HOME}/integrity_resultats}"

# == Handlers des modes =========================================================

_run_compute() {
  local target="$ARG2"
  local hashfile="$ARG3"
  local sidecar_comment="${ARG4:-}"

  [ -n "$target"   ] || die "compute : dossier cible manquant.\nUsage : $0 compute <dossier> <base.b3> [commentaire]"
  [ -n "$hashfile" ] || die "compute : fichier de sortie .b3 manquant.\nUsage : $0 compute <dossier> <base.b3> [commentaire]"
  [ ! -d "$hashfile" ] || die "compute : '$hashfile' est un dossier. Le fichier .b3 de sortie doit être un chemin de fichier."

  core_assert_target_valid "$target"

  # Utilise ui_progress_callback uniquement si QUIET == 0
  local callback=""
  (( QUIET )) || callback="ui_progress_callback"

  core_compute "$target" "$hashfile" "$callback"
  ui_progress_clear

  say "Base enregistrée : $hashfile ($(wc -l < "$hashfile") fichiers)"

  # Sidecar : généré si jq est disponible
  if command -v jq &>/dev/null; then
    core_sidecar_write "$hashfile" "$target" "$sidecar_comment" "$INTEGRITY_VERSION"
    say "Sidecar : ${hashfile}.meta.json"
  fi
}

_run_verify() {
  local b3file="$ARG2"
  local workdir="${ARG3:-}"

  [ -n "$b3file" ] || die "verify : fichier .b3 manquant.\nUsage : $0 verify <base.b3> [dossier]"

  core_assert_b3_valid "$b3file" "base"

  # Résolution du chemin absolu AVANT le cd : un chemin relatif deviendrait
  # invalide après changement de répertoire
  local hashfile_abs
  hashfile_abs="$(cd "$(dirname "$b3file")" && pwd)/$(basename "$b3file")"

  # Affichage du sidecar avant le cd (chemin encore valide)
  (( QUIET )) || core_sidecar_read "$hashfile_abs"

  if [ -n "$workdir" ]; then
    [ -d "$workdir" ] || die "verify : '$workdir' n'est pas un dossier valide."
    cd "$workdir"
  fi

  local outdir
  outdir=$(core_make_result_dir "$hashfile_abs" "$RESULTATS_DIR")

  # core_verify positionne les variables CORE_VERIFY_* dans le scope courant
  local exit_code=0
  core_verify "$hashfile_abs" || exit_code=$?

  results_write_verify \
    "$outdir" "$hashfile_abs" \
    "$CORE_VERIFY_STATUS" "$CORE_VERIFY_NB_OK" "$CORE_VERIFY_NB_FAIL" \
    "$CORE_VERIFY_LINES_FAIL" "$CORE_VERIFY_LINES_ERR"

  ui_show_verify_result \
    "$CORE_VERIFY_STATUS" "$CORE_VERIFY_NB_OK" "$CORE_VERIFY_NB_FAIL" \
    "$CORE_VERIFY_LINES_FAIL" "$CORE_VERIFY_LINES_ERR" \
    "$outdir"

  return $exit_code
}

_run_compare() {
  local old="$ARG2"
  local new="$ARG3"

  [ -n "$old" ] || die "compare : fichier ancienne base manquant.\nUsage : $0 compare <ancienne.b3> <nouvelle.b3>"
  [ -n "$new" ] || die "compare : fichier nouvelle base manquant.\nUsage : $0 compare <ancienne.b3> <nouvelle.b3>"

  core_assert_b3_valid "$old" "ancienne base"
  core_assert_b3_valid "$new" "nouvelle base"

  # Affichage des sidecars avant toute opération
  if (( ! QUIET )); then
    core_sidecar_read "$old"
    core_sidecar_read "$new"
  fi

  local outdir
  outdir=$(core_make_result_dir "$old" "$RESULTATS_DIR")

  # core_compare positionne CORE_COMPARE_NB_* dans le scope courant
  core_compare "$old" "$new" "$outdir"

  results_write_compare \
    "$outdir" "$old" "$new" \
    "$CORE_COMPARE_NB_MOD" "$CORE_COMPARE_NB_DIS" "$CORE_COMPARE_NB_NOU"

  generate_compare_html \
    "$old" "$new" \
    "$CORE_COMPARE_NB_MOD" "$CORE_COMPARE_NB_DIS" "$CORE_COMPARE_NB_NOU" \
    "${outdir}/modifies.b3" "${outdir}/disparus.txt" "${outdir}/nouveaux.txt" \
    "${outdir}/report.html"

  ui_show_compare_result \
    "$CORE_COMPARE_NB_MOD" "$CORE_COMPARE_NB_DIS" "$CORE_COMPARE_NB_NOU" \
    "$outdir"
}

# == Dispatch ===================================================================

case "$MODE" in
  compute) _run_compute ;;
  verify)  _run_verify  ;;
  compare) _run_compare ;;
  *)
    cat <<EOF
Usage :
  $0 [--quiet] compute <dossier> <base.b3> [commentaire]
  $0 [--quiet] verify  <base.b3> [dossier]
  $0 [--quiet] compare <ancienne.b3> <nouvelle.b3>

Options :
  --quiet      Silencieux : écrit uniquement dans les fichiers de résultats.

Arguments optionnels :
  [commentaire]  Texte libre stocké dans le sidecar <base.b3>.meta.json (compute uniquement).
                 Nécessite jq.

Note :
  Pour l'interface complète (list, diff, stats, check-env, version, pipeline),
  utiliser hash-tool à la racine du projet.
EOF
    exit 1
    ;;
esac

--- Fichier : src/lib/core.sh ---
#!/usr/bin/env bash
# src/lib/core.sh - Logique métier BLAKE3 : hachage, vérification, comparaison, sidecar
#
# Ce module contient uniquement la logique métier. Il ne produit aucune
# sortie terminal directement - toute communication avec l'utilisateur
# est déléguée à src/lib/ui.sh via les codes de retour et les variables
# de sortie déclarées dans les contrats ci-dessous.
#
# Sourcé par src/integrity.sh. Ne pas exécuter directement.
#
# == Dépendances ================================================================
#   b3sum, find, sort, awk, join, comm, mktemp, stat, du
#   jq (optionnel - requis pour core_sidecar_write et core_sidecar_read)
#
# == Invariants globaux =========================================================
#   - Toutes les fonctions supposent bash >= 4 (vérifié par integrity.sh)
#   - Les chemins dans les bases .b3 sont toujours RELATIFS (jamais absolus)
#   - Le format .b3 est celui natif de b3sum : "<hash64>  <chemin>" (2 espaces)
#   - L'encodage supposé est UTF-8 ; les noms non UTF-8 sont traités comme des
#     séquences d'octets opaques (find -print0 / mapfile -d '' garantissent
#     l'absence d'interprétation)
#   - La locale n'affecte pas le tri : sort utilise l'ordre binaire (LC_ALL=C
#     doit être positionné par l'appelant si nécessaire pour reproductibilité)

# == Validation =================================================================

# core_assert_b3_valid <fichier> [label]
#
# Contrat d'entrée :
#   $1 - chemin vers un fichier .b3 à valider
#   $2 - label optionnel pour les messages d'erreur (défaut : $1)
#
# Contrat de sortie :
#   exit 0  - fichier valide : existe, est un fichier régulier, non vide,
#             contient au moins une ligne au format "<hash64>  <chemin>"
#   exit 1  - fichier invalide ; appelle die() avec message explicite
#
# Effets de bord : aucun
core_assert_b3_valid() {
  local file="$1"
  local label="${2:-$1}"

  [ -e "$file" ] || die "$label : fichier introuvable."
  [ -f "$file" ] || die "$label : est un dossier, pas un fichier .b3."
  [ -s "$file" ] || die "$label : fichier vide - aucun hash à traiter."

  local valid_lines
  valid_lines=$(grep -c -E '^[0-9a-f]{64}  .+' "$file" || true)
  [ "$valid_lines" -gt 0 ] || die "$label : format invalide - aucune ligne au format b3sum détectée."

  local total_lines
  total_lines=$(wc -l < "$file")
  if [ "$total_lines" -gt "$valid_lines" ]; then
    die "$label : fichier corrompu - $((total_lines - valid_lines)) ligne(s) sur $total_lines ne respectent pas le format b3sum."
  fi
}

# core_assert_target_valid <dossier>
#
# Contrat d'entrée :
#   $1 - chemin vers un dossier à indexer
#
# Contrat de sortie :
#   exit 0  - dossier valide : existe, est un dossier, contient au moins un fichier régulier
#   exit 1  - invalide ; appelle die() avec message explicite
#
# Effets de bord : aucun
core_assert_target_valid() {
  local dir="$1"

  [ -e "$dir" ] || die "Dossier cible introuvable : $dir"
  [ -d "$dir" ] || die "Le chemin cible n'est pas un dossier : $dir"

  local nb_files
  nb_files=$(find "$dir" -type f -print0 | grep -zc '' || echo 0)
  (( nb_files > 0 )) || die "Le dossier $dir ne contient aucun fichier régulier - rien à hacher."
}

# == Utilitaires internes ========================================================

# _core_file_size <fichier>
#
# Contrat de sortie :
#   stdout - taille du fichier en octets (entier)
#   Portable : GNU stat (-c%s) avec fallback BSD stat (-f%z)
#
# Effets de bord : aucun
_core_file_size() {
  local f="$1"
  if stat -c%s "$f" 2>/dev/null; then
    return
  fi
  stat -f%z "$f"
}

# == Hachage ====================================================================

# core_compute <dossier> <fichier_sortie> [callback_progression]
#
# Contrat d'entrée :
#   $1 - dossier cible (chemin relatif RECOMMANDÉ pour portabilité des bases)
#   $2 - chemin du fichier .b3 de sortie (créé ou écrasé)
#   $3 - (optionnel) nom d'une fonction de callback appelée après chaque fichier
#         Signature callback : callback <i> <total_files> <bytes_done> <total_bytes> <eta_seconds>
#         Passer "" ou omettre pour désactiver la progression
#
# Contrat de sortie :
#   exit 0       - base calculée avec succès
#   exit 1       - erreur (propagée depuis b3sum ou find)
#   $2 (fichier) - contient N lignes "<hash64>  <chemin>", triées par chemin,
#                  sans artefact terminal (ETA, \r, etc.)
#
# Invariants garantis :
#   - Les chemins dans $2 sont identiques à ceux vus par find depuis $1
#   - L'ordre est déterministe (sort -z sur les chemins)
#   - Aucune ligne ETA ou de progression ne peut être écrite dans $2 :
#     b3sum est appelé par fichier individuel, la progression est gérée
#     par le callback, pas par redirection
#
# Effets de bord :
#   - Crée ou écrase $2
#   - Appelle $3 si fourni (effets de bord dépendants du callback)
core_compute() {
  local target="$1"
  local hashfile="$2"
  local callback="${3:-}"

  local -a files
  mapfile -d '' files < <(find "$target" -type f -print0 | sort -z)

  local total_files=${#files[@]}
  local total_bytes
  total_bytes=$(du -sb "$target" | awk '{print $1}')

  local bytes_done=0
  local t_start
  t_start=$(date +%s)

  local i=0
  for file in "${files[@]}"; do
    b3sum "$file" >> "$hashfile"

    local fsize
    fsize=$(_core_file_size "$file")
    # Fichier de taille zéro : bytes_done inchangé, ETA non calculée pour ce fichier
    if (( fsize > 0 )); then
      bytes_done=$(( bytes_done + fsize ))
    fi
    i=$(( i + 1 ))

    if [ -n "$callback" ]; then
      local t_now elapsed eta_seconds=0
      t_now=$(date +%s)
      elapsed=$(( t_now - t_start ))
      if (( bytes_done > 0 && elapsed > 0 )); then
        # shellcheck disable=SC2034  # remaining : réservé pour usage futur (affichage temps restant)
        local speed remaining
        speed=$(( bytes_done / elapsed ))
        if (( speed > 0 )); then
          eta_seconds=$(( (total_bytes - bytes_done) / speed ))
        else
          eta_seconds=0
        fi
      fi
      "$callback" "$i" "$total_files" "$bytes_done" "$total_bytes" "$eta_seconds"
    fi
  done
}

# == Vérification ===============================================================

# core_verify <fichier_b3>
#
# Contrat d'entrée :
#   $1 - chemin absolu vers un fichier .b3 valide (validé par core_assert_b3_valid)
#         Le répertoire de travail courant DOIT être celui depuis lequel compute
#         a été exécuté (les chemins dans .b3 sont relatifs à ce répertoire)
#
# Contrat de sortie :
#   exit 0  - tous les fichiers intègres
#   exit 1  - au moins un FAILED ou erreur b3sum
#   CORE_VERIFY_RAW        - sortie brute de b3sum --check
#   CORE_VERIFY_LINES_OK   - lignes "chemin: OK"
#   CORE_VERIFY_LINES_FAIL - lignes "chemin: FAILED"
#   CORE_VERIFY_LINES_ERR  - lignes d'erreur b3sum non liées aux hashes
#   CORE_VERIFY_NB_OK      - entier : nombre de fichiers OK
#   CORE_VERIFY_NB_FAIL    - entier : nombre de fichiers FAILED
#   CORE_VERIFY_STATUS     - "OK" | "ECHEC" | "ERREUR"
#
# Effets de bord :
#   - Positionne les variables CORE_VERIFY_* dans le scope de l'appelant
#     (les variables doivent être déclarées locales dans l'appelant si isolation requise)
core_verify() {
  local hashfile="$1"

  local raw exit_code
  raw=$(b3sum --check "$hashfile" 2>&1) && exit_code=0 || exit_code=$?

  # shellcheck disable=SC2034  # CORE_VERIFY_* : variables de sortie lues par l'appelant (integrity.sh)
  CORE_VERIFY_RAW="$raw"
  CORE_VERIFY_LINES_OK=$(echo    "$raw" | grep ': OK$'    || true)
  CORE_VERIFY_LINES_FAIL=$(echo  "$raw" | grep ': FAILED' || true)
  CORE_VERIFY_LINES_ERR=$(echo   "$raw" | grep -Ev ': (OK|FAILED)' | grep -v '^$' || true)

  if [ -n "$CORE_VERIFY_LINES_OK" ]; then
    CORE_VERIFY_NB_OK=$(echo "$CORE_VERIFY_LINES_OK" | grep -c '^')
  else
    CORE_VERIFY_NB_OK=0
  fi

  if [ -n "$CORE_VERIFY_LINES_FAIL" ]; then
    CORE_VERIFY_NB_FAIL=$(echo "$CORE_VERIFY_LINES_FAIL" | grep -c '^')
  else
    CORE_VERIFY_NB_FAIL=0
  fi

  if [ -n "$CORE_VERIFY_LINES_ERR" ]; then
    CORE_VERIFY_STATUS="ERREUR"
  elif (( CORE_VERIFY_NB_FAIL > 0 )); then
    CORE_VERIFY_STATUS="ECHEC"
  else
    CORE_VERIFY_STATUS="OK"
  fi

  return $exit_code
}

# == Comparaison ================================================================

# core_compare <ancienne_b3> <nouvelle_b3> <outdir>
#
# Contrat d'entrée :
#   $1 - chemin vers l'ancienne base .b3 (validée par core_assert_b3_valid)
#   $2 - chemin vers la nouvelle base .b3 (validée par core_assert_b3_valid)
#   $3 - dossier de sortie (doit exister avant l'appel)
#
# Contrat de sortie :
#   exit 0  - comparaison effectuée (même si des différences existent)
#   exit 1  - erreur technique (b3sum, awk, join, comm)
#   $3/modifies.b3   - fichiers présents dans les deux bases avec hashes différents
#                      Format : "<nouveau_hash>  <chemin>" (format b3sum)
#   $3/disparus.txt  - chemins présents dans $1, absents de $2 (un chemin par ligne)
#   $3/nouveaux.txt  - chemins absents de $1, présents dans $2 (un chemin par ligne)
#   CORE_COMPARE_NB_MOD  - entier : nombre de fichiers modifiés
#   CORE_COMPARE_NB_DIS  - entier : nombre de fichiers disparus
#   CORE_COMPARE_NB_NOU  - entier : nombre de nouveaux fichiers
#
# Algorithme :
#   1. Conversion "<hash>  <chemin>" → "<chemin>\t<hash>" via awk (offset fixe 64+2)
#      Robuste aux chemins avec espaces : le séparateur est le tab, pas l'espace
#   2. sort par chemin (clé 1 uniquement)
#   3. join inner sur le chemin → identifie les modifiés (hashes différents)
#   4. comm -23 / -13 sur les chemins → disparus et nouveaux
#
# Effets de bord :
#   - Écrit $3/modifies.b3, $3/disparus.txt, $3/nouveaux.txt
#   - Positionne CORE_COMPARE_NB_* dans le scope de l'appelant
#   - Utilise mktemp pour les fichiers temporaires (nettoyés via trap EXIT)
core_compare() {
  local old="$1"
  local new="$2"
  local outdir="$3"

  local tmp_old tmp_new
  tmp_old=$(mktemp)
  tmp_new=$(mktemp)

  trap 'rm -f "$tmp_old" "$tmp_new"' EXIT

  # Conversion vers format "chemin\thash" - offset fixe 64 chars pour le hash
  # Robuste aux espaces dans les chemins
  _b3_to_path_hash() {
    awk '{ print substr($0,67) "\t" substr($0,1,64) }' "$1" | sort -t $'\t' -k1,1
  }

  _b3_to_path_hash "$old" > "$tmp_old"
  _b3_to_path_hash "$new" > "$tmp_new"

  # Fichiers modifiés : présents dans les deux bases, hashes différents
  join -t $'\t' -1 1 -2 1 "$tmp_old" "$tmp_new" \
    | awk -F $'\t' '$2 != $3 { print $3 "  " $1 }' \
    > "${outdir}/modifies.b3"

  # Fichiers disparus : dans old, pas dans new
  comm -23 <(cut -f1 "$tmp_old") <(cut -f1 "$tmp_new") > "${outdir}/disparus.txt"

  # Nouveaux fichiers : dans new, pas dans old
  comm -13 <(cut -f1 "$tmp_old") <(cut -f1 "$tmp_new") > "${outdir}/nouveaux.txt"

  # shellcheck disable=SC2034  # CORE_COMPARE_NB_* : variables de sortie lues par l'appelant (integrity.sh)
  CORE_COMPARE_NB_MOD=$(wc -l < "${outdir}/modifies.b3")
  CORE_COMPARE_NB_DIS=$(wc -l < "${outdir}/disparus.txt")
  CORE_COMPARE_NB_NOU=$(wc -l < "${outdir}/nouveaux.txt")

  rm -f "$tmp_old" "$tmp_new"
  trap - EXIT
}

# == Gestion des dossiers de résultats ==========================================

# core_make_result_dir <fichier_b3> <resultats_dir>
#
# Contrat d'entrée :
#   $1 - chemin vers le fichier .b3 (utilisé pour nommer le dossier)
#   $2 - dossier racine des résultats (RESULTATS_DIR)
#
# Contrat de sortie :
#   stdout - chemin absolu du dossier de résultats créé
#   exit 0 - dossier créé avec succès
#   exit 1 - échec de création (permissions, chemin invalide)
#
# Invariant anti-écrasement :
#   Si "<resultats_dir>/resultats_<nom_base>" existe déjà, un suffixe horodaté
#   "_YYYYMMDD-HHMMSS" est ajouté. Aucun résultat existant n'est jamais écrasé.
core_make_result_dir() {
  local b3file="$1"
  local resultats_dir="$2"

  local basename_noext
  basename_noext=$(basename "$b3file" .b3)
  local outdir="${resultats_dir}/resultats_${basename_noext}"

  if [ -d "$outdir" ]; then
    outdir="${outdir}_$(date +%Y%m%d-%H%M%S)"
  fi

  mkdir -p "$outdir" || die "Impossible de créer le dossier de résultats : $outdir"
  echo "$outdir"
}

# == Sidecar file ===============================================================

# core_sidecar_write <b3_path> <data_dir> <comment> <version>
#
# Génère un fichier <b3_path>.meta.json contenant les métadonnées du compute.
#
# Contrat d'entrée :
#   $1 - chemin du fichier .b3 produit (utilisé pour nommer le sidecar)
#   $2 - dossier source ayant été haché
#   $3 - commentaire libre (peut être vide)
#   $4 - version de l'outil (ex. "integrity.sh v2.0.0" ou "hash-tool v2.0.0")
#
# Contrat de sortie :
#   exit 0  - sidecar créé : <b3_path>.meta.json
#   exit 1  - jq introuvable (silencieux : pas d'erreur fatale, compute reste valide)
#   stdout  - aucun
#
# Invariants :
#   - Le fichier .b3 doit exister avant l'appel (nb_files lu via wc -l)
#   - Si jq est absent, la fonction retourne silencieusement sans créer le sidecar
#   - Le sidecar n'écrase pas un éventuel sidecar existant : c'est un nouveau compute
#
# Effets de bord :
#   - Écrit <b3_path>.meta.json sur le disque
core_sidecar_write() {
  local b3_path="$1"
  local data_dir="$2"
  local comment="${3:-}"
  local version="${4:-integrity.sh}"
  local sidecar_path="${b3_path}.meta.json"

  # jq requis - absence non fatale
  command -v jq &>/dev/null || return 0

  local nb_files
  nb_files=$(wc -l < "$b3_path" 2>/dev/null || echo 0)

  jq -n \
    --arg version  "$version" \
    --arg date     "$(date -u +%Y-%m-%dT%H:%M:%SZ)" \
    --arg comment  "$comment" \
    --arg dir      "$data_dir" \
    --argjson nb   "$nb_files" \
    '{
      created_by: $version,
      date:       $date,
      comment:    $comment,
      parameters: {
        directory:  $dir,
        hash_algo:  "blake3",
        nb_files:   $nb
      }
    }' > "$sidecar_path"
}

# core_sidecar_read <b3_path>
#
# Affiche le contenu du sidecar associé à un fichier .b3 si celui-ci existe.
# Aucun effet si le sidecar est absent ou si jq est indisponible.
#
# Contrat d'entrée :
#   $1 - chemin du fichier .b3 (le sidecar est <b3_path>.meta.json)
#
# Contrat de sortie :
#   exit 0  - toujours
#   stdout  - contenu JSON formaté si sidecar présent ; rien sinon
#
# Effets de bord : aucun
core_sidecar_read() {
  local b3_path="$1"
  local sidecar_path="${b3_path}.meta.json"

  [ -f "$sidecar_path" ] || return 0

  echo "--- Métadonnées (sidecar) ---"
  if command -v jq &>/dev/null; then
    jq '.' "$sidecar_path" 2>/dev/null || cat "$sidecar_path"
  else
    cat "$sidecar_path"
  fi
  echo "-----------------------------"
}

--- Fichier : src/lib/report.sh ---
#!/usr/bin/env bash
# lib/report.sh - Génération des rapports de résultats
#
# Sourcé par integrity.sh. Ne pas exécuter directement.
#
# Fonctions exportées :
#   generate_compare_html  <old> <new> <nb_mod> <nb_dis> <nb_nou>
#                          <modifies.b3> <disparus.txt> <nouveaux.txt>
#                          <output.html>

# == Génération du rapport HTML pour compare ===================================
#
# Produit un fichier HTML autonome (CSS inline, pas de dépendance externe).
# Les listes de fichiers sont injectées depuis les fichiers texte produits
# par run_compare(). Le fichier est lisible hors ligne.
#
# Usage :
#   generate_compare_html \
#     "$old_b3" "$new_b3" \
#     "$nb_modifies" "$nb_disparus" "$nb_nouveaux" \
#     "$modifies_file" "$disparus_file" "$nouveaux_file" \
#     "$output_html"

generate_compare_html() {
  local old_b3="$1"
  local new_b3="$2"
  local nb_modifies="$3"
  local nb_disparus="$4"
  local nb_nouveaux="$5"
  local modifies_file="$6"
  local disparus_file="$7"
  local nouveaux_file="$8"
  local output_html="$9"

  local date_rapport
  date_rapport=$(date '+%Y-%m-%d %H:%M:%S')

  local nom_old nom_new
  nom_old=$(basename "$old_b3")
  nom_new=$(basename "$new_b3")

  # Statut global
  local statut statut_class
  if (( nb_modifies == 0 && nb_disparus == 0 && nb_nouveaux == 0 )); then
    statut="IDENTIQUES"
    statut_class="status-ok"
  else
    statut="DIFFÉRENCES DÉTECTÉES"
    statut_class="status-diff"
  fi

  # Lecture des listes de fichiers → HTML
  _render_file_list() {
    local file="$1"
    local empty_msg="$2"
    if [ ! -s "$file" ]; then
      echo "    <p class=\"empty\">$empty_msg</p>"
      return
    fi
    echo "    <ul>"
    while IFS= read -r line; do
      [ -n "$line" ] || continue
      # Pour modifies.b3 : "hash  chemin" → on affiche juste le chemin
      local display
      display=$(echo "$line" | awk '{ if (NF >= 2) { $1=""; print substr($0,2) } else { print $0 } }')
      echo "      <li><code>$(html_escape "$display")</code></li>"
    done < "$file"
    echo "    </ul>"
  }

  html_escape() {
    local s="$1"
    s="${s//&/&amp;}"
    s="${s//</&lt;}"
    s="${s//>/&gt;}"
    echo "$s"
  }

  local list_modifies list_disparus list_nouveaux
  list_modifies=$(_render_file_list "$modifies_file" "Aucun fichier modifié")
  list_disparus=$(_render_file_list "$disparus_file" "Aucun fichier disparu")
  list_nouveaux=$(_render_file_list "$nouveaux_file" "Aucun nouveau fichier")

  cat > "$output_html" <<HTML
<!DOCTYPE html>
<html lang="fr">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Rapport - ${nom_old} vs ${nom_new}</title>
  <style>
    /* == Tokens ==================================================== */
    :root {
      --bg:          #0f1117;
      --bg-card:     #161b27;
      --bg-card-alt: #1c2233;
      --border:      #252d3f;
      --border-glow: #2e3d5a;
      --text:        #c8d4e8;
      --text-dim:    #5a6a85;
      --text-head:   #e8eef8;
      --mono:        'JetBrains Mono', 'Fira Code', 'Cascadia Code', monospace;
      --sans:        'DM Sans', 'Outfit', system-ui, sans-serif;
      --accent-ok:   #22c55e;
      --accent-diff: #f59e0b;
      --accent-mod:  #e879f9;
      --accent-dis:  #f87171;
      --accent-nou:  #34d399;
      --radius:      8px;
      --radius-lg:   14px;
    }

    /* == Reset & base =============================================== */
    *, *::before, *::after { box-sizing: border-box; margin: 0; padding: 0; }

    @import url('https://fonts.googleapis.com/css2?family=DM+Sans:wght@300;400;500;600&family=JetBrains+Mono:wght@400;500&display=swap');

    body {
      background: var(--bg);
      color: var(--text);
      font-family: var(--sans);
      font-size: 14px;
      line-height: 1.6;
      min-height: 100vh;
      padding: 0 0 64px;
    }

    /* == Header ===================================================== */
    .header {
      background: var(--bg-card);
      border-bottom: 1px solid var(--border);
      padding: 28px 40px 24px;
      display: flex;
      align-items: flex-start;
      justify-content: space-between;
      gap: 24px;
    }

    .header-left h1 {
      font-family: var(--mono);
      font-size: 13px;
      font-weight: 500;
      color: var(--text-dim);
      letter-spacing: .08em;
      text-transform: uppercase;
      margin-bottom: 8px;
    }

    .bases-compare {
      display: flex;
      align-items: center;
      gap: 12px;
      flex-wrap: wrap;
    }

    .base-name {
      font-family: var(--mono);
      font-size: 14px;
      font-weight: 500;
      color: var(--text-head);
      background: var(--bg-card-alt);
      border: 1px solid var(--border-glow);
      border-radius: var(--radius);
      padding: 5px 12px;
    }

    .arrow {
      color: var(--text-dim);
      font-size: 16px;
    }

    .meta {
      font-size: 12px;
      color: var(--text-dim);
      margin-top: 10px;
      font-family: var(--mono);
    }

    /* == Status badge =============================================== */
    .status-badge {
      font-family: var(--mono);
      font-size: 11px;
      font-weight: 500;
      letter-spacing: .1em;
      text-transform: uppercase;
      padding: 6px 14px;
      border-radius: 100px;
      border: 1px solid;
      white-space: nowrap;
      align-self: flex-start;
      margin-top: 4px;
    }

    .status-ok   { color: var(--accent-ok);   border-color: var(--accent-ok);   background: rgba(34,197,94,.08);  }
    .status-diff { color: var(--accent-diff);  border-color: var(--accent-diff); background: rgba(245,158,11,.08); }

    /* == Stats bar ================================================== */
    .stats-bar {
      display: grid;
      grid-template-columns: repeat(3, 1fr);
      gap: 1px;
      background: var(--border);
      border-bottom: 1px solid var(--border);
    }

    .stat {
      background: var(--bg-card);
      padding: 20px 32px;
      display: flex;
      flex-direction: column;
      gap: 4px;
    }

    .stat-label {
      font-size: 11px;
      letter-spacing: .08em;
      text-transform: uppercase;
      color: var(--text-dim);
    }

    .stat-value {
      font-family: var(--mono);
      font-size: 28px;
      font-weight: 500;
      line-height: 1;
    }

    .stat-modifies .stat-value { color: var(--accent-mod); }
    .stat-disparus .stat-value { color: var(--accent-dis); }
    .stat-nouveaux .stat-value { color: var(--accent-nou); }

    /* == Sections =================================================== */
    .main {
      max-width: 1100px;
      margin: 0 auto;
      padding: 36px 40px 0;
      display: grid;
      gap: 20px;
    }

    .section {
      background: var(--bg-card);
      border: 1px solid var(--border);
      border-radius: var(--radius-lg);
      overflow: hidden;
    }

    .section-header {
      display: flex;
      align-items: center;
      gap: 10px;
      padding: 14px 20px;
      border-bottom: 1px solid var(--border);
    }

    .section-dot {
      width: 8px;
      height: 8px;
      border-radius: 50%;
      flex-shrink: 0;
    }

    .section-modifies .section-dot { background: var(--accent-mod); }
    .section-disparus .section-dot { background: var(--accent-dis); }
    .section-nouveaux .section-dot { background: var(--accent-nou); }

    .section-title {
      font-size: 12px;
      font-weight: 600;
      letter-spacing: .06em;
      text-transform: uppercase;
      color: var(--text-head);
    }

    .section-count {
      margin-left: auto;
      font-family: var(--mono);
      font-size: 12px;
      color: var(--text-dim);
      background: var(--bg-card-alt);
      border: 1px solid var(--border);
      border-radius: 100px;
      padding: 2px 10px;
    }

    .section-body {
      padding: 16px 20px;
    }

    .section-body ul {
      list-style: none;
      display: flex;
      flex-direction: column;
      gap: 4px;
    }

    .section-body li {
      padding: 6px 10px;
      border-radius: var(--radius);
      background: var(--bg-card-alt);
      border: 1px solid transparent;
      transition: border-color .15s;
    }

    .section-body li:hover {
      border-color: var(--border-glow);
    }

    .section-body code {
      font-family: var(--mono);
      font-size: 12px;
      color: var(--text);
      word-break: break-all;
    }

    .empty {
      font-style: italic;
      color: var(--text-dim);
      font-size: 13px;
      padding: 4px 0;
    }

    /* == Footer ===================================================== */
    .footer {
      text-align: center;
      padding-top: 40px;
      font-size: 11px;
      color: var(--text-dim);
      font-family: var(--mono);
    }

    @media (max-width: 680px) {
      .header        { padding: 20px; flex-direction: column; }
      .stats-bar     { grid-template-columns: 1fr; }
      .main          { padding: 20px; }
    }
  </style>
</head>
<body>

  <!-- == En-tête ======================================================== -->
  <header class="header">
    <div class="header-left">
      <h1>Rapport de comparaison - hash_tool</h1>
      <div class="bases-compare">
        <span class="base-name">$(html_escape "$nom_old")</span>
        <span class="arrow">→</span>
        <span class="base-name">$(html_escape "$nom_new")</span>
      </div>
      <div class="meta">Généré le ${date_rapport}</div>
    </div>
    <div class="status-badge ${statut_class}">${statut}</div>
  </header>

  <!-- == Compteurs ====================================================== -->
  <div class="stats-bar">
    <div class="stat stat-modifies">
      <span class="stat-label">Modifiés</span>
      <span class="stat-value">${nb_modifies}</span>
    </div>
    <div class="stat stat-disparus">
      <span class="stat-label">Disparus</span>
      <span class="stat-value">${nb_disparus}</span>
    </div>
    <div class="stat stat-nouveaux">
      <span class="stat-label">Nouveaux</span>
      <span class="stat-value">${nb_nouveaux}</span>
    </div>
  </div>

  <!-- == Listes ========================================================= -->
  <main class="main">

    <div class="section section-modifies">
      <div class="section-header">
        <div class="section-dot"></div>
        <span class="section-title">Fichiers modifiés</span>
        <span class="section-count">${nb_modifies}</span>
      </div>
      <div class="section-body">
${list_modifies}
      </div>
    </div>

    <div class="section section-disparus">
      <div class="section-header">
        <div class="section-dot"></div>
        <span class="section-title">Fichiers disparus</span>
        <span class="section-count">${nb_disparus}</span>
      </div>
      <div class="section-body">
${list_disparus}
      </div>
    </div>

    <div class="section section-nouveaux">
      <div class="section-header">
        <div class="section-dot"></div>
        <span class="section-title">Nouveaux fichiers</span>
        <span class="section-count">${nb_nouveaux}</span>
      </div>
      <div class="section-body">
${list_nouveaux}
      </div>
    </div>

  </main>

  <footer class="footer">
    integrity.sh · BLAKE3 · ${date_rapport}
  </footer>

</body>
</html>
HTML
}

--- Fichier : src/lib/results.sh ---
#!/usr/bin/env bash
# src/lib/results.sh - Écriture des fichiers de résultats texte
#
# Ce module produit les fichiers recap.txt et failed.txt à partir des
# données de sortie de core_verify() et core_compare().
# Il ne contient ni logique métier ni logique d'affichage terminal.
#
# Sourcé par src/integrity.sh. Ne pas exécuter directement.

# == Résultats de vérification ==================================================

# results_write_verify <outdir> <hashfile> <statut> <nb_ok> <nb_fail> <lines_fail> <lines_err>
#
# Contrat d'entrée :
#   $1 - dossier de sortie (doit exister)
#   $2 - chemin du fichier .b3 vérifié
#   $3 - statut : "OK" | "ECHEC" | "ERREUR"
#   $4 - nombre de fichiers OK
#   $5 - nombre de fichiers FAILED
#   $6 - lignes FAILED (chaîne multi-lignes, peut être vide)
#   $7 - lignes d'erreur b3sum (chaîne multi-lignes, peut être vide)
#
# Contrat de sortie :
#   exit 0
#   $1/recap.txt  - toujours créé
#   $1/failed.txt - créé si $5 > 0 ou $7 non vide ; supprimé sinon
#                   (suppression pour éviter un failed.txt obsolète d'un run précédent)
#
# Effets de bord : écrit sur le disque
results_write_verify() {
  local outdir="$1"
  local hashfile="$2"
  local statut="$3"
  local nb_ok="$4"
  local nb_fail="$5"
  local lines_fail="$6"
  local lines_err="$7"

  # recap.txt
  {
    echo "════════════════════════════════════════"
    echo "  STATUT : $statut"
    echo "════════════════════════════════════════"
    echo ""
    echo "Commande  : integrity.sh verify $(basename "$hashfile")"
    echo "Date      : $(date)"
    echo "Base      : $hashfile"
    echo ""
    echo "OK        : $nb_ok"
    if (( nb_fail > 0 )); then
      echo "FAILED    : $nb_fail  ← voir failed.txt"
    fi
    if [ -n "$lines_err" ]; then
      echo ""
      echo "== Erreurs b3sum ======================"
      echo "$lines_err"
    fi
  } > "${outdir}/recap.txt"

  # failed.txt
  if (( nb_fail > 0 )) || [ -n "$lines_err" ]; then
    {
      echo "════════════════════════════════════════"
      echo "  FICHIERS EN ECHEC"
      echo "════════════════════════════════════════"
      echo ""
      [ -n "$lines_fail" ] && echo "$lines_fail"
      if [ -n "$lines_err" ]; then
        echo ""
        echo "== Erreurs ============================"
        echo "$lines_err"
      fi
    } > "${outdir}/failed.txt"
  else
    rm -f "${outdir}/failed.txt"
  fi
}

# == Résultats de comparaison ===================================================

# results_write_compare <outdir> <old_b3> <new_b3> <nb_mod> <nb_dis> <nb_nou>
#
# Contrat d'entrée :
#   $1 - dossier de sortie (doit exister, contient déjà modifies.b3, disparus.txt, nouveaux.txt)
#   $2 - chemin de l'ancienne base .b3
#   $3 - chemin de la nouvelle base .b3
#   $4 - nombre de fichiers modifiés
#   $5 - nombre de fichiers disparus
#   $6 - nombre de nouveaux fichiers
#
# Contrat de sortie :
#   exit 0
#   $1/recap.txt - créé
#
# Effets de bord : écrit sur le disque
results_write_compare() {
  local outdir="$1"
  local old="$2"
  local new="$3"
  local nb_mod="$4"
  local nb_dis="$5"
  local nb_nou="$6"

  {
    echo "Commande      : integrity.sh compare $(basename "$old") $(basename "$new")"
    echo "Date          : $(date)"
    echo "Ancienne base : $old"
    echo "Nouvelle base : $new"
    echo ""
    echo "Modifiés      : $nb_mod"
    echo "Disparus      : $nb_dis"
    echo "Nouveaux      : $nb_nou"
  } > "${outdir}/recap.txt"
}


--- Fichier : src/lib/ui.sh ---
#!/usr/bin/env bash
# src/lib/ui.sh - Logique d'interface : affichage terminal, ETA, progression
#
# Ce module contient uniquement la logique de présentation et d'interaction
# avec l'utilisateur. Il ne contient aucune logique métier.
#
# Sourcé par src/integrity.sh. Ne pas exécuter directement.
#
# == Dépendances ================================================================
#   Aucune dépendance externe. Utilise uniquement les builtins bash et printf.
#
# == Prérequis ==================================================================
#   La variable QUIET doit être définie avant de sourcer ce module :
#     QUIET=0  - affichage normal
#     QUIET=1  - suppression de toute sortie terminal

# == Primitives de communication ================================================

# die <message>
#
# Contrat d'entrée :
#   $@ - message d'erreur (chaîne quelconque)
#
# Contrat de sortie :
#   exit 1 - toujours
#   stderr - "ERREUR : <message>"
#
# Effets de bord : termine le processus courant
die() {
  echo "ERREUR : $*" >&2
  exit 1
}

# say <message>
#
# Contrat d'entrée :
#   $@ - message à afficher (chaîne quelconque)
#
# Contrat de sortie :
#   stdout - <message> si QUIET == 0
#   (rien)  - si QUIET == 1
#
# Effets de bord : aucun
say() {
  (( QUIET )) || echo "$@"
}

# == Progression et ETA =========================================================

# ui_progress_callback <i> <total_files> <bytes_done> <total_bytes> <eta_seconds>
#
# Fonction de callback compatible avec core_compute().
# À passer comme troisième argument de core_compute si la progression est souhaitée.
#
# Contrat d'entrée :
#   $1 - index du fichier courant (entier, commence à 1)
#   $2 - nombre total de fichiers
#   $3 - octets traités jusqu'ici
#   $4 - octets totaux
#   $5 - ETA en secondes (0 si non calculable)
#
# Contrat de sortie :
#   /dev/tty - ligne de progression sur le terminal courant
#              Écrit sur /dev/tty et non sur stdout : garantit que la progression
#              ne peut pas être capturée dans un pipe ou dans le fichier .b3
#   (rien)   - si QUIET == 1
#
# Effets de bord : aucun (le \r efface la ligne précédente)
ui_progress_callback() {
  (( QUIET )) && return 0

  local i="$1"
  local total_files="$2"
  local bytes_done="$3"
  # shellcheck disable=SC2034  # total_bytes : reçu du callback mais non utilisé ici (réservé pour affichage %)
  local total_bytes="$4"
  local eta_seconds="$5"

  if (( bytes_done > 0 && eta_seconds > 0 )); then
    printf "\r[%d/%d] ETA : %dm %02ds   " \
      "$i" "$total_files" $(( eta_seconds / 60 )) $(( eta_seconds % 60 )) > /dev/tty
  elif (( bytes_done > 0 )); then
    printf "\r[%d/%d] calcul en cours...   " \
      "$i" "$total_files" > /dev/tty
  fi
}

# ui_progress_clear
#
# Efface la ligne de progression ETA du terminal.
# À appeler après core_compute pour laisser un terminal propre.
#
# Contrat de sortie :
#   /dev/tty - ligne vide (40 espaces + \r)
#   (rien)   - si QUIET == 1
ui_progress_clear() {
  (( QUIET )) && return 0
  printf "\r%*s\r" 40 "" > /dev/tty
}

# == Affichage des résultats de vérification ====================================

# ui_show_verify_result <statut> <nb_ok> <nb_fail> <lines_fail> <lines_err> <outdir>
#
# Contrat d'entrée :
#   $1 - statut : "OK" | "ECHEC" | "ERREUR"
#   $2 - nombre de fichiers OK (entier)
#   $3 - nombre de fichiers FAILED (entier)
#   $4 - lignes FAILED (chaîne multi-lignes, peut être vide)
#   $5 - lignes d'erreur b3sum (chaîne multi-lignes, peut être vide)
#   $6 - chemin du dossier de résultats
#
# Contrat de sortie :
#   stdout - résumé formaté si QUIET == 0
#   (rien)  - si QUIET == 1
#
# Effets de bord : aucun
ui_show_verify_result() {
  local statut="$1"
  local nb_ok="$2"
  local nb_fail="$3"
  local lines_fail="$4"
  local lines_err="$5"
  local outdir="$6"

  if [ "$statut" = "OK" ]; then
    say "Vérification OK - $nb_ok fichiers intègres."
  else
    say ""
    say "████████████████████████████████████████"
    if [ "$statut" = "ERREUR" ]; then
      say "  ERREUR lors de la vérification"
    else
      say "  ECHEC : $nb_fail fichier(s) corrompu(s) ou manquant(s)"
    fi
    say "████████████████████████████████████████"
    say ""
    [ -n "$lines_fail" ] && say "$lines_fail"
    [ -n "$lines_err"  ] && say "$lines_err"
    say ""
  fi

  say "Résultats dans : $outdir"
  say "  recap.txt"
  (( nb_fail > 0 )) || [ -n "$lines_err" ] && say "  failed.txt"
}

# ui_show_compare_result <nb_mod> <nb_dis> <nb_nou> <outdir>
#
# Contrat d'entrée :
#   $1 - nombre de fichiers modifiés
#   $2 - nombre de fichiers disparus
#   $3 - nombre de nouveaux fichiers
#   $4 - chemin du dossier de résultats
#
# Contrat de sortie :
#   stdout - résumé formaté si QUIET == 0
#   (rien)  - si QUIET == 1
#
# Effets de bord : aucun
ui_show_compare_result() {
  local nb_mod="$1"
  local nb_dis="$2"
  local nb_nou="$3"
  local outdir="$4"

  say "Résultats enregistrés dans : $outdir"
  say "  recap.txt     - modifiés: $nb_mod, disparus: $nb_dis, nouveaux: $nb_nou"
  say "  modifies.b3   - $nb_mod fichiers"
  say "  disparus.txt  - $nb_dis fichiers"
  say "  nouveaux.txt  - $nb_nou fichiers"
  say "  report.html   - rapport visuel"
}

--- Fichier : docker/entrypoint.sh ---
#!/usr/bin/env bash
# /entrypoint.sh - Point d'entrée Docker pour hash_tool
#
# Dispatche les commandes vers integrity.sh ou runner.sh.
# Toutes les commandes de integrity.sh sont supportées directement.
#
# Exemples :
#   docker run hash_tool help
#   docker run hash_tool compute /data /bases/hashes.b3
#   docker run hash_tool verify  /bases/hashes.b3
#   docker run hash_tool compare /bases/old.b3 /bases/new.b3
#   docker run hash_tool runner  /pipelines/pipeline.json
#   docker run hash_tool runner                              # lit /pipelines/pipeline.json
#   docker run -it hash_tool shell                           # bash interactif (debug)

set -euo pipefail

APP="/app"
INTEGRITY="$APP/src/integrity.sh"
RUNNER="$APP/runner.sh"

# == Aide =====================================================================

print_help() {
  cat <<'EOF'
hash_tool - Vérification d'intégrité BLAKE3

Usage :
  docker run [--rm] [-v ...] hash_tool <commande> [arguments...]

Commandes :
  compute <dossier> <base.b3>       Calcule les hashes d'un dossier
  verify  <base.b3> [dossier]       Vérifie l'intégrité
  compare <ancienne.b3> <nouvelle.b3>  Compare deux bases
  runner  [pipeline.json]           Exécute un pipeline (défaut : /pipelines/pipeline.json)
  shell                             Lance un shell bash interactif (debug)
  help                              Affiche cette aide

Options globales (à placer avant la commande) :
  --quiet                           Supprime la sortie terminal

Volumes conventionnels :
  /data        → données à hacher        (-v /mes/donnees:/data)
  /bases       → fichiers .b3            (-v /mes/bases:/bases)
  /pipelines   → fichiers pipeline.json  (-v /chemin/pipeline.json:/pipelines/pipeline.json)
  /resultats   → résultats               (-v /mes/resultats:/resultats)

Variable d'environnement :
  RESULTATS_DIR  Dossier de résultats (défaut dans le conteneur : /resultats)

Exemples :
  # Calculer les hashes de /data, stocker dans /bases
  docker run --rm \
    -v /mes/donnees:/data:ro \
    -v /mes/bases:/bases \
    hash_tool compute /data /bases/hashes_$(date +%Y-%m-%d).b3

  # Vérifier depuis le dossier d'origine
  docker run --rm \
    -v /mes/donnees:/data:ro \
    -v /mes/bases:/bases:ro \
    -v /mes/resultats:/resultats \
    hash_tool verify /bases/hashes_2024-01-15.b3 /data

  # Comparer deux snapshots
  docker run --rm \
    -v /mes/bases:/bases:ro \
    -v /mes/resultats:/resultats \
    hash_tool compare /bases/hashes_2024-01-15.b3 /bases/hashes_2024-02-01.b3

  # Pipeline complet depuis un fichier JSON
  docker run --rm \
    -v /mes/donnees:/data:ro \
    -v /mes/bases:/bases \
    -v /mes/resultats:/resultats \
    -v /chemin/vers/pipeline.json:/pipelines/pipeline.json:ro \
    hash_tool runner

  # Mode silencieux (CI/cron)
  docker run --rm \
    -v /mes/donnees:/data:ro \
    -v /mes/bases:/bases:ro \
    -v /mes/resultats:/resultats \
    hash_tool --quiet verify /bases/hashes.b3 /data

EOF
}

# == Vérification des outils ===================================================

check_deps() {
  local ok=1
  command -v b3sum &>/dev/null || { echo "ERREUR : b3sum introuvable" >&2; ok=0; }
  command -v jq    &>/dev/null || { echo "ERREUR : jq introuvable"    >&2; ok=0; }
  [ -f "$INTEGRITY" ]          || { echo "ERREUR : $INTEGRITY introuvable" >&2; ok=0; }
  [ -f "$RUNNER" ]             || { echo "ERREUR : $RUNNER introuvable"    >&2; ok=0; }
  (( ok )) || exit 1
}

# == Dispatch ==================================================================

# Extraire --quiet en tête s'il est présent
QUIET_FLAG=""
if [ "${1:-}" = "--quiet" ]; then
  QUIET_FLAG="--quiet"
  shift
fi

CMD="${1:-help}"
shift || true

case "$CMD" in

  compute|verify|compare)
    check_deps
    exec bash "$INTEGRITY" $QUIET_FLAG "$CMD" "$@"
    ;;

  runner)
    check_deps
    PIPELINE="${1:-/pipelines/pipeline.json}"
    if [ ! -f "$PIPELINE" ]; then
      echo "ERREUR : pipeline.json introuvable : $PIPELINE" >&2
      echo "Monter le fichier avec : -v /chemin/pipeline.json:/pipelines/pipeline.json" >&2
      exit 1
    fi
    exec bash "$RUNNER" "$PIPELINE"
    ;;

  shell|bash)
    echo "hash_tool - shell interactif (debug)"
    echo "  b3sum    : $(b3sum --version 2>/dev/null || echo 'non trouvé')"
    echo "  jq       : $(jq --version 2>/dev/null || echo 'non trouvé')"
    echo "  bash     : $BASH_VERSION"
    echo ""
    exec /bin/bash
    ;;

  help|--help|-h)
    print_help
    ;;

  version|--version|-v)
    echo "hash_tool"
    echo "  b3sum : $(b3sum --version 2>/dev/null || echo 'non trouvé')"
    echo "  jq    : $(jq --version 2>/dev/null || echo 'non trouvé')"
    echo "  bash  : $BASH_VERSION"
    ;;

  *)
    echo "ERREUR : commande inconnue : '$CMD'" >&2
    echo "Lancer 'docker run hash_tool help' pour la liste des commandes." >&2
    exit 1
    ;;

esac


--- Fichier : pipelines/pipeline-amelioree.json ---
{
  "pipeline": [
    {
      "type": "compute",
      "params": {
        "input":      "/mnt/data/dossier_exemple",
        "output_dir": "/mnt/bases",
        "filename":   "hashes_exemple.b3"
      },
      "options": {
        "quiet":    false,
        "verbose":  false,
        "readonly": true
      },
      "meta": {
        "comment": "Snapshot initial avant migration"
      },
      "description": "Calculer les empreintes du dossier source (lecture seule)"
    },
    {
      "type": "verify",
      "params": {
        "input": "/mnt/data/dossier_exemple",
        "base":  "/mnt/bases/hashes_exemple.b3"
      },
      "options": {
        "quiet": false
      },
      "description": "Vérifier l'intégrité immédiatement après compute"
    },
    {
      "type": "compute",
      "params": {
        "input":      "/mnt/data/dossier_exemple_v2",
        "output_dir": "/mnt/bases",
        "filename":   "hashes_exemple_v2.b3"
      },
      "options": {
        "quiet":    false,
        "readonly": true
      },
      "meta": {
        "comment": "Snapshot après migration"
      },
      "description": "Calculer les empreintes du dossier destination (post-migration)"
    },
    {
      "type": "compare",
      "params": {
        "reference":  "/mnt/bases/hashes_exemple.b3",
        "input":      "/mnt/bases/hashes_exemple_v2.b3",
        "output_dir": "/mnt/resultats/compare_migration"
      },
      "options": {
        "quiet": false
      },
      "description": "Comparer avant/après migration et produire le rapport HTML"
    },
    {
      "type": "list",
      "params": {
        "input_dir": "/mnt/bases"
      },
      "options": {},
      "description": "Lister les bases d'empreintes disponibles"
    },
    {
      "type": "diff",
      "params": {
        "input":         "/mnt/bases/hashes_exemple.b3",
        "reference_dir": "/mnt/data/dossier_exemple"
      },
      "options": {},
      "description": "Afficher les différences entre la base et le dossier"
    },
    {
      "type": "stats",
      "params": {
        "input": "/mnt/bases/hashes_exemple.b3"
      },
      "options": {},
      "description": "Afficher les statistiques de la base d'empreintes"
    },
    {
      "type": "check-env",
      "params": {},
      "options": {},
      "description": "Vérifier si l'exécution native ou Docker est possible"
    },
    {
      "type": "version",
      "params": {},
      "options": {},
      "description": "Afficher la version du logiciel"
    }
  ]
}


--- Fichier : pipelines/pipeline-debug-deux-adresses.json ---
{
    "pipeline": [

        {
            "op":     "compute",
            "source": "./mon_dossier/source",
            "bases":  "./mon_dossier/bases",
            "nom":    "hashes_dossier_1.b3"
        },

        {
            "op":     "compute",
            "source": "/home/me-dell/Bureau/destination",
            "bases":  "/home/me-dell/Bureau/dossier bureau/bases",
            "nom":    "hashes_dossier_2.b3"
        },

        {
            "op":       "compare",
            "base_a":   "./mon_dossier/bases/hashes_dossier_1.b3",
            "base_b":   "/home/me-dell/Bureau/dossier bureau/bases/bases/hashes_dossier_2.b3",
            "resultats": "./mon_dossier/result"
        }

    ]
}

--- Fichier : pipelines/pipeline-debug.json ---
{
    "pipeline": [

        {
            "op":     "compute",
            "source": "./mon_dossier/source",
            "bases":  "./mon_dossier/bases",
            "nom":    "hashes_dossier_1.b3"
        },

        {
            "op":     "compute",
            "source": "./mon_dossier/destination",
            "bases":  "./mon_dossier/bases",
            "nom":    "hashes_dossier_2.b3"
        },

        {
            "op":       "compare",
            "base_a":   "./mon_dossier/bases/hashes_dossier_1.b3",
            "base_b":   "./mon_dossier/bases/hashes_dossier_2.b3",
            "resultats": "./mon_dossier/result"
        }

    ]
}

--- Fichier : pipelines/pipeline-veracrypt.json ---
{
    "pipeline": [

        {
            "op":     "compute",
            "source": "/mnt/a/dossier_disque_1",
            "bases":  "/mnt/c/Users/TonNom/Desktop/bases",
            "nom":    "hashes_dossier_1.b3"
        },

        {
            "op":     "compute",
            "source": "/mnt/i/dossier_disque_2",
            "bases":  "/mnt/c/Users/TonNom/Desktop/bases",
            "nom":    "hashes_dossier_2.b3"
        },

        {
            "op":     "compute",
            "source": "/mnt/h/dossier_disque_3",
            "bases":  "/mnt/c/Users/TonNom/Desktop/bases",
            "nom":    "hashes_dossier_3.b3"
        },

        {
            "op":     "verify",
            "source": "/mnt/a/dossier_disque_1",
            "base":   "/mnt/c/Users/TonNom/Desktop/bases/hashes_dossier_1.b3"
        },

        {
            "op":       "compare",
            "base_a":   "/mnt/c/Users/TonNom/Desktop/bases/hashes_dossier_1.b3",
            "base_b":   "/mnt/c/Users/TonNom/Desktop/bases/hashes_dossier_2.b3",
            "resultats": "/mnt/c/Users/TonNom/Desktop/rapports/compare_1_vs_2"
        }

    ]
}

--- Fichier : pipelines/pipeline.json ---
{
    "pipeline": [

        {
            "op":     "compute",
            "source": "./mon_dossier/source",
            "bases":  "./mon_dossier/bases",
            "nom":    "hashes_dossier_1.b3"
        },

        {
            "op":     "compute",
            "source": "./mon_dossier/destination",
            "bases":  "./mon_dossier/bases",
            "nom":    "hashes_dossier_2.b3"
        },

        {
            "op":       "compare",
            "base_a":   "./mon_dossier/bases/hashes_dossier_1.b3",
            "base_b":   "./mon_dossier/bases/hashes_dossier_2.b3",
            "resultats": "./mon_dossier/result"
        }

    ]
}

--- Fichier : docs/getting-started.md ---
# Démarrage rapide

---

## Prérequis

| Dépendance | Usage | Installation |
|---|---|---|
| `bash >= 4` | Interpréteur shell | Linux natif ; macOS via `brew install bash` ; WSL |
| `b3sum` | Calcul des empreintes BLAKE3 | `apt install b3sum` / `brew install b3sum` |
| `jq` | Pipelines JSON + sidecar | `apt install jq` / `brew install jq` |
| `find`, `sort`, `awk`, `comm`, `join`, `stat`, `du` | Outils internes | GNU coreutils (natifs sur toute distribution) |

!!! note "macOS"
    `bash` est en version 3.x par défaut sur macOS. hash_tool requiert bash >= 4.
    ```bash
    brew install bash b3sum jq
    # Vérifier : /usr/local/bin/bash --version
    ```

!!! note "Docker (alternative)"
    Si les dépendances ne peuvent pas être installées sur l'hôte, `hash-tool` bascule automatiquement sur Docker. Voir [Démarrage rapide Docker](#docker-démarrage-rapide).

---

## Installation

```bash
git clone https://github.com/hash_tool/hash_tool.git
cd hash_tool
chmod +x hash-tool src/integrity.sh runner.sh
```

Aucune compilation, aucune dépendance système au-delà des outils listés ci-dessus.

### Rendre `hash-tool` accessible globalement (optionnel)

```bash
sudo ln -s "$(pwd)/hash-tool" /usr/local/bin/hash-tool
# Ou : ajouter le dossier hash_tool/ au PATH
```

---

## Environnements supportés

| Environnement | Méthode | Notes |
|---|---|---|
| Linux (Debian, Ubuntu, Alpine, Arch…) | Natif | Environnement de référence |
| macOS | Natif avec bash 4+ via Homebrew | `brew install bash b3sum jq` |
| Windows | Via WSL2 | Distributions Ubuntu ou Debian recommandées |
| NAS Synology | Via Docker (image arm64) | Voir [guide NAS](guides/nas-synology.md) |
| Serveur headless | Mode `-quiet` + cron | Voir [guide CI/Cron](guides/cron-ci.md) |

---

## Vérifier l'environnement

Avant toute utilisation, diagnostiquer l'environnement :

```bash
hash-tool check-env
```

Sortie attendue :

```
=== check-env : Analyse de l'environnement ===

  [OK] b3sum disponible : b3sum 1.5.4
  [OK] jq disponible : jq-1.7
  [OK] bash 5.2.15(1)-release
  [OK] integrity.sh présent et exécutable : /opt/hash_tool/src/integrity.sh
  [OK] runner.sh présent et exécutable : /opt/hash_tool/runner.sh
  [--] Docker non disponible (optionnel)

  Mode d'exécution sélectionné : native
  → Exécution native active
```

---

## Workflow typique

| Étape | Commande | Moment |
|---|---|---|
| 1. Indexer | `hash-tool compute -data ./dossier -save ./bases -meta "..."` | Données saines connues |
| 2. Vérifier | `hash-tool verify -base ./bases/hashes_dossier.b3` | Après transfert / stockage |
| 3. Comparer | `hash-tool compare -old avant.b3 -new apres.b3` | Entre deux états |
| 4. Inspecter | `hash-tool diff -base ./bases/hashes_dossier.b3 -data ./dossier` | Contrôle rapide (sans recalcul) |
| 5. Pipeline | `hash-tool runner -pipeline ./pipelines/pipeline-amelioree.json` | Automatisation multi-étapes |

### Exemple concret - archivage sur disque externe

```bash
# Disque monté sur /mnt/archive

# 1. Première indexation - données saines à J0
hash-tool compute \
  -data /mnt/archive \
  -save /mnt/c/bases \
  -meta "Snapshot initial archive 2024-01-15"

# 2. Vérification après chaque session - J+30, J+90, etc.
hash-tool verify \
  -base /mnt/c/bases/hashes_archive.b3 \
  -data /mnt/archive

# 3. Après ajout de fichiers - voir ce qui a changé sans recalculer
hash-tool diff \
  -base /mnt/c/bases/hashes_archive.b3 \
  -data /mnt/archive

# 4. Nouveau snapshot puis comparaison
hash-tool compute \
  -data /mnt/archive \
  -save /mnt/c/bases \
  -meta "Snapshot après ajout collection 2024-02-15"

hash-tool compare \
  -old /mnt/c/bases/hashes_archive_avant.b3 \
  -new /mnt/c/bases/hashes_archive_apres.b3 \
  -save /mnt/c/rapports
```

---

## Sidecar file - métadonnées associées aux bases

Chaque `compute` génère automatiquement un fichier `.meta.json` à côté du `.b3` :

```bash
hash-tool compute -data ./donnees -save ./bases -meta "Snapshot initial"
```

Produit :

```
./bases/
├── hashes_donnees.b3           ← empreintes BLAKE3
└── hashes_donnees.b3.meta.json ← métadonnées (date, commentaire, paramètres)
```

Contenu du sidecar :

```json
{
  "created_by": "hash-tool v2.0.0",
  "date": "2026-02-26T14:30:00Z",
  "comment": "Snapshot initial",
  "parameters": {
    "directory": "./donnees",
    "hash_algo": "blake3",
    "readonly": false,
    "nb_files": 1247
  }
}
```

Les commandes `verify`, `compare` et `stats` affichent automatiquement les métadonnées sidecar si le fichier est présent.

---

## Lire les résultats

Chaque opération `verify` ou `compare` produit un dossier horodaté dans `~/integrity_resultats/` :

```
~/integrity_resultats/
└── resultats_hashes_archive/
    ├── recap.txt      ← statut global, compteurs
    ├── failed.txt     ← fichiers en échec (si applicable)
    ├── modifies.b3    ← fichiers modifiés (compare uniquement)
    ├── disparus.txt   ← fichiers disparus (compare uniquement)
    ├── nouveaux.txt   ← nouveaux fichiers (compare uniquement)
    └── report.html    ← rapport visuel autonome
```

Ouvrir `report.html` directement dans un navigateur - aucune connexion requise, aucun serveur.

---

## Docker - démarrage rapide

Si les dépendances ne peuvent pas être installées sur l'hôte, `hash-tool` détecte Docker automatiquement et l'utilise en fallback :

```bash
# Build une fois
docker build -t hash_tool .

# Ensuite, hash-tool fonctionne identiquement
# (le mode d'exécution est sélectionné automatiquement)
hash-tool check-env   # affichera : Mode d'exécution : docker
```

Ou directement via Docker :

```bash
docker run --rm \
  -v /mes/donnees:/data:ro \
  -v /mes/bases:/bases \
  hash_tool compute /data /bases/hashes_$(date +%Y-%m-%d).b3
```

Voir la [référence Docker complète](reference/docker.md) pour les volumes, les environnements Synology, et les options Compose.

---

## Commandes disponibles

```
hash-tool compute     Calcule les empreintes d'un dossier.
hash-tool verify      Vérifie l'intégrité d'un dossier à partir d'une base.
hash-tool compare     Compare deux bases d'empreintes.
hash-tool runner      Exécute un pipeline JSON.
hash-tool list        Liste les bases d'empreintes disponibles.
hash-tool diff        Affiche les différences entre une base et un dossier.
hash-tool stats       Affiche des statistiques sur une base.
hash-tool check-env   Analyse l'environnement d'exécution.
hash-tool version     Affiche la version.
hash-tool help        Affiche l'aide (ou 'help <commande>' pour le détail).
```

Aide détaillée par commande :

```bash
hash-tool help compute
hash-tool help verify
hash-tool help runner
# etc.
```

--- Fichier : docs/index.md ---
# hash_tool

hash_tool détecte la corruption silencieuse de fichiers en comparant des empreintes BLAKE3 prises à des instants différents. Il fonctionne depuis une interface CLI unique, ne requiert aucune installation complexe, et produit un rapport HTML lisible sans outil supplémentaire.

---

## Principe

`hash-tool` est l'interface CLI unique. Il détecte automatiquement si l'exécution native est possible (`b3sum` disponible), sinon délègue à Docker - sans que l'utilisateur ait à s'en préoccuper. En interne, `src/integrity.sh` calcule les empreintes et `runner.sh` orchestre les pipelines.

```
┌=============┐    compute     ┌==============┐    ┌==================┐
│  Dossier    │ =============► │  base.b3     │    │  base.b3         │
│  de données │                │  (hashes)    │    │  .meta.json      │ ← sidecar
└=============┘                └==============┘    └==================┘
                                      │
                     verify / compare │
                                      ▼
                               ┌==============┐
                               │  recap.txt   │
                               │  failed.txt  │
                               │  report.html │
                               └==============┘
```

---

## Cas d'usage

- **Archivage long terme** - vérifier qu'un disque n'a pas développé de secteurs défectueux
- **Transfert de données** - confirmer qu'une copie est bit-à-bit identique à la source
- **VeraCrypt** - indexer des partitions chiffrées avant démontage, vérifier après remontage
- **Monitoring périodique** - cron hebdomadaire sur un NAS ou serveur
- **Automatisation CI/CD** - mode `--quiet`, exit code propagé, image Docker légère

---

## Démarrage rapide

=== "CLI unique (recommandé)"

    ```bash
    # 1. Indexer un dossier
    hash-tool compute -data ./mon_dossier -save ./bases -meta "Snapshot initial"

    # 2. Vérifier l'intégrité
    hash-tool verify -base ./bases/hashes_mon_dossier.b3

    # 3. Comparer deux snapshots
    hash-tool compare -old snap1.b3 -new snap2.b3 -save ./rapports

    # 4. Vérifier l'environnement
    hash-tool check-env
    ```

=== "Pipeline JSON"

    ```bash
    # Éditer pipelines/pipeline-amelioree.json, puis :
    hash-tool runner -pipeline ./pipelines/pipeline-amelioree.json
    ```

=== "Docker"

    ```bash
    docker run --rm \
      -v /mes/donnees:/data:ro \
      -v /mes/bases:/bases \
      hash_tool compute /data /bases/hashes_$(date +%Y-%m-%d).b3
    ```

=== "Mode --quiet (CI/cron)"

    ```bash
    # Hook pre-commit git
    hash-tool verify -base base.b3 -quiet || { echo "Corruption détectée"; exit 1; }

    # Monitoring cron
    0 3 * * * hash-tool verify -base /data/base.b3 -quiet || mail -s "ALERT" admin@example.com
    ```

---

## Arbre de décision

| Situation | Commande |
|---|---|
| Première indexation | `hash-tool compute` |
| Vérifier après transfert / stockage | `hash-tool verify` |
| Comparer deux snapshots | `hash-tool compare` |
| Lister les bases disponibles | `hash-tool list` |
| Voir les fichiers nouveaux/disparus sans recalculer | `hash-tool diff` |
| Statistiques sur une base | `hash-tool stats` |
| Pipeline multi-étapes / VeraCrypt | `hash-tool runner` |
| Diagnostic de l'environnement | `hash-tool check-env` |
| Contrôle ad hoc d'un fichier unique | `b3sum fichier.bin` |

---

## Configuration

`RESULTATS_DIR` définit le dossier racine des résultats (défaut : `~/integrity_resultats`).
Peut être surchargé par variable d'environnement ou via l'option `-save`.

---

## Règles d'utilisation critiques

- **Chemins relatifs** dans les bases `.b3`. `runner.sh` gère le `cd` automatiquement.
- **Répertoire de travail** : lancer `verify` depuis le même répertoire qu'au `compute`, ou passer `-data <dossier>`.
- **Stockage séparé** : stocker les `.b3` sur un support distinct des données.
- **Nommage daté** : `hashes_2024-01-15.b3`, jamais `hashes_latest.b3`.
- **Sidecar** : le fichier `.meta.json` associé à chaque `.b3` est optionnel mais recommandé pour la traçabilité.

---

## Docker

Aucune dépendance à installer sur l'hôte. Fonctionne sur Windows, NAS Synology, serveur Debian.

```bash
# Build
docker build -t hash_tool .

# Compute
docker run --rm -v /mes/donnees:/data:ro -v /mes/bases:/bases \
  hash_tool compute /data /bases/hashes_$(date +%Y-%m-%d).b3

# Verify
docker run --rm -v /mes/donnees:/data:ro -v /mes/bases:/bases:ro \
  -v /mes/resultats:/resultats \
  hash_tool verify /bases/hashes.b3 /data

# Pipeline complet
docker run --rm \
  -v /mes/donnees:/data:ro -v /mes/bases:/bases \
  -v /mes/resultats:/resultats \
  -v /chemin/pipeline.json:/pipelines/pipeline.json:ro \
  hash_tool runner
```

Voir [docs/reference/docker.md](reference/docker.md) pour la documentation complète.

---

## Tests

```bash
# Tests integrity.sh (T00–T14)
cd tests && ./run_tests.sh

# Tests runner.sh + pipeline.json (TP01–TP12b)
cd tests && ./run_tests_pipeline.sh

# ShellCheck (inclus dans T00, requiert installation séparée)
apt install shellcheck
```

---

## Structure du projet

```
hash_tool/
├── hash-tool                  ← CLI unique (point d'entrée utilisateur)
├── src/
│   ├── integrity.sh           ← dispatcher CLI (compute, verify, compare)
│   └── lib/
│       ├── core.sh            ← logique métier (hachage, vérification, comparaison)
│       ├── ui.sh              ← interface terminal (affichage, ETA, progression)
│       ├── results.sh         ← écriture fichiers de résultats
│       └── report.sh          ← génération HTML
├── runner.sh                  ← orchestrateur pipeline (formats legacy + étendu)
├── pipelines/
│   ├── pipeline.json              ← pipeline legacy simple
│   ├── pipeline-amelioree.json    ← pipeline format étendu (toutes les commandes)
│   ├── pipeline-veracrypt.json    ← pipeline VeraCrypt multi-disques
│   └── pipeline-debug.json        ← pipeline de test local
├── reports/
│   └── template.html          ← template HTML de référence
├── docs/
│   ├── spec/                  ← spécifications formelles
│   ├── reference/             ← référence des commandes
│   ├── guides/                ← guides utilisateur
│   └── development/           ← documentation développeur
└── tests/
    ├── run_tests.sh           ← T00–T14
    └── run_tests_pipeline.sh  ← TP01–TP12b
```

---

## Dépendances

| Outil | Requis par | Installation |
|---|---|---|
| `bash >= 4` | `hash-tool`, `integrity.sh`, `runner.sh` | Natif Linux ; macOS via `brew install bash` |
| `b3sum` | `integrity.sh` | `apt install b3sum` / `brew install b3sum` |
| `jq` | `hash-tool`, `runner.sh` | `apt install jq` / `brew install jq` |
| `find`, `sort`, `awk`, `comm`, `join`, `stat`, `du` | `integrity.sh` | GNU coreutils (natifs) |
| `docker` (optionnel) | `hash-tool` (fallback) | Uniquement si b3sum non disponible |

!!! note "macOS"
    `bash` est en version 3.x par défaut sur macOS. Installer bash 5 via Homebrew : `brew install bash`.

--- Fichier : docs/troubleshooting /troubleshooting_1.md ---

# troubleshooting 1 : titre

## Commande 

bash ./runner.sh ./pipelines/pipeline-debug.json

## Message d'erreur 

=== PIPELINE DÉMARRÉ : mar. 24 févr. 2026 13:22:40 CET ===
=== Config : ./pipelines/pipeline-debug.json (3 opération(s)) ===

=== COMPUTE : ./mon_dossier/source ===
./runner.sh: ligne 70: /media/veracrypt1/partition_laptop/divers/config ordinateur/2 en cours -- 2025-00-00 -- backup/d11 installation/hash_tool/src/integrity.sh: Permission non accordée

## Solution 

chmod +x ./src/integrity.sh ./src/lib/*.sh

## Explication 

à écrire 


--- Fichier : docs/spec/api-interne.md ---
# API interne - Contrats des modules

**Scope :** développeurs contribuant au code de hash_tool  
**Référence d'implémentation :** `src/lib/core.sh`, `src/lib/ui.sh`, `src/lib/results.sh`, `src/lib/report.sh`

---

## Architecture des modules

```
integrity.sh  (dispatcher CLI)
    │
    ├== src/lib/core.sh      Logique métier pure
    │   Entrées : chemins, fichiers .b3
    │   Sorties : fichiers .b3, variables CORE_*, fichiers de résultats partiels
    │   Aucune sortie terminal directe
    │
    ├== src/lib/ui.sh        Interface terminal
    │   Entrées : données structurées issues de core.*
    │   Sorties : stdout / /dev/tty
    │   Aucune logique métier
    │
    ├== src/lib/results.sh   Écriture fichiers de résultats
    │   Entrées : données structurées + chemin outdir
    │   Sorties : recap.txt, failed.txt sur disque
    │   Aucune sortie terminal directe
    │
    └== src/lib/report.sh    Génération HTML
        Entrées : données structurées + fichiers de listes + chemin output
        Sorties : report.html sur disque
        Aucune sortie terminal directe
```

**Principe de séparation strict :** `core.sh` ne connaît pas `ui.sh`. `ui.sh` ne connaît pas `results.sh`. `integrity.sh` est le seul module qui orchestre l'ensemble.

---

## Module `core.sh`

### `core_assert_b3_valid(file, [label])`

| | |
|---|---|
| **Entrée** | `$1` chemin fichier .b3 ; `$2` label optionnel pour les messages |
| **Sortie** | exit 0 si valide ; exit 1 + message stderr sinon |
| **Effets** | aucun |
| **Invariants vérifiés** | existence, type fichier régulier, non vide, toutes les lignes au format `[0-9a-f]{64}  .+` |

### `core_assert_target_valid(dir)`

| | |
|---|---|
| **Entrée** | `$1` chemin dossier |
| **Sortie** | exit 0 si valide ; exit 1 + message stderr sinon |
| **Effets** | aucun |
| **Invariants vérifiés** | existence, type dossier, contient au moins un fichier régulier |

### `core_compute(target, hashfile, [callback])`

| | |
|---|---|
| **Entrée** | `$1` dossier cible ; `$2` fichier .b3 de sortie ; `$3` nom de fonction callback (optionnel) |
| **Sortie** | exit 0/1 ; `$2` contient le fichier .b3 |
| **Effets** | crée/écrase `$2` ; appelle `$3` après chaque fichier |
| **Signature callback** | `callback(i, total_files, bytes_done, total_bytes, eta_seconds)` |
| **Garantie** | aucune ligne de progression ne peut polluer `$2` |

### `core_verify(hashfile)`

| | |
|---|---|
| **Entrée** | `$1` chemin absolu du fichier .b3 ; répertoire courant = répertoire d'origine du compute |
| **Sortie** | exit 0 si OK ; exit 1 si FAILED/ERREUR |
| **Variables positionnées** | `CORE_VERIFY_RAW`, `CORE_VERIFY_LINES_OK`, `CORE_VERIFY_LINES_FAIL`, `CORE_VERIFY_LINES_ERR`, `CORE_VERIFY_NB_OK`, `CORE_VERIFY_NB_FAIL`, `CORE_VERIFY_STATUS` |
| **Effets** | aucun (pas d'écriture disque) |

### `core_compare(old, new, outdir)`

| | |
|---|---|
| **Entrée** | `$1` ancienne base .b3 ; `$2` nouvelle base .b3 ; `$3` dossier de sortie (doit exister) |
| **Sortie** | exit 0/1 |
| **Fichiers produits** | `$3/modifies.b3`, `$3/disparus.txt`, `$3/nouveaux.txt` |
| **Variables positionnées** | `CORE_COMPARE_NB_MOD`, `CORE_COMPARE_NB_DIS`, `CORE_COMPARE_NB_NOU` |
| **Effets** | écrit 3 fichiers dans `$3` ; utilise mktemp nettoyé via trap |

### `core_make_result_dir(b3file, resultats_dir)`

| | |
|---|---|
| **Entrée** | `$1` chemin .b3 (pour nommer le dossier) ; `$2` dossier racine des résultats |
| **Sortie** | stdout = chemin absolu du dossier créé |
| **Effets** | crée le dossier via mkdir -p |
| **Invariant anti-écrasement** | si le dossier existe, ajoute `_YYYYMMDD-HHMMSS` |

---

## Module `ui.sh`

### Prérequis

La variable `QUIET` doit être définie avant de sourcer `ui.sh` :
- `QUIET=0` - affichage normal
- `QUIET=1` - suppression totale de la sortie terminal

### `die(message)`

| | |
|---|---|
| **Entrée** | `$@` message |
| **Sortie** | exit 1 toujours ; stderr = "ERREUR : <message>" |
| **Note** | fonction globale utilisable depuis tous les modules |

### `say(message)`

| | |
|---|---|
| **Entrée** | `$@` message |
| **Sortie** | stdout si QUIET==0 ; rien si QUIET==1 |

### `ui_progress_callback(i, total_files, bytes_done, total_bytes, eta_seconds)`

| | |
|---|---|
| **Sortie** | `/dev/tty` si QUIET==0 ; rien si QUIET==1 |
| **Note** | écriture sur `/dev/tty` et non stdout - ne peut pas polluer les pipes |

### `ui_progress_clear()`

| | |
|---|---|
| **Sortie** | `/dev/tty` - efface la ligne de progression |

### `ui_show_verify_result(statut, nb_ok, nb_fail, lines_fail, lines_err, outdir)`

| | |
|---|---|
| **Sortie** | stdout si QUIET==0 |

### `ui_show_compare_result(nb_mod, nb_dis, nb_nou, outdir)`

| | |
|---|---|
| **Sortie** | stdout si QUIET==0 |

---

## Module `results.sh`

### `results_write_verify(outdir, hashfile, statut, nb_ok, nb_fail, lines_fail, lines_err)`

| | |
|---|---|
| **Sortie** | `outdir/recap.txt` toujours ; `outdir/failed.txt` si erreurs ; supprime `failed.txt` si OK |

### `results_write_compare(outdir, old, new, nb_mod, nb_dis, nb_nou)`

| | |
|---|---|
| **Sortie** | `outdir/recap.txt` |
| **Prérequis** | `outdir` contient déjà `modifies.b3`, `disparus.txt`, `nouveaux.txt` produits par `core_compare` |

---

## Règles de contribution au code

1. **Aucune sortie terminal dans `core.sh`** - toute communication utilisateur passe par les variables de sortie et les codes de retour
2. **Aucune logique métier dans `ui.sh`** - `ui.sh` formate et affiche, il ne calcule rien
3. **Tout chemin dans un .b3 est relatif** - `core_compute` ne vérifie pas cet invariant (responsabilité de l'appelant via `runner.sh` ou appel direct avec `cd`)
4. **Variables `CORE_*` déclarées `local` dans les appelants** si isolation requise entre appels successifs
5. **`die()` est disponible globalement** - sourcé via `ui.sh` qui est chargé en premier dans `integrity.sh`


--- Fichier : docs/spec/b3-format.md ---
# Spécification formelle du format `.b3`

**Version :** 1.0  
**Statut :** Référence normative  
**Scope :** tout code lisant ou écrivant des fichiers `.b3` dans hash_tool

---

## 1. Définition

Un fichier `.b3` est un fichier texte encodé en UTF-8 contenant une empreinte BLAKE3 par fichier indexé. Son format est celui natif produit par `b3sum` version ≥ 1.3.

---

## 2. Grammaire formelle

```
b3file     ::= line* EOF
line       ::= hash SEP path LF
hash       ::= [0-9a-f]{64}
SEP        ::= "  "          (deux espaces U+0020)
path       ::= <chemin de fichier>
LF         ::= U+000A
EOF        ::= fin de fichier
```

### 2.1 Contraintes sur `hash`

- Exactement 64 caractères hexadécimaux minuscules (`[0-9a-f]`)
- Représentation de l'empreinte BLAKE3 256 bits en notation hexadécimale

### 2.2 Contraintes sur `SEP`

- Exactement deux espaces ASCII (U+0020)
- Aucun autre séparateur n'est valide (tabulation, espace unique, etc.)
- Ce format est identique à celui de `sha256sum`, `sha512sum` et `md5sum` - interopérabilité outil garantie

### 2.3 Contraintes sur `path`

- Chemin **relatif** obligatoire - voir section 3
- Encodé en UTF-8 ; les noms non UTF-8 sont traités comme des séquences d'octets opaques
- Un chemin contenant des espaces est valide (les espaces font partie du chemin, pas du séparateur)
- Le chemin inclut le préfixe `./` si `b3sum` a été appelé avec un argument commençant par `./`

### 2.4 Contraintes sur le fichier

- Trié par chemin (ordre lexicographique binaire, LC_ALL=C) - requis pour que `diff`, `join` et `comm` produisent des résultats déterministes
- Une ligne par fichier régulier - les dossiers vides ne génèrent pas de ligne
- Pas de ligne vide, pas de commentaire, pas de ligne d'en-tête
- Pas de retour chariot (U+000D) - fichier au format Unix uniquement

---

## 3. Invariant des chemins relatifs

**Règle absolue : les chemins dans un fichier `.b3` sont toujours relatifs.**

### Rationale

Un chemin absolu `/mnt/veracrypt1/photos/img.jpg` devient invalide si la partition est remontée sur `/mnt/veracrypt2/` ou déplacée. Un chemin relatif `./photos/img.jpg` reste valide quel que soit le point de montage, à condition de lancer `verify` depuis le même répertoire de travail qu'au `compute`.

### Conséquence opérationnelle

- `b3sum --check base.b3` doit être exécuté depuis le répertoire où `compute` a été lancé
- `runner.sh` gère ce `cd` automatiquement via des sous-shells isolés

### Cas de non-conformité

Un fichier `.b3` contenant des chemins absolus est techniquement lisible par `b3sum --check` mais est considéré **non conforme** au sens de cette spécification. `integrity.sh verify` refusera un tel fichier avec un avertissement.

---

## 4. Exemple conforme

```
a1b2c3d4e5f6a7b8c9d0e1f2a3b4c5d6e7f8a9b0c1d2e3f4a5b6c7d8e9f0a1b2  ./dossier/fichier.txt
e5f6a7b8c9d0e1f2a3b4c5d6e7f8a9b0c1d2e3f4a5b6c7d8e9f0a1b2c3d4e5f6  ./dossier/sous/autre.bin
f0a1b2c3d4e5f6a7b8c9d0e1f2a3b4c5d6e7f8a9b0c1d2e3f4a5b6c7d8e9f0a1  ./fichier avec espaces.pdf
```

---

## 5. Règles de nommage des fichiers `.b3`

Ces règles ne sont pas normatives mais fortement recommandées :

- Nom daté : `hashes_YYYY-MM-DD.b3` ou `hashes_<label>_YYYY-MM-DD.b3`
- Ne jamais utiliser `hashes_latest.b3` - un nom non daté ne permet pas de situer la base dans le temps
- Stocker sur un support distinct des données vérifiées (voir guide VeraCrypt)

---

## 6. Taille indicative

| Nombre de fichiers | Taille approximative |
|---|---|
| 1 000 | ~200 Ko |
| 10 000 | ~2 Mo |
| 100 000 | ~20 Mo |
| 1 000 000 | ~200 Mo |

Calcul : 64 (hash) + 2 (séparateur) + longueur_moyenne_chemin + 1 (LF) ≈ 80–100 octets par ligne.

---

## 7. Validation programmatique

Expression régulière de validation d'une ligne :

```
^[0-9a-f]{64}  .+$
```

Validation utilisée par `core_assert_b3_valid()` dans `src/lib/core.sh` :

```bash
valid_lines=$(grep -c -E '^[0-9a-f]{64}  .+' "$file" || true)
total_lines=$(wc -l < "$file")
# Un fichier est valide si valid_lines == total_lines && valid_lines > 0
```

---

## 8. Interopérabilité

Le format est directement compatible avec les outils suivants sans conversion :

| Outil | Commande |
|---|---|
| `b3sum` | `b3sum --check base.b3` |
| `grep` | `grep FAILED < <(b3sum --check base.b3)` |
| `sort` | `sort base.b3` (tri stable, déterministe) |
| `diff` | `diff base_a.b3 base_b.b3` |
| `wc` | `wc -l base.b3` → nombre de fichiers indexés |


--- Fichier : docs/development/architecture.md ---
#!/usr/bin/env bash
# integrity.sh - Vérification d'intégrité par hachage BLAKE3
#
# Point d'entrée CLI interne. Orchestre les modules :
#   src/lib/core.sh    - logique métier (hachage, vérification, comparaison, sidecar)
#   src/lib/ui.sh      - interface terminal (affichage, ETA, progression)
#   src/lib/results.sh - écriture des fichiers de résultats
#   src/lib/report.sh  - génération des rapports HTML
#
# Usage :
#   ./integrity.sh [--quiet] compute <dossier> <base.b3> [commentaire_sidecar]
#   ./integrity.sh [--quiet] verify  <base.b3> [dossier]
#   ./integrity.sh [--quiet] compare <ancienne.b3> <nouvelle.b3>
#
# Options :
#   --quiet   Supprime toute sortie terminal. Écrit uniquement dans les
#             fichiers de résultats. Exit code propagé sans modification.
#
# Sidecar :
#   compute génère automatiquement <base.b3>.meta.json si jq est disponible.
#   Le troisième argument optionnel de compute est un commentaire libre.
#   verify et compare affichent le sidecar si présent (sauf --quiet).
#
# Dépendances : b3sum, bash >= 4, find, sort, awk, comm, join, stat, du, mktemp
#               jq (optionnel - requis pour la génération du sidecar)
#
# Exit codes :
#   0 - succès (voir contrat de chaque mode dans src/lib/core.sh)
#   1 - erreur (argument manquant, fichier introuvable, corruption détectée)

set -euo pipefail

# == Version ====================================================================

INTEGRITY_VERSION="2.0.0"

# == Prérequis bash =============================================================

(( BASH_VERSINFO[0] >= 4 )) || {
  echo "ERREUR : bash >= 4 requis (actuel : $BASH_VERSION)" >&2
  exit 1
}

# == Résolution des chemins =====================================================

SCRIPT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"

# == Chargement des modules =====================================================

for _module in ui core results report; do
  _path="$SCRIPT_DIR/lib/${_module}.sh"
  [ -f "$_path" ] || { echo "ERREUR : module introuvable : $_path" >&2; exit 1; }
  # shellcheck source=/dev/null
  source "$_path"
done
unset _module _path

# == Parsing des arguments ======================================================

QUIET=0
ARGS=()

for arg in "$@"; do
  case "$arg" in
    --quiet) QUIET=1 ;;
    *)       ARGS+=("$arg") ;;
  esac
done

MODE="${ARGS[0]:-}"
ARG2="${ARGS[1]:-}"
ARG3="${ARGS[2]:-}"
ARG4="${ARGS[3]:-}"   # commentaire sidecar optionnel pour compute

# == Configuration ==============================================================

# Dossier racine des résultats. Peut être surchargé par variable d'environnement.
# runner.sh surcharge cette valeur via export pour isoler les runs de pipeline.
RESULTATS_DIR="${RESULTATS_DIR:-${HOME}/integrity_resultats}"

# == Handlers des modes =========================================================

_run_compute() {
  local target="$ARG2"
  local hashfile="$ARG3"
  local sidecar_comment="${ARG4:-}"

  [ -n "$target"   ] || die "compute : dossier cible manquant.\nUsage : $0 compute <dossier> <base.b3> [commentaire]"
  [ -n "$hashfile" ] || die "compute : fichier de sortie .b3 manquant.\nUsage : $0 compute <dossier> <base.b3> [commentaire]"
  [ ! -d "$hashfile" ] || die "compute : '$hashfile' est un dossier. Le fichier .b3 de sortie doit être un chemin de fichier."

  core_assert_target_valid "$target"

  # Utilise ui_progress_callback uniquement si QUIET == 0
  local callback=""
  (( QUIET )) || callback="ui_progress_callback"

  core_compute "$target" "$hashfile" "$callback"
  ui_progress_clear

  say "Base enregistrée : $hashfile ($(wc -l < "$hashfile") fichiers)"

  # Sidecar : généré si jq est disponible
  if command -v jq &>/dev/null; then
    core_sidecar_write "$hashfile" "$target" "$sidecar_comment" "$INTEGRITY_VERSION"
    say "Sidecar : ${hashfile}.meta.json"
  fi
}

_run_verify() {
  local b3file="$ARG2"
  local workdir="${ARG3:-}"

  [ -n "$b3file" ] || die "verify : fichier .b3 manquant.\nUsage : $0 verify <base.b3> [dossier]"

  core_assert_b3_valid "$b3file" "base"

  # Résolution du chemin absolu AVANT le cd : un chemin relatif deviendrait
  # invalide après changement de répertoire
  local hashfile_abs
  hashfile_abs="$(cd "$(dirname "$b3file")" && pwd)/$(basename "$b3file")"

  # Affichage du sidecar avant le cd (chemin encore valide)
  (( QUIET )) || core_sidecar_read "$hashfile_abs"

  if [ -n "$workdir" ]; then
    [ -d "$workdir" ] || die "verify : '$workdir' n'est pas un dossier valide."
    cd "$workdir"
  fi

  local outdir
  outdir=$(core_make_result_dir "$hashfile_abs" "$RESULTATS_DIR")

  # core_verify positionne les variables CORE_VERIFY_* dans le scope courant
  local exit_code=0
  core_verify "$hashfile_abs" || exit_code=$?

  results_write_verify \
    "$outdir" "$hashfile_abs" \
    "$CORE_VERIFY_STATUS" "$CORE_VERIFY_NB_OK" "$CORE_VERIFY_NB_FAIL" \
    "$CORE_VERIFY_LINES_FAIL" "$CORE_VERIFY_LINES_ERR"

  ui_show_verify_result \
    "$CORE_VERIFY_STATUS" "$CORE_VERIFY_NB_OK" "$CORE_VERIFY_NB_FAIL" \
    "$CORE_VERIFY_LINES_FAIL" "$CORE_VERIFY_LINES_ERR" \
    "$outdir"

  return $exit_code
}

_run_compare() {
  local old="$ARG2"
  local new="$ARG3"

  [ -n "$old" ] || die "compare : fichier ancienne base manquant.\nUsage : $0 compare <ancienne.b3> <nouvelle.b3>"
  [ -n "$new" ] || die "compare : fichier nouvelle base manquant.\nUsage : $0 compare <ancienne.b3> <nouvelle.b3>"

  core_assert_b3_valid "$old" "ancienne base"
  core_assert_b3_valid "$new" "nouvelle base"

  # Affichage des sidecars avant toute opération
  if (( ! QUIET )); then
    core_sidecar_read "$old"
    core_sidecar_read "$new"
  fi

  local outdir
  outdir=$(core_make_result_dir "$old" "$RESULTATS_DIR")

  # core_compare positionne CORE_COMPARE_NB_* dans le scope courant
  core_compare "$old" "$new" "$outdir"

  results_write_compare \
    "$outdir" "$old" "$new" \
    "$CORE_COMPARE_NB_MOD" "$CORE_COMPARE_NB_DIS" "$CORE_COMPARE_NB_NOU"

  generate_compare_html \
    "$old" "$new" \
    "$CORE_COMPARE_NB_MOD" "$CORE_COMPARE_NB_DIS" "$CORE_COMPARE_NB_NOU" \
    "${outdir}/modifies.b3" "${outdir}/disparus.txt" "${outdir}/nouveaux.txt" \
    "${outdir}/report.html"

  ui_show_compare_result \
    "$CORE_COMPARE_NB_MOD" "$CORE_COMPARE_NB_DIS" "$CORE_COMPARE_NB_NOU" \
    "$outdir"
}

# == Dispatch ===================================================================

case "$MODE" in
  compute) _run_compute ;;
  verify)  _run_verify  ;;
  compare) _run_compare ;;
  *)
    cat <<EOF
Usage :
  $0 [--quiet] compute <dossier> <base.b3> [commentaire]
  $0 [--quiet] verify  <base.b3> [dossier]
  $0 [--quiet] compare <ancienne.b3> <nouvelle.b3>

Options :
  --quiet      Silencieux : écrit uniquement dans les fichiers de résultats.

Arguments optionnels :
  [commentaire]  Texte libre stocké dans le sidecar <base.b3>.meta.json (compute uniquement).
                 Nécessite jq.

Note :
  Pour l'interface complète (list, diff, stats, check-env, version, pipeline),
  utiliser hash-tool à la racine du projet.
EOF
    exit 1
    ;;
esac

--- Fichier : docs/development/changelog.md ---
# Changelog - hash_tool




### [1.1.0] - 2026-02-26

#### Corrigé

-Isolation des chemins relatifs** : Correction d'un bug où l'entrée dans un sous-shell via `cd "$OPT_DATA"` empêchait l'écriture de la base dans le dossier `-save` si celui-ci était renseigné en chemin relatif.

-Résolution absolue des cibles** : Le script transforme désormais systématiquement le chemin `-save` en chemin absolu avant de changer de répertoire de travail. Cela garantit que la base `.b3` est enregistrée exactement là où l'utilisateur l'a demandé, même après un `cd` dans le dossier source.

-Robustesse aux espaces** : Ajout de guillemets doubles manquants dans les fonctions `_run_integrity` et `_sidecar_write` pour supporter les chemins Windows/WSL complexes comportant des espaces et des caractères spéciaux.

#### Ajouté

-Contrôle de conformité** : La commande `verify` émet désormais un avertissement si elle détecte des chemins absolus dans un fichier `.b3`, car cela brise l'invariant de portabilité du logiciel.

-Mode Read-only explicite** : Support de l'option `-readonly` lors du `compute` pour marquer l'état de la source dans le fichier de métadonnées sidecar.

#### Modifié

-Priorité des résultats** : L'option `-save` surcharge désormais systématiquement la variable d'environnement `RESULTATS_DIR` pour toutes les commandes (`compute`, `verify`, `compare`, `runner`).


## [1.0] - CLI unique, nouvelles commandes, sidecar, pipeline étendu

### Ajouté

**`hash-tool` - CLI unique (nouveau fichier à la racine)**

- Interface CLI unifiée. L'utilisateur invoque toujours `hash-tool <commande>`, indépendamment du mode d'exécution réel.
- Détection automatique du mode d'exécution : natif (`b3sum` + `jq` disponibles) ou Docker (`hash_tool` image disponible). Aucune intervention utilisateur requise.
- Parser d'arguments uniforme : `-data`, `-base`, `-old`, `-new`, `-pipeline`, `-save`, `-meta`, `-quiet`, `-verbose`, `-readonly`.
- Nouvelles commandes : `list`, `diff`, `stats`, `check-env`, `version`, `help` (global + par sous-commande).
- Variable d'environnement `HASH_TOOL_DOCKER_IMAGE` pour spécifier l'image Docker à utiliser (défaut : `hash_tool`).

**Sidecar file (`.meta.json`)**

- `compute` génère automatiquement `<base.b3>.meta.json` à côté du fichier `.b3`.
- Champs : `created_by`, `date` (ISO 8601 UTC), `comment` (depuis `-meta`), `parameters` (répertoire, algorithme, nb_fichiers, readonly).
- `verify`, `compare`, `stats` affichent le sidecar si présent.
- Le runner (format étendu) génère également le sidecar via `meta.comment` dans le pipeline JSON.

**Commande `list`**

- `hash-tool list -data <dossier>` : parcourt le dossier sur 2 niveaux, liste toutes les bases `.b3` avec leur nombre de fichiers, taille, et commentaire sidecar si présent.
- Indicateur `[+meta]` si un sidecar est associé.

**Commande `diff`**

- `hash-tool diff -base <fichier.b3> [-data <dossier>]` : compare les chemins de la base avec l'état actuel du dossier.
- Ne recalcule pas les hashes - uniquement comparaison des chemins.
- Affiche les fichiers disparus et les nouveaux fichiers non indexés.

**Commande `stats`**

- `hash-tool stats -base <fichier.b3>` : affiche le chemin absolu, la taille du fichier `.b3`, le nombre de fichiers indexés, la distribution des extensions (top 10), et le sidecar si présent.

**Commande `check-env`**

- `hash-tool check-env` : vérifie la disponibilité de `b3sum`, `jq`, `bash >= 4`, `integrity.sh`, `runner.sh`, Docker et l'image Docker.
- Indique le mode d'exécution sélectionné : `native`, `docker`, ou `none`.

**Commande `version`**

- `hash-tool version` : affiche la version `hash-tool` et la version `b3sum`.

**Commande `help`**

- `hash-tool help` : aide globale avec toutes les commandes et options.
- `hash-tool help <commande>` : aide détaillée par sous-commande.

**`runner.sh` - format pipeline étendu**

- Nouveau format `type / params / options / meta / description` - rétrocompatible avec le format legacy `op / source / bases / nom`.
- Détection automatique du format par la présence de `"op"` (legacy) ou `"type"` (étendu).
- Support des nouvelles opérations dans le pipeline : `list`, `diff`, `stats`, `check-env`, `version`.
- Génération du sidecar dans les blocs `compute` (format étendu) si `meta.comment` est fourni.
- Champ `options` par bloc : `quiet`, `verbose`, `readonly`.
- Champ `description` : documentation lisible directement dans le JSON.

**`pipelines/pipeline-amelioree.json`**

- Nouveau fichier pipeline de référence au format étendu, couvrant toutes les commandes disponibles.

### Modifié

- `runner.sh` : ajout de la fonction `dispatch_bloc()` qui détecte le format (legacy/étendu) et route vers la bonne implémentation. Fonctions `run_*_legacy()` et `run_*_extended()` séparées pour chaque opération.

### Non modifié

- `src/integrity.sh` : inchangé - les nouvelles commandes sont intégralement gérées dans `hash-tool`.
- `src/lib/core.sh`, `src/lib/ui.sh`, `src/lib/results.sh`, `src/lib/report.sh` : inchangés.
- Tous les pipelines existants (format legacy) : rétrocompatibles sans modification.

### Installation

```bash
chmod +x hash-tool runner.sh src/integrity.sh
# Optionnel : accès global
sudo ln -s "$(pwd)/hash-tool" /usr/local/bin/hash-tool
```

---

## [0.18] - debug

### Ajouté

- Dans `brouillon_non_prod` : documents `.md` décrivant les prochains travaux (architecture de test, CLI améliorée).

---

## [0.17] - debug

### Ajouté

- Ajout de `brouillon_non_prod` au git : documents de travail non inclus dans le délivrable mais conservés dans le dépôt pour référence.

---

## [0.16] - debug

### Ajouté

- Dossier `troubleshooting/` et fichier `troubleshooting_1.md` : premier cas documenté (Permission non accordée sur `integrity.sh` - solution : `chmod +x`).

---

## [0.15] - Documentation restructurée

- Mise à jour de la documentation.

---

## [0.14] - Documentation complète MkDocs

### Ajouté

- `docs/` : documentation complète au format MkDocs Material.
  - `index.md` : vue d'ensemble, structure du projet.
  - `getting-started.md` : installation, prérequis, premier usage.
  - `reference/integrity-sh.md` : référence exhaustive.
  - `reference/runner-sh.md` : format pipeline.json, comportements, messages d'erreur.
  - `reference/docker.md` : build, volumes, Compose, cron, Synology, ARM64.
  - `guides/veracrypt.md` : workflow multi-disques, lanceur Windows `.bat`.
  - `guides/cron-ci.md` : cron Linux, GitHub Actions, GitLab CI, hooks Git.
  - `guides/nas-synology.md` : DSM 7, Container Manager.
  - `development/architecture.md` : décisions techniques documentées.
  - `development/contributing.md` : couverture tests, conventions, processus de release.
  - `development/changelog.md` : historique.
- `mkdocs.yml` : configuration MkDocs Material, navigation, thème sombre/clair.

### Supprimé

- `docs/*.docx`, `docs/*.pdf` : binaires non diffables retirés du repo.

### Modifié

- `pipelines/pipeline full.json` → `pipelines/pipeline-full.json` : suppression de l'espace.

---

## [0.13] - Débug dockerisation et documentation

### Ajouté

- `hash_tool-positionnement-open-source.docx` : positionnement dans l'écosystème open source.
- `hash_tool-presentation.docx` : présentation macro du projet.

### Modifié

- `Dockerfile` : `b3sum` installé depuis Alpine community (`apk add b3sum`) au lieu de `wget` GitHub. Plus propre, plus robuste, évite les erreurs de nom de binaire.

---

## [0.12] - Dockerisation

### Ajouté

- `Dockerfile` : image Alpine 3.19 avec `bash`, `jq`, `b3sum`, `coreutils`, `findutils`. Image ~14 Mo.
- `docker/entrypoint.sh` : dispatcher des commandes (`compute`, `verify`, `compare`, `runner`, `shell`, `help`, `version`). `--quiet` supporté en premier argument.
- `docker-compose.yml` : trois services - `integrity`, `pipeline`, `cron` (profil optionnel).
- `.dockerignore` : exclut données, résultats, tests, docs du contexte de build.

### Volumes conventionnels

| Volume | Usage |
|---|---|
| `/data` | Données à hacher (`:ro` recommandé) |
| `/bases` | Fichiers `.b3` |
| `/pipelines` | Fichiers `pipeline.json` |
| `/resultats` | Résultats compare/verify |

---

## [0.11] - Restructuration + rapport HTML compare

### Restructuration

```
hash_tool/
├── runner.sh                  ← inchangé
├── src/
│   ├── integrity.sh           ← déplacé depuis la racine
│   └── lib/
│       └── report.sh          ← nouveau, extrait de integrity.sh
├── pipelines/
│   ├── pipeline.json          ← déplacé depuis la racine
│   └── pipeline-full.json     ← renommé
└── reports/
    └── template.html          ← nouveau
```

### Ajouté

- `src/lib/report.sh` : `generate_compare_html()` - rapport HTML autonome (CSS inline, thème sombre, compteurs, badge statut).
- `reports/template.html` : template de référence.
- `pipeline.json` : champ optionnel `"resultats"` sur les blocs `compare`.
- `tests/run_tests_pipeline.sh` : cas **TP10b** - champ `resultats` personnalisé et isolation `RESULTATS_DIR`.

### Modifié

- `runner.sh` : isolation des `cd` dans des sous-shells `( )`. Champ `resultats` pour les blocs `compare`.
- `src/integrity.sh` : délègue la génération HTML à `generate_compare_html()`.

---

## [0.10] - Pipeline JSON + tests pipeline

### Modifié

- `pipeline.json` : migration du format custom vers JSON standard. Champ `op` au lieu des noms de blocs.
- `runner.sh` : réécriture du parser avec `jq`. Validation JSON native, messages d'erreur avec numéro de bloc.

### Ajouté

- `tests/run_tests_pipeline.sh` : 12 cas TP01–TP12.

---

## [0.9] - Pipeline batch : runner.sh + config.txt

### Ajouté

- `runner.sh` : exécuteur de pipeline. Lit `config.txt`, gère le `cd` automatique.
- `config.txt` : déclaration du pipeline au format structuré.
- `runner.bat` : lanceur Windows (WSL) avec `pause`.

---

## [0.8] - batch_compute.sh

### Ajouté

- `batch_compute.sh` : plusieurs `compute` en un seul script. Remplacé par `runner.sh` en 0.9.

---

## [0.7] - Séparation en modules (lib/)

### Ajouté

- `src/lib/core.sh` : logique métier pure extraite de `integrity.sh`.
- `src/lib/ui.sh` : logique d'interface (affichage, ETA, progression).
- `src/lib/results.sh` : écriture des fichiers de résultats.

---

## [0.6] - Mode `--quiet`

### Ajouté

- `--quiet` : supprime toute sortie terminal. Exit code propagé sans modification. Résultats écrits dans les fichiers de sortie normaux.

---

## [0.5] - Horodatage anti-écrasement

### Modifié

- `core_make_result_dir()` : suffixe `_YYYYMMDD-HHMMSS` si le dossier de résultats existe déjà.

---

## [0.4] - ETA et progression

### Ajouté

- Affichage de la progression fichier par fichier avec ETA calculée sur la vélocité réelle.
- Écriture sur `/dev/tty` pour isolation des pipes.

---

## [0.3] - Rapport HTML `compare`

### Ajouté

- `report.html` généré après chaque `compare`.

---

## [0.2] - Commande `compare`

### Ajouté

- `integrity.sh compare <ancienne.b3> <nouvelle.b3>` : comparaison de deux snapshots.
- Produit `modifies.b3`, `disparus.txt`, `nouveaux.txt`.

---

## [0.1] - Initial

### Ajouté

- `integrity.sh compute <dossier> <base.b3>` : calcul des empreintes BLAKE3.
- `integrity.sh verify <base.b3>` : vérification d'intégrité via `b3sum --check`.
- Chemins relatifs dans les bases `.b3`.

--- Fichier : docs/development/contributing.md ---
# Contribuer à hash_tool

---

## Prérequis

```bash
sudo apt install bash b3sum jq shellcheck
```

---

## Tests

```bash
cd tests && ./run_tests.sh
cd tests && ./run_tests_pipeline.sh
```

Zéro warning ShellCheck requis (T00). Tous les tests doivent passer avant soumission.

---

## Conventions de code

### Séparation des responsabilités

Le code est organisé en modules avec des responsabilités strictement séparées. Avant d'écrire du code, identifier dans quel module il appartient :

- **Logique métier** (hachage, vérification, comparaison) → `src/lib/core.sh`
- **Affichage terminal, progression** → `src/lib/ui.sh`
- **Écriture fichiers de résultats** → `src/lib/results.sh`
- **Génération HTML** → `src/lib/report.sh`
- **Orchestration CLI** → `src/integrity.sh`

Ne jamais écrire de sortie terminal dans `core.sh`. Ne jamais écrire de logique métier dans `ui.sh`.

### Contrats de fonction

Toute fonction non triviale doit documenter :
- Les entrées (`$1`, `$2`...)
- Les sorties (exit code, variables positionnées, fichiers créés)
- Les effets de bord
- Les invariants supposés et garantis

Voir `src/lib/core.sh` comme référence de format.

### Conventions bash

- `set -euo pipefail` dans tout script exécutable
- `"$@"` et guillemets systématiques - ShellCheck enforce ce point
- `local` pour toutes les variables de fonction
- `mktemp` pour les fichiers temporaires, nettoyés via `trap EXIT`
- Pas de `ls` dans les scripts - utiliser `find` ou glob

---

## Format des commits

Convention : [Conventional Commits](https://www.conventionalcommits.org/)

```
<type>(<scope>): <description courte>

[corps optionnel]

[footer optionnel]
```

Types :

| Type | Usage |
|---|---|
| `feat` | Nouvelle fonctionnalité |
| `fix` | Correction de bug |
| `refactor` | Refactoring sans changement de comportement |
| `test` | Ajout ou modification de tests |
| `docs` | Documentation uniquement |
| `chore` | Tâches de maintenance (CI, dépendances, etc.) |
| `perf` | Amélioration de performance |

Exemples :

```
feat(core): ajouter support des liens symboliques dans core_compute
fix(ui): corriger l'effacement de la ligne ETA sur terminal étroit
docs(spec): documenter le cas des fichiers de taille zéro dans b3-format.md
test(core): ajouter T15 - vérification comportement sur lien symbolique
```

## Philosophie de test

- Chaque test crée son propre répertoire temporaire isolé dans `/tmp` - pas d'effet de bord entre cas
- Les tests de corruption introduisent volontairement une modification puis vérifient la détection
- Les tests pipeline vérifient l'isolation des sous-shells (pas de fuite de répertoire courant entre blocs)
- Résultat coloré `PASS` / `FAIL` avec compteur final

## Contributions prioritaires

Par ordre de valeur décroissante :

- **GitHub Actions** - CI automatique sur push : `run_tests.sh` + `run_tests_pipeline.sh` + ShellCheck
- **`install.sh`** - script d'installation one-liner avec vérification des dépendances (`b3sum`, `jq`, `bash >= 4`)
- **`--format json`** - sortie machine-readable pour `verify` et `compare` (aujourd'hui : texte uniquement)
- **Rapport HTML** - enrichissement du contenu et de la mise en page

---

## Processus de release

1. **Vérifier que tous les tests passent** sur une machine propre
   ```bash
   cd tests && ./run_tests.sh && ./run_tests_pipeline.sh
   shellcheck src/integrity.sh runner.sh src/lib/*.sh docker/entrypoint.sh
   ```

2. **Mettre à jour `CHANGELOG.md`** avec la nouvelle version et les changements

3. **Mettre à jour la variable `VERSION`** dans `src/integrity.sh` et `runner.sh`

4. **Créer le tag git**
   ```bash
   git tag -a v0.15 -m "Release v0.15 - <description courte>"
   git push origin v0.15
   ```

5. **Créer la GitHub Release** avec le contenu du CHANGELOG correspondant et les checksums :
   ```bash
   b3sum src/integrity.sh runner.sh src/lib/*.sh
   ```

---

## Structure des tests

Les tests sont dans `tests/`. Deux suites indépendantes :

| Suite | Scope | Cas |
|---|---|---|
| `run_tests.sh` | `integrity.sh` | T00–T14 |
| `run_tests_pipeline.sh` | `runner.sh` + `pipeline.json` | TP01–TP12b |

### Ajouter un test

1. Identifier la suite concernée
2. Nommer le cas (T15, T16... ou TP13, TP14...)
3. Documenter : précondition, oracle de test (résultat attendu), postcondition
4. Le test doit être reproductible sur n'importe quelle machine disposant des prérequis
5. Le test ne doit pas dépendre de l'état du système hôte (pas de `/home/user/...`, pas de fichiers extérieurs au `WORKDIR`)

Voir `tests/run_tests.sh` pour la structure standard d'un cas de test.


--- Fichier : docs/development/roadmap.md ---
# Roadmap - hash_tool

---

## Positionnement

> Outil de snapshot d'intégrité BLAKE3 pour collections de fichiers locales.

hash_tool n'est pas un logiciel de sauvegarde. Il ne copie pas, ne restaure pas, ne compresse pas. Il n'est pas un outil de sécurité au sens cryptographique - BLAKE3 est utilisé pour la détection d'erreurs accidentelles, pas pour l'authentification. Il n'est pas un outil de surveillance temps réel. Il opère par snapshots sur demande.

La clarté du périmètre est une qualité, pas une limite. Les outils qui font une seule chose bien sont plus faciles à auditer, à maintenir, à tester et à intégrer dans un pipeline plus large. hash_tool est conçu pour être **une brique, pas une solution complète**.

---

## Panorama des outils existants

| Outil | Type | Algorithme | Lacunes vis-à-vis du créneau |
|---|---|---|---|
| `md5sum` / `sha256sum` | CLI Unix | MD5 / SHA-256 | Fichier par fichier, pas de dossier, pas de rapport, pas de compare |
| `rclone check` | CLI Go | Variable | Couplé au stockage cloud, pas adapté aux usages locaux/hors-ligne |
| Duplicati | GUI/daemon | SHA-256 | Logiciel de sauvegarde complet, lourd, overkill pour la vérification seule |
| TeraCopy | GUI Windows | Plusieurs | Windows uniquement, propriétaire, pas scriptable |
| `hashdeep` | CLI C | Plusieurs | Pas de BLAKE3, pas de rapport HTML, pas de pipeline, inactif depuis 2015 |
| `fclones` | CLI Rust | BLAKE3 | Orienté déduplication, pas intégrité temporelle, pas de compare snapshots |
| `par2` | CLI C++ | Reed-Solomon | Réparation de données, pas détection de corruption sur dossier existant |

Aucun outil ci-dessus ne combine simultanément : (1) BLAKE3, (2) gestion de dossiers complets avec chemins relatifs, (3) comparaison de deux snapshots à des instants différents, (4) rapport HTML autonome, (5) pipeline JSON déclaratif, (6) image Docker Alpine légère. La conjonction de ces six caractéristiques définit le créneau.

---

## Population cible

| Profil | Cas d'usage principal | Besoin non couvert par les alternatives |
|---|---|---|
| Sysadmin de PME / indépendant | Vérifier l'intégrité de sauvegardes NAS après restauration | Outil léger, sans agent, rapport lisible par le client |
| Photographe / vidéaste professionnel | Garantir l'intégrité d'archives de médias sur disques durs | Interface simple, hors-ligne, pas de dépendance cloud |
| Archiviste numérique / bibliothèque | Détecter le bitrot sur des collections à long terme | Rapport horodaté, comparaison de snapshots, exportable |
| Chercheur / laboratoire | Valider l'intégrité de datasets après transfert | Portabilité, chemins relatifs, pas de compte tiers requis |
| Développeur DevOps | Intégrer une vérification d'intégrité dans un pipeline CI/CD | Mode `--quiet`, exit code propagé, image Docker légère |

---

## Créneaux secondaires

**Post-transfert sur supports chiffrés.** Les utilisateurs de partitions chiffrées (VeraCrypt, LUKS, BitLocker) font face à un problème spécifique : le transfert de fichiers est une opération à risque (coupure d'alimentation, démontage forcé, erreur de transfert). Aucun outil dédié ne propose un workflow `compute → verify → compare` adapté à ce contexte. Le pipeline JSON de hash_tool s'y prête directement.

**Validation de migration de données.** Migrations de serveurs, changements de NAS, restructuration d'arborescences - ces opérations nécessitent de comparer l'état avant et après. Les outils existants (`diff`, `rsync --checksum`) travaillent sur des copies simultanées, pas sur des snapshots temporels. hash_tool compare deux `.b3` produits à n'importe quel intervalle de temps.

**Intégration CI/CD légère.** Les pipelines CI qui vérifient l'intégrité d'artefacts de build ou de datasets de test utilisent généralement des checksums ad hoc (SHA-256 d'un seul fichier). hash_tool propose une approche structurée avec `--quiet`, exit code propre, et image Docker légère - sans introduire une dépendance lourde comme rclone ou un service cloud.

**Archivage numérique long terme.** La communauté de l'archivage numérique (bibliothèques, musées, institutions de recherche) utilise des outils comme BagIt ou PREMIS pour l'intégrité à long terme. Ces outils sont complexes, orientés XML, et inadaptés aux petites structures. hash_tool offre un sous-ensemble fonctionnel utilisable sans formation.

---

## Synthèse des créneaux

| Créneau | Intensité du besoin | Vacance actuelle | Priorité |
|---|---|---|---|
| Intégrité de collections de fichiers locaux à long terme | Élevée | Totale | Primaire |
| Post-transfert sur supports chiffrés | Moyenne | Totale | Secondaire |
| Validation de migration de données | Élevée | Partielle | Secondaire |
| Intégration CI/CD légère (BLAKE3) | Moyenne | Partielle | Tertiaire |
| Archivage numérique petites structures | Faible | Totale | Tertiaire |

---

## Limites connues non corrigeables par conception

| Scénario | Détecté ? | Explication |
|---|---|---|
| Clone bit-à-bit | Non | Hash identique par définition |
| Renommage de fichier | Non | Vu comme suppression + ajout |
| Modification de permissions / timestamps | Non | `b3sum` ne hache que le contenu binaire |
| Dossier vide | Non | `find -type f` ignore les dossiers vides |
| Corruption de la base `.b3` elle-même | Non | La base n'est pas auto-protégée par défaut |

Contournement pour la base `.b3` :

```bash
b3sum hashes.b3 > hashes.b3.check
b3sum --check hashes.b3.check
```

---

## Concurrence future

Le seul risque de désintermédiation sérieux serait qu'un outil comme `rclone` ou `restic` implémente nativement BLAKE3 + comparaison de snapshots + rapport HTML + Docker léger. Leur complexité intrinsèque rend ce scénario peu probable à court terme.

---

## Axes d'évolution envisagés

Ces fonctionnalités ne sont pas planifiées avec une date. Elles sont identifiées comme extensions naturelles du périmètre actuel, par ordre de valeur décroissante.

**`--format json` sur `verify` et `compare`.** `recap.txt` est lisible par un humain, pas par un outil. Un export JSON permettrait l'intégration avec des dashboards ou des outils de monitoring sans parser du texte. Contribution prioritaire.

**CI automatique (GitHub Actions).** `run_tests.sh` + `run_tests_pipeline.sh` déclenchés sur push. Contribution prioritaire.

**`install.sh` one-liner.** Script d'installation avec vérification des dépendances. Contribution prioritaire.

**Notifications natives.** Aujourd'hui la notification est à la charge du script appelant (`mail`, webhook Slack, etc.). Un champ `on_failure` dans `pipeline.json` encapsulerait ce pattern récurrent.

**Auto-protection de la base `.b3`.** Un flag `--sign` sur `compute` qui calcule et stocke le hash de la base dans un fichier `.b3.check` adjacent, et un flag `--verify-base` sur `verify` qui valide ce check avant toute opération.

**Parallélisme configurable.** La boucle séquentielle est optimale sur HDD. Sur SSD NVMe avec de nombreux petits fichiers, `xargs -P N` offrirait +20–40%. À conditionner à un flag explicite `--parallel N` pour ne pas casser les environnements où l'ordre de traitement importe.


--- Fichier : docs/guides/cron-ci.md ---
# Guide - CI / Cron

Intégration de hash_tool dans des pipelines automatisés : cron Linux, CI/CD, hooks Git.

---

## Mode `--quiet`

Toutes les commandes acceptent `--quiet` en premier argument. Ce flag :

- Supprime **toute** sortie terminal (stdout et stderr de `integrity.sh`)
- Conserve l'**exit code** : `0` = OK, `1` = ECHEC ou ERREUR
- Continue d'écrire les fichiers de résultats (`recap.txt`, `failed.txt`, `report.html`)

C'est le mode à utiliser systématiquement en automatisation - le script parent ou le système de notification gère la sortie.

```bash
./src/integrity.sh --quiet verify hashes.b3
echo "Exit code : $?"
```

---

## Cron Linux

### Vérification nocturne simple

```cron
# /etc/cron.d/hash-integrity
# Vérification à 03h00 chaque nuit
0 3 * * * user /opt/hash_tool/src/integrity.sh --quiet verify \
    /opt/bases/hashes.b3 /srv/data \
    >> /var/log/hash-integrity.log 2>&1 \
    || echo "$(date) - ALERTE intégrité" | mail -s "Alerte $(hostname)" admin@example.com
```

### Avec pipeline complet

```cron
# Recalcul hebdomadaire + comparaison (dimanche 02h00)
0 2 * * 0 user /opt/hash_tool/runner.sh /opt/hash_tool/pipelines/pipeline-weekly.json \
    >> /var/log/hash-integrity-weekly.log 2>&1 \
    || mail -s "ECHEC pipeline intégrité $(hostname)" admin@example.com
```

### Rotation des logs

```bash
# /etc/logrotate.d/hash-integrity
/var/log/hash-integrity.log {
    weekly
    rotate 52
    compress
    missingok
    notifempty
}
```

---

## Cron via Docker

```cron
0 3 * * * root \
    docker run --rm \
      -v /srv/data:/data:ro \
      -v /srv/bases:/bases:ro \
      -v /srv/resultats:/resultats \
      hash_tool --quiet verify /bases/hashes.b3 /data \
    >> /var/log/hash-integrity.log 2>&1 \
    || mail -s "ALERTE intégrité $(hostname)" admin@example.com
```

---

## Intégration CI/CD

### GitHub Actions

```yaml
# .github/workflows/integrity-check.yml
name: Vérification intégrité

on:
  schedule:
    - cron: '0 3 * * *'   # 03h00 UTC chaque nuit
  workflow_dispatch:        # déclenchement manuel possible

jobs:
  verify:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Installer b3sum
        run: sudo apt-get install -y b3sum

      - name: Vérifier l'intégrité
        run: |
          ./src/integrity.sh --quiet verify bases/hashes.b3
        env:
          RESULTATS_DIR: /tmp/integrity-results

      - name: Uploader les résultats
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: integrity-results
          path: /tmp/integrity-results/
          retention-days: 30
```

### GitLab CI

```yaml
# .gitlab-ci.yml
integrity-verify:
  stage: verify
  image: alpine:3.19
  before_script:
    - apk add --no-cache bash b3sum
  script:
    - ./src/integrity.sh --quiet verify bases/hashes.b3
  artifacts:
    when: always
    paths:
      - integrity-results/
    expire_in: 30 days
  variables:
    RESULTATS_DIR: integrity-results
  rules:
    - if: $CI_PIPELINE_SOURCE == "schedule"
```

### Hook Git pre-commit

Vérifier l'intégrité d'un dossier avant chaque commit :

```bash
#!/usr/bin/env bash
# .git/hooks/pre-commit
set -euo pipefail

BASES_DIR="$(git rev-parse --show-toplevel)/bases"
DATA_DIR="$(git rev-parse --show-toplevel)/data"

if [ -f "$BASES_DIR/hashes.b3" ]; then
    echo "Vérification intégrité..."
    ./src/integrity.sh --quiet verify "$BASES_DIR/hashes.b3" "$DATA_DIR" || {
        echo "ERREUR : corruption détectée. Commit annulé."
        echo "Consulter : $BASES_DIR/resultats/"
        exit 1
    }
    echo "Intégrité OK."
fi
```

```bash
chmod +x .git/hooks/pre-commit
```

---

## Patterns de notification

### Email via `mail`

```bash
./src/integrity.sh --quiet verify hashes.b3 || \
    mail -s "ALERTE intégrité $(hostname)" admin@example.com < \
    "$(ls -d ~/integrity_resultats/resultats_hashes* | tail -1)/recap.txt"
```

### Slack webhook

```bash
#!/usr/bin/env bash
WEBHOOK_URL="https://hooks.slack.com/services/..."

./src/integrity.sh --quiet verify hashes.b3
EXIT=$?

if [ $EXIT -ne 0 ]; then
    RECAP=$(cat "$(ls -d ~/integrity_resultats/resultats_hashes* | tail -1)/recap.txt")
    curl -s -X POST "$WEBHOOK_URL" \
        -H 'Content-type: application/json' \
        --data "{\"text\":\"🚨 *Alerte intégrité* sur \`$(hostname)\`\n\`\`\`${RECAP}\`\`\`\"}"
fi

exit $EXIT
```

### Fichier de statut pour monitoring

```bash
#!/usr/bin/env bash
STATUS_FILE=/var/lib/hash-integrity/last-status

./src/integrity.sh --quiet verify hashes.b3
EXIT=$?

mkdir -p "$(dirname "$STATUS_FILE")"
{
    echo "date=$(date -Iseconds)"
    echo "status=$([ $EXIT -eq 0 ] && echo OK || echo FAILED)"
    echo "exit_code=$EXIT"
} > "$STATUS_FILE"

exit $EXIT
```

Le fichier `last-status` peut être lu par Zabbix, Nagios, Prometheus node_exporter (textfile collector), etc.

---

## Gestion des résultats en CI

Les résultats (`recap.txt`, `failed.txt`, `report.html`) s'accumulent dans `RESULTATS_DIR`. En CI, pointer vers un dossier temporaire :

```bash
export RESULTATS_DIR=/tmp/integrity-$(date +%Y%m%d-%H%M%S)
./src/integrity.sh verify hashes.b3
# Uploader $RESULTATS_DIR comme artefact CI
```

Ou utiliser le champ `resultats` dans `pipeline.json` pour un chemin explicite par run.

---

## Récupérer le résumé en script

```bash
# Vérifier et récupérer le recap
./src/integrity.sh --quiet verify hashes.b3
EXIT=$?

OUTDIR=$(ls -d "${RESULTATS_DIR:-$HOME/integrity_resultats}/resultats_hashes"* 2>/dev/null | tail -1)

if [ $EXIT -ne 0 ] && [ -f "$OUTDIR/failed.txt" ]; then
    NB_FAILED=$(grep -c ': FAILED' "$OUTDIR/failed.txt" || echo 0)
    echo "ECHEC : $NB_FAILED fichier(s) corrompu(s)"
    cat "$OUTDIR/failed.txt"
fi

exit $EXIT
```


--- Fichier : docs/guides/nas-synology.md ---
# Guide - NAS Synology

Déploiement et usage de hash_tool sur NAS Synology avec Docker.

---

## Prérequis

- DSM 7.x
- **Container Manager** (anciennement Docker Manager) installé depuis le Centre de paquets
- Accès SSH au NAS (`ssh admin@192.168.1.x`)

---

## Déterminer l'architecture

```bash
# Via SSH
uname -m
# amd64 → DS920+, DS923+, DS1621+, ...
# aarch64 (arm64) → DS220+, DS420+, DS720+, DS923+ avec CPU AMD
```

| Modèle (exemples) | Architecture |
|---|---|
| DS920+, DS1621+, RS1221+ | amd64 |
| DS220+, DS420+, DS720+ | arm64 (aarch64) |
| DS923+ | amd64 (Ryzen R1600) |

---

## Installation

### Via SSH

```bash
# Se connecter au NAS
ssh admin@192.168.1.x

# Cloner ou copier hash_tool
cd /volume1/docker
git clone https://github.com/hash_tool/hash_tool.git
cd hash_tool

# Build de l'image (adapter la plateforme)
# amd64
docker build -t hash_tool .

# arm64 (DS220+, DS420+...)
docker build --platform linux/arm64 -t hash_tool:arm64 .
```

### Vérifier l'image

```bash
docker run --rm hash_tool version
# hash_tool
#   b3sum : b3sum 1.x.x
#   jq    : jq-1.x
#   bash  : 5.x.x
```

---

## Structure recommandée sur le NAS

```
/volume1/
├== docker/
│   └== hash_tool/          ← scripts et Dockerfile
├== data/                   ← données à surveiller (ou sous-dossiers par partage)
│   ├== photos/
│   ├== documents/
│   └== backups/
├== bases/                  ← fichiers .b3 (séparés des données)
│   ├== hashes_photos.b3
│   ├== hashes_documents.b3
│   └== hashes_backups.b3
└== rapports/               ← résultats verify/compare
    └== ...
```

---

## Utilisation via SSH

### Compute

```bash
docker run --rm \
  -v /volume1/data/photos:/data:ro \
  -v /volume1/bases:/bases \
  hash_tool compute /data /bases/hashes_photos_$(date +%Y-%m-%d).b3
```

### Verify

```bash
docker run --rm \
  -v /volume1/data/photos:/data:ro \
  -v /volume1/bases:/bases:ro \
  -v /volume1/rapports:/resultats \
  hash_tool verify /bases/hashes_photos.b3 /data
```

### Pipeline complet

```bash
docker run --rm \
  -v /volume1/data:/data:ro \
  -v /volume1/bases:/bases \
  -v /volume1/rapports:/resultats \
  -v /volume1/docker/hash_tool/pipelines/pipeline.json:/pipelines/pipeline.json:ro \
  hash_tool runner
```

---

## Automatisation via le planificateur de tâches DSM

DSM dispose d'un planificateur de tâches intégré (Panneau de configuration → Planificateur de tâches).

### Créer une tâche planifiée

1. **Panneau de configuration** → **Planificateur de tâches** → **Créer** → **Tâche planifiée** → **Script défini par l'utilisateur**
2. Onglet **Général** : nommer la tâche, sélectionner l'utilisateur `root`
3. Onglet **Calendrier** : configurer la fréquence (ex : hebdomadaire, dimanche 03h00)
4. Onglet **Paramètres de la tâche** : coller le script ci-dessous

### Script de tâche planifiée

```bash
#!/bin/bash

LOG="/volume1/rapports/hash-integrity.log"
MAILTO="admin@example.com"

echo "$(date) - Démarrage vérification intégrité" >> "$LOG"

docker run --rm \
  -v /volume1/data:/data:ro \
  -v /volume1/bases:/bases:ro \
  -v /volume1/rapports:/resultats \
  hash_tool --quiet verify /bases/hashes.b3 /data \
  >> "$LOG" 2>&1

EXIT=$?

if [ $EXIT -ne 0 ]; then
    echo "$(date) - ALERTE : vérification échouée (exit $EXIT)" >> "$LOG"
    # Notification email DSM - nécessite la configuration SMTP dans le Panneau de configuration
    # synonotify -e "hash_tool : corruption détectée sur $(hostname)"
fi

echo "$(date) - Fin (exit $EXIT)" >> "$LOG"
exit $EXIT
```

### Notifications DSM natives

Pour utiliser le système de notification DSM :

```bash
# Envoyer une notification DSM (email, push, SMS selon config)
synodsmnotify @administrators "hash_tool" "Corruption détectée sur $(/bin/hostname)"
```

---

## Docker Compose sur Synology

Adapter `docker-compose.yml` avec les chemins Synology :

```yaml
x-volumes:
  data:      &vol-data      /volume1/data
  bases:     &vol-bases     /volume1/bases
  pipelines: &vol-pipelines /volume1/docker/hash_tool/pipelines
  resultats: &vol-resultats /volume1/rapports
```

Puis via Container Manager (interface graphique DSM) ou SSH :

```bash
cd /volume1/docker/hash_tool
docker compose run --rm integrity verify /bases/hashes.b3 /data
```

---

## Dépannage

### L'image ne se build pas sur ARM64

```bash
# Vérifier l'architecture
uname -m   # doit afficher aarch64

# Builder avec la plateforme explicite
docker build --platform linux/arm64 -t hash_tool:arm64 .

# Tagger pour utiliser sans suffixe
docker tag hash_tool:arm64 hash_tool
```

### Permission denied sur /volume1

```bash
# Les conteneurs Docker tournent en root par défaut
# Vérifier que les dossiers sont accessibles
ls -la /volume1/data
ls -la /volume1/bases

# Adapter les permissions si nécessaire
chmod 755 /volume1/bases
```

### Container Manager ne trouve pas l'image

Après build via SSH, l'image apparaît dans Container Manager → Images. Si elle n'apparaît pas, rafraîchir ou relancer le service Docker :

```bash
sudo synoservicectl --restart pkgctl-ContainerManager
```


--- Fichier : docs/guides/veracrypt.md ---
# Guide - VeraCrypt & disques multiples

Workflow complet pour archiver et vérifier des données sur partitions VeraCrypt avec `runner.sh`.

---

## Principe

Les partitions VeraCrypt sont montées comme des lettres de lecteur sous Windows / des points de montage sous Linux. Les données n'existent en clair que pendant la session de montage. Il faut donc :

1. **Indexer avant démontage** - calculer les hashes pendant que les données sont accessibles
2. **Stocker les `.b3` hors de la partition vérifiée** - sur `C:` ou une partition non chiffrée
3. **Vérifier après remontage** - au prochain accès, confirmer l'intégrité

---

## Correspondance chemins Windows / WSL

| Lecteur Windows | Chemin WSL |
|---|---|
| `A:\` | `/mnt/a/` |
| `C:\` | `/mnt/c/` |
| `H:\` | `/mnt/h/` |
| `I:\` | `/mnt/i/` |

Si VeraCrypt remonte une partition sur une lettre différente d'une session à l'autre, seul le champ `source` dans `pipeline.json` est à modifier. Les bases `.b3` restent valides car leurs chemins sont relatifs.

---

## Structure recommandée

```
C:\Users\TonNom\Desktop\
├== hash_tool\                  ← scripts (non chiffré)
│   ├== runner.sh
│   ├== src\integrity.sh
│   └== pipelines\
│       └== pipeline-veracrypt.json
├== bases\                      ← fichiers .b3 (non chiffré, hors VeraCrypt)
│   ├== hashes_disque_1.b3
│   ├== hashes_disque_2.b3
│   └== hashes_disque_3.b3
└== rapports\                   ← résultats compare/verify
    └== ...
```

!!! danger "Stocker les .b3 hors de la partition vérifiée"
    Si les `.b3` sont sur la même partition VeraCrypt que les données, une corruption du disque peut corrompre simultanément les données **et** leur empreinte - rendant la vérification inutile.

    Stocker les `.b3` sur `C:` (non chiffré) ou une partition séparée.

---

## Configuration pipeline

### Cas simple - un disque, compute + verify

```json
{
    "pipeline": [
        {
            "op":     "compute",
            "source": "/mnt/a/mes_archives",
            "bases":  "/mnt/c/Users/TonNom/Desktop/bases",
            "nom":    "hashes_disque_a.b3"
        },
        {
            "op":     "verify",
            "source": "/mnt/a/mes_archives",
            "base":   "/mnt/c/Users/TonNom/Desktop/bases/hashes_disque_a.b3"
        }
    ]
}
```

### Cas complet - trois disques avec comparaison

```json
{
    "pipeline": [

        {
            "op":     "compute",
            "source": "/mnt/a/dossier_disque_1",
            "bases":  "/mnt/c/Users/TonNom/Desktop/bases",
            "nom":    "hashes_disque_1.b3"
        },

        {
            "op":     "compute",
            "source": "/mnt/i/dossier_disque_2",
            "bases":  "/mnt/c/Users/TonNom/Desktop/bases",
            "nom":    "hashes_disque_2.b3"
        },

        {
            "op":     "compute",
            "source": "/mnt/h/dossier_disque_3",
            "bases":  "/mnt/c/Users/TonNom/Desktop/bases",
            "nom":    "hashes_disque_3.b3"
        },

        {
            "op":     "verify",
            "source": "/mnt/a/dossier_disque_1",
            "base":   "/mnt/c/Users/TonNom/Desktop/bases/hashes_disque_1.b3"
        },

        {
            "op":        "compare",
            "base_a":    "/mnt/c/Users/TonNom/Desktop/bases/hashes_disque_1.b3",
            "base_b":    "/mnt/c/Users/TonNom/Desktop/bases/hashes_disque_2.b3",
            "resultats": "/mnt/c/Users/TonNom/Desktop/rapports/compare_1_vs_2"
        }

    ]
}
```

---

## Lanceur Windows (double-clic)

Créer `lancer_integrity.bat` sur le bureau :

```bat
@echo off
echo Demarrage verification integrite...
wsl bash /mnt/c/Users/TonNom/Desktop/hash_tool/runner.sh ^
    /mnt/c/Users/TonNom/Desktop/hash_tool/pipelines/pipeline-veracrypt.json
if %errorlevel% neq 0 (
    echo.
    echo ERREUR : le pipeline a echoue. Consulter les resultats.
) else (
    echo.
    echo Pipeline termine avec succes.
)
pause
```

---

## Workflows types

### Workflow d'archivage initial

1. Monter les partitions VeraCrypt
2. Double-clic sur `lancer_integrity.bat`
3. Attendre la fin (progression affichée dans la console WSL)
4. Vérifier que `recap.txt` indique OK
5. Démonter les partitions

### Workflow de vérification périodique

1. Monter les partitions VeraCrypt
2. Modifier `pipeline.json` pour ne conserver que les blocs `verify` (supprimer les `compute`)
3. Double-clic sur `lancer_integrity.bat`
4. Consulter `recap.txt` et `failed.txt` si présent
5. Démonter les partitions

### Workflow de comparaison après copie

Après avoir copié des données d'un disque à un autre :

1. `compute` sur la source (`base_a`)
2. `compute` sur la destination (`base_b`)
3. `compare base_a base_b` → `disparus.txt` et `nouveaux.txt` doivent être vides, `modifies.b3` aussi

---

## Nommage des bases

Utiliser des noms datés pour conserver l'historique :

```
bases/
├== hashes_disque_1_2024-01-15.b3    ← baseline initiale
├== hashes_disque_1_2024-06-01.b3    ← après ajout de fichiers
└== hashes_disque_1_2024-12-01.b3    ← vérification annuelle
```

Ne jamais écraser une base existante - chaque `.b3` est une preuve datée de l'état du disque.

!!! tip
    Pour automatiser le nommage daté depuis Windows avec WSL :
    ```bat
    for /f %%i in ('wsl date +%%Y-%%m-%%d') do set DATE=%%i
    ```


--- Fichier : docs/reference/docker.md ---
# Référence - Docker

**Version image :** 0.12  
**Base :** Alpine 3.19  
**Taille finale :** ~14 Mo  
**Architectures :** `amd64`, `arm64`, `armv7`

---

## Pourquoi Docker

hash_tool dépend de deux binaires - `b3sum` et `jq` - dont les versions et les méthodes d'installation varient selon l'OS. Sur Windows, `b3sum` n'est pas disponible nativement. Sur un NAS Synology, l'accès à un gestionnaire de paquets est limité. Sur un serveur Debian de production, toute installation manuelle est une dette technique.

L'image Docker embarque des versions fixes et vérifiées de tous les outils. L'hôte n'a besoin que de Docker.

| Environnement | Problème sans Docker | Solution Docker |
|---|---|---|
| Windows / WSL | `b3sum` non dispo nativement, `jq` à installer manuellement | `docker run` - aucune installation |
| NAS Synology | Gestionnaire de paquets limité, accès SSH requis | Image ARM64 compatible DSM 7.x |
| Serveur Debian | Versions système potentiellement anciennes | Versions pinned dans le Dockerfile |

---

## Architecture de l'image

### Multi-stage build

L'image utilise un build en deux stages pour dissocier les outils de compilation des outils d'exécution.

```dockerfile
# Stage 1 : fetcher - téléchargement et vérification de b3sum
FROM alpine:3.19 AS fetcher
  # wget b3sum binaire musl depuis GitHub Releases
  # b3sum --check (auto-vérification cryptographique)

# Stage 2 : image finale - runtime uniquement
FROM alpine:3.19
  # apk install bash jq coreutils findutils
  # COPY --from=fetcher /usr/local/bin/b3sum
  # COPY scripts hash_tool
```

Le stage `fetcher` nécessite `wget` et `ca-certificates`, qui ne sont pas copiés dans l'image finale. La toolchain Rust (~700 Mo) n'est jamais présente - `b3sum` est récupéré sous forme de binaire musl pré-compilé depuis les releases officielles BLAKE3.

!!! note "Pourquoi musl ?"
    Alpine Linux utilise musl libc au lieu de glibc. Les binaires musl sont statiquement liés et fonctionnent sans dépendances dynamiques - plus robustes dans un conteneur minimal. Le projet BLAKE3 publie des binaires musl officiels pour amd64, arm64 et armv7.

### Taille finale

| Couche | Taille approx. | Contenu |
|---|---|---|
| Alpine 3.19 base | ~7 Mo | OS minimal musl libc |
| bash + jq + coreutils | ~5 Mo | Shell, parser JSON, outils POSIX |
| b3sum binaire musl | ~2 Mo | Binaire officiel BLAKE3 |
| Scripts hash_tool | < 100 Ko | `runner.sh`, `integrity.sh`, `lib/` |
| **Total image finale** | **~14 Mo** | - |
| Image Debian équivalente | ~180 Mo | Référence comparative |

### Détection d'architecture

La sélection du binaire `b3sum` adapté à l'architecture se fait automatiquement dans le Dockerfile via `uname -m` :

```bash
ARCH="$(uname -m)"
case "$ARCH" in
  x86_64)  B3SUM_ARCH="linux_amd64_musl"   ;;  # PC, serveur standard
  aarch64) B3SUM_ARCH="linux_aarch64_musl"  ;;  # NAS Synology ARM, RPi 4
  armv7l)  B3SUM_ARCH="linux_armv7_musl"    ;;  # Vieux NAS, RPi 2/3
esac
```

Un seul Dockerfile couvre les trois architectures. Le build multi-platform Docker Buildx permet de produire une image manifeste unique pour les trois cibles simultanément.

### Vérification cryptographique du binaire

Le projet BLAKE3 publie pour chaque release un fichier `.b3` contenant le hash BLAKE3 du binaire. Le stage fetcher vérifie le binaire téléchargé avant de le copier dans l'image finale :

```bash
# Télécharger binaire et sa signature
wget -O /usr/local/bin/b3sum "${BASE_URL}/b3sum_${B3SUM_ARCH}"
wget -O /tmp/b3sum.b3        "${BASE_URL}/b3sum_${B3SUM_ARCH}.b3"

# Auto-vérification : b3sum vérifie sa propre signature
chmod +x /usr/local/bin/b3sum
cd /usr/local/bin && b3sum --check /tmp/b3sum.b3

# Si le hash ne correspond pas → build échoue immédiatement
```

!!! note "Chaîne de confiance"
    `b3sum` se vérifie lui-même : le binaire téléchargé calcule son propre hash et le compare au fichier `.b3` publié sur la même release GitHub. Si un seul bit a été altéré (attaque MITM, corruption réseau), le build échoue avec une erreur explicite.

---

## Entrypoint

Le script `docker/entrypoint.sh` dispatche les commandes vers les scripts internes.

| Commande | Script appelé | Description |
|---|---|---|
| `compute <dossier> <base.b3>` | `src/integrity.sh compute` | Calcule les hashes BLAKE3 |
| `verify <base.b3> [dossier]` | `src/integrity.sh verify` | Vérifie l'intégrité |
| `compare <old.b3> <new.b3>` | `src/integrity.sh compare` | Compare deux bases |
| `runner [pipeline.json]` | `runner.sh` | Exécute un pipeline JSON |
| `shell` / `bash` | `/bin/bash` | Shell interactif (debug) |
| `help` | - | Affiche l'aide inline |
| `version` | - | Affiche les versions des outils |

Sans argument, le conteneur affiche l'aide (`CMD ["help"]`). Cela évite l'erreur silencieuse d'un conteneur qui démarre et s'arrête sans indication.

---

## Volumes

L'image définit quatre points de montage conventionnels.

| Volume | Usage | Mode recommandé | Notes |
|---|---|---|---|
| `/data` | Données à hacher | `:ro` | Jamais modifié par hash_tool |
| `/bases` | Fichiers `.b3` | Lecture/écriture | Écriture uniquement pour `compute` |
| `/pipelines` | Fichiers `pipeline.json` | `:ro` | Monter un fichier spécifique |
| `/resultats` | Résultats `verify`/`compare` | Lecture/écriture | `RESULTATS_DIR=/resultats` par défaut |

!!! warning "Séparation données / bases"
    Les fichiers `.b3` doivent être stockés sur un support **distinct** des données vérifiées. Si `/data` et `/bases` pointent vers le même disque physique, une corruption du disque pourrait affecter les deux - rendant la vérification inopérante.

    Sur VeraCrypt : stocker les `.b3` sur `C:` (stable), jamais sur la partition montée.

### Variable d'environnement `RESULTATS_DIR`

`RESULTATS_DIR` est définie à `/resultats` dans l'image. Elle peut être surchargée via `-e` :

```bash
docker run --rm \
  -v /mes/resultats:/custom_res \
  -e RESULTATS_DIR=/custom_res \
  hash_tool verify /bases/hashes.b3
```

Le champ `"resultats"` dans `pipeline.json` surcharge cette variable pour un bloc `compare` spécifique.

---

## Docker Compose

### Services

| Service | Usage | Démarrage |
|---|---|---|
| `integrity` | Commandes ponctuelles `compute`/`verify`/`compare` | `docker compose run --rm integrity <cmd>` |
| `pipeline` | Exécution de `runner.sh` avec `pipeline.json` | `docker compose run --rm pipeline` |
| `cron` | Vérification périodique | `docker compose --profile cron up -d` |

### Configuration des chemins

La section `x-volumes` permet de modifier tous les montages en un seul endroit.

```yaml
# docker-compose.yml - section à adapter
x-volumes:
  data:      &vol-data      /chemin/vers/donnees    # ex: /volume1/data sur Synology
  bases:     &vol-bases     /chemin/vers/bases       # ex: /srv/bases sur Debian
  pipelines: &vol-pipelines /chemin/vers/pipelines
  resultats: &vol-resultats /chemin/vers/resultats
```

Les ancres YAML (`*vol-data`, etc.) propagent les chemins dans tous les services automatiquement.

### Profil cron

Le service `cron` est isolé derrière un profil Docker Compose (`profiles: ["cron"]`). Il n'est pas démarré par `docker compose up` par défaut. Cela évite un service fantôme actif en permanence.

---

## Déploiement par environnement

### Windows / WSL

Prérequis : Docker Desktop avec intégration WSL2 activée.

```bash
# Build depuis WSL
cd /mnt/c/Users/TonNom/Desktop/hash_tool
docker build -t hash_tool .

# Compute d'une partition VeraCrypt montée sur A:
docker run --rm \
  -v /mnt/a/dossier:/data:ro \
  -v /mnt/c/Users/TonNom/bases:/bases \
  -v /mnt/c/Users/TonNom/resultats:/resultats \
  hash_tool compute /data /bases/hashes_$(date +%Y-%m-%d).b3
```

!!! note "Chemins VeraCrypt dans Docker"
    Les partitions VeraCrypt montées sur des lettres Windows (`A:`, `I:`, `H:`) sont accessibles depuis WSL sous `/mnt/a/`, `/mnt/i/`, `/mnt/h/`. Docker Desktop sur WSL2 hérite de ces montages. Adapter uniquement les chemins `-v` lors du changement de lettre de partition.

### NAS Synology

Vérifier l'architecture avec `uname -m` depuis SSH avant de builder.

| Modèle Synology | CPU | Architecture | Tag image |
|---|---|---|---|
| DS923+ | AMD Ryzen R1600 | x86_64 (amd64) | `hash_tool` |
| DS720+ | Intel Celeron J4125 | x86_64 (amd64) | `hash_tool` |
| DS220+ | Intel Celeron J4025 | x86_64 (amd64) | `hash_tool` |
| DS220j | Realtek RTD1296 | aarch64 (arm64) | `hash_tool:arm64` |
| DS218j | Marvell ARMADA 385 | armv7 | `hash_tool:armv7` |

```bash
# Build ARM64 (NAS DS923+, DS720+)
docker build --platform linux/arm64 -t hash_tool:arm64 .

# Depuis SSH Synology ou via Portainer
docker run --rm \
  -v /volume1/data:/data:ro \
  -v /volume1/bases:/bases \
  -v /volume1/resultats:/resultats \
  hash_tool verify /bases/hashes.b3 /data
```

### Serveur Debian

Sur un serveur Debian, la méthode recommandée est le cron Docker pour une vérification nocturne automatique.

```bash
# /etc/cron.d/hash-integrity
0 3 * * * root docker run --rm \
  -v /srv/data:/data:ro \
  -v /srv/bases:/bases:ro \
  -v /srv/resultats:/resultats \
  hash_tool --quiet verify /bases/hashes.b3 /data \
  >> /var/log/hash-integrity.log 2>&1 \
  || mail -s "ALERTE intégrité $(hostname)" admin@example.com
```

---

## Maintenance

### Mise à jour de b3sum

La version de `b3sum` est contrôlée par `ARG B3SUM_VERSION=1.5.4` dans le Dockerfile. Pour mettre à jour, modifier uniquement cette ligne et rebuilder. La vérification cryptographique garantit l'intégrité du nouveau binaire.

```bash
docker build --build-arg B3SUM_VERSION=1.6.0 -t hash_tool .

# URLs des releases BLAKE3 officielles :
# https://github.com/BLAKE3-team/BLAKE3/releases
# Pattern binaire  : b3sum_linux_<arch>_musl
# Pattern signature : b3sum_linux_<arch>_musl.b3
```

### Build hors-ligne

Sur un NAS ou serveur sans accès à GitHub, le binaire `b3sum` peut être pré-téléchargé et copié directement dans le contexte de build.

```bash
# Sur une machine avec accès réseau
wget https://github.com/BLAKE3-team/BLAKE3/releases/download/1.5.4/b3sum_linux_amd64_musl

# Modifier le Dockerfile pour COPY au lieu de wget
COPY b3sum_linux_amd64_musl /usr/local/bin/b3sum
RUN chmod +x /usr/local/bin/b3sum
```

La vérification cryptographique reste applicable manuellement après la copie.

### Extension de l'image

| Évolution | Approche recommandée | Impact sur l'image |
|---|---|---|
| Rapport PDF | Ajouter `wkhtmltopdf` dans l'image | +30 Mo |
| Notifications email | Service dédié dans `docker-compose.yml` | Aucun |
| Export S3 | Script `lib/export.sh` + `awscli` dans image | +20 Mo |
| Interface web | Service séparé, hash_tool en dépendance | Aucun |

---

## Référence rapide

```bash
# Build standard
docker build -t hash_tool .

# Build ARM64
docker build --platform linux/arm64 -t hash_tool:arm64 .

# Aide / versions
docker run --rm hash_tool help
docker run --rm hash_tool version

# Compute
docker run --rm \
  -v /data:/data:ro -v /bases:/bases \
  hash_tool compute /data /bases/hashes_$(date +%Y-%m-%d).b3

# Verify
docker run --rm \
  -v /data:/data:ro -v /bases:/bases:ro -v /res:/resultats \
  hash_tool verify /bases/hashes.b3 /data

# Compare
docker run --rm \
  -v /bases:/bases:ro -v /res:/resultats \
  hash_tool compare /bases/old.b3 /bases/new.b3

# Pipeline
docker run --rm \
  -v /data:/data:ro -v /bases:/bases \
  -v /res:/resultats -v /pipe/pipeline.json:/pipelines/pipeline.json:ro \
  hash_tool runner

# Debug interactif
docker run --rm -it -v /data:/data hash_tool shell
```

### Fichiers du projet liés à Docker

| Fichier | Rôle |
|---|---|
| `Dockerfile` | Build multi-stage Alpine + b3sum + jq |
| `.dockerignore` | Exclusions du contexte de build |
| `docker/entrypoint.sh` | Dispatcher des commandes Docker |
| `docker-compose.yml` | Orchestration 3 services |
| `docs/reference/docker.md` | Ce document |


--- Fichier : docs/reference/integrity-sh.md ---
# Référence - `hash-tool` & `src/integrity.sh`

`hash-tool` est l'interface CLI unique. `src/integrity.sh` est le moteur interne pour `compute`, `verify`, `compare`. Les nouvelles commandes (`list`, `diff`, `stats`, `check-env`, `version`) sont gérées directement par `hash-tool`.

---

## Synopsis

```
hash-tool <commande> [options]
```

**Appel direct `integrity.sh` (non recommandé en usage courant) :**

```
./src/integrity.sh [--quiet] compute <dossier> <base.b3>
./src/integrity.sh [--quiet] verify  <base.b3> [dossier]
./src/integrity.sh [--quiet] compare <ancienne.b3> <nouvelle.b3>
```

---

## Commandes

### `compute`

Calcule les empreintes BLAKE3 de tous les fichiers d'un dossier. Génère un fichier `.b3` et un sidecar `.meta.json`.

```bash
hash-tool compute -data <dossier> [-save <dossier>] [-meta <texte>] [-quiet] [-readonly]
```

| Option | Requis | Description |
|---|---|---|
| `-data <dossier>` | Oui | Dossier à analyser. |
| `-save <dossier>` | Non | Dossier de sortie pour le `.b3` (défaut : répertoire courant). |
| `-meta <texte>` | Non | Commentaire stocké dans le sidecar `.meta.json`. |
| `-quiet` | Non | Supprime toute sortie terminal. |
| `-readonly` | Non | Documenté dans le sidecar (`parameters.readonly: true`). |

**Sortie :**

```
./bases/hashes_donnees.b3           ← empreintes BLAKE3
./bases/hashes_donnees.b3.meta.json ← sidecar métadonnées
Base enregistrée : ./bases/hashes_donnees.b3 (1247 fichiers)
Sidecar : ./bases/hashes_donnees.b3.meta.json
```

**Exit codes :**

| Code | Signification |
|---|---|
| `0` | Base calculée avec succès |
| `1` | Erreur (argument manquant, dossier introuvable, dossier vide) |

---

### `verify`

Vérifie l'intégrité d'un dossier à partir d'une base d'empreintes.

```bash
hash-tool verify -base <fichier.b3> [-data <dossier>] [-save <dossier>] [-quiet]
```

| Option | Requis | Description |
|---|---|---|
| `-base <fichier.b3>` | Oui | Base d'empreintes de référence. |
| `-data <dossier>` | Non | Dossier à vérifier. Défaut : répertoire courant au moment du `compute`. |
| `-save <dossier>` | Non | Dossier de sortie des résultats (surcharge `RESULTATS_DIR`). |
| `-quiet` | Non | Supprime la sortie terminal. Exit code propagé. |

**Fichiers produits :**

```
~/integrity_resultats/resultats_hashes_donnees/
├── recap.txt    ← statut, compteurs OK/FAIL
└── failed.txt   ← chemins FAILED (uniquement si echec)
```

**Exit codes :**

| Code | Signification |
|---|---|
| `0` | Tous les fichiers intègres |
| `1` | Au moins un fichier FAILED ou erreur `b3sum` |

!!! warning "Répertoire de travail"
    `verify` doit être lancé depuis le même répertoire qu'au `compute`, ou `-data` doit pointer vers ce répertoire. Les chemins dans `.b3` sont relatifs - un mauvais `pwd` produit des faux positifs massifs.

---

### `compare`

Compare deux bases d'empreintes et produit un rapport HTML.

```bash
hash-tool compare -old <ancienne.b3> -new <nouvelle.b3> [-save <dossier>]
```

| Option | Requis | Description |
|---|---|---|
| `-old <ancienne.b3>` | Oui | Ancienne base (référence). |
| `-new <nouvelle.b3>` | Oui | Nouvelle base (à comparer). |
| `-save <dossier>` | Non | Dossier de sortie des résultats. |

**Fichiers produits :**

```
~/integrity_resultats/resultats_hashes_avant/
├── recap.txt     ← compteurs : modifiés, disparus, nouveaux
├── modifies.b3   ← fichiers présents dans les deux bases avec hashes différents
├── disparus.txt  ← chemins dans ancienne, absents de nouvelle
├── nouveaux.txt  ← chemins dans nouvelle, absents d'ancienne
└── report.html   ← rapport HTML autonome (CSS inline, thème sombre)
```

**Exit codes :**

| Code | Signification |
|---|---|
| `0` | Comparaison effectuée (même si des différences existent) |
| `1` | Erreur technique |

!!! note
    `compare` retourne `0` même si des différences sont détectées. La présence de différences est une information, pas une erreur. Pour détecter des différences en script, vérifier si `modifies.b3`, `disparus.txt` ou `nouveaux.txt` sont non vides.

---

### `runner`

Exécute un pipeline JSON définissant une suite d'opérations.

```bash
hash-tool runner [-pipeline <fichier.json>] [-save <dossier>]
```

Voir [reference/runner-sh.md](runner-sh.md) pour la documentation complète du format pipeline.

---

### `list`

Liste toutes les bases `.b3` disponibles dans un dossier.

```bash
hash-tool list [-data <dossier>]
```

| Option | Description |
|---|---|
| `-data <dossier>` | Dossier à parcourir (défaut : répertoire courant). |

**Sortie (exemple) :**

```
=== Bases d'empreintes dans : ./bases ===

  hashes_donnees.b3                     1247 fichiers   2.1M [+meta]
     → Snapshot initial (2026-02-26T14:30:00Z)
  hashes_donnees_v2.b3                  1253 fichiers   2.2M [+meta]
     → Snapshot après migration (2026-02-27T09:00:00Z)
```

`[+meta]` indique la présence d'un sidecar `.meta.json`.

---

### `diff`

Affiche les différences entre une base d'empreintes et l'état actuel d'un dossier en termes de présence/absence de fichiers. Ne recalcule pas les hashes.

```bash
hash-tool diff -base <fichier.b3> [-data <dossier>]
```

| Option | Requis | Description |
|---|---|---|
| `-base <fichier.b3>` | Oui | Base de référence. |
| `-data <dossier>` | Non | Dossier courant à comparer (défaut : `.`). |

**Sortie (exemple) :**

```
=== DIFF : hashes_donnees.b3 vs ./donnees ===

  Fichiers disparus depuis la base : 2
    - ./donnees/archive/rapport-2023.pdf
    - ./donnees/temp/export.csv

  Nouveaux fichiers non indexés : 1
    + ./donnees/2026/rapport-q1.pdf
```

**Différence avec `compare` :** `diff` est instantané (pas de hachage), `compare` détecte aussi les modifications de contenu.

---

### `stats`

Affiche des statistiques sur une base d'empreintes.

```bash
hash-tool stats -base <fichier.b3>
```

**Sortie (exemple) :**

```
=== Statistiques : hashes_donnees.b3 ===

  Fichier base     : /opt/bases/hashes_donnees.b3
  Taille fichier   : 2.1M
  Fichiers indexés : 1247

  Extensions :
    .jpg           843 fichiers
    .pdf           201 fichiers
    .docx           89 fichiers
    .txt            67 fichiers
    (autres)        47 fichiers

--- Métadonnées (sidecar) ---
{
  "created_by": "hash-tool v2.0.0",
  "date": "2026-02-26T14:30:00Z",
  "comment": "Snapshot initial",
  "parameters": { "directory": "./donnees", "hash_algo": "blake3", "nb_files": 1247 }
}
-----------------------------
```

---

### `check-env`

Analyse l'environnement d'exécution et indique le mode sélectionné.

```bash
hash-tool check-env
```

**Sortie (exemple - environnement natif complet) :**

```
=== check-env : Analyse de l'environnement ===

  [OK] b3sum disponible : b3sum 1.5.4
  [OK] jq disponible : jq-1.7
  [OK] bash 5.2.15(1)-release
  [OK] integrity.sh présent et exécutable
  [OK] runner.sh présent et exécutable
  [--] Docker non disponible (optionnel)

  Mode d'exécution sélectionné : native
  → Exécution native active
```

---

### `version`

Affiche la version du logiciel.

```bash
hash-tool version
```

---

### `help`

```bash
hash-tool help              # aide globale
hash-tool help <commande>   # aide détaillée par sous-commande
```

---

## Options générales

| Option | Description |
|---|---|
| `-data <chemin>` | Dossier à analyser. |
| `-base <chemin>` | Fichier base d'empreintes (`.b3`). |
| `-old <chemin>` | Ancienne base (pour `compare`). |
| `-new <chemin>` | Nouvelle base (pour `compare`). |
| `-pipeline <chemin>` | Fichier pipeline JSON (pour `runner`). |
| `-save <chemin>` | Dossier de sortie pour les résultats. |
| `-meta <texte>` | Commentaire pour le sidecar JSON (`compute`). |
| `-quiet` | Mode silencieux - pas de sortie terminal. |
| `-verbose` | Mode verbeux. |
| `-readonly` | Marque le compute comme lecture seule dans le sidecar. |

---

## Variable d'environnement

### `RESULTATS_DIR`

| | |
|---|---|
| **Défaut** | `~/integrity_resultats` |
| **Scope** | `verify` et `compare` |

```bash
export RESULTATS_DIR=/srv/rapports
hash-tool verify -base hashes.b3
```

Peut aussi être surchargé via `-save` pour une commande unique.

### `HASH_TOOL_DOCKER_IMAGE`

| | |
|---|---|
| **Défaut** | `hash_tool` |
| **Scope** | `hash-tool` en mode Docker |

```bash
export HASH_TOOL_DOCKER_IMAGE=mon_registry/hash_tool:latest
hash-tool compute -data ./donnees -save ./bases
```

---

## Limites connues

| Scénario | Détecté ? | Remarque |
|---|---|---|
| Contenu de fichier modifié | **Oui** | Hash différent → `verify` FAILED, `compare` MODIFIÉS |
| Fichier supprimé | **Oui** | FAILED (`verify`) ou DISPARUS (`compare`) |
| Fichier ajouté | **Oui** (`compare`, `diff`) | Section NOUVEAUX |
| Dossier vide | **Non** | `find -type f` ignore les dossiers vides |
| Permissions / timestamps | **Non** | Seul le contenu binaire est haché |
| Fichier renommé | **Non** | Vu comme suppression + ajout |
| Clone bit-à-bit | **Non** | Hash identique par définition |
| Corruption de la base `.b3` | **Non** | La base n'est pas auto-protégée |

### Protéger la base `.b3`

```bash
b3sum hashes.b3 > hashes.b3.check
b3sum --check hashes.b3.check
```

---

## Dépendances techniques

| Outil | Usage |
|---|---|
| `b3sum` | Calcul et vérification des hashes BLAKE3 |
| `jq` | Sidecar JSON, pipelines |
| `find` | Parcours récursif du dossier |
| `sort` | Tri déterministe des chemins |
| `awk` | Conversion format `hash chemin` ↔ `chemin\thash` |
| `join` | Identification des fichiers modifiés |
| `comm` | Identification des disparus et nouveaux |
| `stat` | Taille de fichier pour le calcul ETA |
| `du` | Taille totale du dossier pour le calcul ETA |
| `mktemp` | Fichiers temporaires isolés dans `compare` |

--- Fichier : docs/reference/runner-sh.md ---
# Référence - `hash-tool runner` & pipeline JSON

Orchestrateur de pipeline pour exécuter plusieurs opérations en séquence.

**Scripts :** `hash-tool runner` (CLI unique) → `runner.sh` (implémentation)  
**Dépendance :** `jq`

---

## Synopsis

```bash
hash-tool runner [-pipeline <fichier.json>] [-save <dossier>]

# Ou directement :
./runner.sh [pipeline.json]
```

| Argument | Défaut | Description |
|---|---|---|
| `-pipeline` | `pipelines/pipeline.json` | Chemin vers le fichier de configuration du pipeline. |
| `-save` | `RESULTATS_DIR` | Dossier de résultats global (surcharge `RESULTATS_DIR`). |

---

## Pourquoi un runner

Lancer `integrity.sh` manuellement sur plusieurs dossiers est error-prone :

- Oublier le `cd` avant `compute` → chemins absolus dans la base
- Mauvais répertoire de travail pour `verify` → faux positifs massifs
- Ordre d'exécution non garanti sur des appels séparés

`runner.sh` élimine ces risques : il gère automatiquement les `cd`, valide les chemins avant exécution, et s'arrête immédiatement sur toute erreur (`set -euo pipefail`).

---

## Deux formats de pipeline

`runner.sh` supporte deux formats, **rétrocompatibles** et détectés automatiquement :

### Format legacy

Format d'origine, basé sur le champ `"op"`. Toujours fonctionnel.

```json
{
    "pipeline": [
        { "op": "compute", "source": "...", "bases": "...", "nom": "..." },
        { "op": "verify",  "source": "...", "base":  "..." },
        { "op": "compare", "base_a": "...", "base_b": "...", "resultats": "..." }
    ]
}
```

### Format étendu (recommandé)

Structure uniforme `type / params / options / meta / description`. Supporte toutes les commandes et le sidecar.

```json
{
    "pipeline": [
        {
            "type":        "compute",
            "params":      { "input": "...", "output_dir": "...", "filename": "..." },
            "options":     { "quiet": false, "verbose": false, "readonly": true },
            "meta":        { "comment": "Snapshot initial" },
            "description": "Texte explicatif de l'étape"
        }
    ]
}
```

Le format est détecté automatiquement par la présence de `"op"` (legacy) ou `"type"` (étendu).

---

## Opérations - Format legacy

### `compute`

```json
{
    "op":     "compute",
    "source": "/chemin/vers/dossier",
    "bases":  "/chemin/vers/dossier_bases",
    "nom":    "hashes.b3"
}
```

| Champ | Requis | Description |
|---|---|---|
| `op` | Oui | `"compute"` |
| `source` | Oui | Dossier à indexer. `runner.sh` fait `cd` dans ce dossier - chemins relatifs garantis dans la base. |
| `bases` | Oui | Dossier de destination pour le fichier `.b3`. Créé automatiquement si inexistant. |
| `nom` | Oui | Nom du fichier `.b3` à créer dans `bases`. |

### `verify`

```json
{
    "op":     "verify",
    "source": "/chemin/vers/dossier",
    "base":   "/chemin/vers/hashes.b3"
}
```

| Champ | Requis | Description |
|---|---|---|
| `op` | Oui | `"verify"` |
| `source` | Oui | Répertoire de travail d'origine (celui depuis lequel le `compute` a été fait). |
| `base` | Oui | Chemin complet du fichier `.b3`. |

### `compare`

```json
{
    "op":        "compare",
    "base_a":    "/chemin/vers/ancienne.b3",
    "base_b":    "/chemin/vers/nouvelle.b3",
    "resultats": "/chemin/vers/dossier_resultats"
}
```

| Champ | Requis | Description |
|---|---|---|
| `op` | Oui | `"compare"` |
| `base_a` | Oui | Ancienne base (référence). |
| `base_b` | Oui | Nouvelle base (à comparer). |
| `resultats` | Non | Dossier de destination des résultats. Surcharge `RESULTATS_DIR` pour ce seul bloc. |

---

## Opérations - Format étendu

### `compute`

```json
{
    "type": "compute",
    "params": {
        "input":      "/chemin/vers/dossier",
        "output_dir": "/chemin/vers/bases",
        "filename":   "hashes.b3"
    },
    "options": { "quiet": false, "readonly": true },
    "meta":    { "comment": "Snapshot avant migration" },
    "description": "Indexation du dossier source"
}
```

| Champ | Requis | Description |
|---|---|---|
| `params.input` | Oui | Dossier à indexer. |
| `params.output_dir` | Oui | Dossier de destination pour le `.b3`. Créé automatiquement. |
| `params.filename` | Oui | Nom du fichier `.b3`. |
| `options.quiet` | Non | Supprime la sortie terminal. Défaut : `false`. |
| `options.readonly` | Non | Documenté dans le sidecar. Défaut : `false`. |
| `meta.comment` | Non | Commentaire stocké dans le sidecar `.meta.json`. |
| `description` | Non | Documentation lisible dans le JSON. |

**Sidecar :** si `meta.comment` est fourni, un fichier `<filename>.meta.json` est généré à côté du `.b3`.

### `verify`

```json
{
    "type": "verify",
    "params": {
        "input": "/chemin/vers/dossier",
        "base":  "/chemin/vers/hashes.b3"
    },
    "options": { "quiet": false },
    "description": "Vérification d'intégrité"
}
```

| Champ | Requis | Description |
|---|---|---|
| `params.input` | Oui | Répertoire de travail d'origine. |
| `params.base` | Oui | Chemin du fichier `.b3`. |

### `compare`

```json
{
    "type": "compare",
    "params": {
        "reference":  "/chemin/vers/ancienne.b3",
        "input":      "/chemin/vers/nouvelle.b3",
        "output_dir": "/chemin/vers/dossier_resultats"
    },
    "options": { "quiet": false },
    "description": "Comparaison avant/après migration"
}
```

| Champ | Requis | Description |
|---|---|---|
| `params.reference` | Oui | Ancienne base (référence). |
| `params.input` | Oui | Nouvelle base (à comparer). |
| `params.output_dir` | Non | Dossier de résultats. Surcharge `RESULTATS_DIR` pour ce bloc. |

### `list`

```json
{
    "type": "list",
    "params": { "input_dir": "/chemin/vers/bases" },
    "description": "Lister les bases disponibles"
}
```

### `diff`

```json
{
    "type": "diff",
    "params": {
        "input":         "/chemin/vers/hashes.b3",
        "reference_dir": "/chemin/vers/dossier"
    },
    "description": "Différences entre base et dossier courant"
}
```

### `stats`

```json
{
    "type": "stats",
    "params": { "input": "/chemin/vers/hashes.b3" },
    "description": "Statistiques de la base"
}
```

### `check-env`

```json
{
    "type": "check-env",
    "params": {},
    "description": "Vérifier l'environnement d'exécution"
}
```

### `version`

```json
{
    "type": "version",
    "params": {},
    "description": "Afficher la version"
}
```

---

## Exemples complets

### Pipeline VeraCrypt multi-disques (format legacy)

```json
{
    "pipeline": [
        {
            "op":     "compute",
            "source": "/mnt/a/dossier_disque_1",
            "bases":  "/mnt/c/Users/TonNom/Desktop/bases",
            "nom":    "hashes_disque_1.b3"
        },
        {
            "op":     "compute",
            "source": "/mnt/i/dossier_disque_2",
            "bases":  "/mnt/c/Users/TonNom/Desktop/bases",
            "nom":    "hashes_disque_2.b3"
        },
        {
            "op":     "verify",
            "source": "/mnt/a/dossier_disque_1",
            "base":   "/mnt/c/Users/TonNom/Desktop/bases/hashes_disque_1.b3"
        },
        {
            "op":        "compare",
            "base_a":    "/mnt/c/Users/TonNom/Desktop/bases/hashes_disque_1.b3",
            "base_b":    "/mnt/c/Users/TonNom/Desktop/bases/hashes_disque_2.b3",
            "resultats": "/mnt/c/Users/TonNom/Desktop/rapports/compare_1_vs_2"
        }
    ]
}
```

### Pipeline complet avec sidecar (format étendu)

Voir `pipelines/pipeline-amelioree.json` pour un exemple complet couvrant toutes les commandes.

---

## Validation et messages d'erreur

`runner.sh` valide la configuration avant d'exécuter quoi que ce soit :

| Problème | Message |
|---|---|
| JSON invalide | `ERREUR : JSON invalide : /chemin/pipeline.json` |
| Clé `.pipeline` absente | `ERREUR : tableau .pipeline vide ou absent` |
| Champ requis manquant | `ERREUR : Bloc #2 : params.filename manquant ou vide.` |
| Type inconnu | `ERREUR : Bloc #3 : type inconnu : 'migrate'` |
| Dossier source introuvable | `ERREUR : Bloc #1 compute : dossier source introuvable : /mnt/a/...` |
| Base `.b3` introuvable | `ERREUR : Bloc #2 verify : base .b3 introuvable : /mnt/c/...` |
| `runner` imbriqué | `ERREUR : Bloc #1 : 'runner' imbriqué non supporté.` |

---

## Variables d'environnement

### `RESULTATS_DIR`

Dossier de résultats global pour tous les blocs `verify` et `compare` sans champ `output_dir` (format étendu) ou `resultats` (format legacy) explicite.

```bash
export RESULTATS_DIR=/srv/rapports
hash-tool runner -pipeline ./pipeline.json
```

Défaut : `~/integrity_resultats`.

---

## Exit codes

| Code | Signification |
|---|---|
| `0` | Pipeline exécuté entièrement sans erreur |
| `1` | Erreur sur un bloc (blocs suivants non exécutés) |

---

## Isolation des sous-shells

`runner.sh` utilise des sous-shells `( )` pour isoler les `cd` :

```bash
# Le cd ne fuite pas vers les blocs suivants
( cd "$source" && integrity.sh compute . "$bases/$nom" )
```

Chaque bloc `compute` et `verify` démarre dans le répertoire courant du processus principal, quels que soient les `cd` des blocs précédents. `RESULTATS_DIR` est de même isolé pour les blocs avec un champ `output_dir`/`resultats` explicite.

---

## Lancement depuis Windows (WSL)

```bat
@echo off
wsl bash /mnt/c/Users/TonNom/Desktop/hash_tool/runner.sh
pause
```

Avec pipeline explicite :

```bat
@echo off
wsl bash /mnt/c/Users/TonNom/Desktop/hash_tool/runner.sh ^
    /mnt/c/Users/TonNom/Desktop/mon-pipeline.json
pause
```

