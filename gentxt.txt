# === Arborescence du dossier ===

hash_tool
├== docs
│   ├== explication-run-tests.md
│   ├== manuel.md
│   ├== progression-eta.md
│   └== validation.md
├== src
│   ├== integrity.sh
│   └== run_tests.sh
├== test_mano
│   ├== destination
│   │   ├== fichier (1).txt
│   │   ├== fichier (2).txt
│   │   ├== fichier (3).txt
│   │   └== fichier (4).txt
│   └== source
│       ├== fichier (1).txt
│       ├== fichier (2).txt
│       ├== fichier (3).txt
│       └== fichier (4).txt
└== README.md


# === Contenu des fichiers ===

--- Fichier : README.md ---
# integrity.sh - Vérification d'intégrité BLAKE3

Détection de corruption silencieuse et d'erreurs de transfert sur disque, par hachage BLAKE3.

**Dépendances :** `b3sum`, `bash >= 4`, `find`, `sort`, `awk`, `comm`, `join`, `stat`, `du`

---

## Usage

```bash
# Créer une base de hachage pour un dossier
./integrity.sh compute ./mon_dossier hashes_2024-01-15.b3

# Vérifier l'intégrité actuelle contre une base
./integrity.sh verify  ./mon_dossier hashes_2024-01-15.b3

# Comparer deux bases (états historiques)
./integrity.sh compare hashes_2024-01-15.b3 hashes_2024-02-01.b3
```

---

## Arbre de décision rapide

| Situation | Commande |
|---|---|
| Première indexation | `compute` |
| Vérifier après transfert / stockage | `verify` |
| Comparer deux snapshots | `compare` |
| Contrôle ad hoc d'un fichier unique | `b3sum fichier.bin` |

---

## Structure du projet

```
integrity/
|-- README.md              ← ce fichier
|-- integrity.sh           ← script principal
|-- docs/
│   |-- manuel.md          ← référence technique complète
│   |-- progression-eta.md ← progression temps réel et estimation ETA
|-- tests/
    |-- validation.md      ← protocole de test et critères qualité
```

---

## Règles d'utilisation critiques

- Toujours utiliser des **chemins relatifs** (`find ./dossier`, jamais `/chemin/absolu`). Un chemin absolu rend la base inutilisable après déplacement ou remontage.
- Lancer `b3sum --check` depuis le **même répertoire de travail** qu'au moment du `compute`.
- Stocker la base `.b3` sur un **support distinct** des données à vérifier.
- Nommer les bases avec une **date explicite** : `hashes_2024-01-15.b3`, jamais `hashes_latest.b3`.


--- Fichier : test_mano/destination/fichier (1).txt ---
Contrary to popular belief, Lorem Ipsum is not simply random text. It has roots in a piece of classical Latin literature from 45 BC, making it over 2000 years old. Richard McClintock, a Latin professor at Hampden-Sydney College in Virginia, looked up one of the more obscure Latin words, consectetur, from a Lorem Ipsum passage, and going through the cites of the word in classical literature, discovered the undoubtable source. Lorem Ipsum comes from sections 1.10.32 and 1.10.33 of "de Finibus Bonorum et Malorum" (The Extremes of Good and Evil) by Cicero, written in 45 BC. This book is a treatise on the theory of ethics, very popular during the Renaissance. The first line of Lorem Ipsum, "Lorem ipsum dolor sit amet..", comes from a line in section 1.10.32.



--- Fichier : test_mano/destination/fichier (2).txt ---
There are many variations of passages of Lorem Ipsum available, but the majority have suffered alteration in some form, by injected humour, or randomised words which don't look even slightly believable. If you are going to use a passage of Lorem Ipsum, you need to be sure there isn't anything embarrassing hidden in the middle of text. All the Lorem Ipsum generators on the Internet tend to repeat predefined chunks as necessary, making this the first true generator on the Internet. It uses a dictionary of over 200 Latin words, combined with a handful of model sentence structures, to generate Lorem Ipsum which looks reasonable. The generated Lorem Ipsum is therefore always free from repetition, injected humour, or non-characteristic words etc.



--- Fichier : test_mano/destination/fichier (3).txt ---
Lorem Ipsum is simply dummy text of the printing and typesetting industry. Lorem Ipsum has been the industry's standard dummy text ever since the 1500s, when an unknown printer took a galley of type and scrambled it to make a type specimen book. It has survived not only five centuries, but also the leap into electronic typesetting, remaining essentially unchanged. It was popularised in the 1960s with the release of Letraset sheets containing Lorem Ipsum passages, and more recently with desktop publishing software like Aldus PageMaker including versions of Lorem Ipsum.



--- Fichier : test_mano/destination/fichier (4).txt ---
It is a long established fact that a reader will be distracted by the readable content of a page when looking at its layout. The point of using Lorem Ipsum is that it has a more-or-less normal distribution of letters, as opposed to using 'Content here, content here', making it look like readable English. Many desktop publishing packages and web page editors now use Lorem Ipsum as their default model text, and a search for 'lorem ipsum' will uncover many web sites still in their infancy. Various versions have evolved over the years, sometimes by accident, sometimes on purpose (injected humour and the like).



--- Fichier : test_mano/source/fichier (1).txt ---
Contrary to popular belief, Lorem Ipsum is not simply random text. It has roots in a piece of classical Latin literature from 45 BC, making it over 2000 years old. Richard McClintock, a Latin professor at Hampden-Sydney College in Virginia, looked up one of the more obscure Latin words, consectetur, from a Lorem Ipsum passage, and going through the cites of the word in classical literature, discovered the undoubtable source. Lorem Ipsum comes from sections 1.10.32 and 1.10.33 of "de Finibus Bonorum et Malorum" (The Extremes of Good and Evil) by Cicero, written in 45 BC. This book is a treatise on the theory of ethics, very popular during the Renaissance. The first line of Lorem Ipsum, "Lorem ipsum dolor sit amet..", comes from a line in section 1.10.32.

fichier modifié



--- Fichier : test_mano/source/fichier (2).txt ---
There are many variations of passages of Lorem Ipsum available, but the majority have suffered alteration in some form, by injected humour, or randomised words which don't look even slightly believable. If you are going to use a passage of Lorem Ipsum, you need to be sure there isn't anything embarrassing hidden in the middle of text. All the Lorem Ipsum generators on the Internet tend to repeat predefined chunks as necessary, making this the first true generator on the Internet. It uses a dictionary of over 200 Latin words, combined with a handful of model sentence structures, to generate Lorem Ipsum which looks reasonable. The generated Lorem Ipsum is therefore always free from repetition, injected humour, or non-characteristic words etc.



--- Fichier : test_mano/source/fichier (3).txt ---
Lorem Ipsum is simply dummy text of the printing and typesetting industry. Lorem Ipsum has been the industry's standard dummy text ever since the 1500s, when an unknown printer took a galley of type and scrambled it to make a type specimen book. It has survived not only five centuries, but also the leap into electronic typesetting, remaining essentially unchanged. It was popularised in the 1960s with the release of Letraset sheets containing Lorem Ipsum passages, and more recently with desktop publishing software like Aldus PageMaker including versions of Lorem Ipsum.



--- Fichier : test_mano/source/fichier (4).txt ---
It is a long established fact that a reader will be distracted by the readable content of a page when looking at its layout. The point of using Lorem Ipsum is that it has a more-or-less normal distribution of letters, as opposed to using 'Content here, content here', making it look like readable English. Many desktop publishing packages and web page editors now use Lorem Ipsum as their default model text, and a search for 'lorem ipsum' will uncover many web sites still in their infancy. Various versions have evolved over the years, sometimes by accident, sometimes on purpose (injected humour and the like).



--- Fichier : src/integrity.sh ---
#!/usr/bin/env bash
# integrity.sh - vérification d'intégrité par hachage BLAKE3
#
# Usage :
#   ./integrity.sh compute <dossier> <base.b3>
#   ./integrity.sh verify  <dossier> <base.b3>
#   ./integrity.sh compare <ancienne.b3> <nouvelle.b3>
#
# Dépendances : b3sum, find, sort, awk, comm, join, stat, du

set -euo pipefail

MODE=${1:-}
ARG2=${2:-}
ARG3=${3:-}

# == Fonctions =================================================================

# Calcule le hash BLAKE3 de chaque fichier du dossier cible, fichier par fichier,
# en affichant la progression et une estimation du temps restant (ETA).
# Usage : compute_with_progress <dossier> <hashfile>
compute_with_progress() {
  local target="$1"
  local hashfile="$2"

  local -a files
  mapfile -d '' files < <(find "$target" -type f -print0 | sort -z)

  local total_files=${#files[@]}
  local total_bytes
  total_bytes=$(du -sb "$target" | awk '{print $1}')

  local bytes_done=0
  local t_start
  t_start=$(date +%s)

  local i=0
  for file in "${files[@]}"; do
    b3sum "$file" >> "$hashfile"

    bytes_done=$(( bytes_done + $(stat -c%s "$file") ))
    i=$(( i + 1 ))

    local t_now elapsed
    t_now=$(date +%s)
    elapsed=$(( t_now - t_start ))

    if (( bytes_done > 0 && elapsed > 0 )); then
      local speed remaining
      speed=$(( bytes_done / elapsed ))
      remaining=$(( (total_bytes - bytes_done) / speed ))
      printf "\r[%d/%d] ETA : %dm %02ds   " \
        "$i" "$total_files" $(( remaining / 60 )) $(( remaining % 60 ))
    fi
  done

  printf "\r%*s\r" 40 ""  # effacer la ligne de progression
}

# == Dispatch ==================================================================

case "$MODE" in
  compute)
    TARGET=$ARG2
    HASHFILE=$ARG3
    compute_with_progress "$TARGET" "$HASHFILE"
    echo "Base enregistrée : $HASHFILE ($(wc -l < "$HASHFILE") fichiers)"
    ;;

  verify)
    HASHFILE=$ARG3
    b3sum --check "$HASHFILE"
    ;;

  compare)
    OLD=$ARG2
    NEW=$ARG3
    RAPPORT="rapport_$(date +%Y-%m-%d_%H%M%S).txt"
    {
      echo "Rapport de comparaison - $(date)"
      echo "Ancienne base : $OLD"
      echo "Nouvelle base : $NEW"
      echo ""
      sort -k2 "$OLD" > /tmp/_old.b3
      sort -k2 "$NEW" > /tmp/_new.b3

      echo "=== FICHIERS MODIFIÉS ==="
      join -1 2 -2 2 /tmp/_old.b3 /tmp/_new.b3 \
        | awk '$2 != $3 {print $1, "\n  ancien:", $3, "\n  nouveau:", $2}'

      echo ""
      echo "=== FICHIERS DISPARUS ==="
      comm -23 <(awk '{print $2}' /tmp/_old.b3) \
               <(awk '{print $2}' /tmp/_new.b3)

      echo ""
      echo "=== FICHIERS NOUVEAUX ==="
      comm -13 <(awk '{print $2}' /tmp/_old.b3) \
               <(awk '{print $2}' /tmp/_new.b3)

      rm /tmp/_old.b3 /tmp/_new.b3
    } | tee "$RAPPORT"
    echo "Rapport sauvegardé : $RAPPORT"
    ;;

  *)
    echo "Usage: $0 {compute|verify|compare} <args>"
    exit 1
    ;;
esac


--- Fichier : src/run_tests.sh ---
#!/usr/bin/env bash
# run_tests.sh - suite de tests automatisée pour integrity.sh
# Usage : ./run_tests.sh
# Prérequis : b3sum, stat, du installés ; integrity.sh dans le dossier parent

set -uo pipefail

# == Configuration ============================================================

SCRIPT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"
INTEGRITY="$SCRIPT_DIR/../integrity.sh"
WORKDIR="$(mktemp -d /tmp/integrity-test.XXXXXX)"

# == Couleurs =================================================================

GREEN='\033[0;32m'
RED='\033[0;31m'
YELLOW='\033[1;33m'
NC='\033[0m'

# == Compteurs ================================================================

PASS=0
FAIL=0
TOTAL=0

# == Helpers ==================================================================

pass() { echo -e "${GREEN}  PASS${NC} - $1"; ((PASS++)); ((TOTAL++)); }
fail() { echo -e "${RED}  FAIL${NC} - $1"; ((FAIL++)); ((TOTAL++)); }

assert_exit_zero() {
  local label="$1"; shift
  if "$@" > /dev/null 2>&1; then pass "$label"; else fail "$label"; fi
}

assert_exit_nonzero() {
  local label="$1"; shift
  if ! "$@" > /dev/null 2>&1; then pass "$label"; else fail "$label"; fi
}

assert_contains() {
  local label="$1"
  local pattern="$2"
  local output="$3"
  if echo "$output" | grep -q "$pattern"; then pass "$label"; else fail "$label (pattern: '$pattern' absent)"; fi
}

assert_not_contains() {
  local label="$1"
  local pattern="$2"
  local output="$3"
  if ! echo "$output" | grep -q "$pattern"; then pass "$label"; else fail "$label (pattern: '$pattern' présent mais ne devrait pas l'être)"; fi
}

assert_line_count() {
  local label="$1"
  local expected="$2"
  local file="$3"
  local actual
  actual=$(wc -l < "$file")
  if [ "$actual" -eq "$expected" ]; then pass "$label"; else fail "$label (attendu: $expected lignes, obtenu: $actual)"; fi
}

# == Setup ====================================================================

setup() {
  mkdir -p "$WORKDIR/data/sub"
  echo "contenu alpha"  > "$WORKDIR/data/alpha.txt"
  echo "contenu beta"   > "$WORKDIR/data/beta.txt"
  echo "contenu gamma"  > "$WORKDIR/data/gamma.txt"
  echo "contenu delta"  > "$WORKDIR/data/sub/delta.txt"
}

teardown() {
  rm -rf "$WORKDIR"
}

# == Tests ====================================================================

run_tests() {
  cd "$WORKDIR"

  echo ""
  echo "========================================"
  echo "  integrity.sh - suite de tests"
  echo "  Workdir : $WORKDIR"
  echo "========================================"
  echo ""

  # == T01 : Compute de base =================================================
  echo "T01 - Compute de base"
  bash "$INTEGRITY" compute ./data base_t01.b3 > /dev/null 2>&1
  assert_line_count "base_t01.b3 contient 4 lignes" 4 base_t01.b3

  local first_line
  first_line=$(head -1 base_t01.b3)
  assert_contains "ligne au format <hash>  <chemin>" "  ./data/" "$first_line"
  echo ""

  # == T02 : Verify sans modification =======================================
  echo "T02 - Verify sans modification"
  local out_t02
  out_t02=$(b3sum --check base_t01.b3 2>&1)
  assert_exit_zero    "exit code 0" b3sum --check base_t01.b3
  assert_not_contains "aucun FAILED"  "FAILED" "$out_t02"
  echo ""

  # == T03 : Verify après corruption ========================================
  echo "T03 - Verify après corruption d'un fichier"
  echo "contenu modifié" > data/beta.txt
  local out_t03
  out_t03=$(b3sum --check base_t01.b3 2>&1 || true)
  assert_exit_nonzero "exit code non nul"   b3sum --check base_t01.b3
  assert_contains     "beta.txt FAILED"     "FAILED" "$out_t03"
  # Restauration
  echo "contenu beta" > data/beta.txt
  echo ""

  # == T04 : Verify après suppression =======================================
  echo "T04 - Verify après suppression d'un fichier"
  rm data/gamma.txt
  local out_t04
  out_t04=$(b3sum --check base_t01.b3 2>&1 || true)
  assert_exit_nonzero "exit code non nul"    b3sum --check base_t01.b3
  assert_contains     "gamma.txt FAILED"     "FAILED" "$out_t04"
  # Restauration
  echo "contenu gamma" > data/gamma.txt
  echo ""

  # == T05 : Compare - aucune différence ====================================
  echo "T05 - Compare : aucune différence"
  bash "$INTEGRITY" compute ./data base_t05.b3 > /dev/null 2>&1
  local out_t05
  out_t05=$(bash "$INTEGRITY" compare base_t01.b3 base_t05.b3 2>&1)
  assert_not_contains "pas de fichiers modifiés"  "MODIFIÉS" "$(echo "$out_t05" | grep -v '===')"
  assert_not_contains "pas de fichiers disparus"  "DISPARUS" "$(echo "$out_t05" | grep -v '===')"
  assert_not_contains "pas de fichiers nouveaux"  "NOUVEAUX" "$(echo "$out_t05" | grep -v '===')"
  # Vérifier qu'un rapport a été créé
  local rapport_t05
  rapport_t05=$(ls rapport_*.txt 2>/dev/null | tail -1)
  if [ -n "$rapport_t05" ]; then pass "rapport horodaté créé"; else fail "rapport horodaté absent"; ((FAIL++)); ((TOTAL++)); fi
  echo ""

  # == T06 : Compare - fichier modifié ======================================
  echo "T06 - Compare : fichier modifié"
  echo "contenu beta modifié" > data/beta.txt
  bash "$INTEGRITY" compute ./data base_t06.b3 > /dev/null 2>&1
  local out_t06
  out_t06=$(bash "$INTEGRITY" compare base_t01.b3 base_t06.b3 2>&1)
  assert_contains "beta.txt dans MODIFIÉS" "beta.txt" "$out_t06"
  # Restauration
  echo "contenu beta" > data/beta.txt
  echo ""

  # == T07 : Compare - suppression + ajout ==================================
  echo "T07 - Compare : fichier supprimé + fichier ajouté"
  bash "$INTEGRITY" compute ./data base_t07_old.b3 > /dev/null 2>&1
  rm data/alpha.txt
  echo "contenu epsilon" > data/epsilon.txt
  bash "$INTEGRITY" compute ./data base_t07_new.b3 > /dev/null 2>&1
  local out_t07
  out_t07=$(bash "$INTEGRITY" compare base_t07_old.b3 base_t07_new.b3 2>&1)
  assert_contains "alpha.txt dans DISPARUS"  "alpha.txt"   "$out_t07"
  assert_contains "epsilon.txt dans NOUVEAUX" "epsilon.txt" "$out_t07"
  # Restauration
  echo "contenu alpha" > data/alpha.txt
  rm data/epsilon.txt
  echo ""

  # == T08 : Noms de fichiers avec espaces ===================================
  echo "T08 - Robustesse : nom de fichier avec espace"
  echo "contenu avec espace" > "data/fichier avec espace.txt"
  bash "$INTEGRITY" compute ./data base_t08.b3 > /dev/null 2>&1
  local out_t08
  out_t08=$(b3sum --check base_t08.b3 2>&1)
  assert_exit_zero    "exit code 0"   b3sum --check base_t08.b3
  assert_not_contains "aucun FAILED"  "FAILED" "$out_t08"
  rm "data/fichier avec espace.txt"
  echo ""

  # == T09 : Dossier vide ignoré (limite documentée) =========================
  echo "T09 - Limite : dossier vide ignoré"
  mkdir data/dossier_vide
  bash "$INTEGRITY" compute ./data base_t09.b3 > /dev/null 2>&1
  assert_not_contains "dossier_vide absent de la base" "dossier_vide" "$(cat base_t09.b3)"
  pass "comportement conforme à la documentation"
  rmdir data/dossier_vide
  echo ""

  # == T10 : Chemin absolu vs relatif =======================================
  echo "T10 - Chemin absolu vs relatif"
  find "$WORKDIR/data" -type f -print0 | sort -z | xargs -0 b3sum > base_absolu.b3
  find ./data          -type f -print0 | sort -z | xargs -0 b3sum > base_relatif.b3
  local first_abs first_rel
  first_abs=$(head -1 base_absolu.b3)
  first_rel=$(head -1 base_relatif.b3)
  assert_contains     "base absolue contient un chemin absolu"  "^/" "$first_abs" || true
  assert_contains     "base relative contient un chemin relatif" "\./data/" "$first_rel"
  assert_not_contains "bases non interchangeables" "$first_abs" "$first_rel"
  echo ""

  # == T11 : compute_with_progress - intégrité de la base produite ===========
  echo "T11 - ETA : la base produite est identique à une base de référence"
  # Base de référence produite sans progression (pipeline xargs direct)
  find ./data -type f -print0 | sort -z | xargs -0 b3sum > base_ref.b3
  # Base produite par compute_with_progress via le script
  bash "$INTEGRITY" compute ./data base_eta.b3 > /dev/null 2>&1
  # Les deux bases doivent être identiques ligne à ligne (ordre et contenu)
  assert_exit_zero "base ETA identique à la base de référence" diff base_ref.b3 base_eta.b3
  # La base ne doit contenir aucune ligne de progression parasite
  assert_not_contains "aucune ligne ETA dans la base" "ETA" "$(cat base_eta.b3)"
  assert_not_contains "aucun caractère de contrôle dans la base" $'\r' "$(cat base_eta.b3)"
  echo ""
}

# == Main =====================================================================

# Vérification des prérequis
if ! command -v b3sum &> /dev/null; then
  echo -e "${RED}ERREUR${NC} : b3sum non trouvé. Installer avec : cargo install b3sum  ou  apt install b3sum"
  exit 1
fi

if [ ! -f "$INTEGRITY" ]; then
  echo -e "${RED}ERREUR${NC} : integrity.sh introuvable à : $INTEGRITY"
  exit 1
fi

setup
run_tests
teardown

# == Rapport final =============================================================

echo "========================================"
if [ "$FAIL" -eq 0 ]; then
  echo -e "  ${GREEN}$PASS/$TOTAL tests passés${NC}"
else
  echo -e "  ${GREEN}$PASS${NC}/${TOTAL} passés - ${RED}$FAIL échec(s)${NC}"
fi
echo "========================================"
echo ""

[ "$FAIL" -eq 0 ]


--- Fichier : docs/explication-run-tests.md ---
# Explication du code - run_tests.sh

---

## Vue d'ensemble

`run_tests.sh` est une suite de tests automatisée pour `integrity.sh`. Elle n'utilise aucun framework externe - uniquement du bash pur. Elle crée un environnement isolé, exécute 10 cas de test, restaure l'état entre chaque cas, puis nettoie.

```
run_tests.sh
|-- Vérification des prérequis   (b3sum, integrity.sh)
|-- setup()                      création de l'environnement de test
|-- run_tests()                  exécution des 10 cas T01–T10
|-- teardown()                   suppression de l'environnement
|-- Rapport final                compteurs PASS/FAIL + exit code
```

---

## 1. Configuration et chemins

```bash
SCRIPT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"
INTEGRITY="$SCRIPT_DIR/../integrity.sh"
WORKDIR="$(mktemp -d /tmp/integrity-test.XXXXXX)"
```

- `SCRIPT_DIR` : répertoire absolu du script lui-même, indépendant du répertoire depuis lequel on l'appelle.
- `INTEGRITY` : chemin vers `integrity.sh` calculé relativement à `run_tests.sh` - les deux scripts peuvent être déplacés ensemble sans modifier les chemins en dur.
- `WORKDIR` : répertoire temporaire unique créé par `mktemp`. Le suffixe `XXXXXX` est remplacé par 6 caractères aléatoires - garantit l'isolation entre deux exécutions simultanées.

---

## 2. Système de comptage

```bash
PASS=0
FAIL=0
TOTAL=0

pass() { echo -e "${GREEN}  PASS${NC} - $1"; ((PASS++)); ((TOTAL++)); }
fail() { echo -e "${RED}  FAIL${NC} - $1"; ((FAIL++)); ((TOTAL++)); }
```

Deux compteurs indépendants `PASS` et `FAIL`, incrémentés par les fonctions `pass()` et `fail()`. Chaque assertion appelle l'une ou l'autre - jamais les deux. `TOTAL` permet de vérifier qu'aucun test n'a été sauté silencieusement.

---

## 3. Fonctions d'assertion

Chaque assertion encapsule un test élémentaire et appelle `pass()` ou `fail()` selon le résultat.

### `assert_exit_zero` / `assert_exit_nonzero`

```bash
assert_exit_zero() {
  local label="$1"; shift
  if "$@" > /dev/null 2>&1; then pass "$label"; else fail "$label"; fi
}
```

Exécute une commande et vérifie son code de retour. `> /dev/null 2>&1` supprime stdout et stderr - seul le code de retour importe ici. `shift` consomme le premier argument (`label`) pour que `"$@"` ne contienne que la commande à exécuter.

`assert_exit_nonzero` fait l'inverse : il attend un échec (code ≠ 0). Utilisé pour vérifier que `b3sum --check` détecte bien une corruption.

### `assert_contains` / `assert_not_contains`

```bash
assert_contains() {
  local label="$1"
  local pattern="$2"
  local output="$3"
  if echo "$output" | grep -q "$pattern"; then pass "$label"; else fail "$label"; fi
}
```

Cherche un pattern dans une chaîne déjà capturée (pas dans un fichier). Le résultat de la commande est capturé avant l'appel via `local out=$(commande)` - ce qui permet de l'inspecter plusieurs fois sans relancer la commande.

### `assert_line_count`

```bash
assert_line_count() {
  local expected="$2"
  local actual; actual=$(wc -l < "$3")
  if [ "$actual" -eq "$expected" ]; then pass "$label"; else fail "$label"; fi
}
```

Compte les lignes d'un fichier avec `wc -l`. La redirection `< fichier` (sans passer le nom à `wc`) évite que `wc` affiche le nom du fichier dans sa sortie.

---

## 4. Setup et teardown

```bash
setup() {
  mkdir -p "$WORKDIR/data/sub"
  echo "contenu alpha"  > "$WORKDIR/data/alpha.txt"
  echo "contenu beta"   > "$WORKDIR/data/beta.txt"
  echo "contenu gamma"  > "$WORKDIR/data/gamma.txt"
  echo "contenu delta"  > "$WORKDIR/data/sub/delta.txt"
}

teardown() {
  rm -rf "$WORKDIR"
}
```

`setup()` crée 4 fichiers avec contenu connu et déterministe - leurs hashes sont donc reproductibles d'une exécution à l'autre. `sub/delta.txt` teste la récursivité de `find` dans les sous-dossiers.

`teardown()` supprime le `WORKDIR` entier. Appelé en fin de script, même en cas d'échec partiel (voir section 6).

---

## 5. Structure d'un cas de test

Chaque cas suit le même schéma :

```bash
echo "T0X - Description"

# 1. Préparer l'état (modifier fichiers, créer bases...)
# 2. Exécuter la commande testée, capturer la sortie
local out; out=$(commande 2>&1 || true)
# 3. Lancer les assertions
assert_xxx "label" "pattern" "$out"
# 4. Restaurer l'état pour les tests suivants
echo "contenu original" > data/fichier.txt
echo ""
```

Le `|| true` après la commande capturée est critique : sans lui, si la commande retourne un code non nul (ex: `b3sum --check` sur un fichier corrompu), le mode `-e` du script parent interromprait l'exécution avant que l'assertion puisse enregistrer le résultat.

### T11 - Intégrité de la base produite par `compute_with_progress`

C'est le test critique post-intégration ETA. Il vérifie trois choses indépendantes :

1. La base produite par `compute_with_progress` est **bit-à-bit identique** à une base de référence produite par `find | sort | xargs b3sum` - via `diff`. Si un fichier est manquant, dupliqué, ou dans le mauvais ordre, `diff` le détecte.
2. La base ne contient **aucune ligne "ETA"** parasite - le `printf "\r..."` écrit sur le terminal (stderr implicite via `/dev/tty`), pas dans le fichier.
3. La base ne contient **aucun caractère `\r`** - garantit que la progression n'a pas pollué le flux d'écriture.

```bash
assert_exit_zero "base ETA identique à la base de référence" diff base_ref.b3 base_eta.b3
assert_not_contains "aucune ligne ETA dans la base" "ETA" "$(cat base_eta.b3)"
assert_not_contains "aucun caractère de contrôle dans la base" $'\r' "$(cat base_eta.b3)"
```

---

## 6. Vérification des prérequis

```bash
if ! command -v b3sum &> /dev/null; then
  echo -e "${RED}ERREUR${NC} : b3sum non trouvé."
  exit 1
fi

if [ ! -f "$INTEGRITY" ]; then
  echo -e "${RED}ERREUR${NC} : integrity.sh introuvable à : $INTEGRITY"
  exit 1
fi
```

Vérifié avant `setup()` - inutile de créer l'environnement de test si les outils sont absents. `command -v` est la méthode portable pour tester la présence d'un exécutable (préférable à `which`).

---

## 7. Exit code et intégration CI

```bash
[ "$FAIL" -eq 0 ]
```

Dernière ligne du script. Si `FAIL` vaut 0, l'expression est vraie → exit code 0. Si au moins un test a échoué → exit code 1. Ce comportement est exploitable directement dans un pipeline :

```bash
# Hook pre-commit git
./tests/run_tests.sh || exit 1

# Crontab - alerte si régression
0 3 * * * /opt/integrity/tests/run_tests.sh >> /var/log/integrity-tests.log 2>&1
```


--- Fichier : docs/manuel.md ---
# Manuel technique - Vérification d'intégrité de données

**Périmètre :** détection d'erreurs de transfert et de corruption silencieuse sur disque, sans adversaire.  
**Outils couverts :** b3sum (BLAKE3) · xxHash3 · find · diff · bash

---

## Table des matières

1. [Algorithmes de hachage](#1-algorithmes-de-hachage)
2. [Structure du fichier .b3](#2-structure-du-fichier-b3)
3. [Workflow : calcul, stockage, comparaison](#3-workflow--calcul-stockage-comparaison)
4. [Explication du script integrity.sh](#4-explication-du-script-integritysh)
5. [Performances et optimisation disque](#5-performances-et-optimisation-disque)
6. [Limites et angles morts](#6-limites-et-angles-morts)
7. [Référence rapide](#7-référence-rapide)
8. [Annexe - Alternatives et extensions](#8-annexe--alternatives-et-extensions)

---

## 1. Algorithmes de hachage

### Taxonomie

Deux familles distinctes, usages mutuellement exclusifs :

| Propriété | Cryptographique (BLAKE3) | Non-cryptographique (xxHash3) |
|---|---|---|
| Résistance collision intentionnelle | Oui - infaisable calculatoirement | Non - collisions construisibles |
| Résistance préimage | Oui | Non |
| Débit CPU (1 cœur) | ~1 Go/s | ~50 Go/s |
| Débit sur HDD (150 Mo/s) | Identique - disque impose le rythme | Identique |
| Débit sur SATA SSD (500 Mo/s) | Identique | Identique |
| Détection corruption accidentelle | Oui | Oui |
| Utilisable en sécurité | Oui | Non |

### Pourquoi BLAKE3 plutôt que xxHash3

xxHash3 est techniquement suffisant pour détecter des erreurs accidentelles. BLAKE3 est recommandé pour une seule raison : **le coût marginal sur disque est nul** - les deux sont limités par l'I/O. BLAKE3 reste utilisable si le besoin évolue vers un contexte de sécurité. Headroom gratuit.

```bash
# Si xxHash3 est préféré - workflow identique à b3sum
find ./dossier -type f -print0 | sort -z | xargs -0 xxh128sum > base.xxh
```

### Limitations spécifiques à ce workflow

- Ne hache pas les métadonnées (mtime, permissions) - comportement voulu ici, mais à connaître.
- Ne hache pas les dossiers vides : `find -type f` ne remonte que les fichiers réguliers.
- Sensible aux chemins : le fichier `.b3` encode les chemins tels qu'ils ont été passés à `b3sum`. Chemin absolu vs relatif → deux bases incompatibles pour la même donnée.

---

## 2. Structure du fichier .b3

b3sum produit un format texte simple, une ligne par fichier :

```
# Format : <hash>  <chemin>
# Deux espaces séparent le hash du chemin (convention b3sum/sha256sum)

a1b2c3d4e5f6a7b8c9d0e1f2a3b4c5d6e7f8a9b0c1d2e3f4a5b6c7d8e9f0a1b2  ./dossier/fichier.txt
e5f6a7b8c9d0e1f2a3b4c5d6e7f8a9b0c1d2e3f4a5b6c7d8e9f0a1b2c3d4e5f6  ./dossier/sous/autre.bin
```

**Taille du fichier .b3 :** chaque ligne fait ~130–200 octets selon la longueur des chemins.

| Nombre de fichiers | Taille approximative |
|---|---|
| 10 000 | ~2 Mo |
| 100 000 | ~20 Mo |
| 1 000 000 | ~200 Mo |

> **Règle absolue : chemins relatifs.** Toujours utiliser `find ./dossier` et non `find /chemin/absolu/dossier`. Un chemin absolu rend la base inutilisable après déplacement, remontage à un point différent, ou copie sur une autre machine.

---

## 3. Workflow : calcul, stockage, comparaison

### Calcul et enregistrement de la base

```bash
# Calcul de base - commande de référence
find ./mon_dossier -type f -print0 \
  | sort -z \
  | xargs -0 b3sum \
  > hashes_2024-01-15.b3

# Vérification immédiate : nombre de fichiers indexés
wc -l hashes_2024-01-15.b3
```

**Pourquoi `sort -z` :** `find` ne garantit pas un ordre déterministe - il dépend de l'ordre de parcours du filesystem (inode order sur ext4). Sans tri, deux exécutions consécutives peuvent produire des fichiers `.b3` dans des ordres différents, rendant la comparaison par `diff` bruyante et inutilisable.

**Pourquoi `-print0` / `-0` :** les noms de fichiers peuvent contenir des espaces, des retours à la ligne, ou des caractères spéciaux. `-print0` utilise le caractère nul comme séparateur, et `-0` dans `xargs` l'interprète. C'est la seule approche robuste.

### Vérification directe

`b3sum --check` relit les fichiers sur disque et compare leurs hashes à la base enregistrée.

```bash
# Lancer depuis le même répertoire de travail qu'au calcul
b3sum --check hashes_2024-01-15.b3

# Sortie en cas de succès :
# ./mon_dossier/fichier.txt: OK
# ./mon_dossier/sous/autre.bin: OK

# Sortie en cas d'échec :
# ./mon_dossier/sous/corrompu.bin: FAILED
# b3sum: WARNING: 1 computed checksum did NOT match

# Filtrer uniquement les échecs
b3sum --check hashes_2024-01-15.b3 2>&1 | grep FAILED
```

> **Contrainte critique : répertoire de travail.** `b3sum --check` résout les chemins relatifs depuis `pwd`. Si la base a été créée depuis `/data` et que la vérification est lancée depuis `/home`, tous les fichiers apparaissent manquants. Toujours exécuter depuis le répertoire parent du dossier à vérifier.

### Comparaison de deux bases .b3

Utile pour comparer deux états historiques sans avoir accès aux fichiers originaux (archive froide, backup distant).

```bash
# Diff brut - suffisant si les bases sont triées
diff <(sort hashes_2024-01-15.b3) <(sort hashes_2024-02-01.b3)

# Comparaison propre par fichier
sort -k2 hashes_2024-01-15.b3 > /tmp/_old.b3
sort -k2 hashes_2024-02-01.b3 > /tmp/_new.b3

# Fichiers dont le hash a changé
join -1 2 -2 2 /tmp/_old.b3 /tmp/_new.b3 \
  | awk '$2 != $3 {print $1, "\n  ancien:", $3, "\n  nouveau:", $2}'

# Fichiers disparus
comm -23 <(awk '{print $2}' /tmp/_old.b3) \
         <(awk '{print $2}' /tmp/_new.b3)

# Fichiers nouveaux
comm -13 <(awk '{print $2}' /tmp/_old.b3) \
         <(awk '{print $2}' /tmp/_new.b3)
```

**`join -1 2 -2 2` :** joint les deux fichiers sur la colonne 2 (nom de fichier), puis compare les colonnes 1 (hash). Les lignes où `$2 != $3` sont les fichiers dont le contenu a changé.

**`comm` :** compare deux flux triés ligne par ligne. `-23` retient les lignes exclusives au premier flux (disparus). `-13` retient les lignes exclusives au second (nouveaux).

---

## 4. Explication du script integrity.sh

### En-tête et mode strict

```bash
#!/usr/bin/env bash
set -euo pipefail
```

`set -euo pipefail` est le mode strict Bash :

- `-e` : le script s'arrête si une commande échoue.
- `-u` : erreur si une variable non initialisée est utilisée.
- `-o pipefail` : si une commande dans un pipeline échoue, le pipeline entier échoue.

### Lecture des arguments

```bash
MODE=${1:-}
ARG2=${2:-}
ARG3=${3:-}
```

Récupère les 3 arguments positionnels. `:-` donne une valeur vide par défaut si l'argument n'est pas fourni - évite une erreur en mode `-u`.

### Mode `compute`

Le mode `compute` délègue à `compute_with_progress`, fonction dédiée à l'indexation fichier par fichier avec affichage de la progression.

```bash
TARGET=$ARG2
HASHFILE=$ARG3
compute_with_progress "$TARGET" "$HASHFILE"
echo "Base enregistrée : $HASHFILE ($(wc -l < "$HASHFILE") fichiers)"
```

**Pourquoi une fonction séparée :** la logique de progression représente ~20 lignes. Les inliner dans le `case` dégraderait la lisibilité du dispatch sans apport. La fonction est nommée explicitement - son rôle est lisible sans lire son corps.

**Corps de `compute_with_progress` :**

```bash
compute_with_progress() {
  local target="$1"
  local hashfile="$2"

  local -a files
  mapfile -d '' files < <(find "$target" -type f -print0 | sort -z)

  local total_files=${#files[@]}
  local total_bytes
  total_bytes=$(du -sb "$target" | awk '{print $1}')

  local bytes_done=0
  local t_start
  t_start=$(date +%s)

  local i=0
  for file in "${files[@]}"; do
    b3sum "$file" >> "$hashfile"

    bytes_done=$(( bytes_done + $(stat -c%s "$file") ))
    i=$(( i + 1 ))

    local t_now elapsed
    t_now=$(date +%s)
    elapsed=$(( t_now - t_start ))

    if (( bytes_done > 0 && elapsed > 0 )); then
      local speed remaining
      speed=$(( bytes_done / elapsed ))
      remaining=$(( (total_bytes - bytes_done) / speed ))
      printf "\r[%d/%d] ETA : %dm %02ds   " \
        "$i" "$total_files" $(( remaining / 60 )) $(( remaining % 60 ))
    fi
  done

  printf "\r%*s\r" 40 ""  # effacer la ligne de progression
}
```

Points clés :

- `mapfile -d ''` charge les chemins dans un tableau en respectant le séparateur nul - gère les noms de fichiers avec espaces ou caractères spéciaux.
- `>> "$hashfile"` en append : chaque `b3sum "$file"` ajoute une ligne. Le fichier est créé vide implicitement à la première écriture.
- `stat -c%s` lit la taille en octets du fichier traité - opération metadata uniquement, sans relecture du contenu.
- `printf "\r..."` écrase la ligne courante sans sauter de ligne - la progression ne pollue pas stdout.
- `printf "\r%*s\r" 40 ""` efface proprement la ligne de progression avant le message final.

### Mode `verify`

```bash
HASHFILE=$ARG3
b3sum --check "$HASHFILE"
```

Délègue directement à `b3sum --check`. Simple, sans surcharge.

### Mode `compare`

Trie les deux bases sur le nom de fichier (colonne 2), puis produit trois sections : fichiers modifiés (hash différent), fichiers disparus (présents dans l'ancienne base, absents dans la nouvelle), fichiers nouveaux (absent dans l'ancienne, présents dans la nouvelle). Le rapport est à la fois affiché en terminal et sauvegardé via `tee`.

---

## 5. Performances et optimisation disque

### Le goulot est le disque, pas l'algorithme

Sur toute configuration réaliste, l'I/O disque est le facteur limitant. BLAKE3 (~1 Go/s/cœur) ne sera jamais le goulot sur HDD ou SATA SSD.

| Support | Débit typique | Temps lecture 2 To | BLAKE3 est goulot ? |
|---|---|---|---|
| HDD 7200 rpm | 100–150 Mo/s | 4–6 heures | Non |
| SATA SSD | 500 Mo/s | ~1 heure | Non |
| NVMe Gen3 | 2–3 Go/s | 12–17 min | Non (1 Go/s/cœur) |
| NVMe Gen4+ | 5–7 Go/s | 5–7 min | Possible |

**RAM :** b3sum + find + xargs consomment quelques mégaoctets. BLAKE3 traite les fichiers en streaming par chunks de 1 Ko - la taille des fichiers n'influence pas la consommation mémoire. 1 Go de RAM est largement suffisant.

### Stratégie HDD - séquentiel obligatoire

Un HDD est optimisé pour les accès séquentiels. Les accès concurrents cassent la séquentialité de lecture et imposent des déplacements mécaniques de tête coûteux. `xargs -P 4` sur HDD dégrade typiquement les performances de 30 à 50 %. La boucle fichier par fichier de `compute_with_progress` est séquentielle par construction - comportement optimal sur HDD.

Le disque est systématiquement le goulot. BLAKE3 (~1 Go/s/cœur) ne limite jamais sur HDD (100–150 Mo/s) ni sur SATA SSD (500 Mo/s). Sur NVMe Gen4+ (5–7 Go/s), BLAKE3 monothread peut devenir limitant - cas hors périmètre de ce workflow.

### Estimations de durée par volume

| Volume | HDD (150 Mo/s) | SATA SSD (500 Mo/s) | NVMe (3 Go/s) |
|---|---|---|---|
| 100 Go | ~11 min | ~3 min | ~34 sec |
| 500 Go | ~56 min | ~17 min | ~3 min |
| 1 To | ~1h 51min | ~34 min | ~6 min |
| 2 To | ~3h 42min | ~1h 8min | ~11 min |
| 10 To | ~18h 30min | ~5h 40min | ~57 min |

Durées indicatives, pipeline monothread. Sur SSD avec `-P 4`, diviser par 2–3.

---

## 6. Limites et angles morts

### Ce que ce workflow ne couvre pas

| Scénario | Détecté ? | Explication |
|---|---|---|
| Fichier corrompu (contenu modifié) | **Oui** | Hash différent → FAILED ou divergence dans compare |
| Fichier manquant | **Oui** | Absent de la nouvelle base ou FAILED (No such file) |
| Fichier ajouté | **Oui** (compare) | Section NOUVEAUX |
| Dossier vide ajouté/supprimé | **Non** | `find -type f` ignore les dossiers vides |
| Modification de permissions/timestamps | **Non** | b3sum ne hache que le contenu binaire |
| Fichier remplacé par un clone identique | **Non** | Hash identique - indétectable par définition |
| Corruption de la base .b3 elle-même | **Non** | La base n'est pas auto-protégée |
| Corruption pendant la lecture pour hachage | **Non** | Le hash reflète la donnée lue, corrompue ou non |

### Protéger la base de hash

La base `.b3` est le référentiel de confiance. Si elle est corrompue ou altérée, toute comparaison ultérieure est sans valeur.

- Stocker la base sur un support distinct des données à vérifier.
- Hacher la base elle-même et stocker ce méta-hash sur un troisième support (email, cloud, papier imprimé).
- Horodater les bases avec un schéma de nommage explicite : `hashes_2024-01-15.b3`, jamais `hashes_latest.b3`.
- En contexte critique, signer la base avec GPG.

```bash
# Protéger la base par son propre hash
b3sum hashes_2024-01-15.b3 > hashes_2024-01-15.b3.check

# Vérification ultérieure de l'intégrité de la base elle-même
b3sum --check hashes_2024-01-15.b3.check
```

### Le problème des renommages et changements de chemin

`b3sum --check` compare les chemins littéralement. Tout renommage de dossier ou changement de structure rompt la correspondance, même si les données sont intactes.

```bash
# Situation : dossier renommé entre compute et verify
# Calcul depuis :  ./mon_projet/
# Vérification :   ./projet_final/

b3sum --check base.b3
# Résultat : FAILED (No such file or directory) sur TOUS les fichiers
# Le hash est correct - c'est le chemin qui a changé.

# Solution : corriger les chemins dans la base avant vérification
sed 's|./mon_projet/|./projet_final/|g' base.b3 > base_corrigee.b3
b3sum --check base_corrigee.b3
```

---

## 7. Référence rapide

### Commandes essentielles

```bash
# Calcul de base (universel, HDD/SSD)
find ./dossier -type f -print0 | sort -z | xargs -0 b3sum > base.b3

# Vérification directe (état actuel vs base)
b3sum --check base.b3

# Filtrer uniquement les échecs
b3sum --check base.b3 2>&1 | grep FAILED

# Comparaison deux bases (script externe)
./integrity.sh compare ancienne.b3 nouvelle.b3

# Compter les fichiers indexés
wc -l base.b3

# Hacher un fichier unique
b3sum fichier.bin

# Protéger la base elle-même
b3sum base.b3 > base.b3.check
```

### Arbre de décision

| Situation | Mode | Commande |
|---|---|---|
| Première indexation | compute | `find \| sort \| xargs b3sum > base.b3` |
| Vérifier après transfert/stockage | verify | `b3sum --check base.b3` |
| Comparer deux archives | compare | `./integrity.sh compare old.b3 new.b3` |
| Contrôle rapide d'un seul fichier | ad hoc | `b3sum fichier.bin` |
| Rapport horodaté persistant | compare+log | `./integrity.sh compare old.b3 new.b3` |

---

## 8. Annexe - Alternatives et extensions

### A.1 Outils FIM si le besoin évolue vers la sécurité

Si le périmètre évolue vers une surveillance continue ou un contexte de sécurité active, les outils FIM dédiés remplacent ce workflow artisanal.

| Outil | Usage | Complexité | Pertinent si… |
|---|---|---|---|
| Tripwire | Audit système local, détection compromissions post-intrusion | Moyenne | Serveur Linux, conformité PCI-DSS/HIPAA |
| Samhain | FIM distribué, parc multi-hôtes, alertes SIEM | Élevée | Infrastructure d'entreprise |
| AIDE | Alternative open source à Tripwire | Moyenne | Remplacement direct de Tripwire |
| ZFS | Filesystem avec checksum natif sur chaque bloc | Faible (si migration possible) | Protection transparente sans workflow explicite |

La ligne de démarcation structurante : b3sum/xxHash3 sont des **primitives** - ils font ce qu'on leur demande, sans contexte. Tripwire et Samhain sont des **systèmes** - ils maintiennent un état de référence et détectent les dérives.

### A.2 Intégration dans un pipeline automatisé

```bash
# Crontab - vérification hebdomadaire automatique
0 2 * * 0 /opt/integrity.sh verify ./donnees /var/lib/integrity/base.b3 >> /var/log/integrity.log 2>&1

# Post-transfert rsync - vérification immédiate après copie
rsync -av source/ dest/ && b3sum --check base.b3

# Alerte email si des fichiers ont échoué
b3sum --check base.b3 2>&1 | grep FAILED | mail -s 'Alerte intégrité' admin@example.com
```


--- Fichier : docs/progression-eta.md ---
# Progression temps réel et estimation ETA

## Le problème

Le pipeline `find | sort | xargs b3sum` est une boîte noire : `b3sum` ne remonte aucune progression. Par défaut, le mode `compute` s'exécute en silence jusqu'à complétion - aucun indicateur de durée ni d'avancement.

---

## Pourquoi l'ETA nécessite de casser le pipeline `xargs`

Intercaler `pv` dans le pipeline existant est techniquement possible mais inutilisable ici : mesurer le débit sur un flux `cat | pv | b3sum` produit un hash global du flux concaténé, pas une ligne par fichier. Le fichier `.b3` résultant est invalide pour `--check` ou `compare`.

```bash
# Cette approche est invalide - ne pas utiliser
TOTAL=$(find "$TARGET" -type f -print0 | xargs -0 du -sb | awk '{sum+=$1} END {print sum}')
find "$TARGET" -type f -print0 | sort -z \
  | xargs -0 cat \
  | pv -s "$TOTAL" \
  | b3sum \
  > "$HASHFILE"
# Produit un hash unique du flux concaténé - inutilisable
```

La seule approche compatible avec le format `.b3` : remplacer `xargs` par une boucle bash explicite, fichier par fichier. Le contrôle de progression devient trivial. Le coût en performance est négligeable - le disque est le goulot, pas le shell.

---

## Implémentation finale : `compute_with_progress`

```bash
compute_with_progress() {
  local target="$1"
  local hashfile="$2"

  local -a files
  mapfile -d '' files < <(find "$target" -type f -print0 | sort -z)

  local total_files=${#files[@]}
  local total_bytes
  total_bytes=$(du -sb "$target" | awk '{print $1}')

  local bytes_done=0
  local t_start
  t_start=$(date +%s)

  local i=0
  for file in "${files[@]}"; do
    b3sum "$file" >> "$hashfile"

    bytes_done=$(( bytes_done + $(stat -c%s "$file") ))
    i=$(( i + 1 ))

    local t_now elapsed
    t_now=$(date +%s)
    elapsed=$(( t_now - t_start ))

    if (( bytes_done > 0 && elapsed > 0 )); then
      local speed remaining
      speed=$(( bytes_done / elapsed ))
      remaining=$(( (total_bytes - bytes_done) / speed ))
      printf "\r[%d/%d] ETA : %dm %02ds   " \
        "$i" "$total_files" $(( remaining / 60 )) $(( remaining % 60 ))
    fi
  done

  printf "\r%*s\r" 40 ""  # effacer la ligne de progression
}
```

**`mapfile -d ''`** au lieu de `FILES=($(find ...))` : la substitution de commande `$(...)` découpe sur les espaces et les retours à la ligne - les noms de fichiers avec espaces seraient cassés en plusieurs éléments. `mapfile -d ''` lit le flux nul-séparé produit par `-print0` et charge chaque chemin comme un élément distinct du tableau, sans ambiguïté.

---

## Mécanique de l'estimation

L'ETA repose sur trois mesures :

- **octets traités** - cumulés après chaque fichier via `stat -c%s`
- **octets totaux** - calculés une fois avant la boucle via `du -sb`
- **débit instantané** - `octets_traités / secondes_écoulées`

```
ETA = (octets_restants) / débit_moyen
    = (total - fait) / (fait / elapsed)
```

Le débit moyen converge après ~10–20 secondes de traitement. Avant ce seuil, l'ETA est instable - comportement identique à `rsync`, `cp --progress`, ou tout outil du même type. Ce n'est pas un défaut d'implémentation, c'est une contrainte statistique inhérente à toute estimation par extrapolation linéaire sur fenêtre courte.

---

## Coût du changement de stratégie

| | Pipeline `xargs` | Boucle bash (avec progression) |
|---|---|---|
| Débit sur HDD | Optimal | Identique - I/O impose le rythme |
| Débit sur SSD séquentiel | Optimal | Identique |
| Débit sur SSD `-P 4` | +20–40 % | Non applicable - boucle séquentielle |
| Progression temps réel | Non | Oui |
| ETA | Non | Oui |

**Cas où la boucle dégrade les performances :** SSD avec `-P 4`. Le parallélisme par `xargs` n'est pas reproductible en boucle bash sans complexité significative. Sur HDD - cas le plus courant pour de gros volumes - la différence est nulle.


--- Fichier : docs/validation.md ---
# Tests et validation - integrity.sh

**Niveau d'exigence :** production, admin système. Chaque cas doit être exécuté et son résultat vérifié explicitement.

---

## Environnement de test

```bash
# Créer un environnement de test isolé
mkdir -p /tmp/integrity-test/{data,output}
cd /tmp/integrity-test

# Créer des fichiers de test avec contenu connu
echo "contenu alpha" > data/alpha.txt
echo "contenu beta"  > data/beta.txt
echo "contenu gamma" > data/gamma.txt
mkdir -p data/sub
echo "contenu delta" > data/sub/delta.txt
```

---

## Cas de test

### T01 - Compute de base

```bash
./integrity.sh compute ./data base_t01.b3
```

**Résultat attendu :**

- Fichier `base_t01.b3` créé avec 4 lignes (une par fichier).
- Message `Base enregistrée : base_t01.b3 (4 fichiers)`.
- Chaque ligne au format `<hash64chars>  ./data/<chemin>`.

```bash
# Vérification
wc -l base_t01.b3           # → 4
head -1 base_t01.b3         # → hash + chemin lisibles
```

---

### T02 - Verify sans modification

```bash
b3sum --check base_t01.b3
```

**Résultat attendu :** 4 lignes `OK`, aucun `FAILED`, exit code 0.

```bash
echo $?   # → 0
```

---

### T03 - Verify après corruption d'un fichier

```bash
echo "contenu modifié" > data/beta.txt
b3sum --check base_t01.b3
```

**Résultat attendu :**

- `./data/beta.txt: FAILED`
- `b3sum: WARNING: 1 computed checksum did NOT match`
- Exit code non nul.

```bash
echo $?   # → 1
b3sum --check base_t01.b3 2>&1 | grep FAILED   # → ./data/beta.txt: FAILED
```

---

### T04 - Verify après suppression d'un fichier

```bash
# Restaurer l'état T01 d'abord
echo "contenu beta" > data/beta.txt

# Supprimer un fichier
rm data/gamma.txt
b3sum --check base_t01.b3
```

**Résultat attendu :**

- `./data/gamma.txt: FAILED` (No such file or directory)
- Exit code non nul.

---

### T05 - Compare : aucune différence

```bash
# Restaurer l'état T01
echo "contenu gamma" > data/gamma.txt

# Créer une seconde base identique
./integrity.sh compute ./data base_t05.b3
./integrity.sh compare base_t01.b3 base_t05.b3
```

**Résultat attendu :** sections `MODIFIÉS`, `DISPARUS`, `NOUVEAUX` toutes vides. Rapport sauvegardé.

---

### T06 - Compare : fichier modifié

```bash
echo "contenu beta modifié" > data/beta.txt
./integrity.sh compute ./data base_t06.b3
./integrity.sh compare base_t01.b3 base_t06.b3
```

**Résultat attendu :**

- Section `FICHIERS MODIFIÉS` contient `./data/beta.txt` avec ancien et nouveau hash.
- Sections `DISPARUS` et `NOUVEAUX` vides.

---

### T07 - Compare : fichier supprimé + fichier ajouté

```bash
# Repartir d'une base propre
echo "contenu beta" > data/beta.txt
./integrity.sh compute ./data base_t07_old.b3

# Modifier l'état
rm data/alpha.txt
echo "contenu epsilon" > data/epsilon.txt
./integrity.sh compute ./data base_t07_new.b3

./integrity.sh compare base_t07_old.b3 base_t07_new.b3
```

**Résultat attendu :**

- `DISPARUS` : `./data/alpha.txt`
- `NOUVEAUX` : `./data/epsilon.txt`
- `MODIFIÉS` : vide

---

### T08 - Robustesse : fichier avec espace dans le nom

```bash
echo "contenu avec espace" > "data/fichier avec espace.txt"
./integrity.sh compute ./data base_t08.b3
b3sum --check base_t08.b3
```

**Résultat attendu :** tous les fichiers `OK`, y compris `fichier avec espace.txt`.

---

### T09 - Robustesse : dossier vide (limite connue)

```bash
mkdir data/dossier_vide
./integrity.sh compute ./data base_t09.b3
```

**Résultat attendu :** `dossier_vide` absent de `base_t09.b3`. Comportement normal et documenté - `find -type f` n'indexe pas les dossiers vides.

---

### T10 - Chemin absolu vs relatif (piège critique)

```bash
# Calculer avec chemin absolu - mauvaise pratique
b3sum $(find /tmp/integrity-test/data -type f) > base_absolu.b3
head -1 base_absolu.b3   # → chemin absolu /tmp/integrity-test/data/...

# Calculer avec chemin relatif - bonne pratique
cd /tmp/integrity-test
find ./data -type f -print0 | sort -z | xargs -0 b3sum > base_relatif.b3
head -1 base_relatif.b3  # → chemin relatif ./data/...
```

**Résultat attendu :** les deux bases sont incompatibles entre elles. Confirme que les chemins absolus cassent la portabilité.

---

## Nettoyage

```bash
rm -rf /tmp/integrity-test
```

---

## Critères de qualité globaux

| Critère | Exigence |
|---|---|
| Détection corruption | 100 % des fichiers modifiés détectés (T03) |
| Détection suppression | 100 % des fichiers manquants détectés (T04) |
| Faux positifs | Zéro - verify sur base intacte = 100 % OK (T02) |
| Noms avec espaces | Traités sans erreur (T08) |
| Rapport compare | Sauvegardé sur disque, horodaté (T05–T07) |
| Exit code | Non nul si au moins un FAILED (T03, T04) |
| Mode strict `-euo pipefail` | Le script s'arrête sur toute erreur non gérée |


