# === Arborescence du dossier ===

hash_tool
├── docs
│   ├── explication-run-tests.md
│   ├── manuel.md
│   └── progression-eta.md
├── mon_dossier
│   ├── bases
│   ├── destination
│   │   ├── fichier (1).txt
│   │   ├── fichier (2).txt
│   │   ├── fichier (3).txt
│   │   └── fichier (4).txt
│   ├── result
│   └── source
│       ├── fichier (1).txt
│       ├── fichier (2).txt
│       ├── fichier (3).txt
│       └── fichier (4).txt
├── tests
│   ├── run_tests.sh
│   ├── run_tests_pipeline.sh
│   └── validation.md
├── CHANGELOG.md
├── README.md
├── integrity.sh
├── pipeline full.json
├── pipeline.json
├── runner.sh
└── temp.txt


# === Contenu des fichiers ===

--- Fichier : CHANGELOG.md ---
# Changelog — hash_tool / integrity.sh


# Changelog — hash_tool / integrity.sh


## [0.10] — Pipeline JSON + tests pipeline

### Modifié

- `pipeline.json` (ex `config.txt`) : format migré de la syntaxe custom vers JSON standard. Champ `op` remplace les noms de blocs. Parsé par `jq` — validation syntaxique native, interopérable avec tout outil JSON.
- `runner.sh` : réécriture du parser. Suppression du parser bash custom (`IFS`, regex, `local -n`). Remplacement par `jq` pour l'extraction des champs. Validation JSON en entrée (`jq empty`), détection des champs manquants et des opérations inconnues avec messages d'erreur explicites incluant le numéro de bloc.

### Ajouté

- `tests/run_tests_pipeline.sh` : suite de tests dédiée au pipeline. 12 cas TP01–TP12.

### Format pipeline.json

```json
{
    "pipeline": [
        {
            "op":     "compute",
            "source": "/mnt/a/dossier",
            "bases":  "/mnt/c/bases",
            "nom":    "hashes.b3"
        },
        {
            "op":     "verify",
            "source": "/mnt/a/dossier",
            "base":   "/mnt/c/bases/hashes.b3"
        },
        {
            "op":     "compare",
            "base_a": "/mnt/c/bases/hashes_1.b3",
            "base_b": "/mnt/c/bases/hashes_2.b3"
        }
    ]
}
```

### Couverture run_tests_pipeline.sh

| Cas | Description |
|---|---|
| TP01 | JSON invalide — erreur propre sans stacktrace jq |
| TP02 | Clé `.pipeline` absente |
| TP03 | Champ manquant dans un bloc (`nom`) |
| TP04 | Opération inconnue |
| TP05 | Compute — cd correct, chemins relatifs dans la base, comptage fichiers |
| TP06 | Compute — dossier source absent |
| TP07 | Verify — bon répertoire de travail, OK détecté |
| TP08 | Verify — corruption détectée |
| TP09 | Verify — base .b3 absente |
| TP10 | Compare — fichiers de résultats produits |
| TP11 | Compare — base_a absente |
| TP12 | Pipeline complet compute + verify + compare |

---


## [0.9] — Pipeline batch : runner.sh + config.txt

### Ajouté

- `runner.sh` : exécuteur de pipeline batch. Lit `config.txt`, parse les blocs `compute`, `verify`, `compare` et appelle `integrity.sh` avec les arguments corrects. Gère le `cd` automatique avant chaque `compute` et `verify` pour garantir des chemins relatifs dans les bases `.b3`.
- `config.txt` : déclaration du pipeline au format structuré `pipeline = { ... }`. Chaque opération est un bloc nommé avec des champs `clé = "valeur"`. Supporte les commentaires `#` et les lignes vides.
- `runner.bat` : lanceur Windows pour double-clic depuis le bureau. Appelle `runner.sh` via WSL. Paramètre `pause` final pour garder la fenêtre ouverte.

### Format config.txt

```
pipeline = {

    compute {
        source = "/mnt/a/dossier",
        bases  = "/mnt/c/bases",
        nom    = "hashes.b3"
    }

    verify {
        source = "/mnt/a/dossier",
        base   = "/mnt/c/bases/hashes.b3"
    }

    compare {
        base_a = "/mnt/c/bases/hashes_1.b3",
        base_b = "/mnt/c/bases/hashes_2.b3"
    }

}
```

### Comportement runner.sh

- `compute` : `cd` dans `source`, puis `integrity.sh compute . bases/nom` — chemin relatif garanti.
- `verify` : `cd` dans `source`, puis `integrity.sh verify base` — répertoire de travail correct.
- `compare` : appel direct `integrity.sh compare base_a base_b`.
- Crée `bases/` automatiquement si inexistant (`mkdir -p`).
- `set -e` : arrêt immédiat sur toute erreur.

---

## [0.8] — Fonctionnalité batch_compute.sh

### Ajouté

- `batch_compute.sh` : permet de lancer plusieurs commandes `compute` avec un seul script. Remplacé par `runner.sh` + `config.txt` dans la version 0.9.


---

## [0.7] — Robustesse compare : chemins avec espaces

### Corrigé
- `integrity.sh`
  - Bug critique dans `run_compare()` : `sort -k2,2`, `join -1 2 -2 2` et `awk '{print $2}'` utilisent le blanc comme séparateur de champ. Un chemin contenant des espaces est fragmenté en plusieurs champs, ce qui corrompt le tri, le join et l'extraction — produisant des faux positifs massifs (ex. 26569 modifiés pour 163 fichiers dont 1 seul a changé).
  - Correction : conversion préalable de chaque ligne en `chemin\thash` via `awk '{ print substr($0,67) "\t" substr($0,1,64) }'` — le hash b3sum étant toujours exactement 64 caractères, l'offset 67 est garanti par le format. Toutes les opérations suivantes utilisent `-t $'\t'` comme séparateur explicite : `sort -t $'\t' -k1,1`, `join -t $'\t' -1 1 -2 1`, `cut -f1`.
  - `modifies.b3` : format de sortie préservé (`hash  chemin`) via `awk -F $'\t' '$2 != $3 { print $3 "  " $1 }'`.

## [0.6] — Robustesse et mode silencieux

### Ajouté
- `integrity.sh`
  - Flag `--quiet` : supprime toute sortie terminal, écrit uniquement dans les fichiers de résultats (`recap.txt`, `failed.txt`). Exit code propagé pour usage CI/cron.
  - Fonction `say()` : point d'entrée unique pour toute sortie terminal, désactivée si `--quiet`.
  - Fonction `file_size()` : abstraction portable `stat -c%s` (GNU/Linux) / `stat -f%z` (BSD/macOS).
  - Vérification version bash en tête de script : `bash >= 4` requis, exit explicite avec message si non respecté.
  - `make_result_dir()` : horodatage automatique des dossiers de résultats en cas de collision (`_YYYYMMDD-HHMMSS`), plus d'écrasement silencieux.
  - `trap EXIT` dans `run_compare()` : nettoyage garanti des fichiers temporaires même en cas d'erreur intermédiaire.
  - Redirection ETA sur `/dev/tty` dans `compute_with_progress()` : garantit que la progression n'est jamais écrite dans le fichier `.b3`.
- `tests/run_tests.sh`
  - `set -euo pipefail` : mode strict complet activé (ajout de `-e`).
  - Fonction `assert_file_absent()` : helper dédié pour les assertions d'absence de fichier.
  - T00 : ShellCheck sur `integrity.sh` et `run_tests.sh` (SKIP propre si non installé).
  - T12 : couverture exhaustive du mode `--quiet` (stdout vide, fichiers produits, exit code propagé).
  - T13 : vérifie l'horodatage automatique des dossiers de résultats sur collision.
  - T14 : détection d'un argument `[dossier]` invalide pour `verify`.
- `README.md`
  - Section `--quiet` avec exemples CI/cron.
  - Section Tests avec instructions d'exécution et comptage des cas (14 tests).
  - Mention horodatage automatique dans l'arborescence des résultats.

### Modifié
- `integrity.sh`
  - `assert_target_valid()` : `find -print0 | grep -zc ''` au lieu de `find | wc -l` — robuste aux noms de fichiers contenant des newlines.
  - `run_verify()` : comptage de lignes via `grep -c '^'` au lieu de `grep -c '.'` — correction du bug de comptage sur flux vide.
  - `run_compare()` : `sort -k2,2` au lieu de `sort -k2` — clé de tri limitée strictement au champ chemin, sans déborder sur le hash.
  - `run_verify()` : propagation de l'exit code de `b3sum --check` via `return $exit_code` — utilisable en scripting avec `|| alert`.
  - `failed.txt` : suppression explicite via `rm -f` si `nb_failed == 0` après une vérification OK suivant un échec précédent.
- `tests/run_tests.sh`
  - Résolution dynamique des `outdir` via `ls -d ... | tail -1` : compatible avec l'horodatage des dossiers de résultats.
  - T02, T03, T05, T06, T07 : assertions adaptées à la résolution dynamique des dossiers.
- `README.md`
  - Dépendances : mention explicite de `bash >= 4`.
  - Usage : exemple `--quiet` ajouté.

### Corrigé
- `integrity.sh`
  - Bug comptage lignes dans `run_verify()` : `grep -c '.'` sur flux vide retournait 0 mais ne capturait pas correctement les lignes non vides. Remplacé par `grep -c '^'`.
  - Bug tri ambigü dans `run_compare()` : `sort -k2` triait du champ 2 à la fin de ligne, incluant potentiellement le hash. `sort -k2,2` limite la clé au seul champ 2.
  - Bug nettoyage tmpfiles : `run_compare()` laissait des fichiers temporaires en cas d'erreur intermédiaire. Ajout de `trap 'rm -f ...' EXIT`.
  - Bug portabilité `stat` : `stat -c%s` est GNU-only. Ajout de `file_size()` avec fallback BSD `stat -f%z`.
  - Bug comptage fichiers avec newlines : `assert_target_valid()` utilisait `find | wc -l`. Corrigé avec `find -print0 | grep -zc ''`.
- `tests/run_tests.sh`
  - T10 : pattern `"^/"` remplacé par `"  /"` — `grep` opérait sur une chaîne, l'ancre `^` ne matchait pas la deuxième colonne.

---

## [0.5] — Documentation

### Modifié
- `README.md` — règle répertoire de travail pour `verify` précisée : l'argument `[dossier]` est le répertoire d'origine du compute, pas le dossier haché. Exemples correct/incorrect ajoutés.
- `docs/manuel.md` — section `verify` mise à jour avec le même avertissement et les exemples.

---

## [0.4] — Gardes-fous et signalisation des erreurs

### Modifié
- `integrity.sh`
  - Ajout de `die()` : point de sortie unique pour toutes les erreurs, message sur stderr.
  - Ajout de `assert_b3_valid()` : vérifie existence, type fichier, non-vide, format b3sum valide.
  - Ajout de `assert_target_valid()` : vérifie existence du dossier cible et présence d'au moins un fichier.
  - Validation explicite des arguments dans chaque branche du `case` avant tout traitement.
  - `verify` accepte un argument optionnel `[dossier]` : fait `cd` avant `b3sum --check`.
  - Résolution du chemin absolu du `.b3` avant `cd` (correction bug : chemin relatif invalide après changement de répertoire).
  - `RESULTATS_DIR` : `${RESULTATS_DIR:-...}` au lieu d'assignation inconditionnelle — respecte la valeur exportée par l'environnement (fix tests).
  - Suppression de `local hashfile_abs` hors fonction (illégal en bash hors contexte fonction).
  - `run_verify()` : refonte de la signalisation.
    - Trois états distincts : `OK`, `ECHEC`, `ERREUR`.
    - Terminal : affichage sobre si OK, bloc `████` visible si échec ou erreur.
    - `recap.txt` : compteur `FAILED` affiché uniquement si > 0 ; section erreurs b3sum séparée.
    - `failed.txt` : créé uniquement si `nb_failed > 0` ou erreurs b3sum présentes. Supprimé si tout est OK.
- `tests/run_tests.sh`
  - T02 : assertion `failed.txt absent si 0 échec` (logique inversée par rapport à l'ancienne version).
  - T03 : patterns mis à jour (`ECHEC`, `FAILED`) alignés sur le nouveau format de sortie.

---

## [0.3] — Dossiers de résultats (verify et compare)

### Modifié
- `integrity.sh`
  - Ajout de `RESULTATS_DIR` (configurable, défaut `~/integrity_resultats`).
  - Ajout de `make_result_dir()` : crée `resultats_<nom_base>/` sous `RESULTATS_DIR`.
  - `verify` : délègue à `run_verify()` — produit `recap.txt` et `failed.txt`.
  - `compare` : délègue à `run_compare()` — produit `recap.txt`, `modifies.b3`, `disparus.txt`, `nouveaux.txt`.
  - Fichiers temporaires de `compare` passent par `mktemp` (plus de `/tmp/_old.b3` en dur).
  - Signature `verify` simplifiée : `<base.b3>` uniquement (le dossier n'était pas utilisé par `b3sum --check`).
- `README.md` — usage `verify` et `compare` mis à jour ; section Configuration ajoutée avec arbre des fichiers produits.
- `docs/manuel.md` — sections `verify` et `compare` mises à jour ; arbre de décision et référence rapide alignés.
- `tests/run_tests.sh`
  - `RESULTATS_DIR` exporté vers `WORKDIR` pour isoler les résultats des tests.
  - Ajout de `assert_file_exists()`.
  - T02–T07 : assertions sur la présence et le contenu des fichiers de résultats.

---

## [0.2] — Intégration ETA et tests automatisés

### Modifié
- `integrity.sh`
  - Suppression de `detect_parallelism()` et de la logique SSD/parallélisme (hors périmètre HDD gros volumes).
  - Mode `compute` : délègue à `compute_with_progress()`.
  - Ajout de `compute_with_progress()` : boucle fichier par fichier avec affichage progression et ETA.
    - `mapfile -d ''` remplace `FILES=($(find ...))` — gestion correcte des noms avec espaces.
    - `printf "\r%*s\r"` efface proprement la ligne de progression avant le message final.
  - `df` retiré des dépendances.
- `README.md` — dépendances mises à jour (`df` supprimé, `stat` et `du` ajoutés).
- `docs/manuel.md`
  - Section `detect_parallelism` supprimée.
  - Section `compute` réécrite autour de `compute_with_progress`.
  - Section performances : stratégie SSD/NVMe retirée, focus HDD séquentiel.
- `docs/progression-eta.md` — implémentation finale documentée ; note `mapfile -d ''` vs substitution de commande.
- `tests/run_tests.sh` — T11 ajouté : vérifie que la base produite par `compute_with_progress` est bit-à-bit identique à une base de référence, sans artefact ETA ni `\r`.
- `docs/explication-run-tests.md` — comptage corrigé (10 → 11 cas) ; section T11 ajoutée.

### Corrigé
- `tests/run_tests.sh` T10 : pattern `"^/"` remplacé par `"  /"` — `grep` opère sur une chaîne, pas un fichier, l'ancre `^` ne matchait pas la deuxième colonne.

---

## [0.1] — Structure initiale du projet

### Ajouté
- `integrity.sh` — script principal BLAKE3 avec trois modes : `compute`, `verify`, `compare`.
  - `set -euo pipefail` — mode strict.
  - `detect_parallelism()` — détection SSD/HDD via `/sys/block/.../queue/rotational`.
  - Mode `compute` : pipeline `find | sort -z | xargs b3sum`, parallélisme `-P 4` sur SSD.
  - Mode `verify` : délègue à `b3sum --check`.
  - Mode `compare` : tri sur colonne 2, `join` pour les modifiés, `comm` pour disparus/nouveaux, rapport `tee`.
- `README.md` — point d'entrée : dépendances, usage en 3 commandes, arbre de décision, règles critiques.
- `docs/manuel.md` — référence technique complète : algorithmes, structure `.b3`, workflow, explication du script, performances, limites, référence rapide, annexe FIM.
- `docs/progression-eta.md` — analyse du problème ETA sur pipeline `xargs`, deux approches (`pv` invalide, boucle bash), mécanique de l'estimation, tableau de comparaison des performances.
- `docs/explication-run-tests.md` — documentation du code `run_tests.sh` : chemins, compteurs, assertions, setup/teardown, structure d'un cas de test, prérequis, exit code CI.
- `tests/run_tests.sh` — suite de tests automatisée bash pur, 11 cas T01–T11, isolation via `mktemp`, teardown systématique, exit code CI-compatible.
- `tests/validation.md` — protocole de test manuel : 10 cas T01–T10 avec commandes exactes et résultats attendus, critères de qualité globaux.

--- Fichier : README.md ---
# integrity.sh — Vérification d'intégrité BLAKE3

Détection de corruption silencieuse et d'erreurs de transfert sur disque, par hachage BLAKE3.

**Dépendances :** `b3sum`, `bash >= 4`, `find`, `sort`, `awk`, `comm`, `join`, `stat`, `du`

---

## Usage

```bash
# Créer une base de hachage pour un dossier
./integrity.sh compute ./mon_dossier hashes_2024-01-15.b3

# Vérifier l'intégrité — lancer depuis le répertoire où le compute a été fait
./integrity.sh verify hashes_2024-01-15.b3

# Idem depuis un répertoire différent — passer le répertoire de travail d'origine
./integrity.sh verify /data/hashes_2024-01-15.b3 /data

# Comparer deux bases (états historiques) → résultats dans $RESULTATS_DIR/
./integrity.sh compare hashes_2024-01-15.b3 hashes_2024-02-01.b3

# Mode silencieux pour CI/cron
./integrity.sh --quiet verify hashes_2024-01-15.b3
```

---

## Pipeline batch — runner.sh + pipeline.json

Pour lancer plusieurs opérations en une seule commande. Dépendance supplémentaire : `jq`.

**Dépendance :** `jq` (`apt install jq`)

### pipeline.json

```json
{
    "pipeline": [

        {
            "op":     "compute",
            "source": "/mnt/a/dossier_disque_1",
            "bases":  "/mnt/c/Users/TonNom/Desktop/bases",
            "nom":    "hashes_dossier_1.b3"
        },

        {
            "op":     "verify",
            "source": "/mnt/a/dossier_disque_1",
            "base":   "/mnt/c/Users/TonNom/Desktop/bases/hashes_dossier_1.b3"
        },

        {
            "op":     "compare",
            "base_a": "/mnt/c/Users/TonNom/Desktop/bases/hashes_dossier_1.b3",
            "base_b": "/mnt/c/Users/TonNom/Desktop/bases/hashes_dossier_2.b3"
        }

    ]
}
```

Champs par opération :

| `op` | Champs requis |
|---|---|
| `compute` | `source`, `bases`, `nom` |
| `verify` | `source`, `base` |
| `compare` | `base_a`, `base_b` |

### Lancement depuis Windows (double-clic)

```bat
@echo off
wsl bash /mnt/c/Users/TonNom/Desktop/runner.sh
pause
```

`runner.sh`, `pipeline.json` et `integrity.sh` doivent être dans le même dossier.

---

## Mode `--quiet`

Supprime toute sortie terminal et écrit uniquement dans les fichiers de résultats (`recap.txt`, `failed.txt`). Exit code propagé : 0 si OK, non-nul en cas d'échec.

```bash
# Hook pre-commit git
./integrity.sh --quiet verify base.b3 || { echo "Corruption détectée"; exit 1; }

# Monitoring cron
0 3 * * * /opt/integrity.sh --quiet verify /data/base.b3 || mail -s "ALERT" admin@example.com
```

Compatible avec `compute`, `verify`, et `compare`.

---

## Configuration

`RESULTATS_DIR` dans `integrity.sh` définit où sont créés les dossiers de résultats (défaut : `~/integrity_resultats`).

```bash
RESULTATS_DIR="/mon/chemin/resultats"
```

Chaque exécution de `verify` ou `compare` crée un sous-dossier horodaté si le dossier existe déjà :

```
~/integrity_resultats/
├── resultats_hashes_2024-01-15/
│   ├── recap.txt
│   ├── failed.txt
│   ├── modifies.b3
│   ├── disparus.txt
│   └── nouveaux.txt
└── resultats_hashes_2024-01-15_20250215-143022/
    └── ...
```

---

| Situation | Commande |
|---|---|
| Première indexation | `compute` |
| Vérifier après transfert / stockage | `verify` |
| Comparer deux snapshots | `compare` |
| Pipeline multi-dossiers | `runner.sh` + `pipeline.json` |
| Contrôle ad hoc d'un fichier unique | `b3sum fichier.bin` |
| Intégration CI/cron | `--quiet verify` |

---

## Structure du projet

```
hash_tool/
├── README.md
├── integrity.sh           ← script principal
├── runner.sh              ← exécuteur de pipeline
├── pipeline.json          ← déclaration du pipeline
├── docs/
│   ├── manuel.md
│   ├── progression-eta.md
│   └── explication-run-tests.md
└── tests/
    ├── run_tests.sh               ← tests integrity.sh (T00–T14)
    ├── run_tests_pipeline.sh      ← tests runner.sh (TP01–TP12)
    └── validation.md
```

---

## Règles d'utilisation critiques

- Toujours des **chemins relatifs** dans les bases `.b3`. `runner.sh` gère le `cd` automatiquement.
- Lancer `verify` depuis le **même répertoire de travail** qu'au `compute`, ou passer ce répertoire en second argument.
- Stocker les `.b3` sur un **support distinct** des données — sur VeraCrypt, stocker sur `C:` ou un support tiers.
- Nommer les bases avec une **date explicite** : `hashes_2024-01-15.b3`, jamais `hashes_latest.b3`.

---

## Tests

```bash
# Tests integrity.sh (bash >= 4, b3sum requis)
cd tests
./run_tests.sh

# Tests runner.sh + pipeline.json (jq requis en plus)
./run_tests_pipeline.sh

# Avec ShellCheck (recommandé)
apt install shellcheck
./run_tests.sh
```

- `run_tests.sh` : 15 cas T00–T14 — compute, verify, compare, `--quiet`, horodatage, robustesse.
- `run_tests_pipeline.sh` : 12 cas TP01–TP12 — parsing JSON, exécution des 3 modes, erreurs.

--- Fichier : integrity.sh ---

#!/usr/bin/env bash
# integrity.sh — vérification d'intégrité par hachage BLAKE3
#
# Usage :
#   ./integrity.sh compute <dossier> <base.b3>
#   ./integrity.sh verify  <base.b3> [dossier]
#   ./integrity.sh compare <ancienne.b3> <nouvelle.b3>
#
# Options :
#   --quiet   Supprime toute sortie terminal ; écrit uniquement dans les
#             fichiers de résultats (recap.txt, failed.txt, etc.).
#             Utile pour usage en CI/cron/script parent.
#
# Dépendances : b3sum, find, sort, awk, comm, join, stat, du

set -euo pipefail

# ── Vérification version bash ──────────────────────────────────────────────────

(( BASH_VERSINFO[0] >= 4 )) || {
  echo "ERREUR : bash >= 4 requis (actuel : $BASH_VERSION)" >&2
  exit 1
}

# ── Parsing des arguments ──────────────────────────────────────────────────────

QUIET=0
ARGS=()

for arg in "$@"; do
  case "$arg" in
    --quiet) QUIET=1 ;;
    *)       ARGS+=("$arg") ;;
  esac
done

MODE="${ARGS[0]:-}"
ARG2="${ARGS[1]:-}"
ARG3="${ARGS[2]:-}"

# ── Configuration ──────────────────────────────────────────────────────────────

# Dossier racine où seront créés les sous-dossiers de résultats.
# Modifier ce chemin selon l'environnement.
RESULTATS_DIR="${RESULTATS_DIR:-${HOME}/integrity_resultats}"

# ── Fonctions utilitaires ──────────────────────────────────────────────────────

# Affiche un message d'erreur sur stderr et quitte.
die() {
  echo "ERREUR : $*" >&2
  exit 1
}

# Affiche sur stdout uniquement si --quiet n'est pas actif.
say() {
  (( QUIET )) || echo "$@"
}

# Vérifie qu'un fichier .b3 est valide : existe, est un fichier, non vide,
# contient au moins une ligne au format b3sum (<hash>  <chemin>).
assert_b3_valid() {
  local file="$1"
  local label="${2:-$file}"

  [ -e "$file" ] || die "$label : fichier introuvable."
  [ -f "$file" ] || die "$label : est un dossier, pas un fichier .b3."
  [ -s "$file" ] || die "$label : fichier vide — aucun hash à traiter."

  local first_valid
  first_valid=$(grep -m1 -E '^[0-9a-f]{64}  .+' "$file" || true)
  [ -n "$first_valid" ] || die "$label : format invalide — aucune ligne au format b3sum détectée."
}

# Vérifie qu'un dossier cible est valide et contient au moins un fichier.
assert_target_valid() {
  local dir="$1"

  [ -e "$dir" ] || die "Dossier cible introuvable : $dir"
  [ -d "$dir" ] || die "Le chemin cible n'est pas un dossier : $dir"

  local nb_files
  # -print0 + grep -zc : robuste aux noms de fichiers contenant des newlines
  nb_files=$(find "$dir" -type f -print0 | grep -zc '' || echo 0)
  (( nb_files > 0 )) || die "Le dossier $dir ne contient aucun fichier — rien à hacher."
}

# Taille d'un fichier en octets — abstraction GNU/BSD
file_size() {
  local f="$1"
  if stat -c%s "$f" 2>/dev/null; then
    return
  fi
  # BSD/macOS fallback
  stat -f%z "$f"
}

# ── Fonctions principales ──────────────────────────────────────────────────────

# Calcule le hash BLAKE3 de chaque fichier du dossier cible, fichier par fichier,
# en affichant la progression et une estimation du temps restant (ETA).
# La progression est écrite sur le terminal (/dev/tty) uniquement si --quiet
# n'est pas actif, jamais dans le fichier de hashes.
# Usage : compute_with_progress <dossier> <hashfile>
compute_with_progress() {
  local target="$1"
  local hashfile="$2"

  local -a files
  mapfile -d '' files < <(find "$target" -type f -print0 | sort -z)

  local total_files=${#files[@]}
  local total_bytes
  total_bytes=$(du -sb "$target" | awk '{print $1}')

  local bytes_done=0
  local t_start
  t_start=$(date +%s)

  local i=0
  for file in "${files[@]}"; do
    b3sum "$file" >> "$hashfile"

    bytes_done=$(( bytes_done + $(file_size "$file") ))
    i=$(( i + 1 ))

    if (( ! QUIET )); then
      local t_now elapsed
      t_now=$(date +%s)
      elapsed=$(( t_now - t_start ))

      if (( bytes_done > 0 && elapsed > 0 )); then
        local speed remaining
        speed=$(( bytes_done / elapsed ))
        remaining=$(( (total_bytes - bytes_done) / speed ))
        printf "\r[%d/%d] ETA : %dm %02ds   " \
          "$i" "$total_files" $(( remaining / 60 )) $(( remaining % 60 )) > /dev/tty
      fi
    fi
  done

  if (( ! QUIET )); then
    printf "\r%*s\r" 40 "" > /dev/tty  # effacer la ligne de progression
  fi
}

# Crée le dossier de résultats nommé d'après le fichier .b3 fourni.
# Horodaté si le dossier existe déjà, pour éviter l'écrasement silencieux.
# Usage : outdir=$(make_result_dir <fichier.b3>)
make_result_dir() {
  local b3file="$1"
  local basename
  basename=$(basename "$b3file" .b3)
  local outdir="${RESULTATS_DIR}/resultats_${basename}"

  if [ -d "$outdir" ]; then
    outdir="${outdir}_$(date +%Y%m%d-%H%M%S)"
  fi

  mkdir -p "$outdir"
  echo "$outdir"
}

# Produit les fichiers de résultats pour le mode verify.
# Usage : run_verify <hashfile_absolu>
run_verify() {
  local hashfile="$1"
  local outdir
  outdir=$(make_result_dir "$hashfile")

  local raw exit_code
  raw=$(b3sum --check "$hashfile" 2>&1) && exit_code=0 || exit_code=$?

  # Séparer les lignes OK, FAILED, et les erreurs b3sum (ni OK ni FAILED)
  local lines_ok lines_failed lines_error
  lines_ok=$(echo    "$raw" | grep ': OK$'     || true)
  lines_failed=$(echo "$raw" | grep ': FAILED'  || true)
  lines_error=$(echo  "$raw" | grep -Ev ': (OK|FAILED)' | grep -v '^$' || true)

  # Comptage robuste : grep -c '^' compte toutes les lignes non vides du flux
  local nb_ok nb_failed
  if [ -n "$lines_ok" ]; then
    nb_ok=$(echo "$lines_ok" | grep -c '^')
  else
    nb_ok=0
  fi
  if [ -n "$lines_failed" ]; then
    nb_failed=$(echo "$lines_failed" | grep -c '^')
  else
    nb_failed=0
  fi

  local statut
  if [ -n "$lines_error" ]; then
    statut="ERREUR"
  elif (( nb_failed > 0 )); then
    statut="ECHEC"
  else
    statut="OK"
  fi

  # ── recap.txt ────────────────────────────────────────────────────────────────
  {
    echo "════════════════════════════════════════"
    echo "  STATUT : $statut"
    echo "════════════════════════════════════════"
    echo ""
    echo "Commande  : integrity.sh verify $(basename "$hashfile")"
    echo "Date      : $(date)"
    echo "Base      : $hashfile"
    echo ""
    echo "OK        : $nb_ok"
    if (( nb_failed > 0 )); then
      echo "FAILED    : $nb_failed  ← voir failed.txt"
    fi
    if [ -n "$lines_error" ]; then
      echo ""
      echo "── Erreurs b3sum ──────────────────────"
      echo "$lines_error"
    fi
  } > "${outdir}/recap.txt"

  # ── failed.txt — créé uniquement si des échecs existent ───────────────────
  if (( nb_failed > 0 )) || [ -n "$lines_error" ]; then
    {
      echo "════════════════════════════════════════"
      echo "  FICHIERS EN ECHEC"
      echo "════════════════════════════════════════"
      echo ""
      if (( nb_failed > 0 )); then
        echo "$lines_failed"
      fi
      if [ -n "$lines_error" ]; then
        echo ""
        echo "── Erreurs ────────────────────────────"
        echo "$lines_error"
      fi
    } > "${outdir}/failed.txt"
  else
    rm -f "${outdir}/failed.txt"
  fi

  # ── Affichage terminal (supprimé si --quiet) ───────────────────────────────
  if [ "$statut" = "OK" ]; then
    say "Vérification OK — $nb_ok fichiers intègres."
  else
    say ""
    say "████████████████████████████████████████"
    if [ "$statut" = "ERREUR" ]; then
      say "  ERREUR lors de la vérification"
    else
      say "  ECHEC : $nb_failed fichier(s) corrompu(s) ou manquant(s)"
    fi
    say "████████████████████████████████████████"
    say ""
    if (( nb_failed > 0 )); then say "$lines_failed"; fi
    if [ -n "$lines_error" ]; then say "$lines_error"; fi
    say ""
  fi

  say "Résultats dans : $outdir"
  say "  recap.txt"
  if (( nb_failed > 0 )) || [ -n "$lines_error" ]; then
    say "  failed.txt"
  fi

  # Propager l'échec au appelant en mode --quiet (utile pour CI)
  return $exit_code
}

# Produit les fichiers de résultats pour le mode compare.
# Usage : run_compare <ancienne.b3> <nouvelle.b3>
run_compare() {
  local old="$1"
  local new="$2"
  local outdir
  outdir=$(make_result_dir "$old")

  local tmp_old tmp_new
  tmp_old=$(mktemp)
  tmp_new=$(mktemp)

  # Nettoyage garanti même en cas d'erreur intermédiaire
  trap 'rm -f "$tmp_old" "$tmp_new"' EXIT

  # Convertit "hash  chemin" → "chemin\thash"
  # substr(0,64) = hash fixe ; substr(67) = chemin (robuste aux espaces)
  b3_to_path_hash() {
    awk '{ print substr($0,67) "\t" substr($0,1,64) }' "$1" | sort -t $'\t' -k1,1
  }

  b3_to_path_hash "$old" > "$tmp_old"
  b3_to_path_hash "$new" > "$tmp_new"

  # modifies.b3 : présents dans les deux bases avec hash différent
  # join sur champ 1 (chemin), compare champ 2 (hash)
  join -t $'\t' -1 1 -2 1 "$tmp_old" "$tmp_new" \
    | awk -F $'\t' '$2 != $3 { print $3 "  " $1 }' \
    > "${outdir}/modifies.b3"

  # disparus.txt : chemins dans A absents de B
  comm -23 <(cut -f1 "$tmp_old") \
           <(cut -f1 "$tmp_new") \
    > "${outdir}/disparus.txt"

  # nouveaux.txt : chemins dans B absents de A
  comm -13 <(cut -f1 "$tmp_old") \
           <(cut -f1 "$tmp_new") \
    > "${outdir}/nouveaux.txt"

  local nb_modifies nb_disparus nb_nouveaux
  nb_modifies=$(wc -l < "${outdir}/modifies.b3")
  nb_disparus=$(wc -l < "${outdir}/disparus.txt")
  nb_nouveaux=$(wc -l < "${outdir}/nouveaux.txt")

  # recap.txt
  {
    echo "Commande      : integrity.sh compare $(basename "$old") $(basename "$new")"
    echo "Date          : $(date)"
    echo "Ancienne base : $old"
    echo "Nouvelle base : $new"
    echo ""
    echo "Modifiés      : $nb_modifies"
    echo "Disparus      : $nb_disparus"
    echo "Nouveaux      : $nb_nouveaux"
  } > "${outdir}/recap.txt"

  rm -f "$tmp_old" "$tmp_new"
  trap - EXIT  # désarmer le trap après nettoyage explicite

  say "Résultats enregistrés dans : $outdir"
  say "  recap.txt     — modifiés: $nb_modifies, disparus: $nb_disparus, nouveaux: $nb_nouveaux"
  say "  modifies.b3   — $nb_modifies fichiers"
  say "  disparus.txt  — $nb_disparus fichiers"
  say "  nouveaux.txt  — $nb_nouveaux fichiers"
}

# ── Dispatch ──────────────────────────────────────────────────────────────────

case "$MODE" in
  compute)
    [ -n "$ARG2" ] || die "compute : dossier cible manquant.\nUsage : $0 compute <dossier> <base.b3>"
    [ -n "$ARG3" ] || die "compute : fichier de sortie .b3 manquant.\nUsage : $0 compute <dossier> <base.b3>"
    [ ! -d "$ARG3" ] || die "compute : '$ARG3' est un dossier. Le fichier .b3 de sortie doit être un chemin de fichier."
    assert_target_valid "$ARG2"
    compute_with_progress "$ARG2" "$ARG3"
    say "Base enregistrée : $ARG3 ($(wc -l < "$ARG3") fichiers)"
    ;;

  verify)
    [ -n "$ARG2" ] || die "verify : fichier .b3 manquant.\nUsage : $0 verify <base.b3> [dossier]"
    assert_b3_valid "$ARG2" "base"
    # Résoudre le chemin absolu du .b3 AVANT tout cd
    HASHFILE_ABS="$(cd "$(dirname "$ARG2")" && pwd)/$(basename "$ARG2")"
    if [ -n "$ARG3" ]; then
      [ -d "$ARG3" ] || die "verify : '$ARG3' n'est pas un dossier valide."
      cd "$ARG3"
    fi
    run_verify "$HASHFILE_ABS"
    ;;

  compare)
    [ -n "$ARG2" ] || die "compare : fichier ancienne base manquant.\nUsage : $0 compare <ancienne.b3> <nouvelle.b3>"
    [ -n "$ARG3" ] || die "compare : fichier nouvelle base manquant.\nUsage : $0 compare <ancienne.b3> <nouvelle.b3>"
    assert_b3_valid "$ARG2" "ancienne base"
    assert_b3_valid "$ARG3" "nouvelle base"
    run_compare "$ARG2" "$ARG3"
    ;;

  *)
    echo "Usage:"
    echo "  $0 [--quiet] compute <dossier> <base.b3>"
    echo "  $0 [--quiet] verify  <base.b3> [dossier]"
    echo "  $0 [--quiet] compare <ancienne.b3> <nouvelle.b3>"
    echo ""
    echo "Options:"
    echo "  --quiet   Silencieux : écrit uniquement dans les fichiers de résultats."
    exit 1
    ;;
esac




--- Fichier : pipeline full.json ---
{
    "pipeline": [

        {
            "op": "compute",
            "source": "/mnt/a/dossier_disque_1",
            "bases":  "/mnt/c/Users/TonNom/Desktop/bases",
            "nom":    "hashes_dossier_1.b3"
        },

        {
            "op": "compute",
            "source": "/mnt/i/dossier_disque_2",
            "bases":  "/mnt/c/Users/TonNom/Desktop/bases",
            "nom":    "hashes_dossier_2.b3"
        },

        {
            "op": "compute",
            "source": "/mnt/h/dossier_disque_3",
            "bases":  "/mnt/c/Users/TonNom/Desktop/bases",
            "nom":    "hashes_dossier_3.b3"
        },

        {
            "op":   "verify",
            "source": "/mnt/a/dossier_disque_1",
            "base": "/mnt/c/Users/TonNom/Desktop/bases/hashes_dossier_1.b3"
        },

        {
            "op":     "compare",
            "base_a": "/mnt/c/Users/TonNom/Desktop/bases/hashes_dossier_1.b3",
            "base_b": "/mnt/c/Users/TonNom/Desktop/bases/hashes_dossier_2.b3"
        }

    ]
}

--- Fichier : pipeline.json ---


{
    "pipeline": [

        {
            "op": "compute",
            "source": "./mon_dossier/source",
            "bases":  "./mon_dossier/bases",
            "nom":    "hashes_dossier_1.b3"
        },

        {
            "op": "compute",
            "source": "./mon_dossier/destination",
            "bases":  "./mon_dossier/bases",
            "nom":    "hashes_dossier_2.b3"
        },

        {
            "op":     "compare",
            "base_a": "./mon_dossier/bases/hashes_dossier_1.b3",
            "base_b": "./mon_dossier/bases/hashes_dossier_2.b3"
        }

    ]
}

--- Fichier : runner.sh ---
#!/usr/bin/env bash
# runner.sh — Exécuteur de pipeline integrity.sh depuis pipeline.json
#
# Usage :
#   ./runner.sh                   # lit pipeline.json dans le même dossier
#   ./runner.sh /chemin/pipeline.json
#
# Dépendances : bash >= 4, jq, integrity.sh (même dossier)

set -euo pipefail

# ── Chemins ───────────────────────────────────────────────────────────────────

SCRIPT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"
INTEGRITY="$SCRIPT_DIR/integrity.sh"
CONFIG="${1:-$SCRIPT_DIR/pipeline.json}"

# ── Prérequis ─────────────────────────────────────────────────────────────────

(( BASH_VERSINFO[0] >= 4 )) || { echo "ERREUR : bash >= 4 requis" >&2; exit 1; }

command -v jq &>/dev/null    || { echo "ERREUR : jq non trouvé (apt install jq)" >&2; exit 1; }
[ -f "$INTEGRITY" ]          || { echo "ERREUR : integrity.sh introuvable : $INTEGRITY" >&2; exit 1; }
[ -f "$CONFIG" ]             || { echo "ERREUR : pipeline.json introuvable : $CONFIG" >&2; exit 1; }

# ── Validation JSON ───────────────────────────────────────────────────────────

jq empty "$CONFIG" 2>/dev/null || { echo "ERREUR : JSON invalide : $CONFIG" >&2; exit 1; }

# Vérifier que .pipeline est un tableau non vide
nb_ops=$(jq '.pipeline | length' "$CONFIG")
(( nb_ops > 0 )) || { echo "ERREUR : pipeline.json — tableau .pipeline vide ou absent" >&2; exit 1; }

# ── Fonctions ─────────────────────────────────────────────────────────────────

die() { echo "ERREUR : $*" >&2; exit 1; }

require_field() {
    local op_index="$1"
    local field="$2"
    local val
    val=$(jq -r --argjson i "$op_index" '.pipeline[$i].'"$field" "$CONFIG")
    [ "$val" != "null" ] && [ -n "$val" ] || die "Bloc #$((op_index+1)) : champ '$field' manquant ou vide."
    echo "$val"
}

run_compute() {
    local i="$1"
    local source bases nom
    source=$(require_field "$i" "source")
    bases=$(require_field "$i" "bases")
    nom=$(require_field "$i" "nom")

    echo "=== COMPUTE : $source ==="
    [ -d "$source" ] || die "Bloc #$((i+1)) compute : dossier source introuvable : $source"

    mkdir -p "$bases"
    cd "$source"
    "$INTEGRITY" compute . "$bases/$nom"
}

run_verify() {
    local i="$1"
    local source base
    source=$(require_field "$i" "source")
    base=$(require_field "$i" "base")

    echo "=== VERIFY : $source ==="
    [ -d "$source" ] || die "Bloc #$((i+1)) verify : dossier source introuvable : $source"
    [ -f "$base" ]   || die "Bloc #$((i+1)) verify : base .b3 introuvable : $base"

    cd "$source"
    "$INTEGRITY" verify "$base"
}

run_compare() {
    local i="$1"
    local base_a base_b
    base_a=$(require_field "$i" "base_a")
    base_b=$(require_field "$i" "base_b")

    echo "=== COMPARE : $(basename "$base_a") vs $(basename "$base_b") ==="
    [ -f "$base_a" ] || die "Bloc #$((i+1)) compare : base_a introuvable : $base_a"
    [ -f "$base_b" ] || die "Bloc #$((i+1)) compare : base_b introuvable : $base_b"

    "$INTEGRITY" compare "$base_a" "$base_b"
}

# ── Main ──────────────────────────────────────────────────────────────────────

echo "=== PIPELINE DÉMARRÉ : $(date) ==="
echo "=== Config : $CONFIG ($nb_ops opération(s)) ==="
echo ""

for (( i=0; i<nb_ops; i++ )); do
    op=$(jq -r --argjson i "$i" '.pipeline[$i].op' "$CONFIG")
    [ "$op" != "null" ] && [ -n "$op" ] || die "Bloc #$((i+1)) : champ 'op' manquant."

    case "$op" in
        compute) run_compute "$i" ;;
        verify)  run_verify  "$i" ;;
        compare) run_compare "$i" ;;
        *)       die "Bloc #$((i+1)) : opération inconnue : '$op'" ;;
    esac

    echo ""
done

echo "=== PIPELINE TERMINÉ : $(date) ==="

--- Fichier : temp.txt ---


bash ./integrity.sh compute "/media/veracrypt1/partition_laptop/a ranger" hash_1.b3

bash ./integrity.sh compare hash_1.b3 hash_2.b3



--- Fichier : mon_dossier/destination/fichier (1).txt ---
Contrary to popular belief, Lorem Ipsum is not simply random text. It has roots in a piece of classical Latin literature from 45 BC, making it over 2000 years old. Richard McClintock, a Latin professor at Hampden-Sydney College in Virginia, looked up one of the more obscure Latin words, consectetur, from a Lorem Ipsum passage, and going through the cites of the word in classical literature, discovered the undoubtable source. Lorem Ipsum comes from sections 1.10.32 and 1.10.33 of "de Finibus Bonorum et Malorum" (The Extremes of Good and Evil) by Cicero, written in 45 BC. This book is a treatise on the theory of ethics, very popular during the Renaissance. The first line of Lorem Ipsum, "Lorem ipsum dolor sit amet..", comes from a line in section 1.10.32.



--- Fichier : mon_dossier/destination/fichier (2).txt ---
There are many variations of passages of Lorem Ipsum available, but the majority have suffered alteration in some form, by injected humour, or randomised words which don't look even slightly believable. If you are going to use a passage of Lorem Ipsum, you need to be sure there isn't anything embarrassing hidden in the middle of text. All the Lorem Ipsum generators on the Internet tend to repeat predefined chunks as necessary, making this the first true generator on the Internet. It uses a dictionary of over 200 Latin words, combined with a handful of model sentence structures, to generate Lorem Ipsum which looks reasonable. The generated Lorem Ipsum is therefore always free from repetition, injected humour, or non-characteristic words etc.



--- Fichier : mon_dossier/destination/fichier (3).txt ---
Lorem Ipsum is simply dummy text of the printing and typesetting industry. Lorem Ipsum has been the industry's standard dummy text ever since the 1500s, when an unknown printer took a galley of type and scrambled it to make a type specimen book. It has survived not only five centuries, but also the leap into electronic typesetting, remaining essentially unchanged. It was popularised in the 1960s with the release of Letraset sheets containing Lorem Ipsum passages, and more recently with desktop publishing software like Aldus PageMaker including versions of Lorem Ipsum.



--- Fichier : mon_dossier/destination/fichier (4).txt ---
It is a long established fact that a reader will be distracted by the readable content of a page when looking at its layout. The point of using Lorem Ipsum is that it has a more-or-less normal distribution of letters, as opposed to using 'Content here, content here', making it look like readable English. Many desktop publishing packages and web page editors now use Lorem Ipsum as their default model text, and a search for 'lorem ipsum' will uncover many web sites still in their infancy. Various versions have evolved over the years, sometimes by accident, sometimes on purpose (injected humour and the like).



--- Fichier : mon_dossier/source/fichier (1).txt ---
Contrary to popular belief, Lorem Ipsum is not simply random text. It has roots in a piece of classical Latin literature from 45 BC, making it over 2000 years old. Richard McClintock, a Latin professor at Hampden-Sydney College in Virginia, looked up one of the more obscure Latin words, consectetur, from a Lorem Ipsum passage, and going through the cites of the word in classical literature, discovered the undoubtable source. Lorem Ipsum comes from sections 1.10.32 and 1.10.33 of "de Finibus Bonorum et Malorum" (The Extremes of Good and Evil) by Cicero, written in 45 BC. This book is a treatise on the theory of ethics, very popular during the Renaissance. The first line of Lorem Ipsum, "Lorem ipsum dolor sit amet..", comes from a line in section 1.10.32.

fichier modifié



--- Fichier : mon_dossier/source/fichier (2).txt ---
There are many variations of passages of Lorem Ipsum available, but the majority have suffered alteration in some form, by injected humour, or randomised words which don't look even slightly believable. If you are going to use a passage of Lorem Ipsum, you need to be sure there isn't anything embarrassing hidden in the middle of text. All the Lorem Ipsum generators on the Internet tend to repeat predefined chunks as necessary, making this the first true generator on the Internet. It uses a dictionary of over 200 Latin words, combined with a handful of model sentence structures, to generate Lorem Ipsum which looks reasonable. The generated Lorem Ipsum is therefore always free from repetition, injected humour, or non-characteristic words etc.



--- Fichier : mon_dossier/source/fichier (3).txt ---
Lorem Ipsum is simply dummy text of the printing and typesetting industry. Lorem Ipsum has been the industry's standard dummy text ever since the 1500s, when an unknown printer took a galley of type and scrambled it to make a type specimen book. It has survived not only five centuries, but also the leap into electronic typesetting, remaining essentially unchanged. It was popularised in the 1960s with the release of Letraset sheets containing Lorem Ipsum passages, and more recently with desktop publishing software like Aldus PageMaker including versions of Lorem Ipsum.



--- Fichier : mon_dossier/source/fichier (4).txt ---
It is a long established fact that a reader will be distracted by the readable content of a page when looking at its layout. The point of using Lorem Ipsum is that it has a more-or-less normal distribution of letters, as opposed to using 'Content here, content here', making it look like readable English. Many desktop publishing packages and web page editors now use Lorem Ipsum as their default model text, and a search for 'lorem ipsum' will uncover many web sites still in their infancy. Various versions have evolved over the years, sometimes by accident, sometimes on purpose (injected humour and the like).



--- Fichier : tests/run_tests.sh ---
#!/usr/bin/env bash
# run_tests.sh — suite de tests automatisée pour integrity.sh
# Usage : ./run_tests.sh
# Prérequis : b3sum, stat, du installés ; integrity.sh dans le dossier parent

set -euo pipefail

# ── Configuration ─────────────────────────────────────────────────────────────

SCRIPT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"
INTEGRITY="$SCRIPT_DIR/../integrity.sh"
WORKDIR="$(mktemp -d /tmp/integrity-test.XXXXXX)"

# Rediriger les résultats dans le WORKDIR pour les tests
export RESULTATS_DIR="$WORKDIR/resultats"

# ── Couleurs ──────────────────────────────────────────────────────────────────

GREEN='\033[0;32m'
RED='\033[0;31m'
NC='\033[0m'

# ── Compteurs ─────────────────────────────────────────────────────────────────

PASS=0
FAIL=0
TOTAL=0

# ── Helpers ───────────────────────────────────────────────────────────────────

pass() { echo -e "${GREEN}  PASS${NC} — $1"; ((PASS++)); ((TOTAL++)); }
fail() { echo -e "${RED}  FAIL${NC} — $1"; ((FAIL++)); ((TOTAL++)); }

assert_exit_zero() {
  local label="$1"; shift
  if "$@" > /dev/null 2>&1; then pass "$label"; else fail "$label"; fi
}

assert_exit_nonzero() {
  local label="$1"; shift
  if ! "$@" > /dev/null 2>&1; then pass "$label"; else fail "$label"; fi
}

assert_contains() {
  local label="$1"
  local pattern="$2"
  local output="$3"
  if echo "$output" | grep -q "$pattern"; then pass "$label"; else fail "$label (pattern: '$pattern' absent)"; fi
}

assert_not_contains() {
  local label="$1"
  local pattern="$2"
  local output="$3"
  if ! echo "$output" | grep -q "$pattern"; then pass "$label"; else fail "$label (pattern: '$pattern' présent mais ne devrait pas l'être)"; fi
}

assert_line_count() {
  local label="$1"
  local expected="$2"
  local file="$3"
  local actual
  actual=$(wc -l < "$file")
  if [ "$actual" -eq "$expected" ]; then pass "$label"; else fail "$label (attendu: $expected lignes, obtenu: $actual)"; fi
}

assert_file_exists() {
  local label="$1"
  local file="$2"
  if [ -f "$file" ]; then pass "$label"; else fail "$label (fichier absent : $file)"; fi
}

assert_file_absent() {
  local label="$1"
  local file="$2"
  if [ ! -f "$file" ]; then pass "$label"; else fail "$label (fichier présent à tort : $file)"; fi
}

# ── Setup ─────────────────────────────────────────────────────────────────────

setup() {
  mkdir -p "$WORKDIR/data/sub"
  echo "contenu alpha"  > "$WORKDIR/data/alpha.txt"
  echo "contenu beta"   > "$WORKDIR/data/beta.txt"
  echo "contenu gamma"  > "$WORKDIR/data/gamma.txt"
  echo "contenu delta"  > "$WORKDIR/data/sub/delta.txt"
}

teardown() {
  rm -rf "$WORKDIR"
}

# ── Tests ─────────────────────────────────────────────────────────────────────

run_tests() {
  cd "$WORKDIR"

  echo ""
  echo "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━"
  echo "  integrity.sh — suite de tests"
  echo "  Workdir : $WORKDIR"
  echo "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━"
  echo ""

  # ── T00 : ShellCheck ──────────────────────────────────────────────────────
  echo "T00 — ShellCheck"
  if command -v shellcheck &> /dev/null; then
    assert_exit_zero "ShellCheck integrity.sh" shellcheck "$INTEGRITY"
    assert_exit_zero "ShellCheck run_tests.sh" shellcheck "$0"
  else
    echo "  SKIP — shellcheck non installé (apt install shellcheck)"
  fi
  echo ""

  # ── T01 : Compute de base ─────────────────────────────────────────────────
  echo "T01 — Compute de base"
  bash "$INTEGRITY" compute ./data base_t01.b3 > /dev/null 2>&1
  assert_line_count "base_t01.b3 contient 4 lignes" 4 base_t01.b3

  local first_line
  first_line=$(head -1 base_t01.b3)
  assert_contains "ligne au format <hash>  <chemin>" "  ./data/" "$first_line"
  echo ""

  # ── T02 : Verify sans modification ───────────────────────────────────────
  echo "T02 — Verify sans modification"
  local out_t02
  out_t02=$(bash "$INTEGRITY" verify base_t01.b3 2>&1 || true)
  assert_not_contains "aucun FAILED dans terminal" "FAILED" "$out_t02"
  assert_contains     "terminal indique OK"        "OK"     "$out_t02"

  local outdir_t02
  outdir_t02=$(ls -d "${RESULTATS_DIR}/resultats_base_t01"* 2>/dev/null | tail -1)
  assert_file_exists "recap.txt créé"   "${outdir_t02}/recap.txt"
  assert_contains    "recap contient OK" "OK" "$(cat "${outdir_t02}/recap.txt")"
  assert_file_absent "failed.txt absent si 0 échec" "${outdir_t02}/failed.txt"
  echo ""

  # ── T03 : Verify après corruption ────────────────────────────────────────
  echo "T03 — Verify après corruption d'un fichier"
  echo "contenu modifié" > data/beta.txt
  local out_t03
  out_t03=$(bash "$INTEGRITY" verify base_t01.b3 2>&1 || true)
  assert_contains "terminal affiche bloc ECHEC"    "ECHEC"   "$out_t03"
  assert_contains "terminal liste beta.txt FAILED" "FAILED"  "$out_t03"

  local outdir_t03
  outdir_t03=$(ls -d "${RESULTATS_DIR}/resultats_base_t01"* 2>/dev/null | tail -1)
  assert_file_exists "failed.txt créé"              "${outdir_t03}/failed.txt"
  assert_contains    "failed.txt contient beta.txt" "beta.txt" "$(cat "${outdir_t03}/failed.txt")"
  assert_contains    "recap indique FAILED > 0"     "FAILED"   "$(cat "${outdir_t03}/recap.txt")"
  # Restauration
  echo "contenu beta" > data/beta.txt
  echo ""

  # ── T04 : Verify après suppression ───────────────────────────────────────
  echo "T04 — Verify après suppression d'un fichier"
  rm data/gamma.txt
  local out_t04
  out_t04=$(bash "$INTEGRITY" verify base_t01.b3 2>&1 || true)
  assert_contains "gamma.txt FAILED" "FAILED" "$out_t04"
  # Restauration
  echo "contenu gamma" > data/gamma.txt
  echo ""

  # ── T05 : Compare — aucune différence ────────────────────────────────────
  echo "T05 — Compare : aucune différence"
  bash "$INTEGRITY" compute ./data base_t05.b3 > /dev/null 2>&1
  bash "$INTEGRITY" compare base_t01.b3 base_t05.b3 > /dev/null 2>&1

  local outdir_t05
  outdir_t05=$(ls -d "${RESULTATS_DIR}/resultats_base_t01"* 2>/dev/null | tail -1)
  assert_file_exists "recap.txt créé"    "${outdir_t05}/recap.txt"
  assert_file_exists "modifies.b3 créé"  "${outdir_t05}/modifies.b3"
  assert_file_exists "disparus.txt créé" "${outdir_t05}/disparus.txt"
  assert_file_exists "nouveaux.txt créé" "${outdir_t05}/nouveaux.txt"
  assert_line_count  "modifies.b3 vide"  0 "${outdir_t05}/modifies.b3"
  assert_line_count  "disparus.txt vide" 0 "${outdir_t05}/disparus.txt"
  assert_line_count  "nouveaux.txt vide" 0 "${outdir_t05}/nouveaux.txt"
  echo ""

  # ── T06 : Compare — fichier modifié ──────────────────────────────────────
  echo "T06 — Compare : fichier modifié"
  echo "contenu beta modifié" > data/beta.txt
  bash "$INTEGRITY" compute ./data base_t06.b3 > /dev/null 2>&1
  bash "$INTEGRITY" compare base_t01.b3 base_t06.b3 > /dev/null 2>&1

  local outdir_t06
  outdir_t06=$(ls -d "${RESULTATS_DIR}/resultats_base_t01"* 2>/dev/null | tail -1)
  assert_contains "modifies.b3 contient beta.txt" "beta.txt" "$(cat "${outdir_t06}/modifies.b3")"
  # Restauration
  echo "contenu beta" > data/beta.txt
  echo ""

  # ── T07 : Compare — suppression + ajout ──────────────────────────────────
  echo "T07 — Compare : fichier supprimé + fichier ajouté"
  bash "$INTEGRITY" compute ./data base_t07_old.b3 > /dev/null 2>&1
  rm data/alpha.txt
  echo "contenu epsilon" > data/epsilon.txt
  bash "$INTEGRITY" compute ./data base_t07_new.b3 > /dev/null 2>&1
  bash "$INTEGRITY" compare base_t07_old.b3 base_t07_new.b3 > /dev/null 2>&1

  local outdir_t07
  outdir_t07=$(ls -d "${RESULTATS_DIR}/resultats_base_t07_old"* 2>/dev/null | tail -1)
  assert_contains "disparus.txt contient alpha.txt"   "alpha.txt"   "$(cat "${outdir_t07}/disparus.txt")"
  assert_contains "nouveaux.txt contient epsilon.txt" "epsilon.txt" "$(cat "${outdir_t07}/nouveaux.txt")"
  # Restauration
  echo "contenu alpha" > data/alpha.txt
  rm data/epsilon.txt
  echo ""

  # ── T08 : Noms de fichiers avec espaces ───────────────────────────────────
  echo "T08 — Robustesse : nom de fichier avec espace"
  echo "contenu avec espace" > "data/fichier avec espace.txt"
  bash "$INTEGRITY" compute ./data base_t08.b3 > /dev/null 2>&1
  local out_t08
  out_t08=$(bash "$INTEGRITY" verify base_t08.b3 2>&1 || true)
  assert_not_contains "aucun FAILED" "FAILED" "$out_t08"
  rm "data/fichier avec espace.txt"
  echo ""

  # ── T09 : Dossier vide ignoré (limite documentée) ─────────────────────────
  echo "T09 — Limite : dossier vide ignoré"
  mkdir data/dossier_vide
  bash "$INTEGRITY" compute ./data base_t09.b3 > /dev/null 2>&1
  assert_not_contains "dossier_vide absent de la base" "dossier_vide" "$(cat base_t09.b3)"
  pass "comportement conforme à la documentation"
  rmdir data/dossier_vide
  echo ""

  # ── T10 : Chemin absolu vs relatif ───────────────────────────────────────
  echo "T10 — Chemin absolu vs relatif"
  find "$WORKDIR/data" -type f -print0 | sort -z | xargs -0 b3sum > base_absolu.b3
  find ./data          -type f -print0 | sort -z | xargs -0 b3sum > base_relatif.b3
  local first_abs first_rel
  first_abs=$(head -1 base_absolu.b3)
  first_rel=$(head -1 base_relatif.b3)
  assert_contains     "base absolue contient un chemin absolu"   "  /" "$first_abs"
  assert_contains     "base relative contient un chemin relatif" "\./data/" "$first_rel"
  assert_not_contains "bases non interchangeables" "$first_abs" "$first_rel"
  echo ""

  # ── T11 : compute_with_progress — intégrité de la base produite ───────────
  echo "T11 — ETA : la base produite est identique à une base de référence"
  find ./data -type f -print0 | sort -z | xargs -0 b3sum > base_ref.b3
  bash "$INTEGRITY" compute ./data base_eta.b3 > /dev/null 2>&1
  assert_exit_zero    "base ETA identique à la base de référence" diff base_ref.b3 base_eta.b3
  assert_not_contains "aucune ligne ETA dans la base"             "ETA"  "$(cat base_eta.b3)"
  assert_not_contains "aucun caractère de contrôle dans la base"  $'\r'  "$(cat base_eta.b3)"
  echo ""

  # ── T12 : Mode --quiet ────────────────────────────────────────────────────
  echo "T12 — Mode --quiet : aucune sortie terminal"
  bash "$INTEGRITY" compute ./data base_t12.b3 > /dev/null 2>&1

  local out_quiet_ok
  out_quiet_ok=$(bash "$INTEGRITY" --quiet verify base_t12.b3 2>&1 || true)
  assert_not_contains "--quiet verify OK : stdout vide" "OK"   "$out_quiet_ok"
  assert_not_contains "--quiet verify OK : stdout vide" "Résultats" "$out_quiet_ok"

  # Vérifier que les fichiers de résultats sont bien produits malgré --quiet
  local outdir_t12
  outdir_t12=$(ls -d "${RESULTATS_DIR}/resultats_base_t12"* 2>/dev/null | tail -1)
  assert_file_exists "recap.txt produit en mode --quiet" "${outdir_t12}/recap.txt"

  # --quiet avec échec : stdout toujours vide, fichiers produits, exit code non nul
  echo "contenu corrompu" > data/beta.txt
  local out_quiet_fail exit_quiet
  out_quiet_fail=$(bash "$INTEGRITY" --quiet verify base_t12.b3 2>&1 || true)
  bash "$INTEGRITY" --quiet verify base_t12.b3 > /dev/null 2>&1 && exit_quiet=0 || exit_quiet=$?
  assert_not_contains "--quiet verify ECHEC : stdout vide" "ECHEC"  "$out_quiet_fail"
  assert_not_contains "--quiet verify ECHEC : stdout vide" "FAILED" "$out_quiet_fail"

  local outdir_t12b
  outdir_t12b=$(ls -d "${RESULTATS_DIR}/resultats_base_t12"* 2>/dev/null | tail -1)
  assert_file_exists "failed.txt produit en mode --quiet" "${outdir_t12b}/failed.txt"

  if (( exit_quiet != 0 )); then
    pass "--quiet propage l'exit code non nul sur échec"
  else
    fail "--quiet propage l'exit code non nul sur échec (exit_quiet=$exit_quiet)"
  fi

  # Restauration
  echo "contenu beta" > data/beta.txt

  # --quiet compute : pas de sortie progression
  local out_quiet_compute
  out_quiet_compute=$(bash "$INTEGRITY" --quiet compute ./data base_t12c.b3 2>&1 || true)
  assert_not_contains "--quiet compute : stdout vide" "Base enregistrée" "$out_quiet_compute"
  assert_not_contains "--quiet compute : pas d'ETA"   "ETA"              "$out_quiet_compute"
  echo ""

  # ── T13 : Horodatage make_result_dir — pas d'écrasement ──────────────────
  echo "T13 — Horodatage : deux exécutions successives sur la même base"
  bash "$INTEGRITY" compute ./data base_t13.b3 > /dev/null 2>&1
  bash "$INTEGRITY" verify base_t13.b3 > /dev/null 2>&1 || true
  sleep 1
  bash "$INTEGRITY" verify base_t13.b3 > /dev/null 2>&1 || true
  local nb_resultats
  nb_resultats=$(ls -d "${RESULTATS_DIR}/resultats_base_t13"* 2>/dev/null | wc -l)
  if (( nb_resultats >= 2 )); then
    pass "deux dossiers distincts créés (pas d'écrasement)"
  else
    fail "écrasement détecté : $nb_resultats dossier(s) au lieu de >= 2"
  fi
  echo ""

  # ── T14 : verify avec [dossier] incorrect ────────────────────────────────
  echo "T14 — verify : dossier argument invalide détecté"
  local out_t14
  out_t14=$(bash "$INTEGRITY" verify base_t01.b3 /chemin/inexistant 2>&1 || true)
  assert_contains "erreur si dossier invalide" "ERREUR" "$out_t14"
  echo ""
}

# ── Main ──────────────────────────────────────────────────────────────────────

if ! command -v b3sum &> /dev/null; then
  echo -e "${RED}ERREUR${NC} : b3sum non trouvé. Installer avec : cargo install b3sum  ou  apt install b3sum"
  exit 1
fi

if [ ! -f "$INTEGRITY" ]; then
  echo -e "${RED}ERREUR${NC} : integrity.sh introuvable à : $INTEGRITY"
  exit 1
fi

setup
run_tests
teardown

# ── Rapport final ──────────────────────────────────────────────────────────────

echo "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━"
if [ "$FAIL" -eq 0 ]; then
  echo -e "  ${GREEN}$PASS/$TOTAL tests passés${NC}"
else
  echo -e "  ${GREEN}$PASS${NC}/${TOTAL} passés — ${RED}$FAIL échec(s)${NC}"
fi
echo "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━"
echo ""

[ "$FAIL" -eq 0 ]

--- Fichier : tests/run_tests_pipeline.sh ---
#!/usr/bin/env bash
# run_tests_pipeline.sh — Tests automatisés pour runner.sh + pipeline.json
#
# Couvre : parsing JSON, compute, verify, compare, erreurs (dossier absent, JSON invalide)
#
# Prérequis : bash >= 4, jq, b3sum, integrity.sh et runner.sh dans le répertoire parent
# Usage     : cd tests && ./run_tests_pipeline.sh

set -euo pipefail

# ── Chemins ───────────────────────────────────────────────────────────────────

SCRIPT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"
RUNNER="$SCRIPT_DIR/../runner.sh"
INTEGRITY="$SCRIPT_DIR/../integrity.sh"
WORKDIR="$(mktemp -d /tmp/integrity-pipeline-test.XXXXXX)"
export RESULTATS_DIR="$WORKDIR/resultats"

# ── Couleurs ──────────────────────────────────────────────────────────────────

GREEN='\033[0;32m'
RED='\033[0;31m'
NC='\033[0m'

# ── Compteurs ─────────────────────────────────────────────────────────────────

PASS=0
FAIL=0
TOTAL=0

pass() { echo -e "${GREEN}  PASS${NC} — $1"; (( PASS++ )); (( TOTAL++ )); }
fail() { echo -e "${RED}  FAIL${NC} — $1"; (( FAIL++ )); (( TOTAL++ )); }

# ── Assertions ────────────────────────────────────────────────────────────────

assert_exit_zero() {
    local label="$1"; shift
    if "$@" >/dev/null 2>&1; then pass "$label"; else fail "$label"; fi
}

assert_exit_nonzero() {
    local label="$1"; shift
    if ! "$@" >/dev/null 2>&1; then pass "$label"; else fail "$label"; fi
}

assert_contains() {
    local label="$1" pattern="$2" output="$3"
    if echo "$output" | grep -q "$pattern"; then pass "$label"; else fail "$label"; fi
}

assert_not_contains() {
    local label="$1" pattern="$2" output="$3"
    if ! echo "$output" | grep -q "$pattern"; then pass "$label"; else fail "$label"; fi
}

assert_file_exists() {
    local label="$1" file="$2"
    if [ -f "$file" ]; then pass "$label"; else fail "$label (absent : $file)"; fi
}

assert_file_absent() {
    local label="$1" file="$2"
    if [ ! -f "$file" ]; then pass "$label"; else fail "$label (présent à tort : $file)"; fi
}

assert_line_count() {
    local label="$1" expected="$2" file="$3"
    local actual
    actual=$(wc -l < "$file")
    if [ "$actual" -eq "$expected" ]; then pass "$label"; else fail "$label (attendu $expected, obtenu $actual)"; fi
}

# ── Helpers ───────────────────────────────────────────────────────────────────

# Écrit un pipeline.json dans WORKDIR et retourne son chemin
write_config() {
    local path="$WORKDIR/pipeline.json"
    cat > "$path"
    echo "$path"
}

# ── Setup / Teardown ──────────────────────────────────────────────────────────

setup() {
    mkdir -p "$WORKDIR"/{src_a,src_b,src_absent,bases,resultats}

    echo "alpha content" > "$WORKDIR/src_a/alpha.txt"
    echo "beta content"  > "$WORKDIR/src_a/beta.txt"
    mkdir -p "$WORKDIR/src_a/sub"
    echo "delta content" > "$WORKDIR/src_a/sub/delta.txt"

    echo "gamma content" > "$WORKDIR/src_b/gamma.txt"
    echo "delta content" > "$WORKDIR/src_b/delta.txt"
}

teardown() {
    rm -rf "$WORKDIR"
}

# ── Tests ─────────────────────────────────────────────────────────────────────

run_tests() {
    cd "$WORKDIR"

    # ── TP01 : JSON invalide — runner doit échouer proprement ────────────────
    echo "TP01 — JSON invalide : runner échoue avec message explicite"
    local cfg_invalid="$WORKDIR/invalid.json"
    echo "{ pipeline: [ BROKEN" > "$cfg_invalid"
    local out_tp01
    out_tp01=$(bash "$RUNNER" "$cfg_invalid" 2>&1 || true)
    assert_contains    "exit non nul sur JSON invalide"    "ERREUR"  "$out_tp01"
    assert_not_contains "pas de stacktrace jq brute"       "parse error" "$out_tp01"
    echo ""

    # ── TP02 : tableau .pipeline absent ──────────────────────────────────────
    echo "TP02 — .pipeline absent : runner échoue"
    local cfg_no_pipeline
    cfg_no_pipeline=$(write_config <<'EOF'
{ "config": [] }
EOF
)
    local out_tp02
    out_tp02=$(bash "$RUNNER" "$cfg_no_pipeline" 2>&1 || true)
    assert_contains "erreur si .pipeline absent" "ERREUR" "$out_tp02"
    echo ""

    # ── TP03 : champ manquant dans un bloc compute ────────────────────────────
    echo "TP03 — Champ 'nom' manquant dans compute : erreur explicite"
    local cfg_missing_field
    cfg_missing_field=$(write_config <<EOF
{
    "pipeline": [
        {
            "op":     "compute",
            "source": "$WORKDIR/src_a",
            "bases":  "$WORKDIR/bases"
        }
    ]
}
EOF
)
    local out_tp03
    out_tp03=$(bash "$RUNNER" "$cfg_missing_field" 2>&1 || true)
    assert_contains "erreur si champ 'nom' absent" "ERREUR" "$out_tp03"
    assert_contains "mention du champ manquant"    "nom"    "$out_tp03"
    echo ""

    # ── TP04 : opération inconnue ─────────────────────────────────────────────
    echo "TP04 — Opération inconnue : erreur explicite"
    local cfg_unknown_op
    cfg_unknown_op=$(write_config <<'EOF'
{
    "pipeline": [
        { "op": "migrate", "source": "/tmp" }
    ]
}
EOF
)
    local out_tp04
    out_tp04=$(bash "$RUNNER" "$cfg_unknown_op" 2>&1 || true)
    assert_contains "erreur si op inconnue" "ERREUR"   "$out_tp04"
    assert_contains "nom de l'op dans l'erreur" "migrate" "$out_tp04"
    echo ""

    # ── TP05 : compute — cd correct, chemin relatif dans la base ─────────────
    echo "TP05 — Compute : cd correct, chemins relatifs dans la base"
    local cfg_compute
    cfg_compute=$(write_config <<EOF
{
    "pipeline": [
        {
            "op":     "compute",
            "source": "$WORKDIR/src_a",
            "bases":  "$WORKDIR/bases",
            "nom":    "hashes_a.b3"
        }
    ]
}
EOF
)
    bash "$RUNNER" "$cfg_compute" >/dev/null 2>&1
    assert_file_exists "base hashes_a.b3 créée" "$WORKDIR/bases/hashes_a.b3"

    # Vérifier que les chemins dans la base sont relatifs (commencent par ./)
    local first_path
    first_path=$(awk '{print $2}' "$WORKDIR/bases/hashes_a.b3" | head -1)
    assert_contains    "chemin relatif dans la base (./))" "./" "$first_path"
    assert_not_contains "pas de chemin absolu dans la base" "$WORKDIR" "$first_path"

    # 3 fichiers indexés (alpha.txt, beta.txt, sub/delta.txt)
    assert_line_count "3 fichiers indexés" 3 "$WORKDIR/bases/hashes_a.b3"
    echo ""

    # ── TP06 : compute — dossier source absent ────────────────────────────────
    echo "TP06 — Compute : dossier source absent → erreur explicite"
    local cfg_absent
    cfg_absent=$(write_config <<EOF
{
    "pipeline": [
        {
            "op":     "compute",
            "source": "$WORKDIR/src_absent_inexistant",
            "bases":  "$WORKDIR/bases",
            "nom":    "hashes_absent.b3"
        }
    ]
}
EOF
)
    local out_tp06
    out_tp06=$(bash "$RUNNER" "$cfg_absent" 2>&1 || true)
    assert_contains     "erreur si source absente"       "ERREUR"  "$out_tp06"
    assert_file_absent  "pas de base créée si source KO" "$WORKDIR/bases/hashes_absent.b3"
    echo ""

    # ── TP07 : verify — bon répertoire de travail ─────────────────────────────
    echo "TP07 — Verify : répertoire de travail correct, vérification OK"
    # Prérequis : base hashes_a.b3 créée en TP05
    local cfg_verify
    cfg_verify=$(write_config <<EOF
{
    "pipeline": [
        {
            "op":     "verify",
            "source": "$WORKDIR/src_a",
            "base":   "$WORKDIR/bases/hashes_a.b3"
        }
    ]
}
EOF
)
    local out_tp07
    out_tp07=$(bash "$RUNNER" "$cfg_verify" 2>&1 || true)
    assert_contains     "verify retourne OK"     "OK"     "$out_tp07"
    assert_not_contains "aucun FAILED"           "FAILED" "$out_tp07"

    # recap.txt produit
    local outdir_tp07
    outdir_tp07=$(ls -d "${RESULTATS_DIR}/resultats_hashes_a"* 2>/dev/null | tail -1)
    assert_file_exists "recap.txt produit par verify" "${outdir_tp07}/recap.txt"
    echo ""

    # ── TP08 : verify — détection de corruption ───────────────────────────────
    echo "TP08 — Verify : détection de corruption"
    echo "contenu corrompu" > "$WORKDIR/src_a/alpha.txt"
    local out_tp08
    out_tp08=$(bash "$RUNNER" "$cfg_verify" 2>&1 || true)
    assert_contains "corruption détectée" "ECHEC" "$out_tp08"
    # Restauration
    echo "alpha content" > "$WORKDIR/src_a/alpha.txt"
    echo ""

    # ── TP09 : verify — base .b3 absente ─────────────────────────────────────
    echo "TP09 — Verify : base .b3 absente → erreur explicite"
    local cfg_verify_bad_base
    cfg_verify_bad_base=$(write_config <<EOF
{
    "pipeline": [
        {
            "op":     "verify",
            "source": "$WORKDIR/src_a",
            "base":   "$WORKDIR/bases/inexistante.b3"
        }
    ]
}
EOF
)
    local out_tp09
    out_tp09=$(bash "$RUNNER" "$cfg_verify_bad_base" 2>&1 || true)
    assert_contains "erreur si base absente" "ERREUR" "$out_tp09"
    echo ""

    # ── TP10 : compare — appel correct, résultats produits ───────────────────
    echo "TP10 — Compare : appel correct, fichiers de résultats produits"
    # Créer une seconde base (src_b)
    local cfg_compute_b
    cfg_compute_b=$(write_config <<EOF
{
    "pipeline": [
        {
            "op":     "compute",
            "source": "$WORKDIR/src_b",
            "bases":  "$WORKDIR/bases",
            "nom":    "hashes_b.b3"
        }
    ]
}
EOF
)
    bash "$RUNNER" "$cfg_compute_b" >/dev/null 2>&1

    local cfg_compare
    cfg_compare=$(write_config <<EOF
{
    "pipeline": [
        {
            "op":     "compare",
            "base_a": "$WORKDIR/bases/hashes_a.b3",
            "base_b": "$WORKDIR/bases/hashes_b.b3"
        }
    ]
}
EOF
)
    bash "$RUNNER" "$cfg_compare" >/dev/null 2>&1

    local outdir_tp10
    outdir_tp10=$(ls -d "${RESULTATS_DIR}/resultats_hashes_a"* 2>/dev/null | tail -1)
    assert_file_exists "recap.txt produit"     "${outdir_tp10}/recap.txt"
    assert_file_exists "modifies.b3 produit"   "${outdir_tp10}/modifies.b3"
    assert_file_exists "disparus.txt produit"  "${outdir_tp10}/disparus.txt"
    assert_file_exists "nouveaux.txt produit"  "${outdir_tp10}/nouveaux.txt"
    echo ""

    # ── TP11 : compare — base_a absente ──────────────────────────────────────
    echo "TP11 — Compare : base_a absente → erreur explicite"
    local cfg_compare_bad
    cfg_compare_bad=$(write_config <<EOF
{
    "pipeline": [
        {
            "op":     "compare",
            "base_a": "$WORKDIR/bases/fantome.b3",
            "base_b": "$WORKDIR/bases/hashes_b.b3"
        }
    ]
}
EOF
)
    local out_tp11
    out_tp11=$(bash "$RUNNER" "$cfg_compare_bad" 2>&1 || true)
    assert_contains "erreur si base_a absente" "ERREUR" "$out_tp11"
    echo ""

    # ── TP12 : pipeline multi-opérations — exécution séquentielle complète ───
    echo "TP12 — Pipeline complet : compute + verify + compare"
    # Recalcul propre
    rm -f "$WORKDIR/bases/hashes_a.b3" "$WORKDIR/bases/hashes_b.b3"

    local cfg_full
    cfg_full=$(write_config <<EOF
{
    "pipeline": [
        {
            "op":     "compute",
            "source": "$WORKDIR/src_a",
            "bases":  "$WORKDIR/bases",
            "nom":    "hashes_a.b3"
        },
        {
            "op":     "compute",
            "source": "$WORKDIR/src_b",
            "bases":  "$WORKDIR/bases",
            "nom":    "hashes_b.b3"
        },
        {
            "op":     "verify",
            "source": "$WORKDIR/src_a",
            "base":   "$WORKDIR/bases/hashes_a.b3"
        },
        {
            "op":     "compare",
            "base_a": "$WORKDIR/bases/hashes_a.b3",
            "base_b": "$WORKDIR/bases/hashes_b.b3"
        }
    ]
}
EOF
)
    local out_tp12
    out_tp12=$(bash "$RUNNER" "$cfg_full" 2>&1 || true)
    assert_contains     "COMPUTE src_a mentionné" "COMPUTE" "$out_tp12"
    assert_contains     "VERIFY mentionné"        "VERIFY"  "$out_tp12"
    assert_contains     "COMPARE mentionné"       "COMPARE" "$out_tp12"
    assert_file_exists  "hashes_a.b3 créée"       "$WORKDIR/bases/hashes_a.b3"
    assert_file_exists  "hashes_b.b3 créée"       "$WORKDIR/bases/hashes_b.b3"
    assert_not_contains "pas d'ERREUR dans pipeline complet" "ERREUR" "$out_tp12"
    echo ""
}

# ── Main ──────────────────────────────────────────────────────────────────────

for dep in jq b3sum; do
    command -v "$dep" &>/dev/null || {
        echo -e "${RED}ERREUR${NC} : $dep non trouvé."
        exit 1
    }
done

[ -f "$RUNNER" ]    || { echo -e "${RED}ERREUR${NC} : runner.sh introuvable : $RUNNER";    exit 1; }
[ -f "$INTEGRITY" ] || { echo -e "${RED}ERREUR${NC} : integrity.sh introuvable : $INTEGRITY"; exit 1; }

setup
run_tests
teardown

echo "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━"
if [ "$FAIL" -eq 0 ]; then
    echo -e "  ${GREEN}$PASS/$TOTAL tests passés${NC}"
else
    echo -e "  ${GREEN}$PASS${NC}/${TOTAL} passés — ${RED}$FAIL échec(s)${NC}"
fi
echo "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━"
echo ""

[ "$FAIL" -eq 0 ]

--- Fichier : tests/validation.md ---
# Tests et validation - integrity.sh

**Niveau d'exigence :** production, admin système. Chaque cas doit être exécuté et son résultat vérifié explicitement.

---

## Environnement de test

```bash
# Créer un environnement de test isolé
mkdir -p /tmp/integrity-test/{data,output}
cd /tmp/integrity-test

# Créer des fichiers de test avec contenu connu
echo "contenu alpha" > data/alpha.txt
echo "contenu beta"  > data/beta.txt
echo "contenu gamma" > data/gamma.txt
mkdir -p data/sub
echo "contenu delta" > data/sub/delta.txt
```

---

## Cas de test

### T01 - Compute de base

```bash
./integrity.sh compute ./data base_t01.b3
```

**Résultat attendu :**

- Fichier `base_t01.b3` créé avec 4 lignes (une par fichier).
- Message `Base enregistrée : base_t01.b3 (4 fichiers)`.
- Chaque ligne au format `<hash64chars>  ./data/<chemin>`.

```bash
# Vérification
wc -l base_t01.b3           # → 4
head -1 base_t01.b3         # → hash + chemin lisibles
```

---

### T02 - Verify sans modification

```bash
b3sum --check base_t01.b3
```

**Résultat attendu :** 4 lignes `OK`, aucun `FAILED`, exit code 0.

```bash
echo $?   # → 0
```

---

### T03 - Verify après corruption d'un fichier

```bash
echo "contenu modifié" > data/beta.txt
b3sum --check base_t01.b3
```

**Résultat attendu :**

- `./data/beta.txt: FAILED`
- `b3sum: WARNING: 1 computed checksum did NOT match`
- Exit code non nul.

```bash
echo $?   # → 1
b3sum --check base_t01.b3 2>&1 | grep FAILED   # → ./data/beta.txt: FAILED
```

---

### T04 - Verify après suppression d'un fichier

```bash
# Restaurer l'état T01 d'abord
echo "contenu beta" > data/beta.txt

# Supprimer un fichier
rm data/gamma.txt
b3sum --check base_t01.b3
```

**Résultat attendu :**

- `./data/gamma.txt: FAILED` (No such file or directory)
- Exit code non nul.

---

### T05 - Compare : aucune différence

```bash
# Restaurer l'état T01
echo "contenu gamma" > data/gamma.txt

# Créer une seconde base identique
./integrity.sh compute ./data base_t05.b3
./integrity.sh compare base_t01.b3 base_t05.b3
```

**Résultat attendu :** sections `MODIFIÉS`, `DISPARUS`, `NOUVEAUX` toutes vides. Rapport sauvegardé.

---

### T06 - Compare : fichier modifié

```bash
echo "contenu beta modifié" > data/beta.txt
./integrity.sh compute ./data base_t06.b3
./integrity.sh compare base_t01.b3 base_t06.b3
```

**Résultat attendu :**

- Section `FICHIERS MODIFIÉS` contient `./data/beta.txt` avec ancien et nouveau hash.
- Sections `DISPARUS` et `NOUVEAUX` vides.

---

### T07 - Compare : fichier supprimé + fichier ajouté

```bash
# Repartir d'une base propre
echo "contenu beta" > data/beta.txt
./integrity.sh compute ./data base_t07_old.b3

# Modifier l'état
rm data/alpha.txt
echo "contenu epsilon" > data/epsilon.txt
./integrity.sh compute ./data base_t07_new.b3

./integrity.sh compare base_t07_old.b3 base_t07_new.b3
```

**Résultat attendu :**

- `DISPARUS` : `./data/alpha.txt`
- `NOUVEAUX` : `./data/epsilon.txt`
- `MODIFIÉS` : vide

---

### T08 - Robustesse : fichier avec espace dans le nom

```bash
echo "contenu avec espace" > "data/fichier avec espace.txt"
./integrity.sh compute ./data base_t08.b3
b3sum --check base_t08.b3
```

**Résultat attendu :** tous les fichiers `OK`, y compris `fichier avec espace.txt`.

---

### T09 - Robustesse : dossier vide (limite connue)

```bash
mkdir data/dossier_vide
./integrity.sh compute ./data base_t09.b3
```

**Résultat attendu :** `dossier_vide` absent de `base_t09.b3`. Comportement normal et documenté - `find -type f` n'indexe pas les dossiers vides.

---

### T10 - Chemin absolu vs relatif (piège critique)

```bash
# Calculer avec chemin absolu - mauvaise pratique
b3sum $(find /tmp/integrity-test/data -type f) > base_absolu.b3
head -1 base_absolu.b3   # → chemin absolu /tmp/integrity-test/data/...

# Calculer avec chemin relatif - bonne pratique
cd /tmp/integrity-test
find ./data -type f -print0 | sort -z | xargs -0 b3sum > base_relatif.b3
head -1 base_relatif.b3  # → chemin relatif ./data/...
```

**Résultat attendu :** les deux bases sont incompatibles entre elles. Confirme que les chemins absolus cassent la portabilité.

---

## Nettoyage

```bash
rm -rf /tmp/integrity-test
```

---

## Critères de qualité globaux

| Critère | Exigence |
|---|---|
| Détection corruption | 100 % des fichiers modifiés détectés (T03) |
| Détection suppression | 100 % des fichiers manquants détectés (T04) |
| Faux positifs | Zéro - verify sur base intacte = 100 % OK (T02) |
| Noms avec espaces | Traités sans erreur (T08) |
| Rapport compare | Sauvegardé sur disque, horodaté (T05–T07) |
| Exit code | Non nul si au moins un FAILED (T03, T04) |
| Mode strict `-euo pipefail` | Le script s'arrête sur toute erreur non gérée |


--- Fichier : docs/explication-run-tests.md ---
# Explication du code — run_tests.sh + run_tests_pipeline.sh

---

## Vue d'ensemble

Deux suites de tests indépendantes, bash pur, sans framework externe.

```
tests/
├── run_tests.sh            ← integrity.sh — 15 cas T00–T14
└── run_tests_pipeline.sh   ← runner.sh + pipeline.json — 12 cas TP01–TP12
```

Chaque suite : prérequis → setup → tests → teardown → rapport + exit code CI.

---

## PARTIE 1 — run_tests.sh (integrity.sh)

### 1.1 Configuration et chemins

```bash
SCRIPT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"
INTEGRITY="$SCRIPT_DIR/../integrity.sh"
WORKDIR="$(mktemp -d /tmp/integrity-test.XXXXXX)"
```

- `SCRIPT_DIR` : répertoire absolu du script, indépendant du `pwd` appelant.
- `INTEGRITY` : chemin relatif à `run_tests.sh` — déplaçables ensemble sans modifier les chemins.
- `WORKDIR` : répertoire temporaire isolé par `mktemp`, suffix aléatoire 6 chars.

### 1.2 Système de comptage

```bash
PASS=0; FAIL=0; TOTAL=0
pass() { echo -e "${GREEN}  PASS${NC} — $1"; (( PASS++ )); (( TOTAL++ )); }
fail() { echo -e "${RED}  FAIL${NC} — $1"; (( FAIL++ )); (( TOTAL++ )); }
```

`TOTAL` permet de détecter un test sauté silencieusement.

### 1.3 Fonctions d'assertion

**`assert_exit_zero` / `assert_exit_nonzero`** : exécute une commande, vérifie le code de retour. `> /dev/null 2>&1` supprime toute sortie. `shift` consomme le label pour que `"$@"` ne contienne que la commande.

**`assert_contains` / `assert_not_contains`** : cherche un pattern dans une chaîne capturée. La capture via `local out=$(commande)` avant l'assertion permet plusieurs inspections sans relancer la commande.

**`assert_line_count`** : `wc -l < fichier` (sans le nom) — pas d'affichage du nom par `wc`.

**`assert_file_exists` / `assert_file_absent`** : présence ou absence d'un fichier régulier.

### 1.4 Setup / Teardown

4 fichiers déterministes (contenu connu → hashes reproductibles). `sub/delta.txt` valide la récursivité de `find`. `teardown()` supprime `WORKDIR` entier.

### 1.5 Pattern || true

```bash
local out
out=$(commande 2>&1 || true)
```

Critique : sans `|| true`, un code de retour non nul sous `-euo pipefail` interrompt le script avant que l'assertion enregistre l'échec.

### 1.6 Cas de test spécifiques

**T00 — ShellCheck** : analyse statique sur `integrity.sh` et `run_tests.sh`. `SKIP` propre si non installé.

**T11 — Intégrité base avec ETA** : vérifie que `compute_with_progress` produit une base bit-à-bit identique à `find | sort | xargs b3sum`, sans artefact `ETA` ni `\r`.

**T12 — Mode `--quiet`** : stdout vide sur verify OK, verify ECHEC, et compute. Exit code non nul propagé. Fichiers de résultats produits malgré `--quiet`.

**T13 — Horodatage** : deux `verify` successifs sur la même base → deux dossiers distincts (pas d'écrasement). `sleep 1` garantit des timestamps différents.

**T14 — Argument invalide** : `verify base.b3 /chemin/inexistant` → `ERREUR` explicite.

### 1.7 Tableau des cas

| Cas | Description |
|---|---|
| T00 | ShellCheck (analyse statique) |
| T01 | Compute de base |
| T02 | Verify sans modification |
| T03 | Verify après corruption |
| T04 | Verify après suppression |
| T05 | Compare sans différence |
| T06 | Compare avec fichier modifié |
| T07 | Compare avec fichier supprimé + ajouté |
| T08 | Noms de fichiers avec espaces |
| T09 | Dossiers vides ignorés |
| T10 | Chemins absolus vs relatifs |
| T11 | Intégrité base avec ETA |
| T12 | Mode `--quiet` |
| T13 | Horodatage anti-écrasement |
| T14 | Argument invalide pour verify |

---

## PARTIE 2 — run_tests_pipeline.sh (runner.sh + pipeline.json)

### 2.1 Configuration et chemins

```bash
SCRIPT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"
RUNNER="$SCRIPT_DIR/../runner.sh"
INTEGRITY="$SCRIPT_DIR/../integrity.sh"
WORKDIR="$(mktemp -d /tmp/integrity-pipeline-test.XXXXXX)"
export RESULTATS_DIR="$WORKDIR/resultats"
```

`RESULTATS_DIR` est exporté pour que `integrity.sh` (appelé par `runner.sh`) redirige ses résultats dans le `WORKDIR` isolé — pas dans `~/integrity_resultats`.

### 2.2 Helper write_config

```bash
write_config() {
    local path="$WORKDIR/pipeline.json"
    cat > "$path"
    echo "$path"
}
```

Lit le JSON depuis stdin (heredoc), l'écrit dans `WORKDIR/pipeline.json`, retourne le chemin. Permet de générer un `pipeline.json` différent par test sans fichiers temporaires nommés à la main.

Usage :

```bash
local cfg
cfg=$(write_config <<EOF
{ "pipeline": [ { "op": "compute", ... } ] }
EOF
)
bash "$RUNNER" "$cfg"
```

### 2.3 Stratégie de test par cas

**TP01–TP04 (parsing)** : tests négatifs — chaque test passe un JSON ou une config invalide et vérifie que `runner.sh` échoue avec un message `ERREUR` explicite, sans stacktrace `jq` brute ni crash silencieux.

**TP05–TP06 (compute)** : TP05 vérifie trois invariants sur la base produite — existence, chemins relatifs (`./ `en début de chemin), comptage exact de fichiers. TP06 vérifie l'échec propre sur source absente.

**TP07–TP09 (verify)** : TP07 vérifie le bon répertoire de travail (vérification OK, `recap.txt` produit). TP08 vérifie la détection de corruption. TP09 vérifie l'échec propre sur base absente.

**TP10–TP11 (compare)** : TP10 vérifie les quatre fichiers de résultats produits. TP11 vérifie l'échec propre sur `base_a` absente.

**TP12 (pipeline complet)** : test d'intégration — compute × 2 + verify + compare dans un seul `pipeline.json`. Vérifie les labels dans la sortie, les bases créées, et l'absence d'erreur.

### 2.4 Résolution des dossiers de résultats

```bash
outdir_tp07=$(ls -d "${RESULTATS_DIR}/resultats_hashes_a"* 2>/dev/null | tail -1)
```

`tail -1` récupère le dossier le plus récent — compatible avec l'horodatage automatique de `make_result_dir()`. Sans `tail -1`, si un dossier `resultats_hashes_a` existe déjà d'un test précédent, `ls` retourne plusieurs lignes et l'assertion porte sur la mauvaise.

### 2.5 Prérequis et exécution

```bash
cd tests
./run_tests_pipeline.sh
```

Prérequis : `jq`, `b3sum`, `bash >= 4`, `runner.sh` et `integrity.sh` dans le répertoire parent. Exit code CI-compatible : 0 si tous passent, 1 si au moins un échec.

### 2.6 Tableau des cas

| Cas | Description |
|---|---|
| TP01 | JSON invalide — erreur propre sans stacktrace jq |
| TP02 | Clé `.pipeline` absente |
| TP03 | Champ `nom` manquant dans compute |
| TP04 | Opération inconnue |
| TP05 | Compute — cd correct, chemins relatifs, comptage |
| TP06 | Compute — dossier source absent |
| TP07 | Verify — bon répertoire de travail, OK |
| TP08 | Verify — corruption détectée |
| TP09 | Verify — base .b3 absente |
| TP10 | Compare — fichiers de résultats produits |
| TP11 | Compare — base_a absente |
| TP12 | Pipeline complet compute + verify + compare |

---

## Prérequis globaux

```bash
# run_tests.sh
apt install b3sum shellcheck   # shellcheck optionnel

# run_tests_pipeline.sh
apt install b3sum jq
```

Les deux suites sont indépendantes et peuvent être lancées séparément.

--- Fichier : docs/manuel.md ---
# Manuel technique — Vérification d'intégrité de données

**Périmètre :** détection d'erreurs de transfert et de corruption silencieuse sur disque, sans adversaire.  
**Outils couverts :** b3sum (BLAKE3) · xxHash3 · find · diff · bash · jq

---

## Table des matières

1. [Algorithmes de hachage](#1-algorithmes-de-hachage)
2. [Structure du fichier .b3](#2-structure-du-fichier-b3)
3. [Workflow : calcul, stockage, comparaison](#3-workflow--calcul-stockage-comparaison)
4. [Explication du script integrity.sh](#4-explication-du-script-integritysh)
5. [Pipeline batch : runner.sh + pipeline.json](#5-pipeline-batch--runnersh--pipelinejson)
6. [Performances et optimisation disque](#6-performances-et-optimisation-disque)
7. [Limites et angles morts](#7-limites-et-angles-morts)
8. [Référence rapide](#8-référence-rapide)
9. [Annexe — Alternatives et extensions](#9-annexe--alternatives-et-extensions)

---

## 1. Algorithmes de hachage

### Taxonomie

Deux familles distinctes, usages mutuellement exclusifs :

| Propriété | Cryptographique (BLAKE3) | Non-cryptographique (xxHash3) |
|---|---|---|
| Résistance collision intentionnelle | Oui — infaisable calculatoirement | Non — collisions construisibles |
| Résistance préimage | Oui | Non |
| Débit CPU (1 cœur) | ~1 Go/s | ~50 Go/s |
| Débit sur HDD (150 Mo/s) | Identique — disque impose le rythme | Identique |
| Débit sur SATA SSD (500 Mo/s) | Identique | Identique |
| Détection corruption accidentelle | Oui | Oui |
| Utilisable en sécurité | Oui | Non |

### Pourquoi BLAKE3 plutôt que xxHash3

xxHash3 est techniquement suffisant pour détecter des erreurs accidentelles. BLAKE3 est recommandé pour une seule raison : **le coût marginal sur disque est nul** — les deux sont limités par l'I/O. BLAKE3 reste utilisable si le besoin évolue vers un contexte de sécurité. Headroom gratuit.

```bash
# Si xxHash3 est préféré — workflow identique à b3sum
find ./dossier -type f -print0 | sort -z | xargs -0 xxh128sum > base.xxh
```

### Limitations spécifiques à ce workflow

- Ne hache pas les métadonnées (mtime, permissions).
- Ne hache pas les dossiers vides : `find -type f` ne remonte que les fichiers réguliers.
- Sensible aux chemins : chemin absolu vs relatif → deux bases incompatibles pour la même donnée.

---

## 2. Structure du fichier .b3

b3sum produit un format texte simple, une ligne par fichier :

```
# Format : <hash>  <chemin>
# Deux espaces séparent le hash du chemin (convention b3sum/sha256sum)

a1b2c3d4e5f6a7b8c9d0e1f2a3b4c5d6e7f8a9b0c1d2e3f4a5b6c7d8e9f0a1b2  ./dossier/fichier.txt
e5f6a7b8c9d0e1f2a3b4c5d6e7f8a9b0c1d2e3f4a5b6c7d8e9f0a1b2c3d4e5f6  ./dossier/sous/autre.bin
```

| Nombre de fichiers | Taille approximative |
|---|---|
| 10 000 | ~2 Mo |
| 100 000 | ~20 Mo |
| 1 000 000 | ~200 Mo |

> **Règle absolue : chemins relatifs.** Toujours `find ./dossier`, jamais `find /chemin/absolu`. Un chemin absolu rend la base inutilisable après déplacement ou remontage.

---

## 3. Workflow : calcul, stockage, comparaison

### Calcul et enregistrement de la base

```bash
find ./mon_dossier -type f -print0 \
  | sort -z \
  | xargs -0 b3sum \
  > hashes_2024-01-15.b3

wc -l hashes_2024-01-15.b3
```

**`sort -z`** : `find` ne garantit pas un ordre déterministe. Sans tri, `diff` entre deux bases est inutilisable.

**`-print0` / `-0`** : robuste aux noms de fichiers avec espaces ou caractères spéciaux.

### Vérification directe

```bash
b3sum --check hashes_2024-01-15.b3

# Sortie OK :
# ./mon_dossier/fichier.txt: OK

# Sortie ECHEC :
# ./mon_dossier/sous/corrompu.bin: FAILED
# b3sum: WARNING: 1 computed checksum did NOT match

b3sum --check hashes_2024-01-15.b3 2>&1 | grep FAILED
```

> **Contrainte critique : répertoire de travail.** `b3sum --check` résout les chemins relatifs depuis `pwd`. Toujours exécuter depuis le répertoire où `compute` a été lancé.

### Comparaison de deux bases .b3

```bash
diff <(sort hashes_2024-01-15.b3) <(sort hashes_2024-02-01.b3)
```

`run_compare()` dans `integrity.sh` automatise cette comparaison avec `join`, `comm`, et un rapport structuré.

---

## 4. Explication du script integrity.sh

### En-tête et mode strict

```bash
#!/usr/bin/env bash
set -euo pipefail
```

- `-e` : arrêt sur échec de commande.
- `-u` : erreur sur variable non initialisée.
- `-o pipefail` : échec du pipeline si une commande intermédiaire échoue.

### Parsing des arguments

```bash
QUIET=0
ARGS=()
for arg in "$@"; do
  case "$arg" in
    --quiet) QUIET=1 ;;
    *)       ARGS+=("$arg") ;;
  esac
done
MODE="${ARGS[0]:-}"
ARG2="${ARGS[1]:-}"
ARG3="${ARGS[2]:-}"
```

`--quiet` filtré avant la lecture positionnelle. `:-` donne une valeur vide par défaut en mode `-u`.

### Mode compute

```bash
compute_with_progress() {
  local -a files
  mapfile -d '' files < <(find "$target" -type f -print0 | sort -z)

  for file in "${files[@]}"; do
    b3sum "$file" >> "$hashfile"
    # ETA calculé et affiché sur /dev/tty — jamais dans le pipe
    printf "\r[%d/%d] ETA : %dm %02ds   " ... > /dev/tty
  done
}
```

**`mapfile -d ''`** : charge les chemins en tableau depuis flux nul-séparé. Robuste aux espaces et caractères spéciaux.

**`> /dev/tty`** : progression écrite directement sur le terminal, ne peut pas polluer la base `.b3`.

### Mode verify

```bash
hashfile_abs=$(realpath "$ARG2")
[ -n "${ARG3:-}" ] && cd "$ARG3"
run_verify "$hashfile_abs"
```

Le chemin absolu est résolu **avant** le `cd` — un chemin relatif deviendrait invalide après changement de répertoire.

### Mode compare

`run_compare()` convertit `hash  chemin` → `chemin\thash` via `awk` (offset fixe 64 chars pour le hash), puis utilise `sort`, `join`, `comm` avec `-t $'\t'` — robuste aux chemins avec espaces.

---

## 5. Pipeline batch : runner.sh + pipeline.json

### Problème résolu

Lancer `integrity.sh` manuellement sur plusieurs dossiers depuis des partitions différentes (VeraCrypt, disques externes) est error-prone : répertoire de travail incorrect, chemins absolus dans les bases, oubli de `cd`. `runner.sh` automatise et sécurise ces étapes.

**Dépendance supplémentaire :** `jq` (`apt install jq` dans WSL).

### pipeline.json — format

```json
{
    "pipeline": [

        {
            "op":     "compute",
            "source": "/mnt/a/dossier_disque_1",
            "bases":  "/mnt/c/Users/TonNom/Desktop/bases",
            "nom":    "hashes_dossier_1.b3"
        },

        {
            "op":     "compute",
            "source": "/mnt/i/dossier_disque_2",
            "bases":  "/mnt/c/Users/TonNom/Desktop/bases",
            "nom":    "hashes_dossier_2.b3"
        },

        {
            "op":     "verify",
            "source": "/mnt/a/dossier_disque_1",
            "base":   "/mnt/c/Users/TonNom/Desktop/bases/hashes_dossier_1.b3"
        },

        {
            "op":     "compare",
            "base_a": "/mnt/c/Users/TonNom/Desktop/bases/hashes_dossier_1.b3",
            "base_b": "/mnt/c/Users/TonNom/Desktop/bases/hashes_dossier_2.b3"
        }

    ]
}
```

Champs requis par opération :

| `op` | Champs |
|---|---|
| `compute` | `source` — dossier à hacher · `bases` — dossier de destination · `nom` — nom du `.b3` |
| `verify` | `source` — répertoire de travail d'origine · `base` — chemin complet du `.b3` |
| `compare` | `base_a` — ancienne base · `base_b` — nouvelle base |

### runner.sh — comportement

**compute** : `cd "$source"` puis `integrity.sh compute . "$bases/$nom"`. Le `.` garantit des chemins relatifs dans la base.

**verify** : `cd "$source"` puis `integrity.sh verify "$base"`. Le `cd` reproduit le répertoire de travail d'origine du compute.

**compare** : appel direct sans `cd`. `base_a` et `base_b` sont des chemins absolus vers les `.b3`.

**Validation** : `jq empty` vérifie la syntaxe JSON à l'entrée. Champs manquants et opérations inconnues produisent un message `ERREUR` avec numéro de bloc, sans stacktrace `jq`.

### Lancement Windows (double-clic)

```bat
@echo off
wsl bash /mnt/c/Users/TonNom/Desktop/runner.sh
pause
```

### Chemins WSL — partitions VeraCrypt

| Windows | WSL |
|---|---|
| `A:\` | `/mnt/a/` |
| `C:\` | `/mnt/c/` |
| `H:\` | `/mnt/h/` |
| `I:\` | `/mnt/i/` |

Si VeraCrypt remonte une partition sur une lettre différente, seul le champ `source` dans `pipeline.json` est à modifier. La base `.b3` reste valide car ses chemins sont relatifs.

---

## 6. Performances et optimisation disque

Sur HDD (150 Mo/s), SSD SATA (500 Mo/s) ou SSD NVMe séquentiel, le disque est systématiquement le goulot. b3sum à 1 Go/s sur un cœur ne sera jamais le facteur limitant.

La boucle séquentielle de `compute_with_progress` est légèrement moins efficace que `xargs -P 4` sur SSD NVMe avec de nombreux petits fichiers, mais identique sur HDD — cas principal pour gros volumes. Le gain ETA justifie le choix.

Pour SSD NVMe + pas besoin d'ETA :

```bash
find ./dossier -type f -print0 | sort -z | xargs -0 -P 4 b3sum > base.b3
```

---

## 7. Limites et angles morts

| Scénario | Détecté ? | Explication |
|---|---|---|
| Fichier corrompu | **Oui** | Hash différent → FAILED ou divergence compare |
| Fichier manquant | **Oui** | FAILED (No such file) ou section DISPARUS |
| Fichier ajouté | **Oui** (compare) | Section NOUVEAUX |
| Dossier vide | **Non** | `find -type f` ignore les dossiers vides |
| Permissions/timestamps | **Non** | b3sum ne hache que le contenu binaire |
| Clone identique | **Non** | Hash identique — indétectable par définition |
| Corruption de la base .b3 | **Non** | La base n'est pas auto-protégée |

### Protéger la base

```bash
b3sum hashes_2024-01-15.b3 > hashes_2024-01-15.b3.check
b3sum --check hashes_2024-01-15.b3.check
```

Stocker la base sur un support distinct. Sur VeraCrypt : stocker les `.b3` sur `C:`, jamais sur la partition vérifiée.

### Renommages et changements de chemin

`b3sum --check` compare les chemins littéralement. Tout renommage de dossier produit des FAILED sur tous les fichiers, même si le contenu est intact.

```bash
sed 's|./ancien_nom/|./nouveau_nom/|g' base.b3 > base_corrigee.b3
b3sum --check base_corrigee.b3
```

---

## 8. Référence rapide

```bash
# Calcul
find ./dossier -type f -print0 | sort -z | xargs -0 b3sum > base.b3

# Vérification
./integrity.sh verify base.b3

# Comparaison
./integrity.sh compare ancienne.b3 nouvelle.b3

# Pipeline multi-dossiers
./runner.sh                        # lit pipeline.json dans le même dossier
./runner.sh /chemin/pipeline.json  # config explicite

# Compter les fichiers indexés
wc -l base.b3

# Fichier unique
b3sum fichier.bin

# Protéger la base
b3sum base.b3 > base.b3.check
```

| Situation | Mode | Commande |
|---|---|---|
| Première indexation | compute | `./integrity.sh compute ./dossier base.b3` |
| Multi-dossiers / VeraCrypt | runner | `./runner.sh` |
| Vérifier après transfert | verify | `./integrity.sh verify base.b3` |
| Comparer deux archives | compare | `./integrity.sh compare old.b3 new.b3` |
| Fichier unique | ad hoc | `b3sum fichier.bin` |

---

## 9. Annexe — Alternatives et extensions

### A.1 Outils FIM

| Outil | Usage | Complexité | Pertinent si… |
|---|---|---|---|
| Tripwire | Audit système local | Moyenne | Serveur Linux, conformité PCI-DSS/HIPAA |
| Samhain | FIM distribué, alertes SIEM | Élevée | Infrastructure d'entreprise |
| AIDE | Alternative open source à Tripwire | Moyenne | Remplacement direct de Tripwire |
| ZFS | Checksum natif sur chaque bloc | Faible (si migration possible) | Protection transparente |

b3sum/xxHash3 sont des **primitives**. Tripwire et Samhain sont des **systèmes** qui maintiennent un état de référence et détectent les dérives.

### A.2 Intégration automatisée

```bash
# Crontab — vérification hebdomadaire
0 2 * * 0 /opt/integrity.sh --quiet verify /var/lib/integrity/base.b3 >> /var/log/integrity.log 2>&1

# Post-transfert rsync
rsync -av source/ dest/ && b3sum --check base.b3

# Alerte email
b3sum --check base.b3 2>&1 | grep FAILED | mail -s 'Alerte intégrité' admin@example.com
```

--- Fichier : docs/progression-eta.md ---
# Progression temps réel et estimation ETA

## Le problème

Le pipeline `find | sort | xargs b3sum` est une boîte noire : `b3sum` ne remonte aucune progression. Par défaut, le mode `compute` s'exécute en silence jusqu'à complétion - aucun indicateur de durée ni d'avancement.

---

## Pourquoi l'ETA nécessite de casser le pipeline `xargs`

Intercaler `pv` dans le pipeline existant est techniquement possible mais inutilisable ici : mesurer le débit sur un flux `cat | pv | b3sum` produit un hash global du flux concaténé, pas une ligne par fichier. Le fichier `.b3` résultant est invalide pour `--check` ou `compare`.

```bash
# Cette approche est invalide - ne pas utiliser
TOTAL=$(find "$TARGET" -type f -print0 | xargs -0 du -sb | awk '{sum+=$1} END {print sum}')
find "$TARGET" -type f -print0 | sort -z \
  | xargs -0 cat \
  | pv -s "$TOTAL" \
  | b3sum \
  > "$HASHFILE"
# Produit un hash unique du flux concaténé - inutilisable
```

La seule approche compatible avec le format `.b3` : remplacer `xargs` par une boucle bash explicite, fichier par fichier. Le contrôle de progression devient trivial. Le coût en performance est négligeable - le disque est le goulot, pas le shell.

---

## Implémentation finale : `compute_with_progress`

```bash
compute_with_progress() {
  local target="$1"
  local hashfile="$2"

  local -a files
  mapfile -d '' files < <(find "$target" -type f -print0 | sort -z)

  local total_files=${#files[@]}
  local total_bytes
  total_bytes=$(du -sb "$target" | awk '{print $1}')

  local bytes_done=0
  local t_start
  t_start=$(date +%s)

  local i=0
  for file in "${files[@]}"; do
    b3sum "$file" >> "$hashfile"

    bytes_done=$(( bytes_done + $(stat -c%s "$file") ))
    i=$(( i + 1 ))

    local t_now elapsed
    t_now=$(date +%s)
    elapsed=$(( t_now - t_start ))

    if (( bytes_done > 0 && elapsed > 0 )); then
      local speed remaining
      speed=$(( bytes_done / elapsed ))
      remaining=$(( (total_bytes - bytes_done) / speed ))
      printf "\r[%d/%d] ETA : %dm %02ds   " \
        "$i" "$total_files" $(( remaining / 60 )) $(( remaining % 60 ))
    fi
  done

  printf "\r%*s\r" 40 ""  # effacer la ligne de progression
}
```

**`mapfile -d ''`** au lieu de `FILES=($(find ...))` : la substitution de commande `$(...)` découpe sur les espaces et les retours à la ligne - les noms de fichiers avec espaces seraient cassés en plusieurs éléments. `mapfile -d ''` lit le flux nul-séparé produit par `-print0` et charge chaque chemin comme un élément distinct du tableau, sans ambiguïté.

---

## Mécanique de l'estimation

L'ETA repose sur trois mesures :

- **octets traités** - cumulés après chaque fichier via `stat -c%s`
- **octets totaux** - calculés une fois avant la boucle via `du -sb`
- **débit instantané** - `octets_traités / secondes_écoulées`

```
ETA = (octets_restants) / débit_moyen
    = (total - fait) / (fait / elapsed)
```

Le débit moyen converge après ~10–20 secondes de traitement. Avant ce seuil, l'ETA est instable - comportement identique à `rsync`, `cp --progress`, ou tout outil du même type. Ce n'est pas un défaut d'implémentation, c'est une contrainte statistique inhérente à toute estimation par extrapolation linéaire sur fenêtre courte.

---

## Coût du changement de stratégie

| | Pipeline `xargs` | Boucle bash (avec progression) |
|---|---|---|
| Débit sur HDD | Optimal | Identique - I/O impose le rythme |
| Débit sur SSD séquentiel | Optimal | Identique |
| Débit sur SSD `-P 4` | +20–40 % | Non applicable - boucle séquentielle |
| Progression temps réel | Non | Oui |
| ETA | Non | Oui |

**Cas où la boucle dégrade les performances :** SSD avec `-P 4`. Le parallélisme par `xargs` n'est pas reproductible en boucle bash sans complexité significative. Sur HDD - cas le plus courant pour de gros volumes - la différence est nulle.


