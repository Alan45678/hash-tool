# === Arborescence du dossier ===

hash_tool
├── docker
│   └── entrypoint.sh
├── docs
│   ├── development
│   │   ├── ROADMAP.md
│   │   ├── architecture.md
│   │   ├── changelog.md
│   │   └── contributing.md
│   ├── docs
│   ├── guides
│   │   ├── cron-ci.md
│   │   ├── nas-synology.md
│   │   └── veracrypt.md
│   ├── reference
│   │   ├── docker.md
│   │   ├── integrity-sh.md
│   │   └── runner-sh.md
│   ├── spec
│   │   ├── api-interne.md
│   │   └── b3-format.md
│   ├── getting-started.md
│   └── index.md
├── mon_dossier
│   ├── bases
│   │   ├── hashes_dossier_1.b3
│   │   └── hashes_dossier_2.b3
│   ├── destination
│   │   ├── fichier (1).txt
│   │   ├── fichier (2).txt
│   │   ├── fichier (3).txt
│   │   └── fichier (4).txt
│   ├── result
│   │   ├── resultats_hashes_dossier_1
│   │   │   ├── disparus.txt
│   │   │   ├── modifies.b3
│   │   │   ├── nouveaux.txt
│   │   │   ├── recap.txt
│   │   │   └── report.html
│   │   └── resultats_hashes_dossier_1_20260222-100613
│   │       ├── disparus.txt
│   │       ├── modifies.b3
│   │       ├── nouveaux.txt
│   │       ├── recap.txt
│   │       └── report.html
│   └── source
│       ├── fichier (1).txt
│       ├── fichier (2).txt
│       ├── fichier (3).txt
│       └── fichier (4).txt
├── pipelines
│   ├── pipeline-debug.json
│   └── pipeline-veracrypt.json
├── reports
│   └── template.html
├── src
│   ├── lib
│   │   ├── core.sh
│   │   ├── report.sh
│   │   ├── results.sh
│   │   └── ui.sh
│   └── integrity.sh
├── tests
│   ├── run_tests.sh
│   └── run_tests_pipeline.sh
├── .dockerignore
├── .gitignore
├── Dockerfile
├── README.md
├── docker-compose.yml
├── mkdocs.yml
├── requirements-docs.txt
└── runner.sh


# === Contenu des fichiers ===

--- Fichier : .dockerignore ---
# .dockerignore - hash_tool
#
# Exclut du contexte de build Docker ce qui n'est pas nécessaire.
# Réduit la taille du contexte envoyé au daemon.

# Données utilisateur - jamais dans l'image
mon_dossier/
*.b3

# Résultats
resultats/
~/integrity_resultats/

# Tests - non requis dans l'image de production
tests/

# Documentation - non requise dans l'image
docs/
autre/
reports/
*.md
!README.md

# Fichiers temporaires
temp.txt
*.tmp
*.log

# Outils de développement
.git/
.gitignore


--- Fichier : .gitignore ---
# == Données utilisateur =======================================================
autre/
*.b3

# == Résultats =================================================================
resultats/
integrity_resultats/

# == Docker ====================================================================
# Ne pas ignorer : Dockerfile, .dockerignore, docker-compose.yml, docker/
# Ignorer les artefacts de build local
.docker/

# == Fichiers temporaires ======================================================
temp.txt
*.tmp
*.log
*.bak

# == OS ========================================================================
.DS_Store
Thumbs.db
desktop.ini

# == Éditeurs =================================================================
.vscode/
.idea/
*.swp
*.swo
*~

--- Fichier : Dockerfile ---
# =============================================================================
# hash_tool - Dockerfile
#
# Image Alpine légère (~15 Mo) avec b3sum et jq.
# Supporte linux/amd64 et linux/arm64 (NAS Synology, Raspberry Pi, etc.)
#
# b3sum est installé depuis les packages Alpine (community) - plus fiable
# que le téléchargement manuel depuis GitHub Releases.
#
# Build :
#   docker build -t hash_tool .
#   docker build --platform linux/arm64 -t hash_tool:arm64 .
#
# Utilisation :
#   docker run --rm -v /mes/donnees:/data hash_tool verify /data/base.b3
#   docker run --rm -v /mes/donnees:/data -v /mes/bases:/bases hash_tool compute /data /bases/hashes.b3
#   docker run --rm -v /chemin/pipeline.json:/pipelines/pipeline.json \
#              -v /mes/donnees:/data -v /mes/bases:/bases -v /mes/resultats:/resultats \
#              hash_tool runner /pipelines/pipeline.json
# =============================================================================

FROM alpine:3.19

LABEL maintainer="hash_tool" \
      description="Vérification d'intégrité BLAKE3 - integrity.sh + runner.sh" \
      org.opencontainers.image.source="https://github.com/hash_tool"

# Toutes les dépendances depuis apk - pas de wget, pas de binaire externe
# b3sum est dans Alpine community depuis v3.15
RUN apk add --no-cache \
      bash \
      jq \
      b3sum \
      coreutils \
      findutils \
    && rm -rf /var/cache/apk/*

# == Copie des scripts ========================================================

WORKDIR /app

COPY runner.sh           ./runner.sh
COPY src/integrity.sh    ./src/integrity.sh
COPY src/lib/report.sh   ./src/lib/report.sh

RUN chmod +x runner.sh src/integrity.sh src/lib/report.sh

# == Entrypoint ===============================================================

COPY docker/entrypoint.sh /entrypoint.sh
RUN chmod +x /entrypoint.sh

# == Volumes ==================================================================
#
# /data       → données à hacher (montage en lecture seule recommandé)
# /bases      → fichiers .b3 (lecture/écriture)
# /pipelines  → fichiers pipeline.json
# /resultats  → résultats compare/verify
#
VOLUME ["/data", "/bases", "/pipelines", "/resultats"]

# RESULTATS_DIR par défaut redirigé vers /resultats (volume monté)
ENV RESULTATS_DIR=/resultats

ENTRYPOINT ["/entrypoint.sh"]
CMD ["help"]

--- Fichier : README.md ---
# hash_tool - Vérification d'intégrité BLAKE3

voir ReadTheDocs 



--- Fichier : docker-compose.yml ---
# docker-compose.yml - hash_tool
#
# Cas d'usage typiques :
#   docker compose run --rm integrity compute /data /bases/hashes.b3
#   docker compose run --rm integrity verify  /bases/hashes.b3 /data
#   docker compose run --rm integrity compare /bases/old.b3 /bases/new.b3
#   docker compose run --rm pipeline
#
# Adapter les volumes (section x-volumes) selon l'environnement :
#   - Windows/WSL   : /mnt/c/Users/TonNom/...
#   - NAS Synology  : /volume1/...
#   - Serveur Debian: /srv/...

# == Chemins à adapter ========================================================
x-volumes:
  data:      &vol-data      /chemin/vers/donnees     # données à hacher (lecture seule)
  bases:     &vol-bases     /chemin/vers/bases        # fichiers .b3
  pipelines: &vol-pipelines /chemin/vers/pipelines   # fichiers pipeline.json
  resultats: &vol-resultats /chemin/vers/resultats   # résultats compare/verify

# == Services =================================================================
services:

  # Service principal - compute / verify / compare
  integrity:
    image: hash_tool
    build:
      context: .
      dockerfile: Dockerfile
    volumes:
      - *vol-data:/data:ro
      - *vol-bases:/bases
      - *vol-resultats:/resultats
    environment:
      - RESULTATS_DIR=/resultats
    # Pas de commande par défaut - passer la commande à docker compose run
    # Ex : docker compose run --rm integrity verify /bases/hashes.b3 /data

  # Service pipeline - exécute runner.sh avec pipeline.json monté
  pipeline:
    image: hash_tool
    build:
      context: .
      dockerfile: Dockerfile
    volumes:
      - *vol-data:/data:ro
      - *vol-bases:/bases
      - *vol-pipelines:/pipelines
      - *vol-resultats:/resultats
    environment:
      - RESULTATS_DIR=/resultats
    command: ["runner", "/pipelines/pipeline.json"]

  # Service cron - vérification périodique (optionnel)
  # Nécessite : docker compose up -d cron
  cron:
    image: hash_tool
    build:
      context: .
      dockerfile: Dockerfile
    volumes:
      - *vol-data:/data:ro
      - *vol-bases:/bases:ro
      - *vol-resultats:/resultats
    environment:
      - RESULTATS_DIR=/resultats
      - CRON_SCHEDULE=0 3 * * *       # 03h00 chaque nuit
      - CRON_BASE=/bases/hashes.b3    # base à vérifier
    # Le service cron tourne en boucle - nécessite l'image étendue avec crond
    # Voir docs/docker-cron.md pour le setup complet
    command: ["shell"]
    profiles: ["cron"]   # non démarré par défaut (docker compose --profile cron up)
    restart: unless-stopped


--- Fichier : mkdocs.yml ---
site_name: hash_tool
site_description: Vérification d'intégrité de fichiers par hachage BLAKE3
site_author: hash_tool
docs_dir: docs
site_dir: site

repo_url: https://github.com/hash_tool/hash_tool
repo_name: hash_tool/hash_tool
edit_uri: edit/main/docs/

theme:
  name: material
  language: fr
  palette:
    - scheme: slate
      primary: indigo
      accent: indigo
      toggle:
        icon: material/brightness-4
        name: Passer en mode clair
    - scheme: default
      primary: indigo
      accent: indigo
      toggle:
        icon: material/brightness-7
        name: Passer en mode sombre
  font:
    text: DM Sans
    code: JetBrains Mono
  features:
    - navigation.tabs
    - navigation.tabs.sticky
    - navigation.sections
    - navigation.expand
    - navigation.top
    - navigation.footer
    - search.suggest
    - search.highlight
    - content.code.copy
    - content.code.annotate
    - content.tabs.link
  icon:
    repo: fontawesome/brands/github

plugins:
  - search:
      lang: fr

markdown_extensions:
  - admonition
  - pymdownx.details
  - pymdownx.superfences
  - pymdownx.highlight:
      anchor_linenums: true
      line_spans: __span
      pygments_lang_class: true
  - pymdownx.inlinehilite
  - pymdownx.snippets
  - pymdownx.tabbed:
      alternate_style: true
  - tables
  - attr_list
  - md_in_html
  - toc:
      permalink: true

extra:
  social:
    - icon: fontawesome/brands/github
      link: https://github.com/hash_tool/hash_tool

nav:
  - Accueil: index.md
  - Démarrage rapide: getting-started.md

  - Référence:
    - integrity.sh: reference/integrity-sh.md
    - runner.sh & pipeline.json: reference/runner-sh.md
    - Docker: reference/docker.md

  - Spécifications:
    - Format .b3: spec/b3-format.md
    - API interne: spec/api-interne.md

  - Guides:
    - VeraCrypt & disques multiples: guides/veracrypt.md
    - CI / Cron: guides/cron-ci.md
    - NAS Synology: guides/nas-synology.md

  - Développement:
    - Architecture: development/architecture.md
    - Contribuer & Tests: development/contributing.md
    - Roadmap & Positionnement: development/roadmap.md
    - Changelog: development/changelog.md

--- Fichier : requirements-docs.txt ---
mkdocs 
mkdocs-material

--- Fichier : runner.sh ---
#!/usr/bin/env bash
# runner.sh - Exécuteur de pipeline integrity.sh depuis pipeline.json
#
# Usage :
#   ./runner.sh                          # lit pipelines/pipeline.json
#   ./runner.sh /chemin/pipeline.json    # config explicite
#
# Dépendances : bash >= 4, jq, src/integrity.sh

set -euo pipefail

# == Chemins ===================================================================

SCRIPT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"
INTEGRITY="$SCRIPT_DIR/src/integrity.sh"
CONFIG="${1:-$SCRIPT_DIR/pipelines/pipeline.json}"

# == Prérequis =================================================================

(( BASH_VERSINFO[0] >= 4 )) || { echo "ERREUR : bash >= 4 requis" >&2; exit 1; }

command -v jq &>/dev/null  || { echo "ERREUR : jq non trouvé (apt install jq)" >&2; exit 1; }
[ -f "$INTEGRITY" ]        || { echo "ERREUR : src/integrity.sh introuvable : $INTEGRITY" >&2; exit 1; }
[ -f "$CONFIG" ]           || { echo "ERREUR : config introuvable : $CONFIG" >&2; exit 1; }

# == Validation JSON ===========================================================

jq empty "$CONFIG" 2>/dev/null || { echo "ERREUR : JSON invalide : $CONFIG" >&2; exit 1; }

nb_ops=$(jq '.pipeline | length' "$CONFIG")
(( nb_ops > 0 )) || { echo "ERREUR : tableau .pipeline vide ou absent" >&2; exit 1; }

# == Fonctions utilitaires =====================================================

die() { echo "ERREUR : $*" >&2; exit 1; }

# Lit un champ JSON obligatoire - exit si absent ou null
require_field() {
  local idx="$1" field="$2"
  local val
  val=$(jq -r --argjson i "$idx" '.pipeline[$i].'"$field" "$CONFIG")
  [ "$val" != "null" ] && [ -n "$val" ] || die "Bloc #$((idx+1)) : champ '$field' manquant ou vide."
  echo "$val"
}

# Lit un champ JSON optionnel - retourne "" si absent
optional_field() {
  local idx="$1" field="$2"
  local val
  val=$(jq -r --argjson i "$idx" '.pipeline[$i].'"$field // empty" "$CONFIG" 2>/dev/null || true)
  echo "${val:-}"
}

# == Opérations ================================================================

run_compute() {
  local i="$1"
  local source bases nom
  source=$(require_field "$i" "source")
  bases=$(require_field "$i" "bases")
  nom=$(require_field "$i" "nom")

  echo "=== COMPUTE : $source ==="
  [ -d "$source" ] || die "Bloc #$((i+1)) compute : dossier source introuvable : $source"

  mkdir -p "$bases"
  local bases_abs
  bases_abs="$(cd "$bases" && pwd)"
  # Sous-shell : le cd ne fuite pas vers les blocs suivants
  ( cd "$source" && "$INTEGRITY" compute . "$bases_abs/$nom" )
}

run_verify() {
  local i="$1"
  local source base
  source=$(require_field "$i" "source")
  base=$(require_field "$i" "base")

  echo "=== VERIFY : $source ==="
  [ -d "$source" ] || die "Bloc #$((i+1)) verify : dossier source introuvable : $source"
  [ -f "$base" ]   || die "Bloc #$((i+1)) verify : base .b3 introuvable : $base"

  local base_abs
  base_abs="$(cd "$(dirname "$base")" && pwd)/$(basename "$base")"
  ( cd "$source" && "$INTEGRITY" verify "$base_abs" )
}

run_compare() {
  local i="$1"
  local base_a base_b
  base_a=$(require_field "$i" "base_a")
  base_b=$(require_field "$i" "base_b")

  echo "=== COMPARE : $(basename "$base_a") vs $(basename "$base_b") ==="
  [ -f "$base_a" ] || die "Bloc #$((i+1)) compare : base_a introuvable : $base_a"
  [ -f "$base_b" ] || die "Bloc #$((i+1)) compare : base_b introuvable : $base_b"

  # Champ optionnel "resultats" : surcharge RESULTATS_DIR pour ce bloc uniquement
  local resultats_dir
  resultats_dir=$(optional_field "$i" "resultats")

  if [ -n "$resultats_dir" ]; then
    mkdir -p "$resultats_dir"
    local resultats_abs
    resultats_abs="$(cd "$resultats_dir" && pwd)"
    echo "    → résultats dans : $resultats_abs"
    RESULTATS_DIR="$resultats_abs" "$INTEGRITY" compare "$base_a" "$base_b"
  else
    "$INTEGRITY" compare "$base_a" "$base_b"
  fi
}

# == Main ======================================================================

echo "=== PIPELINE DÉMARRÉ : $(date) ==="
echo "=== Config : $CONFIG ($nb_ops opération(s)) ==="
echo ""

for (( i=0; i<nb_ops; i++ )); do
  op=$(jq -r --argjson i "$i" '.pipeline[$i].op' "$CONFIG")
  [ "$op" != "null" ] && [ -n "$op" ] || die "Bloc #$((i+1)) : champ 'op' manquant."

  case "$op" in
    compute) run_compute "$i" ;;
    verify)  run_verify  "$i" ;;
    compare) run_compare "$i" ;;
    *)       die "Bloc #$((i+1)) : opération inconnue : '$op'" ;;
  esac

  echo ""
done

echo "=== PIPELINE TERMINÉ : $(date) ==="

--- Fichier : mon_dossier/destination/fichier (1).txt ---
Contrary to popular belief, Lorem Ipsum is not simply random text. It has roots in a piece of classical Latin literature from 45 BC, making it over 2000 years old. Richard McClintock, a Latin professor at Hampden-Sydney College in Virginia, looked up one of the more obscure Latin words, consectetur, from a Lorem Ipsum passage, and going through the cites of the word in classical literature, discovered the undoubtable source. Lorem Ipsum comes from sections 1.10.32 and 1.10.33 of "de Finibus Bonorum et Malorum" (The Extremes of Good and Evil) by Cicero, written in 45 BC. This book is a treatise on the theory of ethics, very popular during the Renaissance. The first line of Lorem Ipsum, "Lorem ipsum dolor sit amet..", comes from a line in section 1.10.32.



--- Fichier : mon_dossier/destination/fichier (2).txt ---
There are many variations of passages of Lorem Ipsum available, but the majority have suffered alteration in some form, by injected humour, or randomised words which don't look even slightly believable. If you are going to use a passage of Lorem Ipsum, you need to be sure there isn't anything embarrassing hidden in the middle of text. All the Lorem Ipsum generators on the Internet tend to repeat predefined chunks as necessary, making this the first true generator on the Internet. It uses a dictionary of over 200 Latin words, combined with a handful of model sentence structures, to generate Lorem Ipsum which looks reasonable. The generated Lorem Ipsum is therefore always free from repetition, injected humour, or non-characteristic words etc.



--- Fichier : mon_dossier/destination/fichier (3).txt ---
Lorem Ipsum is simply dummy text of the printing and typesetting industry. Lorem Ipsum has been the industry's standard dummy text ever since the 1500s, when an unknown printer took a galley of type and scrambled it to make a type specimen book. It has survived not only five centuries, but also the leap into electronic typesetting, remaining essentially unchanged. It was popularised in the 1960s with the release of Letraset sheets containing Lorem Ipsum passages, and more recently with desktop publishing software like Aldus PageMaker including versions of Lorem Ipsum.



--- Fichier : mon_dossier/destination/fichier (4).txt ---
It is a long established fact that a reader will be distracted by the readable content of a page when looking at its layout. The point of using Lorem Ipsum is that it has a more-or-less normal distribution of letters, as opposed to using 'Content here, content here', making it look like readable English. Many desktop publishing packages and web page editors now use Lorem Ipsum as their default model text, and a search for 'lorem ipsum' will uncover many web sites still in their infancy. Various versions have evolved over the years, sometimes by accident, sometimes on purpose (injected humour and the like).



--- Fichier : mon_dossier/result/resultats_hashes_dossier_1_20260222-100613/disparus.txt ---


--- Fichier : mon_dossier/result/resultats_hashes_dossier_1_20260222-100613/nouveaux.txt ---


--- Fichier : mon_dossier/result/resultats_hashes_dossier_1_20260222-100613/recap.txt ---
Commande      : integrity.sh compare hashes_dossier_1.b3 hashes_dossier_2.b3
Date          : dim. 22 févr. 2026 10:06:13 CET
Ancienne base : ./mon_dossier/bases/hashes_dossier_1.b3
Nouvelle base : ./mon_dossier/bases/hashes_dossier_2.b3

Modifiés      : 1
Disparus      : 0
Nouveaux      : 0


--- Fichier : mon_dossier/result/resultats_hashes_dossier_1/disparus.txt ---


--- Fichier : mon_dossier/result/resultats_hashes_dossier_1/nouveaux.txt ---


--- Fichier : mon_dossier/result/resultats_hashes_dossier_1/recap.txt ---
Commande      : integrity.sh compare hashes_dossier_1.b3 hashes_dossier_2.b3
Date          : dim. 22 févr. 2026 10:05:31 CET
Ancienne base : ./mon_dossier/bases/hashes_dossier_1.b3
Nouvelle base : ./mon_dossier/bases/hashes_dossier_2.b3

Modifiés      : 4
Disparus      : 0
Nouveaux      : 0


--- Fichier : mon_dossier/source/fichier (1).txt ---
Contrary to popular belief, Lorem Ipsum is not simply random text. It has roots in a piece of classical Latin literature from 45 BC, making it over 2000 years old. Richard McClintock, a Latin professor at Hampden-Sydney College in Virginia, looked up one of the more obscure Latin words, consectetur, from a Lorem Ipsum passage, and going through the cites of the word in classical literature, discovered the undoubtable source. Lorem Ipsum comes from sections 1.10.32 and 1.10.33 of "de Finibus Bonorum et Malorum" (The Extremes of Good and Evil) by Cicero, written in 45 BC. This book is a treatise on the theory of ethics, very popular during the Renaissance. The first line of Lorem Ipsum, "Lorem ipsum dolor sit amet..", comes from a line in section 1.10.32.

fichier modifié



--- Fichier : mon_dossier/source/fichier (2).txt ---
There are many variations of passages of Lorem Ipsum available, but the majority have suffered alteration in some form, by injected humour, or randomised words which don't look even slightly believable. If you are going to use a passage of Lorem Ipsum, you need to be sure there isn't anything embarrassing hidden in the middle of text. All the Lorem Ipsum generators on the Internet tend to repeat predefined chunks as necessary, making this the first true generator on the Internet. It uses a dictionary of over 200 Latin words, combined with a handful of model sentence structures, to generate Lorem Ipsum which looks reasonable. The generated Lorem Ipsum is therefore always free from repetition, injected humour, or non-characteristic words etc.



--- Fichier : mon_dossier/source/fichier (3).txt ---
Lorem Ipsum is simply dummy text of the printing and typesetting industry. Lorem Ipsum has been the industry's standard dummy text ever since the 1500s, when an unknown printer took a galley of type and scrambled it to make a type specimen book. It has survived not only five centuries, but also the leap into electronic typesetting, remaining essentially unchanged. It was popularised in the 1960s with the release of Letraset sheets containing Lorem Ipsum passages, and more recently with desktop publishing software like Aldus PageMaker including versions of Lorem Ipsum.



--- Fichier : mon_dossier/source/fichier (4).txt ---
It is a long established fact that a reader will be distracted by the readable content of a page when looking at its layout. The point of using Lorem Ipsum is that it has a more-or-less normal distribution of letters, as opposed to using 'Content here, content here', making it look like readable English. Many desktop publishing packages and web page editors now use Lorem Ipsum as their default model text, and a search for 'lorem ipsum' will uncover many web sites still in their infancy. Various versions have evolved over the years, sometimes by accident, sometimes on purpose (injected humour and the like).



--- Fichier : tests/run_tests.sh ---
#!/usr/bin/env bash
# run_tests.sh - suite de tests automatisée pour integrity.sh
# Usage    : cd tests && ./run_tests.sh
# Prérequis: b3sum, stat, du ; integrity.sh dans ../src/

set -euo pipefail

SCRIPT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"
INTEGRITY="$SCRIPT_DIR/../src/integrity.sh"
WORKDIR="$(mktemp -d /tmp/integrity-test.XXXXXX)"
export RESULTATS_DIR="$WORKDIR/resultats"

GREEN='\033[0;32m'
RED='\033[0;31m'
NC='\033[0m'

PASS=0; FAIL=0; TOTAL=0

pass() { echo -e "${GREEN}  PASS${NC} - $1"; ((PASS++)); ((TOTAL++)); }
fail() { echo -e "${RED}  FAIL${NC} - $1"; ((FAIL++)); ((TOTAL++)); }

assert_exit_zero()    { local l="$1"; shift; if "$@" >/dev/null 2>&1;  then pass "$l"; else fail "$l"; fi; }
assert_exit_nonzero() { local l="$1"; shift; if ! "$@" >/dev/null 2>&1; then pass "$l"; else fail "$l"; fi; }

assert_contains() {
  local label="$1" pattern="$2" output="$3"
  if echo "$output" | grep -q "$pattern"; then pass "$label"; else fail "$label (pattern: '$pattern' absent)"; fi
}

assert_not_contains() {
  local label="$1" pattern="$2" output="$3"
  if ! echo "$output" | grep -q "$pattern"; then pass "$label"; else fail "$label (pattern: '$pattern' présent à tort)"; fi
}

assert_line_count() {
  local label="$1" expected="$2" file="$3"
  local actual; actual=$(wc -l < "$file")
  if [ "$actual" -eq "$expected" ]; then pass "$label"; else fail "$label (attendu: $expected, obtenu: $actual)"; fi
}

assert_file_exists() {
  local label="$1" file="$2"
  if [ -f "$file" ]; then pass "$label"; else fail "$label (absent : $file)"; fi
}

assert_file_absent() {
  local label="$1" file="$2"
  if [ ! -f "$file" ]; then pass "$label"; else fail "$label (présent à tort : $file)"; fi
}

setup() {
  mkdir -p "$WORKDIR/data/sub"
  echo "contenu alpha" > "$WORKDIR/data/alpha.txt"
  echo "contenu beta"  > "$WORKDIR/data/beta.txt"
  echo "contenu gamma" > "$WORKDIR/data/gamma.txt"
  echo "contenu delta" > "$WORKDIR/data/sub/delta.txt"
}

teardown() { rm -rf "$WORKDIR"; }

run_tests() {
  cd "$WORKDIR"

  echo ""
  echo "========================================"
  echo "  integrity.sh - suite de tests"
  echo "  Workdir : $WORKDIR"
  echo "========================================"
  echo ""

  echo "T00 - ShellCheck"
  if command -v shellcheck &>/dev/null; then
    assert_exit_zero "ShellCheck integrity.sh"  shellcheck "$INTEGRITY"
    assert_exit_zero "ShellCheck run_tests.sh"  shellcheck "$0"
  else
    echo "  SKIP - shellcheck non installé"
  fi
  echo ""

  echo "T01 - Compute de base"
  bash "$INTEGRITY" compute ./data base_t01.b3 >/dev/null 2>&1
  assert_line_count "base_t01.b3 contient 4 lignes" 4 base_t01.b3
  assert_contains   "format <hash>  <chemin>"       "  ./data/" "$(head -1 base_t01.b3)"
  echo ""

  echo "T02 - Verify sans modification"
  local out_t02; out_t02=$(bash "$INTEGRITY" verify base_t01.b3 2>&1 || true)
  assert_not_contains "aucun FAILED" "FAILED" "$out_t02"
  assert_contains     "terminal OK"  "OK"     "$out_t02"
  local outdir_t02; outdir_t02=$(ls -d "${RESULTATS_DIR}/resultats_base_t01"* 2>/dev/null | tail -1)
  assert_file_exists  "recap.txt créé"              "${outdir_t02}/recap.txt"
  assert_file_absent  "failed.txt absent si 0 échec" "${outdir_t02}/failed.txt"
  echo ""

  echo "T03 - Verify après corruption"
  echo "contenu modifié" > data/beta.txt
  local out_t03; out_t03=$(bash "$INTEGRITY" verify base_t01.b3 2>&1 || true)
  assert_contains "ECHEC affiché"    "ECHEC"   "$out_t03"
  assert_contains "beta.txt FAILED"  "FAILED"  "$out_t03"
  local outdir_t03; outdir_t03=$(ls -d "${RESULTATS_DIR}/resultats_base_t01"* 2>/dev/null | tail -1)
  assert_file_exists "failed.txt créé"    "${outdir_t03}/failed.txt"
  assert_contains    "failed.txt beta"    "beta.txt" "$(cat "${outdir_t03}/failed.txt")"
  echo "contenu beta" > data/beta.txt
  echo ""

  echo "T04 - Verify après suppression"
  rm data/gamma.txt
  local out_t04; out_t04=$(bash "$INTEGRITY" verify base_t01.b3 2>&1 || true)
  assert_contains "gamma.txt FAILED" "FAILED" "$out_t04"
  echo "contenu gamma" > data/gamma.txt
  echo ""

  echo "T05 - Compare : aucune différence"
  bash "$INTEGRITY" compute ./data base_t05.b3 >/dev/null 2>&1
  bash "$INTEGRITY" compare base_t01.b3 base_t05.b3 >/dev/null 2>&1
  local outdir_t05; outdir_t05=$(ls -d "${RESULTATS_DIR}/resultats_base_t01"* 2>/dev/null | tail -1)
  assert_file_exists "recap.txt"    "${outdir_t05}/recap.txt"
  assert_file_exists "modifies.b3"  "${outdir_t05}/modifies.b3"
  assert_file_exists "report.html"  "${outdir_t05}/report.html"
  assert_line_count  "modifies vide" 0 "${outdir_t05}/modifies.b3"
  assert_line_count  "disparus vide" 0 "${outdir_t05}/disparus.txt"
  assert_line_count  "nouveaux vide" 0 "${outdir_t05}/nouveaux.txt"
  echo ""

  echo "T06 - Compare : fichier modifié"
  echo "contenu beta modifié" > data/beta.txt
  bash "$INTEGRITY" compute ./data base_t06.b3 >/dev/null 2>&1
  bash "$INTEGRITY" compare base_t01.b3 base_t06.b3 >/dev/null 2>&1
  local outdir_t06; outdir_t06=$(ls -d "${RESULTATS_DIR}/resultats_base_t01"* 2>/dev/null | tail -1)
  assert_contains "modifies contient beta" "beta.txt" "$(cat "${outdir_t06}/modifies.b3")"
  assert_file_exists "report.html généré" "${outdir_t06}/report.html"
  assert_contains    "report.html contient beta" "beta" "$(cat "${outdir_t06}/report.html")"
  echo "contenu beta" > data/beta.txt
  echo ""

  echo "T07 - Compare : suppression + ajout"
  bash "$INTEGRITY" compute ./data base_t07_old.b3 >/dev/null 2>&1
  rm data/alpha.txt
  echo "contenu epsilon" > data/epsilon.txt
  bash "$INTEGRITY" compute ./data base_t07_new.b3 >/dev/null 2>&1
  bash "$INTEGRITY" compare base_t07_old.b3 base_t07_new.b3 >/dev/null 2>&1
  local outdir_t07; outdir_t07=$(ls -d "${RESULTATS_DIR}/resultats_base_t07_old"* 2>/dev/null | tail -1)
  assert_contains "disparus alpha"   "alpha.txt"   "$(cat "${outdir_t07}/disparus.txt")"
  assert_contains "nouveaux epsilon" "epsilon.txt" "$(cat "${outdir_t07}/nouveaux.txt")"
  echo "contenu alpha" > data/alpha.txt
  rm data/epsilon.txt
  echo ""

  echo "T08 - Robustesse : fichier avec espace"
  echo "contenu espace" > "data/fichier avec espace.txt"
  bash "$INTEGRITY" compute ./data base_t08.b3 >/dev/null 2>&1
  local out_t08; out_t08=$(bash "$INTEGRITY" verify base_t08.b3 2>&1 || true)
  assert_not_contains "aucun FAILED" "FAILED" "$out_t08"
  rm "data/fichier avec espace.txt"
  echo ""

  echo "T09 - Limite : dossier vide ignoré"
  mkdir data/dossier_vide
  bash "$INTEGRITY" compute ./data base_t09.b3 >/dev/null 2>&1
  assert_not_contains "dossier_vide absent" "dossier_vide" "$(cat base_t09.b3)"
  pass "comportement conforme"
  rmdir data/dossier_vide
  echo ""

  echo "T10 - Chemin absolu vs relatif"
  find "$WORKDIR/data" -type f -print0 | sort -z | xargs -0 b3sum > base_absolu.b3
  find ./data          -type f -print0 | sort -z | xargs -0 b3sum > base_relatif.b3
  assert_contains     "base absolue → chemin absolu"   "  /"      "$(head -1 base_absolu.b3)"
  assert_contains     "base relative → chemin relatif" "\./data/" "$(head -1 base_relatif.b3)"
  assert_not_contains "bases non interchangeables"     "$(head -1 base_absolu.b3)" "$(head -1 base_relatif.b3)"
  echo ""

  echo "T11 - ETA : base identique à référence"
  find ./data -type f -print0 | sort -z | xargs -0 b3sum > base_ref.b3
  bash "$INTEGRITY" compute ./data base_eta.b3 >/dev/null 2>&1
  assert_exit_zero    "base ETA == référence" diff base_ref.b3 base_eta.b3
  assert_not_contains "pas de ligne ETA"      "ETA" "$(cat base_eta.b3)"
  assert_not_contains "pas de \\r"            $'\r' "$(cat base_eta.b3)"
  echo ""

  echo "T12 - Mode --quiet"
  bash "$INTEGRITY" compute ./data base_t12.b3 >/dev/null 2>&1
  local out_quiet_ok; out_quiet_ok=$(bash "$INTEGRITY" --quiet verify base_t12.b3 2>&1 || true)
  assert_not_contains "--quiet OK : pas de stdout" "OK"        "$out_quiet_ok"
  assert_not_contains "--quiet OK : pas de stdout" "Résultats" "$out_quiet_ok"
  local outdir_t12; outdir_t12=$(ls -d "${RESULTATS_DIR}/resultats_base_t12"* 2>/dev/null | tail -1)
  assert_file_exists  "recap.txt produit --quiet" "${outdir_t12}/recap.txt"

  echo "contenu corrompu" > data/beta.txt
  local exit_quiet; bash "$INTEGRITY" --quiet verify base_t12.b3 >/dev/null 2>&1 && exit_quiet=0 || exit_quiet=$?
  if (( exit_quiet != 0 )); then pass "--quiet propage exit code"; else fail "--quiet propage exit code"; fi
  echo "contenu beta" > data/beta.txt

  local out_quiet_cmp; out_quiet_cmp=$(bash "$INTEGRITY" --quiet compute ./data base_t12c.b3 2>&1 || true)
  assert_not_contains "--quiet compute : pas de stdout" "Base enregistrée" "$out_quiet_cmp"
  echo ""

  echo "T13 - Horodatage anti-écrasement"
  bash "$INTEGRITY" compute ./data base_t13.b3 >/dev/null 2>&1
  bash "$INTEGRITY" verify base_t13.b3 >/dev/null 2>&1 || true
  sleep 1
  bash "$INTEGRITY" verify base_t13.b3 >/dev/null 2>&1 || true
  local nb_r; nb_r=$(ls -d "${RESULTATS_DIR}/resultats_base_t13"* 2>/dev/null | wc -l)
  if (( nb_r >= 2 )); then pass "deux dossiers distincts"; else fail "écrasement détecté ($nb_r dossier(s))"; fi
  echo ""

  echo "T14 - verify : dossier argument invalide"
  local out_t14; out_t14=$(bash "$INTEGRITY" verify base_t01.b3 /chemin/inexistant 2>&1 || true)
  assert_contains "ERREUR si dossier invalide" "ERREUR" "$out_t14"
  echo ""
}

# == Main ======================================================================

command -v b3sum &>/dev/null || { echo -e "${RED}ERREUR${NC} : b3sum non trouvé."; exit 1; }
[ -f "$INTEGRITY" ]          || { echo -e "${RED}ERREUR${NC} : integrity.sh introuvable : $INTEGRITY"; exit 1; }

setup
run_tests
teardown

echo "========================================"
if [ "$FAIL" -eq 0 ]; then
  echo -e "  ${GREEN}$PASS/$TOTAL tests passés${NC}"
else
  echo -e "  ${GREEN}$PASS${NC}/${TOTAL} passés - ${RED}$FAIL échec(s)${NC}"
fi
echo "========================================"
echo ""

[ "$FAIL" -eq 0 ]

--- Fichier : tests/run_tests_pipeline.sh ---
#!/usr/bin/env bash
# run_tests_pipeline.sh - Tests automatisés pour runner.sh + pipeline.json
#
# Couvre : parsing JSON, compute, verify, compare, champ resultats, erreurs
#
# Prérequis : bash >= 4, jq, b3sum
#             runner.sh    à ../
#             integrity.sh à ../src/
# Usage     : cd tests && ./run_tests_pipeline.sh

set -euo pipefail

SCRIPT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"
RUNNER="$SCRIPT_DIR/../runner.sh"
INTEGRITY="$SCRIPT_DIR/../src/integrity.sh"
WORKDIR="$(mktemp -d /tmp/integrity-pipeline-test.XXXXXX)"
export RESULTATS_DIR="$WORKDIR/resultats"

GREEN='\033[0;32m'
RED='\033[0;31m'
NC='\033[0m'

PASS=0; FAIL=0; TOTAL=0

pass() { echo -e "${GREEN}  PASS${NC} - $1"; (( PASS++ )); (( TOTAL++ )); }
fail() { echo -e "${RED}  FAIL${NC} - $1"; (( FAIL++ )); (( TOTAL++ )); }

assert_contains() {
    local label="$1" pattern="$2" output="$3"
    if echo "$output" | grep -q "$pattern"; then pass "$label"; else fail "$label (pattern '$pattern' absent)"; fi
}

assert_not_contains() {
    local label="$1" pattern="$2" output="$3"
    if ! echo "$output" | grep -q "$pattern"; then pass "$label"; else fail "$label (pattern '$pattern' présent à tort)"; fi
}

assert_file_exists() {
    local label="$1" file="$2"
    if [ -f "$file" ]; then pass "$label"; else fail "$label (absent : $file)"; fi
}

assert_file_absent() {
    local label="$1" file="$2"
    if [ ! -f "$file" ]; then pass "$label"; else fail "$label (présent à tort : $file)"; fi
}

assert_line_count() {
    local label="$1" expected="$2" file="$3"
    local actual; actual=$(wc -l < "$file")
    if [ "$actual" -eq "$expected" ]; then pass "$label"; else fail "$label (attendu $expected, obtenu $actual)"; fi
}

write_config() {
    local path="$WORKDIR/pipeline.json"
    cat > "$path"
    echo "$path"
}

setup() {
    mkdir -p "$WORKDIR"/{src_a,src_b,bases,resultats}

    echo "alpha content" > "$WORKDIR/src_a/alpha.txt"
    echo "beta content"  > "$WORKDIR/src_a/beta.txt"
    mkdir -p "$WORKDIR/src_a/sub"
    echo "delta content" > "$WORKDIR/src_a/sub/delta.txt"

    echo "gamma content" > "$WORKDIR/src_b/gamma.txt"
    echo "delta content" > "$WORKDIR/src_b/delta.txt"
}

teardown() { rm -rf "$WORKDIR"; }

run_tests() {
    cd "$WORKDIR"

    echo ""
    echo "========================================"
    echo "  runner.sh - suite de tests"
    echo "  Workdir : $WORKDIR"
    echo "========================================"
    echo ""

    # == TP01 : JSON invalide ==================================================
    echo "TP01 - JSON invalide : erreur propre sans stacktrace jq"
    local cfg_invalid="$WORKDIR/invalid.json"
    echo "{ pipeline: [ BROKEN" > "$cfg_invalid"
    local out_tp01; out_tp01=$(bash "$RUNNER" "$cfg_invalid" 2>&1 || true)
    assert_contains     "ERREUR signalée"         "ERREUR"      "$out_tp01"
    assert_not_contains "pas de stacktrace jq"    "parse error" "$out_tp01"
    echo ""

    # == TP02 : .pipeline absent ===============================================
    echo "TP02 - .pipeline absent"
    local cfg_no_pipeline
    cfg_no_pipeline=$(write_config <<'EOF'
{ "config": [] }
EOF
)
    local out_tp02; out_tp02=$(bash "$RUNNER" "$cfg_no_pipeline" 2>&1 || true)
    assert_contains "ERREUR si .pipeline absent" "ERREUR" "$out_tp02"
    echo ""

    # == TP03 : champ manquant =================================================
    echo "TP03 - Champ 'nom' manquant dans compute"
    local cfg_missing
    cfg_missing=$(write_config <<EOF
{
    "pipeline": [
        { "op": "compute", "source": "$WORKDIR/src_a", "bases": "$WORKDIR/bases" }
    ]
}
EOF
)
    local out_tp03; out_tp03=$(bash "$RUNNER" "$cfg_missing" 2>&1 || true)
    assert_contains "ERREUR signalée"       "ERREUR" "$out_tp03"
    assert_contains "champ 'nom' mentionné" "nom"    "$out_tp03"
    echo ""

    # == TP04 : opération inconnue =============================================
    echo "TP04 - Opération inconnue"
    local cfg_unknown
    cfg_unknown=$(write_config <<'EOF'
{ "pipeline": [ { "op": "migrate", "source": "/tmp" } ] }
EOF
)
    local out_tp04; out_tp04=$(bash "$RUNNER" "$cfg_unknown" 2>&1 || true)
    assert_contains "ERREUR signalée"           "ERREUR"   "$out_tp04"
    assert_contains "nom de l'op dans l'erreur" "migrate"  "$out_tp04"
    echo ""

    # == TP05 : compute - chemins relatifs =====================================
    echo "TP05 - Compute : cd correct, chemins relatifs dans la base"
    local cfg_compute
    cfg_compute=$(write_config <<EOF
{
    "pipeline": [
        { "op": "compute", "source": "$WORKDIR/src_a", "bases": "$WORKDIR/bases", "nom": "hashes_a.b3" }
    ]
}
EOF
)
    bash "$RUNNER" "$cfg_compute" >/dev/null 2>&1
    assert_file_exists "base hashes_a.b3 créée" "$WORKDIR/bases/hashes_a.b3"
    local first_path; first_path=$(awk '{print $2}' "$WORKDIR/bases/hashes_a.b3" | head -1)
    assert_contains     "chemin relatif (./) dans base"    "./"       "$first_path"
    assert_not_contains "pas de chemin absolu dans base"   "$WORKDIR" "$first_path"
    assert_line_count   "3 fichiers indexés"               3          "$WORKDIR/bases/hashes_a.b3"
    echo ""

    # == TP06 : compute - source absente ======================================
    echo "TP06 - Compute : source absente → erreur"
    local cfg_absent
    cfg_absent=$(write_config <<EOF
{
    "pipeline": [
        { "op": "compute", "source": "$WORKDIR/inexistant", "bases": "$WORKDIR/bases", "nom": "ko.b3" }
    ]
}
EOF
)
    local out_tp06; out_tp06=$(bash "$RUNNER" "$cfg_absent" 2>&1 || true)
    assert_contains    "ERREUR signalée"              "ERREUR"  "$out_tp06"
    assert_file_absent "pas de base créée si source KO" "$WORKDIR/bases/ko.b3"
    echo ""

    # == TP07 : verify - OK ===================================================
    echo "TP07 - Verify : répertoire de travail correct, vérification OK"
    local cfg_verify
    cfg_verify=$(write_config <<EOF
{
    "pipeline": [
        { "op": "verify", "source": "$WORKDIR/src_a", "base": "$WORKDIR/bases/hashes_a.b3" }
    ]
}
EOF
)
    local out_tp07; out_tp07=$(bash "$RUNNER" "$cfg_verify" 2>&1 || true)
    assert_contains     "verify OK"     "OK"     "$out_tp07"
    assert_not_contains "aucun FAILED"  "FAILED" "$out_tp07"
    local outdir_tp07; outdir_tp07=$(ls -d "${RESULTATS_DIR}/resultats_hashes_a"* 2>/dev/null | tail -1)
    assert_file_exists  "recap.txt produit" "${outdir_tp07}/recap.txt"
    echo ""

    # == TP08 : verify - corruption ===========================================
    echo "TP08 - Verify : corruption détectée"
    echo "contenu corrompu" > "$WORKDIR/src_a/alpha.txt"
    local out_tp08; out_tp08=$(bash "$RUNNER" "$cfg_verify" 2>&1 || true)
    assert_contains "ECHEC détecté" "ECHEC" "$out_tp08"
    echo "alpha content"   > "$WORKDIR/src_a/alpha.txt"
    echo ""

    # == TP09 : verify - base absente =========================================
    echo "TP09 - Verify : base .b3 absente → erreur"
    local cfg_verify_bad
    cfg_verify_bad=$(write_config <<EOF
{
    "pipeline": [
        { "op": "verify", "source": "$WORKDIR/src_a", "base": "$WORKDIR/bases/fantome.b3" }
    ]
}
EOF
)
    local out_tp09; out_tp09=$(bash "$RUNNER" "$cfg_verify_bad" 2>&1 || true)
    assert_contains "ERREUR si base absente" "ERREUR" "$out_tp09"
    echo ""

    # == TP10 : compare - résultats produits (RESULTATS_DIR par défaut) ========
    echo "TP10 - Compare : fichiers de résultats produits (sans champ resultats)"
    local cfg_compute_b
    cfg_compute_b=$(write_config <<EOF
{
    "pipeline": [
        { "op": "compute", "source": "$WORKDIR/src_b", "bases": "$WORKDIR/bases", "nom": "hashes_b.b3" }
    ]
}
EOF
)
    bash "$RUNNER" "$cfg_compute_b" >/dev/null 2>&1

    local cfg_compare
    cfg_compare=$(write_config <<EOF
{
    "pipeline": [
        { "op": "compare", "base_a": "$WORKDIR/bases/hashes_a.b3", "base_b": "$WORKDIR/bases/hashes_b.b3" }
    ]
}
EOF
)
    bash "$RUNNER" "$cfg_compare" >/dev/null 2>&1
    local outdir_tp10; outdir_tp10=$(ls -d "${RESULTATS_DIR}/resultats_hashes_a"* 2>/dev/null | tail -1)
    assert_file_exists "recap.txt"    "${outdir_tp10}/recap.txt"
    assert_file_exists "modifies.b3"  "${outdir_tp10}/modifies.b3"
    assert_file_exists "disparus.txt" "${outdir_tp10}/disparus.txt"
    assert_file_exists "nouveaux.txt" "${outdir_tp10}/nouveaux.txt"
    assert_file_exists "report.html"  "${outdir_tp10}/report.html"
    echo ""

    # == TP10b : compare - champ resultats personnalisé =======================
    echo "TP10b - Compare : champ 'resultats' personnalisé dans pipeline.json"
    local custom_dir="$WORKDIR/mon_rapport_custom"
    local cfg_compare_custom
    cfg_compare_custom=$(write_config <<EOF
{
    "pipeline": [
        {
            "op":       "compare",
            "base_a":   "$WORKDIR/bases/hashes_a.b3",
            "base_b":   "$WORKDIR/bases/hashes_b.b3",
            "resultats": "$custom_dir"
        }
    ]
}
EOF
)
    bash "$RUNNER" "$cfg_compare_custom" >/dev/null 2>&1
    local outdir_custom; outdir_custom=$(ls -d "${custom_dir}/resultats_hashes_a"* 2>/dev/null | tail -1)
    assert_file_exists "rapport dans dossier custom"            "${outdir_custom}/recap.txt"
    assert_file_exists "report.html dans dossier custom"        "${outdir_custom}/report.html"
    # Vérifier que le dossier par défaut n'a PAS reçu ce résultat
    local nb_before; nb_before=$(ls -d "${RESULTATS_DIR}/resultats_hashes_a"* 2>/dev/null | wc -l)
    bash "$RUNNER" "$cfg_compare_custom" >/dev/null 2>&1
    local nb_after; nb_after=$(ls -d "${RESULTATS_DIR}/resultats_hashes_a"* 2>/dev/null | wc -l)
    if [ "$nb_before" -eq "$nb_after" ]; then
        pass "champ resultats isolé : RESULTATS_DIR par défaut non pollué"
    else
        fail "champ resultats isolé : RESULTATS_DIR par défaut non pollué"
    fi
    echo ""

    # == TP11 : compare - base_a absente ======================================
    echo "TP11 - Compare : base_a absente → erreur"
    local cfg_compare_bad
    cfg_compare_bad=$(write_config <<EOF
{
    "pipeline": [
        { "op": "compare", "base_a": "$WORKDIR/bases/fantome.b3", "base_b": "$WORKDIR/bases/hashes_b.b3" }
    ]
}
EOF
)
    local out_tp11; out_tp11=$(bash "$RUNNER" "$cfg_compare_bad" 2>&1 || true)
    assert_contains "ERREUR si base_a absente" "ERREUR" "$out_tp11"
    echo ""

    # == TP12 : pipeline complet ===============================================
    echo "TP12 - Pipeline complet : compute × 2 + verify + compare"
    rm -f "$WORKDIR/bases/hashes_a.b3" "$WORKDIR/bases/hashes_b.b3"
    local cfg_full
    cfg_full=$(write_config <<EOF
{
    "pipeline": [
        { "op": "compute", "source": "$WORKDIR/src_a", "bases": "$WORKDIR/bases", "nom": "hashes_a.b3" },
        { "op": "compute", "source": "$WORKDIR/src_b", "bases": "$WORKDIR/bases", "nom": "hashes_b.b3" },
        { "op": "verify",  "source": "$WORKDIR/src_a", "base":  "$WORKDIR/bases/hashes_a.b3" },
        { "op": "compare", "base_a": "$WORKDIR/bases/hashes_a.b3", "base_b": "$WORKDIR/bases/hashes_b.b3",
          "resultats": "$WORKDIR/resultats_pipeline" }
    ]
}
EOF
)
    local out_tp12; out_tp12=$(bash "$RUNNER" "$cfg_full" 2>&1 || true)
    assert_contains     "COMPUTE mentionné"     "COMPUTE" "$out_tp12"
    assert_contains     "VERIFY mentionné"      "VERIFY"  "$out_tp12"
    assert_contains     "COMPARE mentionné"     "COMPARE" "$out_tp12"
    assert_file_exists  "hashes_a.b3 créée"     "$WORKDIR/bases/hashes_a.b3"
    assert_file_exists  "hashes_b.b3 créée"     "$WORKDIR/bases/hashes_b.b3"
    assert_not_contains "pas d'ERREUR"          "ERREUR"  "$out_tp12"
    local outdir_tp12; outdir_tp12=$(ls -d "${WORKDIR}/resultats_pipeline/resultats_hashes_a"* 2>/dev/null | tail -1)
    assert_file_exists  "report.html pipeline complet" "${outdir_tp12}/report.html"
    echo ""
}

# == Main ======================================================================

for dep in jq b3sum; do
    command -v "$dep" &>/dev/null || { echo -e "${RED}ERREUR${NC} : $dep non trouvé."; exit 1; }
done

[ -f "$RUNNER" ]    || { echo -e "${RED}ERREUR${NC} : runner.sh introuvable : $RUNNER";      exit 1; }
[ -f "$INTEGRITY" ] || { echo -e "${RED}ERREUR${NC} : src/integrity.sh introuvable : $INTEGRITY"; exit 1; }

setup
run_tests
teardown

echo "========================================"
if [ "$FAIL" -eq 0 ]; then
    echo -e "  ${GREEN}$PASS/$TOTAL tests passés${NC}"
else
    echo -e "  ${GREEN}$PASS${NC}/${TOTAL} passés - ${RED}$FAIL échec(s)${NC}"
fi
echo "========================================"
echo ""

[ "$FAIL" -eq 0 ]

--- Fichier : reports/template.html ---
<!DOCTYPE html>
<html lang="fr">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Rapport - [BASE_A] vs [BASE_B]</title>
  <!--
    ══════════════════════════════════════════════════════════════════
    reports/template.html - Barebone rapport de comparaison hash_tool
    ══════════════════════════════════════════════════════════════════

    Ce fichier est un template statique de référence.
    Le rapport réel est généré automatiquement par src/lib/report.sh
    dans le dossier "resultats" défini dans pipeline.json.

    Structure du rapport généré :
      <resultats>/
        ├== report.html      ← rapport visuel (ce template rempli)
        ├== recap.txt        ← résumé texte
        ├== modifies.b3      ← fichiers avec hash différent
        ├== disparus.txt     ← fichiers présents dans A, absents de B
        └== nouveaux.txt     ← fichiers absents de A, présents dans B

    Pour personnaliser le rendu HTML : modifier src/lib/report.sh
    (fonction generate_compare_html).

    Placeholders utilisés dans report.sh :
      [BASE_A]       nom du fichier .b3 ancienne base
      [BASE_B]       nom du fichier .b3 nouvelle base
      [DATE]         date de génération
      [STATUT]       IDENTIQUES | DIFFÉRENCES DÉTECTÉES
      [NB_MODIFIES]  nombre de fichiers modifiés
      [NB_DISPARUS]  nombre de fichiers disparus
      [NB_NOUVEAUX]  nombre de nouveaux fichiers
      [LIST_*]       listes HTML injectées par _render_file_list()
    ══════════════════════════════════════════════════════════════════
  -->
  <style>
    /* → Voir src/lib/report.sh pour le CSS complet injecté dans les rapports générés */

    :root {
      --bg:       #0f1117;
      --bg-card:  #161b27;
      --border:   #252d3f;
      --text:     #c8d4e8;
      --text-dim: #5a6a85;
      --mono:     monospace;
      --sans:     system-ui, sans-serif;
    }

    body {
      background: var(--bg);
      color: var(--text);
      font-family: var(--sans);
      font-size: 14px;
      display: flex;
      align-items: center;
      justify-content: center;
      min-height: 100vh;
      padding: 40px;
    }

    .placeholder {
      max-width: 560px;
      text-align: center;
    }

    .placeholder h1 {
      font-family: var(--mono);
      font-size: 12px;
      letter-spacing: .1em;
      text-transform: uppercase;
      color: var(--text-dim);
      margin-bottom: 24px;
    }

    .placeholder p {
      color: var(--text-dim);
      line-height: 1.7;
      font-size: 13px;
      margin-bottom: 12px;
    }

    code {
      font-family: var(--mono);
      font-size: 12px;
      background: var(--bg-card);
      border: 1px solid var(--border);
      border-radius: 4px;
      padding: 2px 6px;
      color: var(--text);
    }
  </style>
</head>
<body>
  <div class="placeholder">
    <h1>hash_tool · template.html</h1>
    <p>Ce fichier est le template de référence du rapport de comparaison.</p>
    <p>
      Les rapports réels sont générés automatiquement dans le dossier
      <code>resultats</code> défini par le champ
      <code>"resultats"</code> dans <code>pipeline.json</code>.
    </p>
    <p>
      Pour personnaliser le rendu : modifier
      <code>src/lib/report.sh</code> → fonction
      <code>generate_compare_html()</code>.
    </p>
  </div>
</body>
</html>

--- Fichier : src/integrity.sh ---
#!/usr/bin/env bash
# integrity.sh - Vérification d'intégrité par hachage BLAKE3
#
# Point d'entrée CLI. Orchestre les modules :
#   src/lib/core.sh    - logique métier (hachage, vérification, comparaison)
#   src/lib/ui.sh      - interface terminal (affichage, ETA, progression)
#   src/lib/results.sh - écriture des fichiers de résultats
#   src/lib/report.sh  - génération des rapports HTML
#
# Usage :
#   ./integrity.sh [--quiet] compute <dossier> <base.b3>
#   ./integrity.sh [--quiet] verify  <base.b3> [dossier]
#   ./integrity.sh [--quiet] compare <ancienne.b3> <nouvelle.b3>
#
# Options :
#   --quiet   Supprime toute sortie terminal. Écrit uniquement dans les
#             fichiers de résultats. Exit code propagé sans modification.
#
# Dépendances : b3sum, bash >= 4, find, sort, awk, comm, join, stat, du, mktemp
#
# Exit codes :
#   0 - succès (voir contrat de chaque mode dans src/lib/core.sh)
#   1 - erreur (argument manquant, fichier introuvable, corruption détectée)

set -euo pipefail

# == Prérequis bash =============================================================

(( BASH_VERSINFO[0] >= 4 )) || {
  echo "ERREUR : bash >= 4 requis (actuel : $BASH_VERSION)" >&2
  exit 1
}

# == Résolution des chemins =====================================================

SCRIPT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"

# == Chargement des modules =====================================================

for _module in ui core results report; do
  _path="$SCRIPT_DIR/lib/${_module}.sh"
  [ -f "$_path" ] || { echo "ERREUR : module introuvable : $_path" >&2; exit 1; }
  # shellcheck source=/dev/null
  source "$_path"
done
unset _module _path

# == Parsing des arguments ======================================================

QUIET=0
ARGS=()

for arg in "$@"; do
  case "$arg" in
    --quiet) QUIET=1 ;;
    *)       ARGS+=("$arg") ;;
  esac
done

MODE="${ARGS[0]:-}"
ARG2="${ARGS[1]:-}"
ARG3="${ARGS[2]:-}"

# == Configuration ==============================================================

# Dossier racine des résultats. Peut être surchargé par variable d'environnement.
# runner.sh surcharge cette valeur via export pour isoler les runs de pipeline.
RESULTATS_DIR="${RESULTATS_DIR:-${HOME}/integrity_resultats}"

# == Handlers des modes =========================================================

_run_compute() {
  local target="$ARG2"
  local hashfile="$ARG3"

  [ -n "$target"   ] || die "compute : dossier cible manquant.\nUsage : $0 compute <dossier> <base.b3>"
  [ -n "$hashfile" ] || die "compute : fichier de sortie .b3 manquant.\nUsage : $0 compute <dossier> <base.b3>"
  [ ! -d "$hashfile" ] || die "compute : '$hashfile' est un dossier. Le fichier .b3 de sortie doit être un chemin de fichier."

  core_assert_target_valid "$target"

  # Utilise ui_progress_callback uniquement si QUIET == 0
  local callback=""
  (( QUIET )) || callback="ui_progress_callback"

  core_compute "$target" "$hashfile" "$callback"
  ui_progress_clear

  say "Base enregistrée : $hashfile ($(wc -l < "$hashfile") fichiers)"
}

_run_verify() {
  local b3file="$ARG2"
  local workdir="${ARG3:-}"

  [ -n "$b3file" ] || die "verify : fichier .b3 manquant.\nUsage : $0 verify <base.b3> [dossier]"

  core_assert_b3_valid "$b3file" "base"

  # Résolution du chemin absolu AVANT le cd : un chemin relatif deviendrait
  # invalide après changement de répertoire
  local hashfile_abs
  hashfile_abs="$(cd "$(dirname "$b3file")" && pwd)/$(basename "$b3file")"

  if [ -n "$workdir" ]; then
    [ -d "$workdir" ] || die "verify : '$workdir' n'est pas un dossier valide."
    cd "$workdir"
  fi

  local outdir
  outdir=$(core_make_result_dir "$hashfile_abs" "$RESULTATS_DIR")

  # core_verify positionne les variables CORE_VERIFY_* dans le scope courant
  local exit_code=0
  core_verify "$hashfile_abs" || exit_code=$?

  results_write_verify \
    "$outdir" "$hashfile_abs" \
    "$CORE_VERIFY_STATUS" "$CORE_VERIFY_NB_OK" "$CORE_VERIFY_NB_FAIL" \
    "$CORE_VERIFY_LINES_FAIL" "$CORE_VERIFY_LINES_ERR"

  ui_show_verify_result \
    "$CORE_VERIFY_STATUS" "$CORE_VERIFY_NB_OK" "$CORE_VERIFY_NB_FAIL" \
    "$CORE_VERIFY_LINES_FAIL" "$CORE_VERIFY_LINES_ERR" \
    "$outdir"

  return $exit_code
}

_run_compare() {
  local old="$ARG2"
  local new="$ARG3"

  [ -n "$old" ] || die "compare : fichier ancienne base manquant.\nUsage : $0 compare <ancienne.b3> <nouvelle.b3>"
  [ -n "$new" ] || die "compare : fichier nouvelle base manquant.\nUsage : $0 compare <ancienne.b3> <nouvelle.b3>"

  core_assert_b3_valid "$old" "ancienne base"
  core_assert_b3_valid "$new" "nouvelle base"

  local outdir
  outdir=$(core_make_result_dir "$old" "$RESULTATS_DIR")

  # core_compare positionne CORE_COMPARE_NB_* dans le scope courant
  core_compare "$old" "$new" "$outdir"

  results_write_compare \
    "$outdir" "$old" "$new" \
    "$CORE_COMPARE_NB_MOD" "$CORE_COMPARE_NB_DIS" "$CORE_COMPARE_NB_NOU"

  generate_compare_html \
    "$old" "$new" \
    "$CORE_COMPARE_NB_MOD" "$CORE_COMPARE_NB_DIS" "$CORE_COMPARE_NB_NOU" \
    "${outdir}/modifies.b3" "${outdir}/disparus.txt" "${outdir}/nouveaux.txt" \
    "${outdir}/report.html"

  ui_show_compare_result \
    "$CORE_COMPARE_NB_MOD" "$CORE_COMPARE_NB_DIS" "$CORE_COMPARE_NB_NOU" \
    "$outdir"
}

# == Dispatch ===================================================================

case "$MODE" in
  compute) _run_compute ;;
  verify)  _run_verify  ;;
  compare) _run_compare ;;
  *)
    echo "Usage:"
    echo "  $0 [--quiet] compute <dossier> <base.b3>"
    echo "  $0 [--quiet] verify  <base.b3> [dossier]"
    echo "  $0 [--quiet] compare <ancienne.b3> <nouvelle.b3>"
    echo ""
    echo "Options:"
    echo "  --quiet   Silencieux : écrit uniquement dans les fichiers de résultats."
    exit 1
    ;;
esac


--- Fichier : src/lib/core.sh ---
#!/usr/bin/env bash
# src/lib/core.sh - Logique métier BLAKE3 : hachage, vérification, comparaison
#
# Ce module contient uniquement la logique métier. Il ne produit aucune
# sortie terminal directement - toute communication avec l'utilisateur
# est déléguée à src/lib/ui.sh via les codes de retour et les variables
# de sortie déclarées dans les contrats ci-dessous.
#
# Sourcé par src/integrity.sh. Ne pas exécuter directement.
#
# == Dépendances ================================================================
#   b3sum, find, sort, awk, join, comm, mktemp, stat, du
#
# == Invariants globaux =========================================================
#   - Toutes les fonctions supposent bash >= 4 (vérifié par integrity.sh)
#   - Les chemins dans les bases .b3 sont toujours RELATIFS (jamais absolus)
#   - Le format .b3 est celui natif de b3sum : "<hash64>  <chemin>" (2 espaces)
#   - L'encodage supposé est UTF-8 ; les noms non UTF-8 sont traités comme des
#     séquences d'octets opaques (find -print0 / mapfile -d '' garantissent
#     l'absence d'interprétation)
#   - La locale n'affecte pas le tri : sort utilise l'ordre binaire (LC_ALL=C
#     doit être positionné par l'appelant si nécessaire pour reproductibilité)

# == Validation =================================================================

# core_assert_b3_valid <fichier> [label]
#
# Contrat d'entrée :
#   $1 - chemin vers un fichier .b3 à valider
#   $2 - label optionnel pour les messages d'erreur (défaut : $1)
#
# Contrat de sortie :
#   exit 0  - fichier valide : existe, est un fichier régulier, non vide,
#             contient au moins une ligne au format "<hash64>  <chemin>"
#   exit 1  - fichier invalide ; appelle die() avec message explicite
#
# Effets de bord : aucun
core_assert_b3_valid() {
  local file="$1"
  local label="${2:-$1}"

  [ -e "$file" ] || die "$label : fichier introuvable."
  [ -f "$file" ] || die "$label : est un dossier, pas un fichier .b3."
  [ -s "$file" ] || die "$label : fichier vide - aucun hash à traiter."

  local valid_lines
  valid_lines=$(grep -c -E '^[0-9a-f]{64}  .+' "$file" || true)
  [ "$valid_lines" -gt 0 ] || die "$label : format invalide - aucune ligne au format b3sum détectée."

  local total_lines
  total_lines=$(wc -l < "$file")
  if [ "$total_lines" -gt "$valid_lines" ]; then
    die "$label : fichier corrompu - $((total_lines - valid_lines)) ligne(s) sur $total_lines ne respectent pas le format b3sum."
  fi
}

# core_assert_target_valid <dossier>
#
# Contrat d'entrée :
#   $1 - chemin vers un dossier à indexer
#
# Contrat de sortie :
#   exit 0  - dossier valide : existe, est un dossier, contient au moins un fichier régulier
#   exit 1  - invalide ; appelle die() avec message explicite
#
# Effets de bord : aucun
core_assert_target_valid() {
  local dir="$1"

  [ -e "$dir" ] || die "Dossier cible introuvable : $dir"
  [ -d "$dir" ] || die "Le chemin cible n'est pas un dossier : $dir"

  local nb_files
  nb_files=$(find "$dir" -type f -print0 | grep -zc '' || echo 0)
  (( nb_files > 0 )) || die "Le dossier $dir ne contient aucun fichier régulier - rien à hacher."
}

# == Utilitaires internes ========================================================

# _core_file_size <fichier>
#
# Contrat de sortie :
#   stdout - taille du fichier en octets (entier)
#   Portable : GNU stat (-c%s) avec fallback BSD stat (-f%z)
#
# Effets de bord : aucun
_core_file_size() {
  local f="$1"
  if stat -c%s "$f" 2>/dev/null; then
    return
  fi
  stat -f%z "$f"
}

# == Hachage ====================================================================

# core_compute <dossier> <fichier_sortie> [callback_progression]
#
# Contrat d'entrée :
#   $1 - dossier cible (chemin relatif RECOMMANDÉ pour portabilité des bases)
#   $2 - chemin du fichier .b3 de sortie (créé ou écrasé)
#   $3 - (optionnel) nom d'une fonction de callback appelée après chaque fichier
#         Signature callback : callback <i> <total_files> <bytes_done> <total_bytes> <eta_seconds>
#         Passer "" ou omettre pour désactiver la progression
#
# Contrat de sortie :
#   exit 0       - base calculée avec succès
#   exit 1       - erreur (propagée depuis b3sum ou find)
#   $2 (fichier) - contient N lignes "<hash64>  <chemin>", triées par chemin,
#                  sans artefact terminal (ETA, \r, etc.)
#
# Invariants garantis :
#   - Les chemins dans $2 sont identiques à ceux vus par find depuis $1
#   - L'ordre est déterministe (sort -z sur les chemins)
#   - Aucune ligne ETA ou de progression ne peut être écrite dans $2 :
#     b3sum est appelé par fichier individuel, la progression est gérée
#     par le callback, pas par redirection
#
# Effets de bord :
#   - Crée ou écrase $2
#   - Appelle $3 si fourni (effets de bord dépendants du callback)
core_compute() {
  local target="$1"
  local hashfile="$2"
  local callback="${3:-}"

  local -a files
  mapfile -d '' files < <(find "$target" -type f -print0 | sort -z)

  local total_files=${#files[@]}
  local total_bytes
  total_bytes=$(du -sb "$target" | awk '{print $1}')

  local bytes_done=0
  local t_start
  t_start=$(date +%s)

  local i=0
  for file in "${files[@]}"; do
    b3sum "$file" >> "$hashfile"

    local fsize
    fsize=$(_core_file_size "$file")
    # Fichier de taille zéro : bytes_done inchangé, ETA non calculée pour ce fichier
    if (( fsize > 0 )); then
      bytes_done=$(( bytes_done + fsize ))
    fi
    i=$(( i + 1 ))

    if [ -n "$callback" ]; then
      local t_now elapsed eta_seconds=0
      t_now=$(date +%s)
      elapsed=$(( t_now - t_start ))
      if (( bytes_done > 0 && elapsed > 0 )); then
        local speed remaining
        speed=$(( bytes_done / elapsed ))
        (( speed > 0 )) && eta_seconds=$(( (total_bytes - bytes_done) / speed )) || eta_seconds=0
      fi
      "$callback" "$i" "$total_files" "$bytes_done" "$total_bytes" "$eta_seconds"
    fi
  done
}

# == Vérification ===============================================================

# core_verify <fichier_b3>
#
# Contrat d'entrée :
#   $1 - chemin absolu vers un fichier .b3 valide (validé par core_assert_b3_valid)
#         Le répertoire de travail courant DOIT être celui depuis lequel compute
#         a été exécuté (les chemins dans .b3 sont relatifs à ce répertoire)
#
# Contrat de sortie :
#   exit 0  - tous les fichiers intègres
#   exit 1  - au moins un FAILED ou erreur b3sum
#   CORE_VERIFY_RAW        - sortie brute de b3sum --check
#   CORE_VERIFY_LINES_OK   - lignes "chemin: OK"
#   CORE_VERIFY_LINES_FAIL - lignes "chemin: FAILED"
#   CORE_VERIFY_LINES_ERR  - lignes d'erreur b3sum non liées aux hashes
#   CORE_VERIFY_NB_OK      - entier : nombre de fichiers OK
#   CORE_VERIFY_NB_FAIL    - entier : nombre de fichiers FAILED
#   CORE_VERIFY_STATUS     - "OK" | "ECHEC" | "ERREUR"
#
# Effets de bord :
#   - Positionne les variables CORE_VERIFY_* dans le scope de l'appelant
#     (les variables doivent être déclarées locales dans l'appelant si isolation requise)
core_verify() {
  local hashfile="$1"

  local raw exit_code
  raw=$(b3sum --check "$hashfile" 2>&1) && exit_code=0 || exit_code=$?

  CORE_VERIFY_RAW="$raw"
  CORE_VERIFY_LINES_OK=$(echo    "$raw" | grep ': OK$'    || true)
  CORE_VERIFY_LINES_FAIL=$(echo  "$raw" | grep ': FAILED' || true)
  CORE_VERIFY_LINES_ERR=$(echo   "$raw" | grep -Ev ': (OK|FAILED)' | grep -v '^$' || true)

  if [ -n "$CORE_VERIFY_LINES_OK" ]; then
    CORE_VERIFY_NB_OK=$(echo "$CORE_VERIFY_LINES_OK" | grep -c '^')
  else
    CORE_VERIFY_NB_OK=0
  fi

  if [ -n "$CORE_VERIFY_LINES_FAIL" ]; then
    CORE_VERIFY_NB_FAIL=$(echo "$CORE_VERIFY_LINES_FAIL" | grep -c '^')
  else
    CORE_VERIFY_NB_FAIL=0
  fi

  if [ -n "$CORE_VERIFY_LINES_ERR" ]; then
    CORE_VERIFY_STATUS="ERREUR"
  elif (( CORE_VERIFY_NB_FAIL > 0 )); then
    CORE_VERIFY_STATUS="ECHEC"
  else
    CORE_VERIFY_STATUS="OK"
  fi

  return $exit_code
}

# == Comparaison ================================================================

# core_compare <ancienne_b3> <nouvelle_b3> <outdir>
#
# Contrat d'entrée :
#   $1 - chemin vers l'ancienne base .b3 (validée par core_assert_b3_valid)
#   $2 - chemin vers la nouvelle base .b3 (validée par core_assert_b3_valid)
#   $3 - dossier de sortie (doit exister avant l'appel)
#
# Contrat de sortie :
#   exit 0  - comparaison effectuée (même si des différences existent)
#   exit 1  - erreur technique (b3sum, awk, join, comm)
#   $3/modifies.b3   - fichiers présents dans les deux bases avec hashes différents
#                      Format : "<nouveau_hash>  <chemin>" (format b3sum)
#   $3/disparus.txt  - chemins présents dans $1, absents de $2 (un chemin par ligne)
#   $3/nouveaux.txt  - chemins absents de $1, présents dans $2 (un chemin par ligne)
#   CORE_COMPARE_NB_MOD  - entier : nombre de fichiers modifiés
#   CORE_COMPARE_NB_DIS  - entier : nombre de fichiers disparus
#   CORE_COMPARE_NB_NOU  - entier : nombre de nouveaux fichiers
#
# Algorithme :
#   1. Conversion "<hash>  <chemin>" → "<chemin>\t<hash>" via awk (offset fixe 64+2)
#      Robuste aux chemins avec espaces : le séparateur est le tab, pas l'espace
#   2. sort par chemin (clé 1 uniquement)
#   3. join inner sur le chemin → identifie les modifiés (hashes différents)
#   4. comm -23 / -13 sur les chemins → disparus et nouveaux
#
# Effets de bord :
#   - Écrit $3/modifies.b3, $3/disparus.txt, $3/nouveaux.txt
#   - Positionne CORE_COMPARE_NB_* dans le scope de l'appelant
#   - Utilise mktemp pour les fichiers temporaires (nettoyés via trap EXIT)
core_compare() {
  local old="$1"
  local new="$2"
  local outdir="$3"

  local tmp_old tmp_new
  tmp_old=$(mktemp)
  tmp_new=$(mktemp)

  trap 'rm -f "$tmp_old" "$tmp_new"' EXIT

  # Conversion vers format "chemin\thash" - offset fixe 64 chars pour le hash
  # Robuste aux espaces dans les chemins
  _b3_to_path_hash() {
    awk '{ print substr($0,67) "\t" substr($0,1,64) }' "$1" | sort -t $'\t' -k1,1
  }

  _b3_to_path_hash "$old" > "$tmp_old"
  _b3_to_path_hash "$new" > "$tmp_new"

  # Fichiers modifiés : présents dans les deux bases, hashes différents
  join -t $'\t' -1 1 -2 1 "$tmp_old" "$tmp_new" \
    | awk -F $'\t' '$2 != $3 { print $3 "  " $1 }' \
    > "${outdir}/modifies.b3"

  # Fichiers disparus : dans old, pas dans new
  comm -23 <(cut -f1 "$tmp_old") <(cut -f1 "$tmp_new") > "${outdir}/disparus.txt"

  # Nouveaux fichiers : dans new, pas dans old
  comm -13 <(cut -f1 "$tmp_old") <(cut -f1 "$tmp_new") > "${outdir}/nouveaux.txt"

  CORE_COMPARE_NB_MOD=$(wc -l < "${outdir}/modifies.b3")
  CORE_COMPARE_NB_DIS=$(wc -l < "${outdir}/disparus.txt")
  CORE_COMPARE_NB_NOU=$(wc -l < "${outdir}/nouveaux.txt")

  rm -f "$tmp_old" "$tmp_new"
  trap - EXIT
}

# == Gestion des dossiers de résultats ==========================================

# core_make_result_dir <fichier_b3> <resultats_dir>
#
# Contrat d'entrée :
#   $1 - chemin vers le fichier .b3 (utilisé pour nommer le dossier)
#   $2 - dossier racine des résultats (RESULTATS_DIR)
#
# Contrat de sortie :
#   stdout - chemin absolu du dossier de résultats créé
#   exit 0 - dossier créé avec succès
#   exit 1 - échec de création (permissions, chemin invalide)
#
# Invariant anti-écrasement :
#   Si "<resultats_dir>/resultats_<nom_base>" existe déjà, un suffixe horodaté
#   "_YYYYMMDD-HHMMSS" est ajouté. Aucun résultat existant n'est jamais écrasé.
core_make_result_dir() {
  local b3file="$1"
  local resultats_dir="$2"

  local basename_noext
  basename_noext=$(basename "$b3file" .b3)
  local outdir="${resultats_dir}/resultats_${basename_noext}"

  if [ -d "$outdir" ]; then
    outdir="${outdir}_$(date +%Y%m%d-%H%M%S)"
  fi

  mkdir -p "$outdir" || die "Impossible de créer le dossier de résultats : $outdir"
  echo "$outdir"
}


--- Fichier : src/lib/report.sh ---
#!/usr/bin/env bash
# lib/report.sh - Génération des rapports de résultats
#
# Sourcé par integrity.sh. Ne pas exécuter directement.
#
# Fonctions exportées :
#   generate_compare_html  <old> <new> <nb_mod> <nb_dis> <nb_nou>
#                          <modifies.b3> <disparus.txt> <nouveaux.txt>
#                          <output.html>

# == Génération du rapport HTML pour compare ===================================
#
# Produit un fichier HTML autonome (CSS inline, pas de dépendance externe).
# Les listes de fichiers sont injectées depuis les fichiers texte produits
# par run_compare(). Le fichier est lisible hors ligne.
#
# Usage :
#   generate_compare_html \
#     "$old_b3" "$new_b3" \
#     "$nb_modifies" "$nb_disparus" "$nb_nouveaux" \
#     "$modifies_file" "$disparus_file" "$nouveaux_file" \
#     "$output_html"

generate_compare_html() {
  local old_b3="$1"
  local new_b3="$2"
  local nb_modifies="$3"
  local nb_disparus="$4"
  local nb_nouveaux="$5"
  local modifies_file="$6"
  local disparus_file="$7"
  local nouveaux_file="$8"
  local output_html="$9"

  local date_rapport
  date_rapport=$(date '+%Y-%m-%d %H:%M:%S')

  local nom_old nom_new
  nom_old=$(basename "$old_b3")
  nom_new=$(basename "$new_b3")

  # Statut global
  local statut statut_class
  if (( nb_modifies == 0 && nb_disparus == 0 && nb_nouveaux == 0 )); then
    statut="IDENTIQUES"
    statut_class="status-ok"
  else
    statut="DIFFÉRENCES DÉTECTÉES"
    statut_class="status-diff"
  fi

  # Lecture des listes de fichiers → HTML
  _render_file_list() {
    local file="$1"
    local empty_msg="$2"
    if [ ! -s "$file" ]; then
      echo "    <p class=\"empty\">$empty_msg</p>"
      return
    fi
    echo "    <ul>"
    while IFS= read -r line; do
      [ -n "$line" ] || continue
      # Pour modifies.b3 : "hash  chemin" → on affiche juste le chemin
      local display
      display=$(echo "$line" | awk '{ if (NF >= 2) { $1=""; print substr($0,2) } else { print $0 } }')
      echo "      <li><code>$(html_escape "$display")</code></li>"
    done < "$file"
    echo "    </ul>"
  }

  html_escape() {
    local s="$1"
    s="${s//&/&amp;}"
    s="${s//</&lt;}"
    s="${s//>/&gt;}"
    echo "$s"
  }

  local list_modifies list_disparus list_nouveaux
  list_modifies=$(_render_file_list "$modifies_file" "Aucun fichier modifié")
  list_disparus=$(_render_file_list "$disparus_file" "Aucun fichier disparu")
  list_nouveaux=$(_render_file_list "$nouveaux_file" "Aucun nouveau fichier")

  cat > "$output_html" <<HTML
<!DOCTYPE html>
<html lang="fr">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Rapport - ${nom_old} vs ${nom_new}</title>
  <style>
    /* == Tokens ==================================================== */
    :root {
      --bg:          #0f1117;
      --bg-card:     #161b27;
      --bg-card-alt: #1c2233;
      --border:      #252d3f;
      --border-glow: #2e3d5a;
      --text:        #c8d4e8;
      --text-dim:    #5a6a85;
      --text-head:   #e8eef8;
      --mono:        'JetBrains Mono', 'Fira Code', 'Cascadia Code', monospace;
      --sans:        'DM Sans', 'Outfit', system-ui, sans-serif;
      --accent-ok:   #22c55e;
      --accent-diff: #f59e0b;
      --accent-mod:  #e879f9;
      --accent-dis:  #f87171;
      --accent-nou:  #34d399;
      --radius:      8px;
      --radius-lg:   14px;
    }

    /* == Reset & base =============================================== */
    *, *::before, *::after { box-sizing: border-box; margin: 0; padding: 0; }

    @import url('https://fonts.googleapis.com/css2?family=DM+Sans:wght@300;400;500;600&family=JetBrains+Mono:wght@400;500&display=swap');

    body {
      background: var(--bg);
      color: var(--text);
      font-family: var(--sans);
      font-size: 14px;
      line-height: 1.6;
      min-height: 100vh;
      padding: 0 0 64px;
    }

    /* == Header ===================================================== */
    .header {
      background: var(--bg-card);
      border-bottom: 1px solid var(--border);
      padding: 28px 40px 24px;
      display: flex;
      align-items: flex-start;
      justify-content: space-between;
      gap: 24px;
    }

    .header-left h1 {
      font-family: var(--mono);
      font-size: 13px;
      font-weight: 500;
      color: var(--text-dim);
      letter-spacing: .08em;
      text-transform: uppercase;
      margin-bottom: 8px;
    }

    .bases-compare {
      display: flex;
      align-items: center;
      gap: 12px;
      flex-wrap: wrap;
    }

    .base-name {
      font-family: var(--mono);
      font-size: 14px;
      font-weight: 500;
      color: var(--text-head);
      background: var(--bg-card-alt);
      border: 1px solid var(--border-glow);
      border-radius: var(--radius);
      padding: 5px 12px;
    }

    .arrow {
      color: var(--text-dim);
      font-size: 16px;
    }

    .meta {
      font-size: 12px;
      color: var(--text-dim);
      margin-top: 10px;
      font-family: var(--mono);
    }

    /* == Status badge =============================================== */
    .status-badge {
      font-family: var(--mono);
      font-size: 11px;
      font-weight: 500;
      letter-spacing: .1em;
      text-transform: uppercase;
      padding: 6px 14px;
      border-radius: 100px;
      border: 1px solid;
      white-space: nowrap;
      align-self: flex-start;
      margin-top: 4px;
    }

    .status-ok   { color: var(--accent-ok);   border-color: var(--accent-ok);   background: rgba(34,197,94,.08);  }
    .status-diff { color: var(--accent-diff);  border-color: var(--accent-diff); background: rgba(245,158,11,.08); }

    /* == Stats bar ================================================== */
    .stats-bar {
      display: grid;
      grid-template-columns: repeat(3, 1fr);
      gap: 1px;
      background: var(--border);
      border-bottom: 1px solid var(--border);
    }

    .stat {
      background: var(--bg-card);
      padding: 20px 32px;
      display: flex;
      flex-direction: column;
      gap: 4px;
    }

    .stat-label {
      font-size: 11px;
      letter-spacing: .08em;
      text-transform: uppercase;
      color: var(--text-dim);
    }

    .stat-value {
      font-family: var(--mono);
      font-size: 28px;
      font-weight: 500;
      line-height: 1;
    }

    .stat-modifies .stat-value { color: var(--accent-mod); }
    .stat-disparus .stat-value { color: var(--accent-dis); }
    .stat-nouveaux .stat-value { color: var(--accent-nou); }

    /* == Sections =================================================== */
    .main {
      max-width: 1100px;
      margin: 0 auto;
      padding: 36px 40px 0;
      display: grid;
      gap: 20px;
    }

    .section {
      background: var(--bg-card);
      border: 1px solid var(--border);
      border-radius: var(--radius-lg);
      overflow: hidden;
    }

    .section-header {
      display: flex;
      align-items: center;
      gap: 10px;
      padding: 14px 20px;
      border-bottom: 1px solid var(--border);
    }

    .section-dot {
      width: 8px;
      height: 8px;
      border-radius: 50%;
      flex-shrink: 0;
    }

    .section-modifies .section-dot { background: var(--accent-mod); }
    .section-disparus .section-dot { background: var(--accent-dis); }
    .section-nouveaux .section-dot { background: var(--accent-nou); }

    .section-title {
      font-size: 12px;
      font-weight: 600;
      letter-spacing: .06em;
      text-transform: uppercase;
      color: var(--text-head);
    }

    .section-count {
      margin-left: auto;
      font-family: var(--mono);
      font-size: 12px;
      color: var(--text-dim);
      background: var(--bg-card-alt);
      border: 1px solid var(--border);
      border-radius: 100px;
      padding: 2px 10px;
    }

    .section-body {
      padding: 16px 20px;
    }

    .section-body ul {
      list-style: none;
      display: flex;
      flex-direction: column;
      gap: 4px;
    }

    .section-body li {
      padding: 6px 10px;
      border-radius: var(--radius);
      background: var(--bg-card-alt);
      border: 1px solid transparent;
      transition: border-color .15s;
    }

    .section-body li:hover {
      border-color: var(--border-glow);
    }

    .section-body code {
      font-family: var(--mono);
      font-size: 12px;
      color: var(--text);
      word-break: break-all;
    }

    .empty {
      font-style: italic;
      color: var(--text-dim);
      font-size: 13px;
      padding: 4px 0;
    }

    /* == Footer ===================================================== */
    .footer {
      text-align: center;
      padding-top: 40px;
      font-size: 11px;
      color: var(--text-dim);
      font-family: var(--mono);
    }

    @media (max-width: 680px) {
      .header        { padding: 20px; flex-direction: column; }
      .stats-bar     { grid-template-columns: 1fr; }
      .main          { padding: 20px; }
    }
  </style>
</head>
<body>

  <!-- == En-tête ======================================================== -->
  <header class="header">
    <div class="header-left">
      <h1>Rapport de comparaison - hash_tool</h1>
      <div class="bases-compare">
        <span class="base-name">$(html_escape "$nom_old")</span>
        <span class="arrow">→</span>
        <span class="base-name">$(html_escape "$nom_new")</span>
      </div>
      <div class="meta">Généré le ${date_rapport}</div>
    </div>
    <div class="status-badge ${statut_class}">${statut}</div>
  </header>

  <!-- == Compteurs ====================================================== -->
  <div class="stats-bar">
    <div class="stat stat-modifies">
      <span class="stat-label">Modifiés</span>
      <span class="stat-value">${nb_modifies}</span>
    </div>
    <div class="stat stat-disparus">
      <span class="stat-label">Disparus</span>
      <span class="stat-value">${nb_disparus}</span>
    </div>
    <div class="stat stat-nouveaux">
      <span class="stat-label">Nouveaux</span>
      <span class="stat-value">${nb_nouveaux}</span>
    </div>
  </div>

  <!-- == Listes ========================================================= -->
  <main class="main">

    <div class="section section-modifies">
      <div class="section-header">
        <div class="section-dot"></div>
        <span class="section-title">Fichiers modifiés</span>
        <span class="section-count">${nb_modifies}</span>
      </div>
      <div class="section-body">
${list_modifies}
      </div>
    </div>

    <div class="section section-disparus">
      <div class="section-header">
        <div class="section-dot"></div>
        <span class="section-title">Fichiers disparus</span>
        <span class="section-count">${nb_disparus}</span>
      </div>
      <div class="section-body">
${list_disparus}
      </div>
    </div>

    <div class="section section-nouveaux">
      <div class="section-header">
        <div class="section-dot"></div>
        <span class="section-title">Nouveaux fichiers</span>
        <span class="section-count">${nb_nouveaux}</span>
      </div>
      <div class="section-body">
${list_nouveaux}
      </div>
    </div>

  </main>

  <footer class="footer">
    integrity.sh · BLAKE3 · ${date_rapport}
  </footer>

</body>
</html>
HTML
}

--- Fichier : src/lib/results.sh ---
#!/usr/bin/env bash
# src/lib/results.sh - Écriture des fichiers de résultats texte
#
# Ce module produit les fichiers recap.txt et failed.txt à partir des
# données de sortie de core_verify() et core_compare().
# Il ne contient ni logique métier ni logique d'affichage terminal.
#
# Sourcé par src/integrity.sh. Ne pas exécuter directement.

# == Résultats de vérification ==================================================

# results_write_verify <outdir> <hashfile> <statut> <nb_ok> <nb_fail> <lines_fail> <lines_err>
#
# Contrat d'entrée :
#   $1 - dossier de sortie (doit exister)
#   $2 - chemin du fichier .b3 vérifié
#   $3 - statut : "OK" | "ECHEC" | "ERREUR"
#   $4 - nombre de fichiers OK
#   $5 - nombre de fichiers FAILED
#   $6 - lignes FAILED (chaîne multi-lignes, peut être vide)
#   $7 - lignes d'erreur b3sum (chaîne multi-lignes, peut être vide)
#
# Contrat de sortie :
#   exit 0
#   $1/recap.txt  - toujours créé
#   $1/failed.txt - créé si $5 > 0 ou $7 non vide ; supprimé sinon
#                   (suppression pour éviter un failed.txt obsolète d'un run précédent)
#
# Effets de bord : écrit sur le disque
results_write_verify() {
  local outdir="$1"
  local hashfile="$2"
  local statut="$3"
  local nb_ok="$4"
  local nb_fail="$5"
  local lines_fail="$6"
  local lines_err="$7"

  # recap.txt
  {
    echo "════════════════════════════════════════"
    echo "  STATUT : $statut"
    echo "════════════════════════════════════════"
    echo ""
    echo "Commande  : integrity.sh verify $(basename "$hashfile")"
    echo "Date      : $(date)"
    echo "Base      : $hashfile"
    echo ""
    echo "OK        : $nb_ok"
    if (( nb_fail > 0 )); then
      echo "FAILED    : $nb_fail  ← voir failed.txt"
    fi
    if [ -n "$lines_err" ]; then
      echo ""
      echo "== Erreurs b3sum ======================"
      echo "$lines_err"
    fi
  } > "${outdir}/recap.txt"

  # failed.txt
  if (( nb_fail > 0 )) || [ -n "$lines_err" ]; then
    {
      echo "════════════════════════════════════════"
      echo "  FICHIERS EN ECHEC"
      echo "════════════════════════════════════════"
      echo ""
      [ -n "$lines_fail" ] && echo "$lines_fail"
      if [ -n "$lines_err" ]; then
        echo ""
        echo "== Erreurs ============================"
        echo "$lines_err"
      fi
    } > "${outdir}/failed.txt"
  else
    rm -f "${outdir}/failed.txt"
  fi
}

# == Résultats de comparaison ===================================================

# results_write_compare <outdir> <old_b3> <new_b3> <nb_mod> <nb_dis> <nb_nou>
#
# Contrat d'entrée :
#   $1 - dossier de sortie (doit exister, contient déjà modifies.b3, disparus.txt, nouveaux.txt)
#   $2 - chemin de l'ancienne base .b3
#   $3 - chemin de la nouvelle base .b3
#   $4 - nombre de fichiers modifiés
#   $5 - nombre de fichiers disparus
#   $6 - nombre de nouveaux fichiers
#
# Contrat de sortie :
#   exit 0
#   $1/recap.txt - créé
#
# Effets de bord : écrit sur le disque
results_write_compare() {
  local outdir="$1"
  local old="$2"
  local new="$3"
  local nb_mod="$4"
  local nb_dis="$5"
  local nb_nou="$6"

  {
    echo "Commande      : integrity.sh compare $(basename "$old") $(basename "$new")"
    echo "Date          : $(date)"
    echo "Ancienne base : $old"
    echo "Nouvelle base : $new"
    echo ""
    echo "Modifiés      : $nb_mod"
    echo "Disparus      : $nb_dis"
    echo "Nouveaux      : $nb_nou"
  } > "${outdir}/recap.txt"
}


--- Fichier : src/lib/ui.sh ---
#!/usr/bin/env bash
# src/lib/ui.sh - Logique d'interface : affichage terminal, ETA, progression
#
# Ce module contient uniquement la logique de présentation et d'interaction
# avec l'utilisateur. Il ne contient aucune logique métier.
#
# Sourcé par src/integrity.sh. Ne pas exécuter directement.
#
# == Dépendances ================================================================
#   Aucune dépendance externe. Utilise uniquement les builtins bash et printf.
#
# == Prérequis ==================================================================
#   La variable QUIET doit être définie avant de sourcer ce module :
#     QUIET=0  - affichage normal
#     QUIET=1  - suppression de toute sortie terminal

# == Primitives de communication ================================================

# die <message>
#
# Contrat d'entrée :
#   $@ - message d'erreur (chaîne quelconque)
#
# Contrat de sortie :
#   exit 1 - toujours
#   stderr - "ERREUR : <message>"
#
# Effets de bord : termine le processus courant
die() {
  echo "ERREUR : $*" >&2
  exit 1
}

# say <message>
#
# Contrat d'entrée :
#   $@ - message à afficher (chaîne quelconque)
#
# Contrat de sortie :
#   stdout - <message> si QUIET == 0
#   (rien)  - si QUIET == 1
#
# Effets de bord : aucun
say() {
  (( QUIET )) || echo "$@"
}

# == Progression et ETA =========================================================

# ui_progress_callback <i> <total_files> <bytes_done> <total_bytes> <eta_seconds>
#
# Fonction de callback compatible avec core_compute().
# À passer comme troisième argument de core_compute si la progression est souhaitée.
#
# Contrat d'entrée :
#   $1 - index du fichier courant (entier, commence à 1)
#   $2 - nombre total de fichiers
#   $3 - octets traités jusqu'ici
#   $4 - octets totaux
#   $5 - ETA en secondes (0 si non calculable)
#
# Contrat de sortie :
#   /dev/tty - ligne de progression sur le terminal courant
#              Écrit sur /dev/tty et non sur stdout : garantit que la progression
#              ne peut pas être capturée dans un pipe ou dans le fichier .b3
#   (rien)   - si QUIET == 1
#
# Effets de bord : aucun (le \r efface la ligne précédente)
ui_progress_callback() {
  (( QUIET )) && return 0

  local i="$1"
  local total_files="$2"
  local bytes_done="$3"
  local total_bytes="$4"
  local eta_seconds="$5"

  if (( bytes_done > 0 && eta_seconds > 0 )); then
    printf "\r[%d/%d] ETA : %dm %02ds   " \
      "$i" "$total_files" $(( eta_seconds / 60 )) $(( eta_seconds % 60 )) > /dev/tty
  elif (( bytes_done > 0 )); then
    printf "\r[%d/%d] calcul en cours...   " \
      "$i" "$total_files" > /dev/tty
  fi
}

# ui_progress_clear
#
# Efface la ligne de progression ETA du terminal.
# À appeler après core_compute pour laisser un terminal propre.
#
# Contrat de sortie :
#   /dev/tty - ligne vide (40 espaces + \r)
#   (rien)   - si QUIET == 1
ui_progress_clear() {
  (( QUIET )) && return 0
  printf "\r%*s\r" 40 "" > /dev/tty
}

# == Affichage des résultats de vérification ====================================

# ui_show_verify_result <statut> <nb_ok> <nb_fail> <lines_fail> <lines_err> <outdir>
#
# Contrat d'entrée :
#   $1 - statut : "OK" | "ECHEC" | "ERREUR"
#   $2 - nombre de fichiers OK (entier)
#   $3 - nombre de fichiers FAILED (entier)
#   $4 - lignes FAILED (chaîne multi-lignes, peut être vide)
#   $5 - lignes d'erreur b3sum (chaîne multi-lignes, peut être vide)
#   $6 - chemin du dossier de résultats
#
# Contrat de sortie :
#   stdout - résumé formaté si QUIET == 0
#   (rien)  - si QUIET == 1
#
# Effets de bord : aucun
ui_show_verify_result() {
  local statut="$1"
  local nb_ok="$2"
  local nb_fail="$3"
  local lines_fail="$4"
  local lines_err="$5"
  local outdir="$6"

  if [ "$statut" = "OK" ]; then
    say "Vérification OK - $nb_ok fichiers intègres."
  else
    say ""
    say "████████████████████████████████████████"
    if [ "$statut" = "ERREUR" ]; then
      say "  ERREUR lors de la vérification"
    else
      say "  ECHEC : $nb_fail fichier(s) corrompu(s) ou manquant(s)"
    fi
    say "████████████████████████████████████████"
    say ""
    [ -n "$lines_fail" ] && say "$lines_fail"
    [ -n "$lines_err"  ] && say "$lines_err"
    say ""
  fi

  say "Résultats dans : $outdir"
  say "  recap.txt"
  (( nb_fail > 0 )) || [ -n "$lines_err" ] && say "  failed.txt"
}

# ui_show_compare_result <nb_mod> <nb_dis> <nb_nou> <outdir>
#
# Contrat d'entrée :
#   $1 - nombre de fichiers modifiés
#   $2 - nombre de fichiers disparus
#   $3 - nombre de nouveaux fichiers
#   $4 - chemin du dossier de résultats
#
# Contrat de sortie :
#   stdout - résumé formaté si QUIET == 0
#   (rien)  - si QUIET == 1
#
# Effets de bord : aucun
ui_show_compare_result() {
  local nb_mod="$1"
  local nb_dis="$2"
  local nb_nou="$3"
  local outdir="$4"

  say "Résultats enregistrés dans : $outdir"
  say "  recap.txt     - modifiés: $nb_mod, disparus: $nb_dis, nouveaux: $nb_nou"
  say "  modifies.b3   - $nb_mod fichiers"
  say "  disparus.txt  - $nb_dis fichiers"
  say "  nouveaux.txt  - $nb_nou fichiers"
  say "  report.html   - rapport visuel"
}


--- Fichier : docker/entrypoint.sh ---
#!/usr/bin/env bash
# /entrypoint.sh - Point d'entrée Docker pour hash_tool
#
# Dispatche les commandes vers integrity.sh ou runner.sh.
# Toutes les commandes de integrity.sh sont supportées directement.
#
# Exemples :
#   docker run hash_tool help
#   docker run hash_tool compute /data /bases/hashes.b3
#   docker run hash_tool verify  /bases/hashes.b3
#   docker run hash_tool compare /bases/old.b3 /bases/new.b3
#   docker run hash_tool runner  /pipelines/pipeline.json
#   docker run hash_tool runner                              # lit /pipelines/pipeline.json
#   docker run -it hash_tool shell                           # bash interactif (debug)

set -euo pipefail

APP="/app"
INTEGRITY="$APP/src/integrity.sh"
RUNNER="$APP/runner.sh"

# == Aide =====================================================================

print_help() {
  cat <<'EOF'
hash_tool - Vérification d'intégrité BLAKE3

Usage :
  docker run [--rm] [-v ...] hash_tool <commande> [arguments...]

Commandes :
  compute <dossier> <base.b3>       Calcule les hashes d'un dossier
  verify  <base.b3> [dossier]       Vérifie l'intégrité
  compare <ancienne.b3> <nouvelle.b3>  Compare deux bases
  runner  [pipeline.json]           Exécute un pipeline (défaut : /pipelines/pipeline.json)
  shell                             Lance un shell bash interactif (debug)
  help                              Affiche cette aide

Options globales (à placer avant la commande) :
  --quiet                           Supprime la sortie terminal

Volumes conventionnels :
  /data        → données à hacher        (-v /mes/donnees:/data)
  /bases       → fichiers .b3            (-v /mes/bases:/bases)
  /pipelines   → fichiers pipeline.json  (-v /chemin/pipeline.json:/pipelines/pipeline.json)
  /resultats   → résultats               (-v /mes/resultats:/resultats)

Variable d'environnement :
  RESULTATS_DIR  Dossier de résultats (défaut dans le conteneur : /resultats)

Exemples :
  # Calculer les hashes de /data, stocker dans /bases
  docker run --rm \
    -v /mes/donnees:/data:ro \
    -v /mes/bases:/bases \
    hash_tool compute /data /bases/hashes_$(date +%Y-%m-%d).b3

  # Vérifier depuis le dossier d'origine
  docker run --rm \
    -v /mes/donnees:/data:ro \
    -v /mes/bases:/bases:ro \
    -v /mes/resultats:/resultats \
    hash_tool verify /bases/hashes_2024-01-15.b3 /data

  # Comparer deux snapshots
  docker run --rm \
    -v /mes/bases:/bases:ro \
    -v /mes/resultats:/resultats \
    hash_tool compare /bases/hashes_2024-01-15.b3 /bases/hashes_2024-02-01.b3

  # Pipeline complet depuis un fichier JSON
  docker run --rm \
    -v /mes/donnees:/data:ro \
    -v /mes/bases:/bases \
    -v /mes/resultats:/resultats \
    -v /chemin/vers/pipeline.json:/pipelines/pipeline.json:ro \
    hash_tool runner

  # Mode silencieux (CI/cron)
  docker run --rm \
    -v /mes/donnees:/data:ro \
    -v /mes/bases:/bases:ro \
    -v /mes/resultats:/resultats \
    hash_tool --quiet verify /bases/hashes.b3 /data

EOF
}

# == Vérification des outils ===================================================

check_deps() {
  local ok=1
  command -v b3sum &>/dev/null || { echo "ERREUR : b3sum introuvable" >&2; ok=0; }
  command -v jq    &>/dev/null || { echo "ERREUR : jq introuvable"    >&2; ok=0; }
  [ -f "$INTEGRITY" ]          || { echo "ERREUR : $INTEGRITY introuvable" >&2; ok=0; }
  [ -f "$RUNNER" ]             || { echo "ERREUR : $RUNNER introuvable"    >&2; ok=0; }
  (( ok )) || exit 1
}

# == Dispatch ==================================================================

# Extraire --quiet en tête s'il est présent
QUIET_FLAG=""
if [ "${1:-}" = "--quiet" ]; then
  QUIET_FLAG="--quiet"
  shift
fi

CMD="${1:-help}"
shift || true

case "$CMD" in

  compute|verify|compare)
    check_deps
    exec bash "$INTEGRITY" $QUIET_FLAG "$CMD" "$@"
    ;;

  runner)
    check_deps
    PIPELINE="${1:-/pipelines/pipeline.json}"
    if [ ! -f "$PIPELINE" ]; then
      echo "ERREUR : pipeline.json introuvable : $PIPELINE" >&2
      echo "Monter le fichier avec : -v /chemin/pipeline.json:/pipelines/pipeline.json" >&2
      exit 1
    fi
    exec bash "$RUNNER" "$PIPELINE"
    ;;

  shell|bash)
    echo "hash_tool - shell interactif (debug)"
    echo "  b3sum    : $(b3sum --version 2>/dev/null || echo 'non trouvé')"
    echo "  jq       : $(jq --version 2>/dev/null || echo 'non trouvé')"
    echo "  bash     : $BASH_VERSION"
    echo ""
    exec /bin/bash
    ;;

  help|--help|-h)
    print_help
    ;;

  version|--version|-v)
    echo "hash_tool"
    echo "  b3sum : $(b3sum --version 2>/dev/null || echo 'non trouvé')"
    echo "  jq    : $(jq --version 2>/dev/null || echo 'non trouvé')"
    echo "  bash  : $BASH_VERSION"
    ;;

  *)
    echo "ERREUR : commande inconnue : '$CMD'" >&2
    echo "Lancer 'docker run hash_tool help' pour la liste des commandes." >&2
    exit 1
    ;;

esac


--- Fichier : pipelines/pipeline-debug.json ---
{
    "pipeline": [

        {
            "op":     "compute",
            "source": "./mon_dossier/source",
            "bases":  "./mon_dossier/bases",
            "nom":    "hashes_dossier_1.b3"
        },

        {
            "op":     "compute",
            "source": "./mon_dossier/destination",
            "bases":  "./mon_dossier/bases",
            "nom":    "hashes_dossier_2.b3"
        },

        {
            "op":       "compare",
            "base_a":   "./mon_dossier/bases/hashes_dossier_1.b3",
            "base_b":   "./mon_dossier/bases/hashes_dossier_2.b3",
            "resultats": "./mon_dossier/result"
        }

    ]
}

--- Fichier : pipelines/pipeline-veracrypt.json ---
{
    "pipeline": [

        {
            "op":     "compute",
            "source": "/mnt/a/dossier_disque_1",
            "bases":  "/mnt/c/Users/TonNom/Desktop/bases",
            "nom":    "hashes_dossier_1.b3"
        },

        {
            "op":     "compute",
            "source": "/mnt/i/dossier_disque_2",
            "bases":  "/mnt/c/Users/TonNom/Desktop/bases",
            "nom":    "hashes_dossier_2.b3"
        },

        {
            "op":     "compute",
            "source": "/mnt/h/dossier_disque_3",
            "bases":  "/mnt/c/Users/TonNom/Desktop/bases",
            "nom":    "hashes_dossier_3.b3"
        },

        {
            "op":     "verify",
            "source": "/mnt/a/dossier_disque_1",
            "base":   "/mnt/c/Users/TonNom/Desktop/bases/hashes_dossier_1.b3"
        },

        {
            "op":       "compare",
            "base_a":   "/mnt/c/Users/TonNom/Desktop/bases/hashes_dossier_1.b3",
            "base_b":   "/mnt/c/Users/TonNom/Desktop/bases/hashes_dossier_2.b3",
            "resultats": "/mnt/c/Users/TonNom/Desktop/rapports/compare_1_vs_2"
        }

    ]
}

--- Fichier : docs/getting-started.md ---
# Démarrage rapide

---

## Prérequis

| Dépendance | Usage | Installation |
|---|---|---|
| `bash >= 4` | Interpréteur shell | Linux natif ; macOS via `brew install bash` ; WSL |
| `b3sum` | Calcul des empreintes BLAKE3 | `apt install b3sum` / `brew install b3sum` |
| `jq` | Parsing `pipeline.json` (runner uniquement) | `apt install jq` / `brew install jq` |
| `find`, `sort`, `awk`, `comm`, `join`, `stat`, `du` | Outils internes | GNU coreutils (natifs sur toute distribution) |

!!! note "macOS"
    `bash` est en version 3.x par défaut sur macOS. hash_tool requiert bash >= 4.
    ```bash
    brew install bash
    # Vérifier : /usr/local/bin/bash --version
    ```

---

## Installation

```bash
git clone https://github.com/hash_tool/hash_tool.git
cd hash_tool
chmod +x src/integrity.sh runner.sh
```

Aucune compilation, aucune dépendance système au-delà des outils listés ci-dessus.

---

## Environnements supportés

| Environnement | Méthode | Notes |
|---|---|---|
| Linux (Debian, Ubuntu, Alpine, Arch…) | Natif | Environnement de référence |
| macOS | Natif avec bash 4+ via Homebrew | `brew install bash b3sum jq` |
| Windows | Via WSL2 | Distributions Ubuntu ou Debian recommandées |
| NAS Synology | Via Docker (image arm64) | Voir [guide NAS](guides/nas-synology.md) |
| Serveur headless | Mode `--quiet` + cron | Voir [guide CI/Cron](guides/cron-ci.md) |

---

## Workflow typique

| Étape | Commande | Moment |
|---|---|---|
| 1. Indexer | `./src/integrity.sh compute ./dossier bases/hashes_2024-01-15.b3` | Données saines connues |
| 2. Vérifier | `./src/integrity.sh verify bases/hashes_2024-01-15.b3` | Après transfert / stockage |
| 3. Comparer | `./src/integrity.sh compare bases/avant.b3 bases/apres.b3` | Entre deux états |
| 4. Pipeline | `./runner.sh pipelines/pipeline.json` | Automatisation multi-étapes |

### Exemple concret - archivage sur disque externe

```bash
# Brancher le disque externe, VeraCrypt le monte sur /mnt/archive

# 1. Première indexation - données saines à J0
cd /mnt/archive
../hash_tool/src/integrity.sh compute . /mnt/c/bases/archive_2024-01-15.b3

# 2. Vérification après chaque session - J+30, J+90, etc.
cd /mnt/archive
../hash_tool/src/integrity.sh verify /mnt/c/bases/archive_2024-01-15.b3

# 3. Après ajout de fichiers - comparer les deux états
cd /mnt/archive
../hash_tool/src/integrity.sh compute . /mnt/c/bases/archive_2024-02-15.b3
../hash_tool/src/integrity.sh compare \
  /mnt/c/bases/archive_2024-01-15.b3 \
  /mnt/c/bases/archive_2024-02-15.b3
```

---

## Lire les résultats

Chaque opération `verify` ou `compare` produit un dossier horodaté dans `~/integrity_resultats/` :

```
~/integrity_resultats/
└== resultats_archive_2024-01-15/
    ├== recap.txt      ← statut global, compteurs
    ├== failed.txt     ← fichiers en échec (si applicable)
    └== report.html    ← rapport visuel autonome (ouvrir dans un navigateur)
```

Ouvrir `report.html` directement dans un navigateur - aucune connexion requise, aucun serveur.

---

## Docker - démarrage rapide

Si les dépendances ne peuvent pas être installées sur l'hôte :

```bash
docker build -t hash_tool .

docker run --rm \
  -v /mes/donnees:/data:ro \
  -v /mes/bases:/bases \
  hash_tool compute /data /bases/hashes_$(date +%Y-%m-%d).b3
```

Voir la [référence Docker complète](reference/docker.md) pour les volumes, les environnements Synology, et les options Compose.


--- Fichier : docs/index.md ---
# hash_tool

hash_tool détecte la corruption silencieuse de fichiers en comparant des empreintes BLAKE3 prises à des instants différents. Il fonctionne depuis la ligne de commande, ne requiert aucune installation complexe, et produit un rapport HTML lisible sans outil supplémentaire.




## Principe

`integrity.sh` calcule une empreinte cryptographique de chaque fichier d'un dossier, stocke ces empreintes dans un fichier `.b3`, puis permet de vérifier ultérieurement que rien n'a changé. `runner.sh` orchestre plusieurs opérations via un fichier `pipeline.json`.

```
┌=============┐    compute     ┌==============┐
│  Dossier    │ =============► │  base.b3     │
│  de données │                │  (hashes)    │
└=============┘                └==============┘
                                      │
                     verify / compare │
                                      ▼
                               ┌==============┐
                               │  Rapport     │
                               │  recap.txt   │
                               │  report.html │
                               └==============┘
```

---

## Cas d'usage

- **Archivage long terme** - vérifier qu'un disque n'a pas développé de secteurs défectueux
- **Transfert de données** - confirmer qu'une copie est bit-à-bit identique à la source
- **VeraCrypt** - indexer des partitions chiffrées avant démontage, vérifier après remontage
- **Monitoring périodique** - cron hebdomadaire sur un NAS ou serveur

---

## Démarrage rapide

=== "Script direct"

    ```bash
    # 1. Indexer un dossier
    ./src/integrity.sh compute ./mon_dossier hashes_$(date +%Y-%m-%d).b3

    # 2. Vérifier l'intégrité
    ./src/integrity.sh verify hashes_$(date +%Y-%m-%d).b3

    # 3. Comparer deux snapshots
    ./src/integrity.sh compare ancien.b3 nouveau.b3
    ```

=== "Pipeline JSON"

    ```bash
    # Éditer pipelines/pipeline.json, puis :
    ./runner.sh                              # lit pipelines/pipeline.json
    ./runner.sh /chemin/vers/pipeline.json   # config explicite
    ```

=== "Docker"

    ```bash
    docker run --rm \
      -v /mes/donnees:/data:ro \
      -v /mes/bases:/bases \
      hash_tool compute /data /bases/hashes_$(date +%Y-%m-%d).b3
    ```

=== Mode `--quiet`

Supprime toute sortie terminal, écrit uniquement dans les fichiers de résultats. Exit code propagé.

    ```bash
    # Hook pre-commit git
    ./src/integrity.sh --quiet verify base.b3 || { echo "Corruption détectée"; exit 1; }

    # Monitoring cron
    0 3 * * * /opt/hash_tool/src/integrity.sh --quiet verify /data/base.b3 || mail -s "ALERT" admin@example.com
    ```

---

## Arbre de décision

| Situation | Commande |
|---|---|
| Première indexation | `compute` |
| Vérifier après transfert / stockage | `verify` |
| Comparer deux snapshots | `compare` |
| Pipeline multi-dossiers / VeraCrypt | `runner.sh` + `pipeline.json` |
| Contrôle ad hoc d'un fichier unique | `b3sum fichier.bin` |
| Intégration CI/cron | `--quiet verify` |




## Configuration

`RESULTATS_DIR` définit le dossier racine des résultats (défaut : `~/integrity_resultats`).
Peut être surchargé par variable d'environnement, ou par le champ `resultats` dans `pipeline.json`.

---

## Règles d'utilisation critiques

- **Chemins relatifs** dans les bases `.b3`. `runner.sh` gère le `cd` automatiquement.
- **Répertoire de travail** : lancer `verify` depuis le même répertoire qu'au `compute`, ou passer ce répertoire en second argument.
- **Stockage séparé** : stocker les `.b3` sur un support distinct des données.
- **Nommage daté** : `hashes_2024-01-15.b3`, jamais `hashes_latest.b3`.

---

## Docker

Aucune dépendance à installer sur l'hôte. Fonctionne sur Windows, NAS Synology, serveur Debian.

```bash
# Build
docker build -t hash_tool .

# Compute
docker run --rm -v /mes/donnees:/data:ro -v /mes/bases:/bases \
  hash_tool compute /data /bases/hashes_$(date +%Y-%m-%d).b3

# Verify
docker run --rm -v /mes/donnees:/data:ro -v /mes/bases:/bases:ro \
  -v /mes/resultats:/resultats \
  hash_tool verify /bases/hashes.b3 /data

# Pipeline complet
docker run --rm \
  -v /mes/donnees:/data:ro -v /mes/bases:/bases \
  -v /mes/resultats:/resultats \
  -v /chemin/pipeline.json:/pipelines/pipeline.json:ro \
  hash_tool runner
```

Voir [docs/reference/docker.md](docs/reference/docker.md) pour la documentation complète (NAS, cron, ARM64, Compose).

---

## Tests

```bash
# Tests integrity.sh (T00–T14)
cd tests && ./run_tests.sh

# Tests runner.sh + pipeline.json (TP01–TP12b)
cd tests && ./run_tests_pipeline.sh

# ShellCheck (inclus dans T00, requiert installation séparée)
apt install shellcheck
```

---

## Documentation

```bash
# Installer les dépendances
pip install mkdocs mkdocs-material

# Prévisualiser en local
mkdocs serve    # http://localhost:8000

# Générer le site statique
mkdocs build    # → site/
```

---



---

## Structure de la documentation

La documentation est organisée en trois niveaux :

### Documentation utilisateur
Pour installer, configurer et utiliser hash_tool sans connaître son implémentation interne.

- [Démarrage rapide](getting-started.md) - installation et premier usage
- [Guide VeraCrypt](guides/veracrypt.md) - workflow multi-disques
- [Guide CI/Cron](guides/cron-ci.md) - automatisation
- [Guide NAS Synology](guides/nas-synology.md) - déploiement NAS

### Documentation développeur
Pour comprendre l'architecture, contribuer au code ou intégrer les modules.

- [Architecture](development/architecture.md) - décisions techniques et rationale
- [Contribuer](development/contributing.md) - conventions, tests, processus de release
- [Changelog](development/changelog.md) - historique des versions
- [API interne](spec/api-interne.md) - contrats des modules

### Documentation de référence
Spécifications formelles et référence exhaustive des commandes.

- [Spécification format `.b3`](spec/b3-format.md) - grammaire, invariants, exemples
- [Référence integrity.sh](reference/integrity-sh.md) - modes, arguments, exit codes, limites
- [Référence runner.sh](reference/runner-sh.md) - format pipeline.json, comportements
- [Référence Docker](reference/docker.md) - build, volumes, Compose, cron, ARM64

---

## Dépendances

| Outil | Requis par | Installation |
|---|---|---|
| `bash >= 4` | `integrity.sh`, `runner.sh` | Natif Linux/macOS |
| `b3sum` | `integrity.sh` | `apt install b3sum` |
| `jq` | `runner.sh` | `apt install jq` |
| `find`, `sort`, `awk`, `comm`, `join`, `stat`, `du` | `integrity.sh` | GNU coreutils (natifs) |

!!! note "macOS"
    `bash` est en version 3.x par défaut sur macOS. Installer bash 5 via Homebrew : `brew install bash`.

---

## Structure du projet

```
hash_tool/
├== src/
│   ├== integrity.sh           ← dispatcher CLI
│   └== lib/
│       ├== core.sh            ← logique métier (hachage, vérification, comparaison)
│       ├== ui.sh              ← interface terminal (affichage, ETA, progression)
│       ├== results.sh         ← écriture fichiers de résultats
│       └== report.sh          ← génération HTML
├== runner.sh                  ← orchestrateur pipeline
├== pipelines/
│   ├== pipeline.json          ← pipeline de test local
│   └== pipeline-full.json     ← pipeline VeraCrypt multi-disques
├== reports/
│   └== template.html          ← template HTML de référence
├== docs/
│   ├== spec/                  ← spécifications formelles
│   │   ├== b3-format.md       ← format .b3
│   │   └== api-interne.md     ← contrats des modules
│   ├== reference/             ← référence des commandes
│   ├== guides/                ← guides utilisateur
│   └== development/           ← documentation développeur
└== tests/
    ├== run_tests.sh           ← T00–T14
    └== run_tests_pipeline.sh  ← TP01–TP12b
```


--- Fichier : docs/spec/api-interne.md ---
# API interne - Contrats des modules

**Scope :** développeurs contribuant au code de hash_tool  
**Référence d'implémentation :** `src/lib/core.sh`, `src/lib/ui.sh`, `src/lib/results.sh`, `src/lib/report.sh`

---

## Architecture des modules

```
integrity.sh  (dispatcher CLI)
    │
    ├== src/lib/core.sh      Logique métier pure
    │   Entrées : chemins, fichiers .b3
    │   Sorties : fichiers .b3, variables CORE_*, fichiers de résultats partiels
    │   Aucune sortie terminal directe
    │
    ├== src/lib/ui.sh        Interface terminal
    │   Entrées : données structurées issues de core.*
    │   Sorties : stdout / /dev/tty
    │   Aucune logique métier
    │
    ├== src/lib/results.sh   Écriture fichiers de résultats
    │   Entrées : données structurées + chemin outdir
    │   Sorties : recap.txt, failed.txt sur disque
    │   Aucune sortie terminal directe
    │
    └== src/lib/report.sh    Génération HTML
        Entrées : données structurées + fichiers de listes + chemin output
        Sorties : report.html sur disque
        Aucune sortie terminal directe
```

**Principe de séparation strict :** `core.sh` ne connaît pas `ui.sh`. `ui.sh` ne connaît pas `results.sh`. `integrity.sh` est le seul module qui orchestre l'ensemble.

---

## Module `core.sh`

### `core_assert_b3_valid(file, [label])`

| | |
|---|---|
| **Entrée** | `$1` chemin fichier .b3 ; `$2` label optionnel pour les messages |
| **Sortie** | exit 0 si valide ; exit 1 + message stderr sinon |
| **Effets** | aucun |
| **Invariants vérifiés** | existence, type fichier régulier, non vide, toutes les lignes au format `[0-9a-f]{64}  .+` |

### `core_assert_target_valid(dir)`

| | |
|---|---|
| **Entrée** | `$1` chemin dossier |
| **Sortie** | exit 0 si valide ; exit 1 + message stderr sinon |
| **Effets** | aucun |
| **Invariants vérifiés** | existence, type dossier, contient au moins un fichier régulier |

### `core_compute(target, hashfile, [callback])`

| | |
|---|---|
| **Entrée** | `$1` dossier cible ; `$2` fichier .b3 de sortie ; `$3` nom de fonction callback (optionnel) |
| **Sortie** | exit 0/1 ; `$2` contient le fichier .b3 |
| **Effets** | crée/écrase `$2` ; appelle `$3` après chaque fichier |
| **Signature callback** | `callback(i, total_files, bytes_done, total_bytes, eta_seconds)` |
| **Garantie** | aucune ligne de progression ne peut polluer `$2` |

### `core_verify(hashfile)`

| | |
|---|---|
| **Entrée** | `$1` chemin absolu du fichier .b3 ; répertoire courant = répertoire d'origine du compute |
| **Sortie** | exit 0 si OK ; exit 1 si FAILED/ERREUR |
| **Variables positionnées** | `CORE_VERIFY_RAW`, `CORE_VERIFY_LINES_OK`, `CORE_VERIFY_LINES_FAIL`, `CORE_VERIFY_LINES_ERR`, `CORE_VERIFY_NB_OK`, `CORE_VERIFY_NB_FAIL`, `CORE_VERIFY_STATUS` |
| **Effets** | aucun (pas d'écriture disque) |

### `core_compare(old, new, outdir)`

| | |
|---|---|
| **Entrée** | `$1` ancienne base .b3 ; `$2` nouvelle base .b3 ; `$3` dossier de sortie (doit exister) |
| **Sortie** | exit 0/1 |
| **Fichiers produits** | `$3/modifies.b3`, `$3/disparus.txt`, `$3/nouveaux.txt` |
| **Variables positionnées** | `CORE_COMPARE_NB_MOD`, `CORE_COMPARE_NB_DIS`, `CORE_COMPARE_NB_NOU` |
| **Effets** | écrit 3 fichiers dans `$3` ; utilise mktemp nettoyé via trap |

### `core_make_result_dir(b3file, resultats_dir)`

| | |
|---|---|
| **Entrée** | `$1` chemin .b3 (pour nommer le dossier) ; `$2` dossier racine des résultats |
| **Sortie** | stdout = chemin absolu du dossier créé |
| **Effets** | crée le dossier via mkdir -p |
| **Invariant anti-écrasement** | si le dossier existe, ajoute `_YYYYMMDD-HHMMSS` |

---

## Module `ui.sh`

### Prérequis

La variable `QUIET` doit être définie avant de sourcer `ui.sh` :
- `QUIET=0` - affichage normal
- `QUIET=1` - suppression totale de la sortie terminal

### `die(message)`

| | |
|---|---|
| **Entrée** | `$@` message |
| **Sortie** | exit 1 toujours ; stderr = "ERREUR : <message>" |
| **Note** | fonction globale utilisable depuis tous les modules |

### `say(message)`

| | |
|---|---|
| **Entrée** | `$@` message |
| **Sortie** | stdout si QUIET==0 ; rien si QUIET==1 |

### `ui_progress_callback(i, total_files, bytes_done, total_bytes, eta_seconds)`

| | |
|---|---|
| **Sortie** | `/dev/tty` si QUIET==0 ; rien si QUIET==1 |
| **Note** | écriture sur `/dev/tty` et non stdout - ne peut pas polluer les pipes |

### `ui_progress_clear()`

| | |
|---|---|
| **Sortie** | `/dev/tty` - efface la ligne de progression |

### `ui_show_verify_result(statut, nb_ok, nb_fail, lines_fail, lines_err, outdir)`

| | |
|---|---|
| **Sortie** | stdout si QUIET==0 |

### `ui_show_compare_result(nb_mod, nb_dis, nb_nou, outdir)`

| | |
|---|---|
| **Sortie** | stdout si QUIET==0 |

---

## Module `results.sh`

### `results_write_verify(outdir, hashfile, statut, nb_ok, nb_fail, lines_fail, lines_err)`

| | |
|---|---|
| **Sortie** | `outdir/recap.txt` toujours ; `outdir/failed.txt` si erreurs ; supprime `failed.txt` si OK |

### `results_write_compare(outdir, old, new, nb_mod, nb_dis, nb_nou)`

| | |
|---|---|
| **Sortie** | `outdir/recap.txt` |
| **Prérequis** | `outdir` contient déjà `modifies.b3`, `disparus.txt`, `nouveaux.txt` produits par `core_compare` |

---

## Règles de contribution au code

1. **Aucune sortie terminal dans `core.sh`** - toute communication utilisateur passe par les variables de sortie et les codes de retour
2. **Aucune logique métier dans `ui.sh`** - `ui.sh` formate et affiche, il ne calcule rien
3. **Tout chemin dans un .b3 est relatif** - `core_compute` ne vérifie pas cet invariant (responsabilité de l'appelant via `runner.sh` ou appel direct avec `cd`)
4. **Variables `CORE_*` déclarées `local` dans les appelants** si isolation requise entre appels successifs
5. **`die()` est disponible globalement** - sourcé via `ui.sh` qui est chargé en premier dans `integrity.sh`


--- Fichier : docs/spec/b3-format.md ---
# Spécification formelle du format `.b3`

**Version :** 1.0  
**Statut :** Référence normative  
**Scope :** tout code lisant ou écrivant des fichiers `.b3` dans hash_tool

---

## 1. Définition

Un fichier `.b3` est un fichier texte encodé en UTF-8 contenant une empreinte BLAKE3 par fichier indexé. Son format est celui natif produit par `b3sum` version ≥ 1.3.

---

## 2. Grammaire formelle

```
b3file     ::= line* EOF
line       ::= hash SEP path LF
hash       ::= [0-9a-f]{64}
SEP        ::= "  "          (deux espaces U+0020)
path       ::= <chemin de fichier>
LF         ::= U+000A
EOF        ::= fin de fichier
```

### 2.1 Contraintes sur `hash`

- Exactement 64 caractères hexadécimaux minuscules (`[0-9a-f]`)
- Représentation de l'empreinte BLAKE3 256 bits en notation hexadécimale

### 2.2 Contraintes sur `SEP`

- Exactement deux espaces ASCII (U+0020)
- Aucun autre séparateur n'est valide (tabulation, espace unique, etc.)
- Ce format est identique à celui de `sha256sum`, `sha512sum` et `md5sum` - interopérabilité outil garantie

### 2.3 Contraintes sur `path`

- Chemin **relatif** obligatoire - voir section 3
- Encodé en UTF-8 ; les noms non UTF-8 sont traités comme des séquences d'octets opaques
- Un chemin contenant des espaces est valide (les espaces font partie du chemin, pas du séparateur)
- Le chemin inclut le préfixe `./` si `b3sum` a été appelé avec un argument commençant par `./`

### 2.4 Contraintes sur le fichier

- Trié par chemin (ordre lexicographique binaire, LC_ALL=C) - requis pour que `diff`, `join` et `comm` produisent des résultats déterministes
- Une ligne par fichier régulier - les dossiers vides ne génèrent pas de ligne
- Pas de ligne vide, pas de commentaire, pas de ligne d'en-tête
- Pas de retour chariot (U+000D) - fichier au format Unix uniquement

---

## 3. Invariant des chemins relatifs

**Règle absolue : les chemins dans un fichier `.b3` sont toujours relatifs.**

### Rationale

Un chemin absolu `/mnt/veracrypt1/photos/img.jpg` devient invalide si la partition est remontée sur `/mnt/veracrypt2/` ou déplacée. Un chemin relatif `./photos/img.jpg` reste valide quel que soit le point de montage, à condition de lancer `verify` depuis le même répertoire de travail qu'au `compute`.

### Conséquence opérationnelle

- `b3sum --check base.b3` doit être exécuté depuis le répertoire où `compute` a été lancé
- `runner.sh` gère ce `cd` automatiquement via des sous-shells isolés

### Cas de non-conformité

Un fichier `.b3` contenant des chemins absolus est techniquement lisible par `b3sum --check` mais est considéré **non conforme** au sens de cette spécification. `integrity.sh verify` refusera un tel fichier avec un avertissement.

---

## 4. Exemple conforme

```
a1b2c3d4e5f6a7b8c9d0e1f2a3b4c5d6e7f8a9b0c1d2e3f4a5b6c7d8e9f0a1b2  ./dossier/fichier.txt
e5f6a7b8c9d0e1f2a3b4c5d6e7f8a9b0c1d2e3f4a5b6c7d8e9f0a1b2c3d4e5f6  ./dossier/sous/autre.bin
f0a1b2c3d4e5f6a7b8c9d0e1f2a3b4c5d6e7f8a9b0c1d2e3f4a5b6c7d8e9f0a1  ./fichier avec espaces.pdf
```

---

## 5. Règles de nommage des fichiers `.b3`

Ces règles ne sont pas normatives mais fortement recommandées :

- Nom daté : `hashes_YYYY-MM-DD.b3` ou `hashes_<label>_YYYY-MM-DD.b3`
- Ne jamais utiliser `hashes_latest.b3` - un nom non daté ne permet pas de situer la base dans le temps
- Stocker sur un support distinct des données vérifiées (voir guide VeraCrypt)

---

## 6. Taille indicative

| Nombre de fichiers | Taille approximative |
|---|---|
| 1 000 | ~200 Ko |
| 10 000 | ~2 Mo |
| 100 000 | ~20 Mo |
| 1 000 000 | ~200 Mo |

Calcul : 64 (hash) + 2 (séparateur) + longueur_moyenne_chemin + 1 (LF) ≈ 80–100 octets par ligne.

---

## 7. Validation programmatique

Expression régulière de validation d'une ligne :

```
^[0-9a-f]{64}  .+$
```

Validation utilisée par `core_assert_b3_valid()` dans `src/lib/core.sh` :

```bash
valid_lines=$(grep -c -E '^[0-9a-f]{64}  .+' "$file" || true)
total_lines=$(wc -l < "$file")
# Un fichier est valide si valid_lines == total_lines && valid_lines > 0
```

---

## 8. Interopérabilité

Le format est directement compatible avec les outils suivants sans conversion :

| Outil | Commande |
|---|---|
| `b3sum` | `b3sum --check base.b3` |
| `grep` | `grep FAILED < <(b3sum --check base.b3)` |
| `sort` | `sort base.b3` (tri stable, déterministe) |
| `diff` | `diff base_a.b3 base_b.b3` |
| `wc` | `wc -l base.b3` → nombre de fichiers indexés |


--- Fichier : docs/development/ROADMAP.md ---
# Roadmap - hash_tool

---

## Positionnement

> Outil de snapshot d'intégrité BLAKE3 pour collections de fichiers locales.

hash_tool n'est pas un logiciel de sauvegarde. Il ne copie pas, ne restaure pas, ne compresse pas. Il n'est pas un outil de sécurité au sens cryptographique - BLAKE3 est utilisé pour la détection d'erreurs accidentelles, pas pour l'authentification. Il n'est pas un outil de surveillance temps réel. Il opère par snapshots sur demande.

La clarté du périmètre est une qualité, pas une limite. Les outils qui font une seule chose bien sont plus faciles à auditer, à maintenir, à tester et à intégrer dans un pipeline plus large. hash_tool est conçu pour être **une brique, pas une solution complète**.

---

## Panorama des outils existants

| Outil | Type | Algorithme | Lacunes vis-à-vis du créneau |
|---|---|---|---|
| `md5sum` / `sha256sum` | CLI Unix | MD5 / SHA-256 | Fichier par fichier, pas de dossier, pas de rapport, pas de compare |
| `rclone check` | CLI Go | Variable | Couplé au stockage cloud, pas adapté aux usages locaux/hors-ligne |
| Duplicati | GUI/daemon | SHA-256 | Logiciel de sauvegarde complet, lourd, overkill pour la vérification seule |
| TeraCopy | GUI Windows | Plusieurs | Windows uniquement, propriétaire, pas scriptable |
| `hashdeep` | CLI C | Plusieurs | Pas de BLAKE3, pas de rapport HTML, pas de pipeline, inactif depuis 2015 |
| `fclones` | CLI Rust | BLAKE3 | Orienté déduplication, pas intégrité temporelle, pas de compare snapshots |
| `par2` | CLI C++ | Reed-Solomon | Réparation de données, pas détection de corruption sur dossier existant |

Aucun outil ci-dessus ne combine simultanément : (1) BLAKE3, (2) gestion de dossiers complets avec chemins relatifs, (3) comparaison de deux snapshots à des instants différents, (4) rapport HTML autonome, (5) pipeline JSON déclaratif, (6) image Docker Alpine légère. La conjonction de ces six caractéristiques définit le créneau.

---

## Population cible

| Profil | Cas d'usage principal | Besoin non couvert par les alternatives |
|---|---|---|
| Sysadmin de PME / indépendant | Vérifier l'intégrité de sauvegardes NAS après restauration | Outil léger, sans agent, rapport lisible par le client |
| Photographe / vidéaste professionnel | Garantir l'intégrité d'archives de médias sur disques durs | Interface simple, hors-ligne, pas de dépendance cloud |
| Archiviste numérique / bibliothèque | Détecter le bitrot sur des collections à long terme | Rapport horodaté, comparaison de snapshots, exportable |
| Chercheur / laboratoire | Valider l'intégrité de datasets après transfert | Portabilité, chemins relatifs, pas de compte tiers requis |
| Développeur DevOps | Intégrer une vérification d'intégrité dans un pipeline CI/CD | Mode `--quiet`, exit code propagé, image Docker légère |

---

## Créneaux secondaires

**Post-transfert sur supports chiffrés.** Les utilisateurs de partitions chiffrées (VeraCrypt, LUKS, BitLocker) font face à un problème spécifique : le transfert de fichiers est une opération à risque (coupure d'alimentation, démontage forcé, erreur de transfert). Aucun outil dédié ne propose un workflow `compute → verify → compare` adapté à ce contexte. Le pipeline JSON de hash_tool s'y prête directement.

**Validation de migration de données.** Migrations de serveurs, changements de NAS, restructuration d'arborescences - ces opérations nécessitent de comparer l'état avant et après. Les outils existants (`diff`, `rsync --checksum`) travaillent sur des copies simultanées, pas sur des snapshots temporels. hash_tool compare deux `.b3` produits à n'importe quel intervalle de temps.

**Intégration CI/CD légère.** Les pipelines CI qui vérifient l'intégrité d'artefacts de build ou de datasets de test utilisent généralement des checksums ad hoc (SHA-256 d'un seul fichier). hash_tool propose une approche structurée avec `--quiet`, exit code propre, et image Docker légère - sans introduire une dépendance lourde comme rclone ou un service cloud.

**Archivage numérique long terme.** La communauté de l'archivage numérique (bibliothèques, musées, institutions de recherche) utilise des outils comme BagIt ou PREMIS pour l'intégrité à long terme. Ces outils sont complexes, orientés XML, et inadaptés aux petites structures. hash_tool offre un sous-ensemble fonctionnel utilisable sans formation.

---

## Synthèse des créneaux

| Créneau | Intensité du besoin | Vacance actuelle | Priorité |
|---|---|---|---|
| Intégrité de collections de fichiers locaux à long terme | Élevée | Totale | Primaire |
| Post-transfert sur supports chiffrés | Moyenne | Totale | Secondaire |
| Validation de migration de données | Élevée | Partielle | Secondaire |
| Intégration CI/CD légère (BLAKE3) | Moyenne | Partielle | Tertiaire |
| Archivage numérique petites structures | Faible | Totale | Tertiaire |

---

## Limites connues non corrigeables par conception

| Scénario | Détecté ? | Explication |
|---|---|---|
| Clone bit-à-bit | Non | Hash identique par définition |
| Renommage de fichier | Non | Vu comme suppression + ajout |
| Modification de permissions / timestamps | Non | `b3sum` ne hache que le contenu binaire |
| Dossier vide | Non | `find -type f` ignore les dossiers vides |
| Corruption de la base `.b3` elle-même | Non | La base n'est pas auto-protégée par défaut |

Contournement pour la base `.b3` :

```bash
b3sum hashes.b3 > hashes.b3.check
b3sum --check hashes.b3.check
```

---

## Concurrence future

Le seul risque de désintermédiation sérieux serait qu'un outil comme `rclone` ou `restic` implémente nativement BLAKE3 + comparaison de snapshots + rapport HTML + Docker léger. Leur complexité intrinsèque rend ce scénario peu probable à court terme.

---

## Axes d'évolution envisagés

Ces fonctionnalités ne sont pas planifiées avec une date. Elles sont identifiées comme extensions naturelles du périmètre actuel, par ordre de valeur décroissante.

**`--format json` sur `verify` et `compare`.** `recap.txt` est lisible par un humain, pas par un outil. Un export JSON permettrait l'intégration avec des dashboards ou des outils de monitoring sans parser du texte. Contribution prioritaire.

**CI automatique (GitHub Actions).** `run_tests.sh` + `run_tests_pipeline.sh` déclenchés sur push. Contribution prioritaire.

**`install.sh` one-liner.** Script d'installation avec vérification des dépendances. Contribution prioritaire.

**Notifications natives.** Aujourd'hui la notification est à la charge du script appelant (`mail`, webhook Slack, etc.). Un champ `on_failure` dans `pipeline.json` encapsulerait ce pattern récurrent.

**Auto-protection de la base `.b3`.** Un flag `--sign` sur `compute` qui calcule et stocke le hash de la base dans un fichier `.b3.check` adjacent, et un flag `--verify-base` sur `verify` qui valide ce check avant toute opération.

**Parallélisme configurable.** La boucle séquentielle est optimale sur HDD. Sur SSD NVMe avec de nombreux petits fichiers, `xargs -P N` offrirait +20–40%. À conditionner à un flag explicite `--parallel N` pour ne pas casser les environnements où l'ordre de traitement importe.


--- Fichier : docs/development/architecture.md ---
# Architecture

Décisions techniques, choix d'implémentation, flux de données et rationale.

---

## Vue d'ensemble

hash_tool est organisé en quatre couches avec séparation stricte des responsabilités :

```
runner.sh                      ← orchestration pipeline (entrée utilisateur)
    └== src/integrity.sh       ← dispatcher CLI (parsing args, orchestration)
            ├== src/lib/core.sh      ← logique métier pure
            ├== src/lib/ui.sh        ← interface terminal (affichage, ETA)
            ├== src/lib/results.sh   ← écriture fichiers de résultats
            └== src/lib/report.sh    ← génération rapports HTML
```

Les dépendances sont **strictement unidirectionnelles** : `integrity.sh` orchestre les modules, les modules ne se connaissent pas entre eux.

### Rationale de la séparation

La séparation n'est pas un exercice de style. Elle résout des problèmes concrets :

- **Testabilité** : `core_compute()`, `core_verify()`, `core_compare()` peuvent être testés sans terminal, sans affichage, sans effets de bord UI.
- **Mode `--quiet`** : activé dans `ui.sh` uniquement. Le code métier n'a pas à savoir si on est en mode silencieux.
- **Réutilisabilité** : `src/lib/core.sh` peut être sourcé par un script tiers pour utiliser les fonctions métier sans l'interface CLI.
- **Maintenance** : modifier le format d'affichage de l'ETA ne touche pas à la logique de hachage, et vice versa.

---

## Flux de données

### Mode `compute`

```
integrity.sh
    │
    ├= core_assert_target_valid(target)
    │      ↓ exit 1 si invalide
    │
    ├= core_compute(target, hashfile, callback=ui_progress_callback)
    │      │
    │      ├= find -type f -print0 | sort -z → liste fichiers
    │      ├= pour chaque fichier :
    │      │       b3sum fichier >> hashfile
    │      │       callback(i, total, bytes_done, total_bytes, eta)
    │      │           └= ui_progress_callback → printf > /dev/tty
    │      └= retour : hashfile contient N lignes "<hash>  <chemin>"
    │
    ├= ui_progress_clear()     → efface ligne ETA du terminal
    └= say("Base enregistrée") → stdout
```

### Mode `verify`

```
integrity.sh
    │
    ├= core_assert_b3_valid(b3file)
    ├= résolution chemin absolu (avant cd)
    ├= cd workdir (si ARG3 fourni)
    ├= core_make_result_dir → outdir
    │
    ├= core_verify(hashfile_abs)
    │      │
    │      ├= b3sum --check hashfile → raw output
    │      ├= parsing raw → CORE_VERIFY_LINES_OK/FAIL/ERR
    │      └= positionne CORE_VERIFY_STATUS, NB_OK, NB_FAIL
    │
    ├= results_write_verify(outdir, ...) → outdir/recap.txt, outdir/failed.txt
    └= ui_show_verify_result(...)        → stdout
```

### Mode `compare`

```
integrity.sh
    │
    ├= core_assert_b3_valid(old), core_assert_b3_valid(new)
    ├= core_make_result_dir → outdir
    │
    ├= core_compare(old, new, outdir)
    │      │
    │      ├= _b3_to_path_hash(old) → tmp_old : "chemin\thash"
    │      ├= _b3_to_path_hash(new) → tmp_new : "chemin\thash"
    │      ├= join inner → modifies.b3
    │      ├= comm -23   → disparus.txt
    │      ├= comm -13   → nouveaux.txt
    │      └= positionne CORE_COMPARE_NB_MOD/DIS/NOU
    │
    ├= results_write_compare(outdir, ...) → outdir/recap.txt
    ├= generate_compare_html(...)         → outdir/report.html
    └= ui_show_compare_result(...)        → stdout
```

---

## Choix algorithmique - BLAKE3

### Comparaison MD5 / SHA-256 / BLAKE3

| Critère | MD5 | SHA-256 | BLAKE3 |
|---|---|---|---|
| Vitesse sur fichiers volumineux | Rapide | Lent | Très rapide (~3× SHA-256) |
| Sécurité cryptographique | Cassé | Solide | Solide |
| Parallélisation | Non | Non | Oui (SIMD, multi-thread) |
| Adapté à l'intégrité de fichiers | Oui* | Oui | Oui (référence actuelle) |

\* MD5 est suffisant pour détecter la corruption accidentelle mais ne doit plus être utilisé pour des usages sécuritaires.

### Rationale

xxHash3 est techniquement suffisant pour détecter des erreurs accidentelles - pas d'adversaire dans ce cas d'usage. BLAKE3 est retenu pour une seule raison : **coût marginal nul sur disque**. Sur HDD (150 Mo/s) ou SATA SSD (500 Mo/s), le disque est le goulot. BLAKE3 à ~1 Go/s sur un cœur n'est jamais le facteur limitant. Le headroom cryptographique est gratuit.

Si le besoin évolue vers un contexte adversarial (signature, authentification), BLAKE3 reste utilisable sans changer de workflow ni de format de base. Voir `SECURITY.md` pour le modèle de menace.

### Pourquoi ne pas SHA-256 ou SHA-512

- BLAKE3 est ~3–5× plus rapide que SHA-256 sur les mêmes données
- Format de sortie `b3sum` identique à `sha256sum` - interopérabilité conservée
- `b3sum` disponible dans Alpine, Debian, Ubuntu, Homebrew sans compilation

---

## Format du fichier `.b3`

Voir la spécification normative complète : [`docs/spec/b3-format.md`](../spec/b3-format.md).

Résumé des invariants :
- Format natif `b3sum` : `<hash64>  <chemin>` (deux espaces)
- Chemins **relatifs** obligatoires
- Trié par chemin (ordre binaire, LC_ALL=C)
- Pas de ligne vide, pas de commentaire, format Unix (LF)

### Rationale du format natif b3sum

Le format `b3sum` natif est délibérément conservé plutôt qu'un format propriétaire :

- **Interopérabilité directe** : `b3sum --check base.b3` fonctionne sans post-traitement
- **Lisibilité humaine** : `grep`, `awk`, `sort` opèrent directement
- **Zéro parser dédié** : l'offset fixe hash=64 chars + SEP=2 chars est exploité dans `core_compare()` pour parser les lignes sans ambiguïté même avec des espaces dans les chemins :
  ```bash
  awk '{ print substr($0,67) "\t" substr($0,1,64) }' base.b3
  ```

---

## Chemins relatifs - décision fondamentale

Les bases `.b3` stockent des **chemins relatifs**. C'est une contrainte non négociable.

### Rationale

Un chemin absolu `/mnt/veracrypt1/photos/img.jpg` devient invalide si la partition est remontée sur `/mnt/veracrypt2/`. Un chemin relatif `./photos/img.jpg` reste valide quel que soit le point de montage, dès lors que `verify` est lancé depuis le bon répertoire.

`runner.sh` encapsule cette contrainte via `cd "$source"` + `integrity.sh compute . ...` - l'utilisateur n'a pas à y penser.

### Impact sur `verify`

`b3sum --check` résout les chemins relatifs depuis le `pwd`. Avant tout `cd`, `integrity.sh` résout le chemin absolu du fichier `.b3` :

```bash
hashfile_abs="$(cd "$(dirname "$b3file")" && pwd)/$(basename "$b3file")"
# cd vers le répertoire de travail d'origine
cd "$workdir"
# Utilise l'absolu - le relatif serait invalide après le cd
b3sum --check "$hashfile_abs"
```

---

## Isolation des sous-shells dans `runner.sh`

Chaque opération `compute` et `verify` est exécutée dans un sous-shell :

```bash
( cd "$source" && "$INTEGRITY" compute . "$bases_abs/$nom" )
```

Le `cd` est isolé dans `( )` - il ne fuite pas vers les blocs suivants du pipeline.

Pour `RESULTATS_DIR` sur les blocs `compare` avec champ `resultats` :

```bash
RESULTATS_DIR="$resultats_abs" "$INTEGRITY" compare "$base_a" "$base_b"
```

Variable préfixée à la commande - scope limité à cet appel, sans `export`, sans modification du processus parent.

---

## Robustesse aux noms de fichiers avec espaces

Trois points critiques dans l'implémentation :

**1. `find -print0` + `sort -z` + `mapfile -d ''`**

```bash
mapfile -d '' files < <(find "$target" -type f -print0 | sort -z)
```

`find -print0` sépare les chemins par des octets nuls. `sort -z` trie sur le même séparateur. `mapfile -d ''` charge le tableau sans ambiguïté avec des espaces ou des newlines dans les noms.

**2. Séparateur tab dans `core_compare()`**

Après conversion `hash  chemin` → `chemin\thash`, toutes les opérations (`sort`, `join`, `comm`, `cut`) utilisent `-t $'\t'`. Un chemin contenant des espaces ne fragmente pas les champs.

**3. `"$@"` et guillemets systématiques**

Tous les arguments sont propagés entre guillemets doubles. ShellCheck enforce ce point (T00 dans la suite de tests).

---

## Progression ETA - pourquoi casser le pipeline `xargs`

Le pipeline naturel `find | sort | xargs b3sum` est une boîte noire : `b3sum` ne remonte aucune progression.

Intercaler `pv` est invalide : mesurer le débit sur le flux concaténé `cat | pv | b3sum` produit un hash unique du flux, pas une ligne par fichier.

La boucle bash fichier par fichier est la seule approche compatible avec le format `.b3`. Le coût en performance est nul sur HDD (disque = goulot). Sur SSD NVMe avec `-P 4`, la parallélisation `xargs` offrirait +20–40% - mais l'ETA est incompatible avec le parallélisme sans complexité majeure.

### Rationale de l'écriture sur `/dev/tty`

La progression est écrite sur `/dev/tty` directement :

```bash
printf "\r[%d/%d] ETA : %dm %02ds   " ... > /dev/tty
```

`/dev/tty` est le terminal courant, indépendamment des redirections. Garantit que la progression n'est **jamais** capturée dans le fichier `.b3` ni dans un pipe parent.

### Separation via callback

`core_compute()` reçoit un nom de fonction callback au lieu d'appeler directement `ui_progress_callback()`. Ceci permet :
- Tests unitaires de `core_compute()` avec un callback vide ou mock
- Découplage de la logique métier de la logique d'affichage

---

## Rapport HTML - CSS inline

`report.html` est autonome : tout le CSS est inline, aucune dépendance externe.

### Rationale

Le rapport doit être lisible hors ligne, sur un NAS sans accès internet, dans un gestionnaire de fichiers local. Un CDN externe (`fonts.googleapis.com`) serait inaccessible dans ces contextes.

L'import Google Fonts dans le CSS est donc purement décoratif - le fallback `system-ui, sans-serif` fonctionne parfaitement sans réseau.

---

## Horodatage anti-écrasement

`core_make_result_dir()` vérifie l'existence du dossier cible et ajoute un suffixe `_YYYYMMDD-HHMMSS` en cas de collision.

### Rationale

Conserver l'historique complet des vérifications a plus de valeur que d'économiser de l'espace disque. Un résultat écrasé silencieusement est une donnée perdue.

---

## Structure `src/` vs racine

- **`runner.sh` à la racine** : point d'entrée utilisateur, visible directement
- **`src/`** : code interne non destiné à être appelé directement dans le cas général
- **`src/lib/`** : modules internes sourcés par `integrity.sh`. La structure prépare l'extension : `notify.sh`, `export.sh`, etc.

---

## Validation JSON dans `runner.sh`

```bash
jq empty "$CONFIG" 2>/dev/null || { echo "ERREUR : JSON invalide : $CONFIG" >&2; exit 1; }
```

`jq empty` parse le JSON sans produire de sortie. L'erreur brute de `jq` est redirigée vers `/dev/null` ; le message d'erreur est celui de `runner.sh`, pas une stacktrace interne de `jq`.

---

## Dépendances externes - décisions

| Outil | Alternatif envisagé | Raison du choix |
|---|---|---|
| `b3sum` | `sha256sum`, `xxhash` | BLAKE3, performance, format compatible |
| `jq` | parser bash custom | Validation JSON native, robustesse, maintenabilité |
| Alpine 3.19 (Docker) | Ubuntu, Debian slim | ~14 Mo vs ~80 Mo, `b3sum` disponible dans community |
| `bash >= 4` | `sh`, `dash` | `mapfile`, tableaux, `BASH_VERSINFO` |


--- Fichier : docs/development/changelog.md ---
# Changelog - hash_tool / integrity.sh

## [0.15] - Documentation restructurée

maj de la doc 

## [0.14] - Documentation restructurée

### Ajouté
- `docs/` : documentation complète au format MkDocs Material.
  - `index.md` : page d'accueil, vue d'ensemble, structure du projet.
  - `getting-started.md` : installation, prérequis, premier usage pas à pas.
  - `reference/integrity-sh.md` : référence exhaustive - modes, arguments, variables, exit codes, limites.
  - `reference/runner-sh.md` : schéma complet pipeline.json, comportements, messages d'erreur.
  - `reference/docker.md` : build, volumes, Compose, cron, Synology, ARM64.
  - `guides/veracrypt.md` : workflow multi-disques, lanceur Windows `.bat`.
  - `guides/cron-ci.md` : cron Linux, GitHub Actions, GitLab CI, hooks Git, patterns de notification.
  - `guides/nas-synology.md` : DSM 7, Container Manager, planificateur de tâches.
  - `development/architecture.md` : décisions techniques documentées (BLAKE3, chemins relatifs, ETA, CSS inline, etc.).
  - `development/contributing.md` : couverture tests, conventions, processus de release.
  - `development/changelog.md` : historique reformaté Keep a Changelog.
- `mkdocs.yml` : configuration MkDocs Material, navigation, extensions pymdownx, thème sombre/clair.
- `CONTRIBUTING.md` : guide de contribution à la racine du projet.
- README-docker.md : readme juste pour docker. 
- README-docs.md : readme juste pour la documentation. 
- README-tests.md : readme juste pour les tests. 

### Supprimé
- `docs/*.docx`, `docs/*.pdf` : binaires non diffables retirés du repo. Générer depuis le markdown via `pandoc` si nécessaire.
- `temp.txt` : ajouté au `.gitignore`.

### Modifié
- `pipelines/pipeline full.json` → `pipelines/pipeline-full.json` : suppression de l'espace dans le nom de fichier.

## [0.13] - Débug de la dockerisation et documentation 

### Ajouté

- `hash_tool-positionnement-open-source.docx` : positionnement du projet dans l'environnement open source actuel, preuve de valeur du projet.
- `hash_tool-presentation.docx` : présentation macro du projet, sans rentrer dans les details de l'implémentation. 

### Modifié

- Modification du `Dockerfile` pour debug : Installer b3sum depuis Alpine community. b3sum est disponible dans les packages Alpine Linux Alpine Linux, ce qui est plus propre et évite le wget GitHub. Plus de multi-stage, plus de wget, plus de problème de nom. La version fournie par Alpine 3.19 est stable et maintenue. C'est la solution la plus robuste.


## [0.12] - Dockerisation

### Ajouté

- `Dockerfile` : image multi-stage basée sur Alpine 3.19.
  - Stage `fetcher` : télécharge le binaire officiel `b3sum` musl depuis GitHub Releases, le vérifie (auto-vérification via `b3sum --check`). Supporte `amd64`, `arm64`, `armv7`.
  - Stage final : Alpine + `bash` + `jq` + `coreutils` + `findutils` + binaire `b3sum` copié. Image finale ~14 Mo sans toolchain Rust.
  - `ARG B3SUM_VERSION` : version b3sum paramétrable au build.

- `docker/entrypoint.sh` : dispatcher des commandes.
  - `compute`, `verify`, `compare` → délégués à `src/integrity.sh`.
  - `runner [pipeline.json]` → délégué à `runner.sh` (défaut : `/pipelines/pipeline.json`).
  - `shell` / `bash` → shell interactif debug.
  - `help`, `version` → affichage inline.
  - `--quiet` supporté en premier argument.

- `docker-compose.yml` : trois services.
  - `integrity` : commandes ponctuelles (compute/verify/compare).
  - `pipeline` : exécution de `runner.sh` avec `pipeline.json` monté.
  - `cron` : profil optionnel (`--profile cron`) pour vérification périodique.
  - Section `x-volumes` : chemins à adapter en un seul endroit.

- `.dockerignore` : exclut données, résultats, tests, docs du contexte de build.

- `docs/docker.md` : guide complet - build, commandes, volumes, NAS Synology, cron Debian, taille image, mise à jour b3sum.

### Volumes conventionnels

| Volume conteneur | Usage |
|---|---|
| `/data` | Données à hacher (`:ro` recommandé) |
| `/bases` | Fichiers `.b3` |
| `/pipelines` | Fichiers `pipeline.json` |
| `/resultats` | Résultats compare/verify |

`RESULTATS_DIR=/resultats` est défini par défaut dans l'image.

---

 - Restructuration + rapport HTML compare

### Restructuration du projet

```
hash_tool/
├== runner.sh                  ← inchangé (point d'entrée)
├== src/
│   ├== integrity.sh           ← déplacé depuis la racine
│   └== lib/
│       └== report.sh          ← nouveau, extrait de integrity.sh
├== pipelines/
│   ├== pipeline.json          ← déplacé depuis la racine
│   └== pipeline-full.json     ← renommé depuis "pipeline full.json"
└== reports/
    └== template.html          ← nouveau, barebone HTML de référence
```

Motivations :
- `src/` isole le code des fichiers de configuration et de données.
- `src/lib/` prépare l'extension à d'autres modules (ex. `notify.sh`, `export.sh`).
- `pipelines/` centralise les configurations de pipeline, évite la pollution de la racine.
- `reports/` documente la structure HTML attendue, sert de référence pour la personnalisation.

### Modifié

- `runner.sh`
  - Chemin `INTEGRITY` mis à jour : `$SCRIPT_DIR/src/integrity.sh`.
  - Chemin `CONFIG` par défaut mis à jour : `$SCRIPT_DIR/pipelines/pipeline.json`.
  - `run_compare()` : lecture du champ optionnel `resultats` dans le bloc JSON. Si présent, exporte `RESULTATS_DIR` avec cette valeur pour le seul appel à `integrity.sh compare`. Isolation par sous-shell : le `RESULTATS_DIR` global du processus parent n'est pas modifié.
  - `run_compute()` et `run_verify()` : isolation du `cd` dans un sous-shell `( )` - le répertoire courant ne fuite plus vers les blocs suivants du pipeline.

- `src/integrity.sh`
  - Chargement de `src/lib/report.sh` via `source` au démarrage.
  - `run_compare()` : délègue la génération HTML à `generate_compare_html()` (définie dans `lib/report.sh`).

### Ajouté

- `src/lib/report.sh` : bibliothèque de génération de rapports.
  - `generate_compare_html()` : produit `report.html` autonome (CSS inline, sans dépendance externe) à partir des fichiers `modifies.b3`, `disparus.txt`, `nouveaux.txt`. Thème sombre, police monospace, compteurs par catégorie, badge statut IDENTIQUES / DIFFÉRENCES DÉTECTÉES.

- `reports/template.html` : barebone HTML statique de référence. Documente les placeholders injectés par `generate_compare_html()` et la structure attendue du dossier de résultats.

- `pipeline.json` (et `pipeline-full.json`) : champ optionnel `"resultats"` sur les blocs `compare`.

  ```json
  {
      "op":       "compare",
      "base_a":   "/chemin/hashes_1.b3",
      "base_b":   "/chemin/hashes_2.b3",
      "resultats": "/chemin/vers/dossier_resultats"
  }
  ```

  Sans ce champ, comportement inchangé : résultats dans `RESULTATS_DIR` (défaut `~/integrity_resultats`).

- `tests/run_tests_pipeline.sh` : cas TP10b - vérifie que le champ `resultats` redirige bien les résultats dans le dossier personnalisé et n'écrit rien dans `RESULTATS_DIR` par défaut.

### Couverture tests mise à jour

| Suite | Cas | Description |
|---|---|---|
| `run_tests.sh` | T00–T14 | Inchangée - `INTEGRITY` mis à jour vers `../src/integrity.sh` |
| `run_tests_pipeline.sh` | TP01–TP12 | Inchangée dans la logique |
| `run_tests_pipeline.sh` | **TP10b** | Nouveau - champ `resultats` personnalisé et isolation |

---


## [0.11] - Restructuration + rapport HTML compare

### Restructuration du projet

```
hash_tool/
├== runner.sh                  ← inchangé (point d'entrée)
├== src/
│   ├== integrity.sh           ← déplacé depuis la racine
│   └== lib/
│       └== report.sh          ← nouveau, extrait de integrity.sh
├== pipelines/
│   ├== pipeline.json          ← déplacé depuis la racine
│   └== pipeline-full.json     ← renommé depuis "pipeline full.json"
└== reports/
    └== template.html          ← nouveau, barebone HTML de référence
```

Motivations :
- `src/` isole le code des fichiers de configuration et de données.
- `src/lib/` prépare l'extension à d'autres modules (ex. `notify.sh`, `export.sh`).
- `pipelines/` centralise les configurations de pipeline, évite la pollution de la racine.
- `reports/` documente la structure HTML attendue, sert de référence pour la personnalisation.

### Modifié

- `runner.sh`
  - Chemin `INTEGRITY` mis à jour : `$SCRIPT_DIR/src/integrity.sh`.
  - Chemin `CONFIG` par défaut mis à jour : `$SCRIPT_DIR/pipelines/pipeline.json`.
  - `run_compare()` : lecture du champ optionnel `resultats` dans le bloc JSON. Si présent, exporte `RESULTATS_DIR` avec cette valeur pour le seul appel à `integrity.sh compare`. Isolation par sous-shell : le `RESULTATS_DIR` global du processus parent n'est pas modifié.
  - `run_compute()` et `run_verify()` : isolation du `cd` dans un sous-shell `( )` - le répertoire courant ne fuite plus vers les blocs suivants du pipeline.

- `src/integrity.sh`
  - Chargement de `src/lib/report.sh` via `source` au démarrage.
  - `run_compare()` : délègue la génération HTML à `generate_compare_html()` (définie dans `lib/report.sh`).

### Ajouté

- `src/lib/report.sh` : bibliothèque de génération de rapports.
  - `generate_compare_html()` : produit `report.html` autonome (CSS inline, sans dépendance externe) à partir des fichiers `modifies.b3`, `disparus.txt`, `nouveaux.txt`. Thème sombre, police monospace, compteurs par catégorie, badge statut IDENTIQUES / DIFFÉRENCES DÉTECTÉES.

- `reports/template.html` : barebone HTML statique de référence. Documente les placeholders injectés par `generate_compare_html()` et la structure attendue du dossier de résultats.

- `pipeline.json` (et `pipeline-full.json`) : champ optionnel `"resultats"` sur les blocs `compare`.

  ```json
  {
      "op":       "compare",
      "base_a":   "/chemin/hashes_1.b3",
      "base_b":   "/chemin/hashes_2.b3",
      "resultats": "/chemin/vers/dossier_resultats"
  }
  ```

  Sans ce champ, comportement inchangé : résultats dans `RESULTATS_DIR` (défaut `~/integrity_resultats`).

- `tests/run_tests_pipeline.sh` : cas TP10b - vérifie que le champ `resultats` redirige bien les résultats dans le dossier personnalisé et n'écrit rien dans `RESULTATS_DIR` par défaut.

### Couverture tests mise à jour

| Suite | Cas | Description |
|---|---|---|
| `run_tests.sh` | T00–T14 | Inchangée - `INTEGRITY` mis à jour vers `../src/integrity.sh` |
| `run_tests_pipeline.sh` | TP01–TP12 | Inchangée dans la logique |
| `run_tests_pipeline.sh` | **TP10b** | Nouveau - champ `resultats` personnalisé et isolation |

---



## [0.10] - Pipeline JSON + tests pipeline

### Modifié

- `pipeline.json` (ex `config.txt`) : format migré de la syntaxe custom vers JSON standard. Champ `op` remplace les noms de blocs. Parsé par `jq` - validation syntaxique native, interopérable avec tout outil JSON.
- `runner.sh` : réécriture du parser. Suppression du parser bash custom (`IFS`, regex, `local -n`). Remplacement par `jq` pour l'extraction des champs. Validation JSON en entrée (`jq empty`), détection des champs manquants et des opérations inconnues avec messages d'erreur explicites incluant le numéro de bloc.

### Ajouté

- `tests/run_tests_pipeline.sh` : suite de tests dédiée au pipeline. 12 cas TP01–TP12.

### Format pipeline.json

```json
{
    "pipeline": [
        {
            "op":     "compute",
            "source": "/mnt/a/dossier",
            "bases":  "/mnt/c/bases",
            "nom":    "hashes.b3"
        },
        {
            "op":     "verify",
            "source": "/mnt/a/dossier",
            "base":   "/mnt/c/bases/hashes.b3"
        },
        {
            "op":     "compare",
            "base_a": "/mnt/c/bases/hashes_1.b3",
            "base_b": "/mnt/c/bases/hashes_2.b3"
        }
    ]
}
```

### Couverture run_tests_pipeline.sh

| Cas | Description |
|---|---|
| TP01 | JSON invalide - erreur propre sans stacktrace jq |
| TP02 | Clé `.pipeline` absente |
| TP03 | Champ manquant dans un bloc (`nom`) |
| TP04 | Opération inconnue |
| TP05 | Compute - cd correct, chemins relatifs dans la base, comptage fichiers |
| TP06 | Compute - dossier source absent |
| TP07 | Verify - bon répertoire de travail, OK détecté |
| TP08 | Verify - corruption détectée |
| TP09 | Verify - base .b3 absente |
| TP10 | Compare - fichiers de résultats produits |
| TP11 | Compare - base_a absente |
| TP12 | Pipeline complet compute + verify + compare |

---


## [0.9] - Pipeline batch : runner.sh + config.txt

### Ajouté

- `runner.sh` : exécuteur de pipeline batch. Lit `config.txt`, parse les blocs `compute`, `verify`, `compare` et appelle `integrity.sh` avec les arguments corrects. Gère le `cd` automatique avant chaque `compute` et `verify` pour garantir des chemins relatifs dans les bases `.b3`.
- `config.txt` : déclaration du pipeline au format structuré `pipeline = { ... }`. Chaque opération est un bloc nommé avec des champs `clé = "valeur"`. Supporte les commentaires `#` et les lignes vides.
- `runner.bat` : lanceur Windows pour double-clic depuis le bureau. Appelle `runner.sh` via WSL. Paramètre `pause` final pour garder la fenêtre ouverte.

### Format config.txt

```
pipeline = {

    compute {
        source = "/mnt/a/dossier",
        bases  = "/mnt/c/bases",
        nom    = "hashes.b3"
    }

    verify {
        source = "/mnt/a/dossier",
        base   = "/mnt/c/bases/hashes.b3"
    }

    compare {
        base_a = "/mnt/c/bases/hashes_1.b3",
        base_b = "/mnt/c/bases/hashes_2.b3"
    }

}
```

### Comportement runner.sh

- `compute` : `cd` dans `source`, puis `integrity.sh compute . bases/nom` - chemin relatif garanti.
- `verify` : `cd` dans `source`, puis `integrity.sh verify base` - répertoire de travail correct.
- `compare` : appel direct `integrity.sh compare base_a base_b`.
- Crée `bases/` automatiquement si inexistant (`mkdir -p`).
- `set -e` : arrêt immédiat sur toute erreur.

---

## [0.8] - Fonctionnalité batch_compute.sh

### Ajouté

- `batch_compute.sh` : permet de lancer plusieurs commandes `compute` avec un seul script. Remplacé par `runner.sh` + `config.txt` dans la version 0.9.


---

## [0.7] - Robustesse compare : chemins avec espaces

### Corrigé
- `integrity.sh`
  - Bug critique dans `run_compare()` : `sort -k2,2`, `join -1 2 -2 2` et `awk '{print $2}'` utilisent le blanc comme séparateur de champ. Un chemin contenant des espaces est fragmenté en plusieurs champs, ce qui corrompt le tri, le join et l'extraction - produisant des faux positifs massifs (ex. 26569 modifiés pour 163 fichiers dont 1 seul a changé).
  - Correction : conversion préalable de chaque ligne en `chemin\thash` via `awk '{ print substr($0,67) "\t" substr($0,1,64) }'` - le hash b3sum étant toujours exactement 64 caractères, l'offset 67 est garanti par le format. Toutes les opérations suivantes utilisent `-t $'\t'` comme séparateur explicite : `sort -t $'\t' -k1,1`, `join -t $'\t' -1 1 -2 1`, `cut -f1`.
  - `modifies.b3` : format de sortie préservé (`hash  chemin`) via `awk -F $'\t' '$2 != $3 { print $3 "  " $1 }'`.

## [0.6] - Robustesse et mode silencieux

### Ajouté
- `integrity.sh`
  - Flag `--quiet` : supprime toute sortie terminal, écrit uniquement dans les fichiers de résultats (`recap.txt`, `failed.txt`). Exit code propagé pour usage CI/cron.
  - Fonction `say()` : point d'entrée unique pour toute sortie terminal, désactivée si `--quiet`.
  - Fonction `file_size()` : abstraction portable `stat -c%s` (GNU/Linux) / `stat -f%z` (BSD/macOS).
  - Vérification version bash en tête de script : `bash >= 4` requis, exit explicite avec message si non respecté.
  - `make_result_dir()` : horodatage automatique des dossiers de résultats en cas de collision (`_YYYYMMDD-HHMMSS`), plus d'écrasement silencieux.
  - `trap EXIT` dans `run_compare()` : nettoyage garanti des fichiers temporaires même en cas d'erreur intermédiaire.
  - Redirection ETA sur `/dev/tty` dans `compute_with_progress()` : garantit que la progression n'est jamais écrite dans le fichier `.b3`.
- `tests/run_tests.sh`
  - `set -euo pipefail` : mode strict complet activé (ajout de `-e`).
  - Fonction `assert_file_absent()` : helper dédié pour les assertions d'absence de fichier.
  - T00 : ShellCheck sur `integrity.sh` et `run_tests.sh` (SKIP propre si non installé).
  - T12 : couverture exhaustive du mode `--quiet` (stdout vide, fichiers produits, exit code propagé).
  - T13 : vérifie l'horodatage automatique des dossiers de résultats sur collision.
  - T14 : détection d'un argument `[dossier]` invalide pour `verify`.
- `README.md`
  - Section `--quiet` avec exemples CI/cron.
  - Section Tests avec instructions d'exécution et comptage des cas (14 tests).
  - Mention horodatage automatique dans l'arborescence des résultats.

### Modifié
- `integrity.sh`
  - `assert_target_valid()` : `find -print0 | grep -zc ''` au lieu de `find | wc -l` - robuste aux noms de fichiers contenant des newlines.
  - `run_verify()` : comptage de lignes via `grep -c '^'` au lieu de `grep -c '.'` - correction du bug de comptage sur flux vide.
  - `run_compare()` : `sort -k2,2` au lieu de `sort -k2` - clé de tri limitée strictement au champ chemin, sans déborder sur le hash.
  - `run_verify()` : propagation de l'exit code de `b3sum --check` via `return $exit_code` - utilisable en scripting avec `|| alert`.
  - `failed.txt` : suppression explicite via `rm -f` si `nb_failed == 0` après une vérification OK suivant un échec précédent.
- `tests/run_tests.sh`
  - Résolution dynamique des `outdir` via `ls -d ... | tail -1` : compatible avec l'horodatage des dossiers de résultats.
  - T02, T03, T05, T06, T07 : assertions adaptées à la résolution dynamique des dossiers.
- `README.md`
  - Dépendances : mention explicite de `bash >= 4`.
  - Usage : exemple `--quiet` ajouté.

### Corrigé
- `integrity.sh`
  - Bug comptage lignes dans `run_verify()` : `grep -c '.'` sur flux vide retournait 0 mais ne capturait pas correctement les lignes non vides. Remplacé par `grep -c '^'`.
  - Bug tri ambigü dans `run_compare()` : `sort -k2` triait du champ 2 à la fin de ligne, incluant potentiellement le hash. `sort -k2,2` limite la clé au seul champ 2.
  - Bug nettoyage tmpfiles : `run_compare()` laissait des fichiers temporaires en cas d'erreur intermédiaire. Ajout de `trap 'rm -f ...' EXIT`.
  - Bug portabilité `stat` : `stat -c%s` est GNU-only. Ajout de `file_size()` avec fallback BSD `stat -f%z`.
  - Bug comptage fichiers avec newlines : `assert_target_valid()` utilisait `find | wc -l`. Corrigé avec `find -print0 | grep -zc ''`.
- `tests/run_tests.sh`
  - T10 : pattern `"^/"` remplacé par `"  /"` - `grep` opérait sur une chaîne, l'ancre `^` ne matchait pas la deuxième colonne.

---

## [0.5] - Documentation

### Modifié
- `README.md` - règle répertoire de travail pour `verify` précisée : l'argument `[dossier]` est le répertoire d'origine du compute, pas le dossier haché. Exemples correct/incorrect ajoutés.
- `docs/manuel.md` - section `verify` mise à jour avec le même avertissement et les exemples.

---

## [0.4] - Gardes-fous et signalisation des erreurs

### Modifié
- `integrity.sh`
  - Ajout de `die()` : point de sortie unique pour toutes les erreurs, message sur stderr.
  - Ajout de `assert_b3_valid()` : vérifie existence, type fichier, non-vide, format b3sum valide.
  - Ajout de `assert_target_valid()` : vérifie existence du dossier cible et présence d'au moins un fichier.
  - Validation explicite des arguments dans chaque branche du `case` avant tout traitement.
  - `verify` accepte un argument optionnel `[dossier]` : fait `cd` avant `b3sum --check`.
  - Résolution du chemin absolu du `.b3` avant `cd` (correction bug : chemin relatif invalide après changement de répertoire).
  - `RESULTATS_DIR` : `${RESULTATS_DIR:-...}` au lieu d'assignation inconditionnelle - respecte la valeur exportée par l'environnement (fix tests).
  - Suppression de `local hashfile_abs` hors fonction (illégal en bash hors contexte fonction).
  - `run_verify()` : refonte de la signalisation.
    - Trois états distincts : `OK`, `ECHEC`, `ERREUR`.
    - Terminal : affichage sobre si OK, bloc `████` visible si échec ou erreur.
    - `recap.txt` : compteur `FAILED` affiché uniquement si > 0 ; section erreurs b3sum séparée.
    - `failed.txt` : créé uniquement si `nb_failed > 0` ou erreurs b3sum présentes. Supprimé si tout est OK.
- `tests/run_tests.sh`
  - T02 : assertion `failed.txt absent si 0 échec` (logique inversée par rapport à l'ancienne version).
  - T03 : patterns mis à jour (`ECHEC`, `FAILED`) alignés sur le nouveau format de sortie.

---

## [0.3] - Dossiers de résultats (verify et compare)

### Modifié
- `integrity.sh`
  - Ajout de `RESULTATS_DIR` (configurable, défaut `~/integrity_resultats`).
  - Ajout de `make_result_dir()` : crée `resultats_<nom_base>/` sous `RESULTATS_DIR`.
  - `verify` : délègue à `run_verify()` - produit `recap.txt` et `failed.txt`.
  - `compare` : délègue à `run_compare()` - produit `recap.txt`, `modifies.b3`, `disparus.txt`, `nouveaux.txt`.
  - Fichiers temporaires de `compare` passent par `mktemp` (plus de `/tmp/_old.b3` en dur).
  - Signature `verify` simplifiée : `<base.b3>` uniquement (le dossier n'était pas utilisé par `b3sum --check`).
- `README.md` - usage `verify` et `compare` mis à jour ; section Configuration ajoutée avec arbre des fichiers produits.
- `docs/manuel.md` - sections `verify` et `compare` mises à jour ; arbre de décision et référence rapide alignés.
- `tests/run_tests.sh`
  - `RESULTATS_DIR` exporté vers `WORKDIR` pour isoler les résultats des tests.
  - Ajout de `assert_file_exists()`.
  - T02–T07 : assertions sur la présence et le contenu des fichiers de résultats.

---

## [0.2] - Intégration ETA et tests automatisés

### Modifié
- `integrity.sh`
  - Suppression de `detect_parallelism()` et de la logique SSD/parallélisme (hors périmètre HDD gros volumes).
  - Mode `compute` : délègue à `compute_with_progress()`.
  - Ajout de `compute_with_progress()` : boucle fichier par fichier avec affichage progression et ETA.
    - `mapfile -d ''` remplace `FILES=($(find ...))` - gestion correcte des noms avec espaces.
    - `printf "\r%*s\r"` efface proprement la ligne de progression avant le message final.
  - `df` retiré des dépendances.
- `README.md` - dépendances mises à jour (`df` supprimé, `stat` et `du` ajoutés).
- `docs/manuel.md`
  - Section `detect_parallelism` supprimée.
  - Section `compute` réécrite autour de `compute_with_progress`.
  - Section performances : stratégie SSD/NVMe retirée, focus HDD séquentiel.
- `docs/progression-eta.md` - implémentation finale documentée ; note `mapfile -d ''` vs substitution de commande.
- `tests/run_tests.sh` - T11 ajouté : vérifie que la base produite par `compute_with_progress` est bit-à-bit identique à une base de référence, sans artefact ETA ni `\r`.
- `docs/explication-run-tests.md` - comptage corrigé (10 → 11 cas) ; section T11 ajoutée.

### Corrigé
- `tests/run_tests.sh` T10 : pattern `"^/"` remplacé par `"  /"` - `grep` opère sur une chaîne, pas un fichier, l'ancre `^` ne matchait pas la deuxième colonne.

---

## [0.1] - Structure initiale du projet

### Ajouté
- `integrity.sh` - script principal BLAKE3 avec trois modes : `compute`, `verify`, `compare`.
  - `set -euo pipefail` - mode strict.
  - `detect_parallelism()` - détection SSD/HDD via `/sys/block/.../queue/rotational`.
  - Mode `compute` : pipeline `find | sort -z | xargs b3sum`, parallélisme `-P 4` sur SSD.
  - Mode `verify` : délègue à `b3sum --check`.
  - Mode `compare` : tri sur colonne 2, `join` pour les modifiés, `comm` pour disparus/nouveaux, rapport `tee`.
- `README.md` - point d'entrée : dépendances, usage en 3 commandes, arbre de décision, règles critiques.
- `docs/manuel.md` - référence technique complète : algorithmes, structure `.b3`, workflow, explication du script, performances, limites, référence rapide, annexe FIM.
- `docs/progression-eta.md` - analyse du problème ETA sur pipeline `xargs`, deux approches (`pv` invalide, boucle bash), mécanique de l'estimation, tableau de comparaison des performances.
- `docs/explication-run-tests.md` - documentation du code `run_tests.sh` : chemins, compteurs, assertions, setup/teardown, structure d'un cas de test, prérequis, exit code CI.
- `tests/run_tests.sh` - suite de tests automatisée bash pur, 11 cas T01–T11, isolation via `mktemp`, teardown systématique, exit code CI-compatible.
- `tests/validation.md` - protocole de test manuel : 10 cas T01–T10 avec commandes exactes et résultats attendus, critères de qualité globaux.


--- Fichier : docs/development/contributing.md ---
# Contribuer à hash_tool

---

## Prérequis

```bash
sudo apt install bash b3sum jq shellcheck
```

---

## Tests

```bash
cd tests && ./run_tests.sh
cd tests && ./run_tests_pipeline.sh
```

Zéro warning ShellCheck requis (T00). Tous les tests doivent passer avant soumission.

---

## Conventions de code

### Séparation des responsabilités

Le code est organisé en modules avec des responsabilités strictement séparées. Avant d'écrire du code, identifier dans quel module il appartient :

- **Logique métier** (hachage, vérification, comparaison) → `src/lib/core.sh`
- **Affichage terminal, progression** → `src/lib/ui.sh`
- **Écriture fichiers de résultats** → `src/lib/results.sh`
- **Génération HTML** → `src/lib/report.sh`
- **Orchestration CLI** → `src/integrity.sh`

Ne jamais écrire de sortie terminal dans `core.sh`. Ne jamais écrire de logique métier dans `ui.sh`.

### Contrats de fonction

Toute fonction non triviale doit documenter :
- Les entrées (`$1`, `$2`...)
- Les sorties (exit code, variables positionnées, fichiers créés)
- Les effets de bord
- Les invariants supposés et garantis

Voir `src/lib/core.sh` comme référence de format.

### Conventions bash

- `set -euo pipefail` dans tout script exécutable
- `"$@"` et guillemets systématiques - ShellCheck enforce ce point
- `local` pour toutes les variables de fonction
- `mktemp` pour les fichiers temporaires, nettoyés via `trap EXIT`
- Pas de `ls` dans les scripts - utiliser `find` ou glob

---

## Format des commits

Convention : [Conventional Commits](https://www.conventionalcommits.org/)

```
<type>(<scope>): <description courte>

[corps optionnel]

[footer optionnel]
```

Types :

| Type | Usage |
|---|---|
| `feat` | Nouvelle fonctionnalité |
| `fix` | Correction de bug |
| `refactor` | Refactoring sans changement de comportement |
| `test` | Ajout ou modification de tests |
| `docs` | Documentation uniquement |
| `chore` | Tâches de maintenance (CI, dépendances, etc.) |
| `perf` | Amélioration de performance |

Exemples :

```
feat(core): ajouter support des liens symboliques dans core_compute
fix(ui): corriger l'effacement de la ligne ETA sur terminal étroit
docs(spec): documenter le cas des fichiers de taille zéro dans b3-format.md
test(core): ajouter T15 - vérification comportement sur lien symbolique
```

## Philosophie de test

- Chaque test crée son propre répertoire temporaire isolé dans `/tmp` - pas d'effet de bord entre cas
- Les tests de corruption introduisent volontairement une modification puis vérifient la détection
- Les tests pipeline vérifient l'isolation des sous-shells (pas de fuite de répertoire courant entre blocs)
- Résultat coloré `PASS` / `FAIL` avec compteur final

## Contributions prioritaires

Par ordre de valeur décroissante :

- **GitHub Actions** - CI automatique sur push : `run_tests.sh` + `run_tests_pipeline.sh` + ShellCheck
- **`install.sh`** - script d'installation one-liner avec vérification des dépendances (`b3sum`, `jq`, `bash >= 4`)
- **`--format json`** - sortie machine-readable pour `verify` et `compare` (aujourd'hui : texte uniquement)
- **Rapport HTML** - enrichissement du contenu et de la mise en page

---

## Processus de release

1. **Vérifier que tous les tests passent** sur une machine propre
   ```bash
   cd tests && ./run_tests.sh && ./run_tests_pipeline.sh
   shellcheck src/integrity.sh runner.sh src/lib/*.sh docker/entrypoint.sh
   ```

2. **Mettre à jour `CHANGELOG.md`** avec la nouvelle version et les changements

3. **Mettre à jour la variable `VERSION`** dans `src/integrity.sh` et `runner.sh`

4. **Créer le tag git**
   ```bash
   git tag -a v0.15 -m "Release v0.15 - <description courte>"
   git push origin v0.15
   ```

5. **Créer la GitHub Release** avec le contenu du CHANGELOG correspondant et les checksums :
   ```bash
   b3sum src/integrity.sh runner.sh src/lib/*.sh
   ```

---

## Structure des tests

Les tests sont dans `tests/`. Deux suites indépendantes :

| Suite | Scope | Cas |
|---|---|---|
| `run_tests.sh` | `integrity.sh` | T00–T14 |
| `run_tests_pipeline.sh` | `runner.sh` + `pipeline.json` | TP01–TP12b |

### Ajouter un test

1. Identifier la suite concernée
2. Nommer le cas (T15, T16... ou TP13, TP14...)
3. Documenter : précondition, oracle de test (résultat attendu), postcondition
4. Le test doit être reproductible sur n'importe quelle machine disposant des prérequis
5. Le test ne doit pas dépendre de l'état du système hôte (pas de `/home/user/...`, pas de fichiers extérieurs au `WORKDIR`)

Voir `tests/run_tests.sh` pour la structure standard d'un cas de test.


--- Fichier : docs/guides/cron-ci.md ---
# Guide - CI / Cron

Intégration de hash_tool dans des pipelines automatisés : cron Linux, CI/CD, hooks Git.

---

## Mode `--quiet`

Toutes les commandes acceptent `--quiet` en premier argument. Ce flag :

- Supprime **toute** sortie terminal (stdout et stderr de `integrity.sh`)
- Conserve l'**exit code** : `0` = OK, `1` = ECHEC ou ERREUR
- Continue d'écrire les fichiers de résultats (`recap.txt`, `failed.txt`, `report.html`)

C'est le mode à utiliser systématiquement en automatisation - le script parent ou le système de notification gère la sortie.

```bash
./src/integrity.sh --quiet verify hashes.b3
echo "Exit code : $?"
```

---

## Cron Linux

### Vérification nocturne simple

```cron
# /etc/cron.d/hash-integrity
# Vérification à 03h00 chaque nuit
0 3 * * * user /opt/hash_tool/src/integrity.sh --quiet verify \
    /opt/bases/hashes.b3 /srv/data \
    >> /var/log/hash-integrity.log 2>&1 \
    || echo "$(date) - ALERTE intégrité" | mail -s "Alerte $(hostname)" admin@example.com
```

### Avec pipeline complet

```cron
# Recalcul hebdomadaire + comparaison (dimanche 02h00)
0 2 * * 0 user /opt/hash_tool/runner.sh /opt/hash_tool/pipelines/pipeline-weekly.json \
    >> /var/log/hash-integrity-weekly.log 2>&1 \
    || mail -s "ECHEC pipeline intégrité $(hostname)" admin@example.com
```

### Rotation des logs

```bash
# /etc/logrotate.d/hash-integrity
/var/log/hash-integrity.log {
    weekly
    rotate 52
    compress
    missingok
    notifempty
}
```

---

## Cron via Docker

```cron
0 3 * * * root \
    docker run --rm \
      -v /srv/data:/data:ro \
      -v /srv/bases:/bases:ro \
      -v /srv/resultats:/resultats \
      hash_tool --quiet verify /bases/hashes.b3 /data \
    >> /var/log/hash-integrity.log 2>&1 \
    || mail -s "ALERTE intégrité $(hostname)" admin@example.com
```

---

## Intégration CI/CD

### GitHub Actions

```yaml
# .github/workflows/integrity-check.yml
name: Vérification intégrité

on:
  schedule:
    - cron: '0 3 * * *'   # 03h00 UTC chaque nuit
  workflow_dispatch:        # déclenchement manuel possible

jobs:
  verify:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Installer b3sum
        run: sudo apt-get install -y b3sum

      - name: Vérifier l'intégrité
        run: |
          ./src/integrity.sh --quiet verify bases/hashes.b3
        env:
          RESULTATS_DIR: /tmp/integrity-results

      - name: Uploader les résultats
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: integrity-results
          path: /tmp/integrity-results/
          retention-days: 30
```

### GitLab CI

```yaml
# .gitlab-ci.yml
integrity-verify:
  stage: verify
  image: alpine:3.19
  before_script:
    - apk add --no-cache bash b3sum
  script:
    - ./src/integrity.sh --quiet verify bases/hashes.b3
  artifacts:
    when: always
    paths:
      - integrity-results/
    expire_in: 30 days
  variables:
    RESULTATS_DIR: integrity-results
  rules:
    - if: $CI_PIPELINE_SOURCE == "schedule"
```

### Hook Git pre-commit

Vérifier l'intégrité d'un dossier avant chaque commit :

```bash
#!/usr/bin/env bash
# .git/hooks/pre-commit
set -euo pipefail

BASES_DIR="$(git rev-parse --show-toplevel)/bases"
DATA_DIR="$(git rev-parse --show-toplevel)/data"

if [ -f "$BASES_DIR/hashes.b3" ]; then
    echo "Vérification intégrité..."
    ./src/integrity.sh --quiet verify "$BASES_DIR/hashes.b3" "$DATA_DIR" || {
        echo "ERREUR : corruption détectée. Commit annulé."
        echo "Consulter : $BASES_DIR/resultats/"
        exit 1
    }
    echo "Intégrité OK."
fi
```

```bash
chmod +x .git/hooks/pre-commit
```

---

## Patterns de notification

### Email via `mail`

```bash
./src/integrity.sh --quiet verify hashes.b3 || \
    mail -s "ALERTE intégrité $(hostname)" admin@example.com < \
    "$(ls -d ~/integrity_resultats/resultats_hashes* | tail -1)/recap.txt"
```

### Slack webhook

```bash
#!/usr/bin/env bash
WEBHOOK_URL="https://hooks.slack.com/services/..."

./src/integrity.sh --quiet verify hashes.b3
EXIT=$?

if [ $EXIT -ne 0 ]; then
    RECAP=$(cat "$(ls -d ~/integrity_resultats/resultats_hashes* | tail -1)/recap.txt")
    curl -s -X POST "$WEBHOOK_URL" \
        -H 'Content-type: application/json' \
        --data "{\"text\":\"🚨 *Alerte intégrité* sur \`$(hostname)\`\n\`\`\`${RECAP}\`\`\`\"}"
fi

exit $EXIT
```

### Fichier de statut pour monitoring

```bash
#!/usr/bin/env bash
STATUS_FILE=/var/lib/hash-integrity/last-status

./src/integrity.sh --quiet verify hashes.b3
EXIT=$?

mkdir -p "$(dirname "$STATUS_FILE")"
{
    echo "date=$(date -Iseconds)"
    echo "status=$([ $EXIT -eq 0 ] && echo OK || echo FAILED)"
    echo "exit_code=$EXIT"
} > "$STATUS_FILE"

exit $EXIT
```

Le fichier `last-status` peut être lu par Zabbix, Nagios, Prometheus node_exporter (textfile collector), etc.

---

## Gestion des résultats en CI

Les résultats (`recap.txt`, `failed.txt`, `report.html`) s'accumulent dans `RESULTATS_DIR`. En CI, pointer vers un dossier temporaire :

```bash
export RESULTATS_DIR=/tmp/integrity-$(date +%Y%m%d-%H%M%S)
./src/integrity.sh verify hashes.b3
# Uploader $RESULTATS_DIR comme artefact CI
```

Ou utiliser le champ `resultats` dans `pipeline.json` pour un chemin explicite par run.

---

## Récupérer le résumé en script

```bash
# Vérifier et récupérer le recap
./src/integrity.sh --quiet verify hashes.b3
EXIT=$?

OUTDIR=$(ls -d "${RESULTATS_DIR:-$HOME/integrity_resultats}/resultats_hashes"* 2>/dev/null | tail -1)

if [ $EXIT -ne 0 ] && [ -f "$OUTDIR/failed.txt" ]; then
    NB_FAILED=$(grep -c ': FAILED' "$OUTDIR/failed.txt" || echo 0)
    echo "ECHEC : $NB_FAILED fichier(s) corrompu(s)"
    cat "$OUTDIR/failed.txt"
fi

exit $EXIT
```


--- Fichier : docs/guides/nas-synology.md ---
# Guide - NAS Synology

Déploiement et usage de hash_tool sur NAS Synology avec Docker.

---

## Prérequis

- DSM 7.x
- **Container Manager** (anciennement Docker Manager) installé depuis le Centre de paquets
- Accès SSH au NAS (`ssh admin@192.168.1.x`)

---

## Déterminer l'architecture

```bash
# Via SSH
uname -m
# amd64 → DS920+, DS923+, DS1621+, ...
# aarch64 (arm64) → DS220+, DS420+, DS720+, DS923+ avec CPU AMD
```

| Modèle (exemples) | Architecture |
|---|---|
| DS920+, DS1621+, RS1221+ | amd64 |
| DS220+, DS420+, DS720+ | arm64 (aarch64) |
| DS923+ | amd64 (Ryzen R1600) |

---

## Installation

### Via SSH

```bash
# Se connecter au NAS
ssh admin@192.168.1.x

# Cloner ou copier hash_tool
cd /volume1/docker
git clone https://github.com/hash_tool/hash_tool.git
cd hash_tool

# Build de l'image (adapter la plateforme)
# amd64
docker build -t hash_tool .

# arm64 (DS220+, DS420+...)
docker build --platform linux/arm64 -t hash_tool:arm64 .
```

### Vérifier l'image

```bash
docker run --rm hash_tool version
# hash_tool
#   b3sum : b3sum 1.x.x
#   jq    : jq-1.x
#   bash  : 5.x.x
```

---

## Structure recommandée sur le NAS

```
/volume1/
├== docker/
│   └== hash_tool/          ← scripts et Dockerfile
├== data/                   ← données à surveiller (ou sous-dossiers par partage)
│   ├== photos/
│   ├== documents/
│   └== backups/
├== bases/                  ← fichiers .b3 (séparés des données)
│   ├== hashes_photos.b3
│   ├== hashes_documents.b3
│   └== hashes_backups.b3
└== rapports/               ← résultats verify/compare
    └== ...
```

---

## Utilisation via SSH

### Compute

```bash
docker run --rm \
  -v /volume1/data/photos:/data:ro \
  -v /volume1/bases:/bases \
  hash_tool compute /data /bases/hashes_photos_$(date +%Y-%m-%d).b3
```

### Verify

```bash
docker run --rm \
  -v /volume1/data/photos:/data:ro \
  -v /volume1/bases:/bases:ro \
  -v /volume1/rapports:/resultats \
  hash_tool verify /bases/hashes_photos.b3 /data
```

### Pipeline complet

```bash
docker run --rm \
  -v /volume1/data:/data:ro \
  -v /volume1/bases:/bases \
  -v /volume1/rapports:/resultats \
  -v /volume1/docker/hash_tool/pipelines/pipeline.json:/pipelines/pipeline.json:ro \
  hash_tool runner
```

---

## Automatisation via le planificateur de tâches DSM

DSM dispose d'un planificateur de tâches intégré (Panneau de configuration → Planificateur de tâches).

### Créer une tâche planifiée

1. **Panneau de configuration** → **Planificateur de tâches** → **Créer** → **Tâche planifiée** → **Script défini par l'utilisateur**
2. Onglet **Général** : nommer la tâche, sélectionner l'utilisateur `root`
3. Onglet **Calendrier** : configurer la fréquence (ex : hebdomadaire, dimanche 03h00)
4. Onglet **Paramètres de la tâche** : coller le script ci-dessous

### Script de tâche planifiée

```bash
#!/bin/bash

LOG="/volume1/rapports/hash-integrity.log"
MAILTO="admin@example.com"

echo "$(date) - Démarrage vérification intégrité" >> "$LOG"

docker run --rm \
  -v /volume1/data:/data:ro \
  -v /volume1/bases:/bases:ro \
  -v /volume1/rapports:/resultats \
  hash_tool --quiet verify /bases/hashes.b3 /data \
  >> "$LOG" 2>&1

EXIT=$?

if [ $EXIT -ne 0 ]; then
    echo "$(date) - ALERTE : vérification échouée (exit $EXIT)" >> "$LOG"
    # Notification email DSM - nécessite la configuration SMTP dans le Panneau de configuration
    # synonotify -e "hash_tool : corruption détectée sur $(hostname)"
fi

echo "$(date) - Fin (exit $EXIT)" >> "$LOG"
exit $EXIT
```

### Notifications DSM natives

Pour utiliser le système de notification DSM :

```bash
# Envoyer une notification DSM (email, push, SMS selon config)
synodsmnotify @administrators "hash_tool" "Corruption détectée sur $(/bin/hostname)"
```

---

## Docker Compose sur Synology

Adapter `docker-compose.yml` avec les chemins Synology :

```yaml
x-volumes:
  data:      &vol-data      /volume1/data
  bases:     &vol-bases     /volume1/bases
  pipelines: &vol-pipelines /volume1/docker/hash_tool/pipelines
  resultats: &vol-resultats /volume1/rapports
```

Puis via Container Manager (interface graphique DSM) ou SSH :

```bash
cd /volume1/docker/hash_tool
docker compose run --rm integrity verify /bases/hashes.b3 /data
```

---

## Dépannage

### L'image ne se build pas sur ARM64

```bash
# Vérifier l'architecture
uname -m   # doit afficher aarch64

# Builder avec la plateforme explicite
docker build --platform linux/arm64 -t hash_tool:arm64 .

# Tagger pour utiliser sans suffixe
docker tag hash_tool:arm64 hash_tool
```

### Permission denied sur /volume1

```bash
# Les conteneurs Docker tournent en root par défaut
# Vérifier que les dossiers sont accessibles
ls -la /volume1/data
ls -la /volume1/bases

# Adapter les permissions si nécessaire
chmod 755 /volume1/bases
```

### Container Manager ne trouve pas l'image

Après build via SSH, l'image apparaît dans Container Manager → Images. Si elle n'apparaît pas, rafraîchir ou relancer le service Docker :

```bash
sudo synoservicectl --restart pkgctl-ContainerManager
```


--- Fichier : docs/guides/veracrypt.md ---
# Guide - VeraCrypt & disques multiples

Workflow complet pour archiver et vérifier des données sur partitions VeraCrypt avec `runner.sh`.

---

## Principe

Les partitions VeraCrypt sont montées comme des lettres de lecteur sous Windows / des points de montage sous Linux. Les données n'existent en clair que pendant la session de montage. Il faut donc :

1. **Indexer avant démontage** - calculer les hashes pendant que les données sont accessibles
2. **Stocker les `.b3` hors de la partition vérifiée** - sur `C:` ou une partition non chiffrée
3. **Vérifier après remontage** - au prochain accès, confirmer l'intégrité

---

## Correspondance chemins Windows / WSL

| Lecteur Windows | Chemin WSL |
|---|---|
| `A:\` | `/mnt/a/` |
| `C:\` | `/mnt/c/` |
| `H:\` | `/mnt/h/` |
| `I:\` | `/mnt/i/` |

Si VeraCrypt remonte une partition sur une lettre différente d'une session à l'autre, seul le champ `source` dans `pipeline.json` est à modifier. Les bases `.b3` restent valides car leurs chemins sont relatifs.

---

## Structure recommandée

```
C:\Users\TonNom\Desktop\
├== hash_tool\                  ← scripts (non chiffré)
│   ├== runner.sh
│   ├== src\integrity.sh
│   └== pipelines\
│       └== pipeline-veracrypt.json
├== bases\                      ← fichiers .b3 (non chiffré, hors VeraCrypt)
│   ├== hashes_disque_1.b3
│   ├== hashes_disque_2.b3
│   └== hashes_disque_3.b3
└== rapports\                   ← résultats compare/verify
    └== ...
```

!!! danger "Stocker les .b3 hors de la partition vérifiée"
    Si les `.b3` sont sur la même partition VeraCrypt que les données, une corruption du disque peut corrompre simultanément les données **et** leur empreinte - rendant la vérification inutile.

    Stocker les `.b3` sur `C:` (non chiffré) ou une partition séparée.

---

## Configuration pipeline

### Cas simple - un disque, compute + verify

```json
{
    "pipeline": [
        {
            "op":     "compute",
            "source": "/mnt/a/mes_archives",
            "bases":  "/mnt/c/Users/TonNom/Desktop/bases",
            "nom":    "hashes_disque_a.b3"
        },
        {
            "op":     "verify",
            "source": "/mnt/a/mes_archives",
            "base":   "/mnt/c/Users/TonNom/Desktop/bases/hashes_disque_a.b3"
        }
    ]
}
```

### Cas complet - trois disques avec comparaison

```json
{
    "pipeline": [

        {
            "op":     "compute",
            "source": "/mnt/a/dossier_disque_1",
            "bases":  "/mnt/c/Users/TonNom/Desktop/bases",
            "nom":    "hashes_disque_1.b3"
        },

        {
            "op":     "compute",
            "source": "/mnt/i/dossier_disque_2",
            "bases":  "/mnt/c/Users/TonNom/Desktop/bases",
            "nom":    "hashes_disque_2.b3"
        },

        {
            "op":     "compute",
            "source": "/mnt/h/dossier_disque_3",
            "bases":  "/mnt/c/Users/TonNom/Desktop/bases",
            "nom":    "hashes_disque_3.b3"
        },

        {
            "op":     "verify",
            "source": "/mnt/a/dossier_disque_1",
            "base":   "/mnt/c/Users/TonNom/Desktop/bases/hashes_disque_1.b3"
        },

        {
            "op":        "compare",
            "base_a":    "/mnt/c/Users/TonNom/Desktop/bases/hashes_disque_1.b3",
            "base_b":    "/mnt/c/Users/TonNom/Desktop/bases/hashes_disque_2.b3",
            "resultats": "/mnt/c/Users/TonNom/Desktop/rapports/compare_1_vs_2"
        }

    ]
}
```

---

## Lanceur Windows (double-clic)

Créer `lancer_integrity.bat` sur le bureau :

```bat
@echo off
echo Demarrage verification integrite...
wsl bash /mnt/c/Users/TonNom/Desktop/hash_tool/runner.sh ^
    /mnt/c/Users/TonNom/Desktop/hash_tool/pipelines/pipeline-veracrypt.json
if %errorlevel% neq 0 (
    echo.
    echo ERREUR : le pipeline a echoue. Consulter les resultats.
) else (
    echo.
    echo Pipeline termine avec succes.
)
pause
```

---

## Workflows types

### Workflow d'archivage initial

1. Monter les partitions VeraCrypt
2. Double-clic sur `lancer_integrity.bat`
3. Attendre la fin (progression affichée dans la console WSL)
4. Vérifier que `recap.txt` indique OK
5. Démonter les partitions

### Workflow de vérification périodique

1. Monter les partitions VeraCrypt
2. Modifier `pipeline.json` pour ne conserver que les blocs `verify` (supprimer les `compute`)
3. Double-clic sur `lancer_integrity.bat`
4. Consulter `recap.txt` et `failed.txt` si présent
5. Démonter les partitions

### Workflow de comparaison après copie

Après avoir copié des données d'un disque à un autre :

1. `compute` sur la source (`base_a`)
2. `compute` sur la destination (`base_b`)
3. `compare base_a base_b` → `disparus.txt` et `nouveaux.txt` doivent être vides, `modifies.b3` aussi

---

## Nommage des bases

Utiliser des noms datés pour conserver l'historique :

```
bases/
├== hashes_disque_1_2024-01-15.b3    ← baseline initiale
├== hashes_disque_1_2024-06-01.b3    ← après ajout de fichiers
└== hashes_disque_1_2024-12-01.b3    ← vérification annuelle
```

Ne jamais écraser une base existante - chaque `.b3` est une preuve datée de l'état du disque.

!!! tip
    Pour automatiser le nommage daté depuis Windows avec WSL :
    ```bat
    for /f %%i in ('wsl date +%%Y-%%m-%%d') do set DATE=%%i
    ```


--- Fichier : docs/reference/docker.md ---
# Référence - Docker

**Version image :** 0.12  
**Base :** Alpine 3.19  
**Taille finale :** ~14 Mo  
**Architectures :** `amd64`, `arm64`, `armv7`

---

## Pourquoi Docker

hash_tool dépend de deux binaires - `b3sum` et `jq` - dont les versions et les méthodes d'installation varient selon l'OS. Sur Windows, `b3sum` n'est pas disponible nativement. Sur un NAS Synology, l'accès à un gestionnaire de paquets est limité. Sur un serveur Debian de production, toute installation manuelle est une dette technique.

L'image Docker embarque des versions fixes et vérifiées de tous les outils. L'hôte n'a besoin que de Docker.

| Environnement | Problème sans Docker | Solution Docker |
|---|---|---|
| Windows / WSL | `b3sum` non dispo nativement, `jq` à installer manuellement | `docker run` - aucune installation |
| NAS Synology | Gestionnaire de paquets limité, accès SSH requis | Image ARM64 compatible DSM 7.x |
| Serveur Debian | Versions système potentiellement anciennes | Versions pinned dans le Dockerfile |

---

## Architecture de l'image

### Multi-stage build

L'image utilise un build en deux stages pour dissocier les outils de compilation des outils d'exécution.

```dockerfile
# Stage 1 : fetcher - téléchargement et vérification de b3sum
FROM alpine:3.19 AS fetcher
  # wget b3sum binaire musl depuis GitHub Releases
  # b3sum --check (auto-vérification cryptographique)

# Stage 2 : image finale - runtime uniquement
FROM alpine:3.19
  # apk install bash jq coreutils findutils
  # COPY --from=fetcher /usr/local/bin/b3sum
  # COPY scripts hash_tool
```

Le stage `fetcher` nécessite `wget` et `ca-certificates`, qui ne sont pas copiés dans l'image finale. La toolchain Rust (~700 Mo) n'est jamais présente - `b3sum` est récupéré sous forme de binaire musl pré-compilé depuis les releases officielles BLAKE3.

!!! note "Pourquoi musl ?"
    Alpine Linux utilise musl libc au lieu de glibc. Les binaires musl sont statiquement liés et fonctionnent sans dépendances dynamiques - plus robustes dans un conteneur minimal. Le projet BLAKE3 publie des binaires musl officiels pour amd64, arm64 et armv7.

### Taille finale

| Couche | Taille approx. | Contenu |
|---|---|---|
| Alpine 3.19 base | ~7 Mo | OS minimal musl libc |
| bash + jq + coreutils | ~5 Mo | Shell, parser JSON, outils POSIX |
| b3sum binaire musl | ~2 Mo | Binaire officiel BLAKE3 |
| Scripts hash_tool | < 100 Ko | `runner.sh`, `integrity.sh`, `lib/` |
| **Total image finale** | **~14 Mo** | - |
| Image Debian équivalente | ~180 Mo | Référence comparative |

### Détection d'architecture

La sélection du binaire `b3sum` adapté à l'architecture se fait automatiquement dans le Dockerfile via `uname -m` :

```bash
ARCH="$(uname -m)"
case "$ARCH" in
  x86_64)  B3SUM_ARCH="linux_amd64_musl"   ;;  # PC, serveur standard
  aarch64) B3SUM_ARCH="linux_aarch64_musl"  ;;  # NAS Synology ARM, RPi 4
  armv7l)  B3SUM_ARCH="linux_armv7_musl"    ;;  # Vieux NAS, RPi 2/3
esac
```

Un seul Dockerfile couvre les trois architectures. Le build multi-platform Docker Buildx permet de produire une image manifeste unique pour les trois cibles simultanément.

### Vérification cryptographique du binaire

Le projet BLAKE3 publie pour chaque release un fichier `.b3` contenant le hash BLAKE3 du binaire. Le stage fetcher vérifie le binaire téléchargé avant de le copier dans l'image finale :

```bash
# Télécharger binaire et sa signature
wget -O /usr/local/bin/b3sum "${BASE_URL}/b3sum_${B3SUM_ARCH}"
wget -O /tmp/b3sum.b3        "${BASE_URL}/b3sum_${B3SUM_ARCH}.b3"

# Auto-vérification : b3sum vérifie sa propre signature
chmod +x /usr/local/bin/b3sum
cd /usr/local/bin && b3sum --check /tmp/b3sum.b3

# Si le hash ne correspond pas → build échoue immédiatement
```

!!! note "Chaîne de confiance"
    `b3sum` se vérifie lui-même : le binaire téléchargé calcule son propre hash et le compare au fichier `.b3` publié sur la même release GitHub. Si un seul bit a été altéré (attaque MITM, corruption réseau), le build échoue avec une erreur explicite.

---

## Entrypoint

Le script `docker/entrypoint.sh` dispatche les commandes vers les scripts internes.

| Commande | Script appelé | Description |
|---|---|---|
| `compute <dossier> <base.b3>` | `src/integrity.sh compute` | Calcule les hashes BLAKE3 |
| `verify <base.b3> [dossier]` | `src/integrity.sh verify` | Vérifie l'intégrité |
| `compare <old.b3> <new.b3>` | `src/integrity.sh compare` | Compare deux bases |
| `runner [pipeline.json]` | `runner.sh` | Exécute un pipeline JSON |
| `shell` / `bash` | `/bin/bash` | Shell interactif (debug) |
| `help` | - | Affiche l'aide inline |
| `version` | - | Affiche les versions des outils |

Sans argument, le conteneur affiche l'aide (`CMD ["help"]`). Cela évite l'erreur silencieuse d'un conteneur qui démarre et s'arrête sans indication.

---

## Volumes

L'image définit quatre points de montage conventionnels.

| Volume | Usage | Mode recommandé | Notes |
|---|---|---|---|
| `/data` | Données à hacher | `:ro` | Jamais modifié par hash_tool |
| `/bases` | Fichiers `.b3` | Lecture/écriture | Écriture uniquement pour `compute` |
| `/pipelines` | Fichiers `pipeline.json` | `:ro` | Monter un fichier spécifique |
| `/resultats` | Résultats `verify`/`compare` | Lecture/écriture | `RESULTATS_DIR=/resultats` par défaut |

!!! warning "Séparation données / bases"
    Les fichiers `.b3` doivent être stockés sur un support **distinct** des données vérifiées. Si `/data` et `/bases` pointent vers le même disque physique, une corruption du disque pourrait affecter les deux - rendant la vérification inopérante.

    Sur VeraCrypt : stocker les `.b3` sur `C:` (stable), jamais sur la partition montée.

### Variable d'environnement `RESULTATS_DIR`

`RESULTATS_DIR` est définie à `/resultats` dans l'image. Elle peut être surchargée via `-e` :

```bash
docker run --rm \
  -v /mes/resultats:/custom_res \
  -e RESULTATS_DIR=/custom_res \
  hash_tool verify /bases/hashes.b3
```

Le champ `"resultats"` dans `pipeline.json` surcharge cette variable pour un bloc `compare` spécifique.

---

## Docker Compose

### Services

| Service | Usage | Démarrage |
|---|---|---|
| `integrity` | Commandes ponctuelles `compute`/`verify`/`compare` | `docker compose run --rm integrity <cmd>` |
| `pipeline` | Exécution de `runner.sh` avec `pipeline.json` | `docker compose run --rm pipeline` |
| `cron` | Vérification périodique | `docker compose --profile cron up -d` |

### Configuration des chemins

La section `x-volumes` permet de modifier tous les montages en un seul endroit.

```yaml
# docker-compose.yml - section à adapter
x-volumes:
  data:      &vol-data      /chemin/vers/donnees    # ex: /volume1/data sur Synology
  bases:     &vol-bases     /chemin/vers/bases       # ex: /srv/bases sur Debian
  pipelines: &vol-pipelines /chemin/vers/pipelines
  resultats: &vol-resultats /chemin/vers/resultats
```

Les ancres YAML (`*vol-data`, etc.) propagent les chemins dans tous les services automatiquement.

### Profil cron

Le service `cron` est isolé derrière un profil Docker Compose (`profiles: ["cron"]`). Il n'est pas démarré par `docker compose up` par défaut. Cela évite un service fantôme actif en permanence.

---

## Déploiement par environnement

### Windows / WSL

Prérequis : Docker Desktop avec intégration WSL2 activée.

```bash
# Build depuis WSL
cd /mnt/c/Users/TonNom/Desktop/hash_tool
docker build -t hash_tool .

# Compute d'une partition VeraCrypt montée sur A:
docker run --rm \
  -v /mnt/a/dossier:/data:ro \
  -v /mnt/c/Users/TonNom/bases:/bases \
  -v /mnt/c/Users/TonNom/resultats:/resultats \
  hash_tool compute /data /bases/hashes_$(date +%Y-%m-%d).b3
```

!!! note "Chemins VeraCrypt dans Docker"
    Les partitions VeraCrypt montées sur des lettres Windows (`A:`, `I:`, `H:`) sont accessibles depuis WSL sous `/mnt/a/`, `/mnt/i/`, `/mnt/h/`. Docker Desktop sur WSL2 hérite de ces montages. Adapter uniquement les chemins `-v` lors du changement de lettre de partition.

### NAS Synology

Vérifier l'architecture avec `uname -m` depuis SSH avant de builder.

| Modèle Synology | CPU | Architecture | Tag image |
|---|---|---|---|
| DS923+ | AMD Ryzen R1600 | x86_64 (amd64) | `hash_tool` |
| DS720+ | Intel Celeron J4125 | x86_64 (amd64) | `hash_tool` |
| DS220+ | Intel Celeron J4025 | x86_64 (amd64) | `hash_tool` |
| DS220j | Realtek RTD1296 | aarch64 (arm64) | `hash_tool:arm64` |
| DS218j | Marvell ARMADA 385 | armv7 | `hash_tool:armv7` |

```bash
# Build ARM64 (NAS DS923+, DS720+)
docker build --platform linux/arm64 -t hash_tool:arm64 .

# Depuis SSH Synology ou via Portainer
docker run --rm \
  -v /volume1/data:/data:ro \
  -v /volume1/bases:/bases \
  -v /volume1/resultats:/resultats \
  hash_tool verify /bases/hashes.b3 /data
```

### Serveur Debian

Sur un serveur Debian, la méthode recommandée est le cron Docker pour une vérification nocturne automatique.

```bash
# /etc/cron.d/hash-integrity
0 3 * * * root docker run --rm \
  -v /srv/data:/data:ro \
  -v /srv/bases:/bases:ro \
  -v /srv/resultats:/resultats \
  hash_tool --quiet verify /bases/hashes.b3 /data \
  >> /var/log/hash-integrity.log 2>&1 \
  || mail -s "ALERTE intégrité $(hostname)" admin@example.com
```

---

## Maintenance

### Mise à jour de b3sum

La version de `b3sum` est contrôlée par `ARG B3SUM_VERSION=1.5.4` dans le Dockerfile. Pour mettre à jour, modifier uniquement cette ligne et rebuilder. La vérification cryptographique garantit l'intégrité du nouveau binaire.

```bash
docker build --build-arg B3SUM_VERSION=1.6.0 -t hash_tool .

# URLs des releases BLAKE3 officielles :
# https://github.com/BLAKE3-team/BLAKE3/releases
# Pattern binaire  : b3sum_linux_<arch>_musl
# Pattern signature : b3sum_linux_<arch>_musl.b3
```

### Build hors-ligne

Sur un NAS ou serveur sans accès à GitHub, le binaire `b3sum` peut être pré-téléchargé et copié directement dans le contexte de build.

```bash
# Sur une machine avec accès réseau
wget https://github.com/BLAKE3-team/BLAKE3/releases/download/1.5.4/b3sum_linux_amd64_musl

# Modifier le Dockerfile pour COPY au lieu de wget
COPY b3sum_linux_amd64_musl /usr/local/bin/b3sum
RUN chmod +x /usr/local/bin/b3sum
```

La vérification cryptographique reste applicable manuellement après la copie.

### Extension de l'image

| Évolution | Approche recommandée | Impact sur l'image |
|---|---|---|
| Rapport PDF | Ajouter `wkhtmltopdf` dans l'image | +30 Mo |
| Notifications email | Service dédié dans `docker-compose.yml` | Aucun |
| Export S3 | Script `lib/export.sh` + `awscli` dans image | +20 Mo |
| Interface web | Service séparé, hash_tool en dépendance | Aucun |

---

## Référence rapide

```bash
# Build standard
docker build -t hash_tool .

# Build ARM64
docker build --platform linux/arm64 -t hash_tool:arm64 .

# Aide / versions
docker run --rm hash_tool help
docker run --rm hash_tool version

# Compute
docker run --rm \
  -v /data:/data:ro -v /bases:/bases \
  hash_tool compute /data /bases/hashes_$(date +%Y-%m-%d).b3

# Verify
docker run --rm \
  -v /data:/data:ro -v /bases:/bases:ro -v /res:/resultats \
  hash_tool verify /bases/hashes.b3 /data

# Compare
docker run --rm \
  -v /bases:/bases:ro -v /res:/resultats \
  hash_tool compare /bases/old.b3 /bases/new.b3

# Pipeline
docker run --rm \
  -v /data:/data:ro -v /bases:/bases \
  -v /res:/resultats -v /pipe/pipeline.json:/pipelines/pipeline.json:ro \
  hash_tool runner

# Debug interactif
docker run --rm -it -v /data:/data hash_tool shell
```

### Fichiers du projet liés à Docker

| Fichier | Rôle |
|---|---|
| `Dockerfile` | Build multi-stage Alpine + b3sum + jq |
| `.dockerignore` | Exclusions du contexte de build |
| `docker/entrypoint.sh` | Dispatcher des commandes Docker |
| `docker-compose.yml` | Orchestration 3 services |
| `docs/reference/docker.md` | Ce document |


--- Fichier : docs/reference/integrity-sh.md ---
# Référence - integrity.sh

Script principal de vérification d'intégrité BLAKE3.

**Emplacement :** `src/integrity.sh`  
**Architecture :** dispatcher CLI - orchestre `src/lib/core.sh`, `src/lib/ui.sh`, `src/lib/results.sh`, `src/lib/report.sh`

---

## Synopsis

```
integrity.sh [--quiet] <mode> [arguments...]

Modes :
  compute <dossier> <base.b3>
  verify  <base.b3> [dossier]
  compare <ancienne.b3> <nouvelle.b3>
```

---

## Options globales

### `--quiet`

Supprime toute sortie terminal. Écrit uniquement dans les fichiers de résultats (`recap.txt`, `failed.txt`, `report.html`). L'exit code est conservé.

```bash
./src/integrity.sh --quiet verify base.b3
echo $?   # 0 = OK, 1 = ECHEC ou ERREUR
```

**Usage type :** intégration CI, cron, scripts parents qui gèrent eux-mêmes la sortie.

!!! warning
    En mode `--quiet`, la progression ETA est également supprimée pendant `compute`.

---

## Mode `compute`

Calcule les hashes BLAKE3 de tous les fichiers d'un dossier et les enregistre dans un fichier `.b3`.

### Syntaxe

```bash
./src/integrity.sh compute <dossier> <base.b3>
```

### Arguments

| Argument | Type | Description |
|---|---|---|
| `<dossier>` | chemin | Dossier à indexer. Relatif ou absolu, mais **préférer relatif** (voir ci-dessous). |
| `<base.b3>` | chemin fichier | Fichier de sortie. Créé ou écrasé. Ne doit pas être un dossier existant. |

### Comportement

1. Valide que `<dossier>` existe et contient au moins un fichier régulier (`core_assert_target_valid`)
2. Parcourt récursivement avec `find -type f -print0 | sort -z`
3. Calcule le hash BLAKE3 de chaque fichier avec `b3sum` (via `core_compute`)
4. Affiche la progression et l'ETA sur `/dev/tty` via callback `ui_progress_callback`
5. Enregistre les résultats dans `<base.b3>`

### Format du fichier `.b3`

Voir la [spécification complète](../spec/b3-format.md). Format synthétique :

```
<hash_64_chars>  <chemin>
```

!!! danger "Règle absolue : chemins relatifs"
    Toujours passer un chemin relatif (`.` ou `./sous-dossier`) comme `<dossier>`.

    ```bash
    # Correct - chemin relatif dans la base
    cd /mnt/a/mes_donnees
    ./src/integrity.sh compute . /mnt/c/bases/hashes.b3

    # Incorrect - chemin absolu, base non portable
    ./src/integrity.sh compute /mnt/a/mes_donnees /mnt/c/bases/hashes.b3
    ```

    `runner.sh` gère ce `cd` automatiquement.

### Exit codes

| Code | Signification |
|---|---|
| `0` | Base calculée avec succès |
| `1` | Erreur (dossier introuvable, dossier vide, argument manquant) |

---

## Mode `verify`

Vérifie que les fichiers correspondent aux hashes stockés dans la base `.b3`.

### Syntaxe

```bash
./src/integrity.sh verify <base.b3> [dossier]
```

### Arguments

| Argument | Type | Description |
|---|---|---|
| `<base.b3>` | chemin fichier | Base de hashes à utiliser pour la vérification. |
| `[dossier]` | chemin (optionnel) | Répertoire de travail à utiliser. Si absent, utilise le `pwd` courant. |

### Comportement

1. Valide le fichier `.b3` (`core_assert_b3_valid`) - toutes les lignes doivent être au format b3sum
2. Résout le chemin absolu de `<base.b3>` **avant** le `cd`
3. Si `[dossier]` est fourni, fait `cd` dans ce dossier
4. Lance `b3sum --check` via `core_verify()`
5. Écrit les résultats dans `$RESULTATS_DIR/resultats_<nom_base>/`

!!! warning "Répertoire de travail"
    `b3sum --check` résout les chemins relatifs depuis le `pwd`. Lancer `verify` depuis le même répertoire qu'au `compute` - ou passer ce répertoire en second argument.

    ```bash
    # Cas 1 : on est dans le bon répertoire
    cd /mnt/a/mes_donnees
    ./src/integrity.sh verify /mnt/c/bases/hashes.b3

    # Cas 2 : on est ailleurs
    ./src/integrity.sh verify /mnt/c/bases/hashes.b3 /mnt/a/mes_donnees
    ```

### Fichiers produits

Créés dans `$RESULTATS_DIR/resultats_<nom_base>/` (horodaté si le dossier existe déjà) :

| Fichier | Présence | Contenu |
|---|---|---|
| `recap.txt` | Toujours | Statut global, compteurs OK/FAILED, erreurs b3sum |
| `failed.txt` | Si échec seulement | Liste des fichiers FAILED ou en erreur |

### Exit codes

| Code | Signification |
|---|---|
| `0` | Tous les fichiers intègres |
| `1` | Au moins un FAILED ou erreur b3sum |

---

## Mode `compare`

Compare deux bases `.b3` et identifie les fichiers modifiés, disparus et nouveaux.

### Syntaxe

```bash
./src/integrity.sh compare <ancienne.b3> <nouvelle.b3>
```

### Arguments

| Argument | Type | Description |
|---|---|---|
| `<ancienne.b3>` | chemin fichier | Base de référence (snapshot antérieur). |
| `<nouvelle.b3>` | chemin fichier | Base à comparer (snapshot récent). |

### Fichiers produits

Créés dans `$RESULTATS_DIR/resultats_<nom_ancienne_base>/` :

| Fichier | Contenu |
|---|---|
| `recap.txt` | Commande, date, bases, compteurs |
| `modifies.b3` | Fichiers présents dans les deux bases avec hashes différents. Format : `nouveau_hash  chemin` |
| `disparus.txt` | Chemins présents dans `<ancienne.b3>` et absents de `<nouvelle.b3>` |
| `nouveaux.txt` | Chemins absents de `<ancienne.b3>` et présents dans `<nouvelle.b3>` |
| `report.html` | Rapport visuel autonome (CSS inline) |

### Exit codes

| Code | Signification |
|---|---|
| `0` | Comparaison effectuée (qu'il y ait des différences ou non) |
| `1` | Erreur (fichier introuvable, format invalide) |

!!! note
    `compare` retourne `0` même si des différences sont détectées. La présence de différences est une information, pas une erreur. Pour détecter des différences en script, vérifier si `modifies.b3`, `disparus.txt` ou `nouveaux.txt` sont non vides.

---

## Variable d'environnement

### `RESULTATS_DIR`

| | |
|---|---|
| **Défaut** | `~/integrity_resultats` |
| **Scope** | `verify` et `compare` |

```bash
export RESULTATS_DIR=/srv/rapports/integrity
./src/integrity.sh verify hashes.b3
```

---

## Limites connues

| Scénario | Détecté ? | Remarque |
|---|---|---|
| Contenu de fichier modifié | **Oui** | Hash différent |
| Fichier supprimé | **Oui** | FAILED (verify) ou DISPARUS (compare) |
| Fichier ajouté | **Oui** (compare) | Section NOUVEAUX |
| Dossier vide | **Non** | `find -type f` ignore les dossiers vides |
| Permissions / timestamps | **Non** | Seul le contenu binaire est haché |
| Fichier renommé | **Non** | Vu comme suppression + ajout |
| Clone bit-à-bit | **Non** | Hash identique par définition |
| Corruption de la base `.b3` | **Non** | La base n'est pas auto-protégée |

### Protéger la base `.b3`

```bash
b3sum hashes.b3 > hashes.b3.check
b3sum --check hashes.b3.check
```

---

## Dépendances techniques

| Outil | Usage |
|---|---|
| `b3sum` | Calcul et vérification des hashes BLAKE3 |
| `find` | Parcours récursif du dossier |
| `sort` | Tri déterministe des chemins |
| `awk` | Conversion format `hash chemin` ↔ `chemin\thash` |
| `join` | Identification des fichiers modifiés |
| `comm` | Identification des disparus et nouveaux |
| `stat` | Taille de fichier pour le calcul ETA |
| `du` | Taille totale du dossier pour le calcul ETA |
| `mktemp` | Fichiers temporaires isolés dans `compare` |


--- Fichier : docs/reference/runner-sh.md ---
# Référence - runner.sh & pipeline.json

Orchestrateur de pipeline pour exécuter plusieurs opérations `integrity.sh` en séquence.

**Emplacement :** `runner.sh`  
**Dépendance supplémentaire :** `jq`

---

## Synopsis

```
runner.sh [pipeline.json]
```

| Argument | Défaut | Description |
|---|---|---|
| `pipeline.json` | `pipelines/pipeline.json` | Chemin vers le fichier de configuration du pipeline. |

---

## Pourquoi runner.sh

Lancer `integrity.sh` manuellement sur plusieurs dossiers est error-prone :

- Oublier le `cd` avant `compute` → chemins absolus dans la base
- Mauvais répertoire de travail pour `verify` → faux positifs massifs
- Ordre d'exécution non garanti sur des appels séparés

`runner.sh` élimine ces risques : il gère automatiquement les `cd`, valide les chemins avant exécution, et s'arrête immédiatement sur toute erreur (`set -euo pipefail`).

---

## Format pipeline.json

### Structure générale

```json
{
    "pipeline": [
        { "op": "compute", ... },
        { "op": "verify",  ... },
        { "op": "compare", ... }
    ]
}
```

Le tableau `pipeline` est exécuté séquentiellement. En cas d'erreur sur un bloc, l'exécution s'arrête immédiatement.

### Opération `compute`

Calcule les hashes d'un dossier et produit un fichier `.b3`.

```json
{
    "op":     "compute",
    "source": "/chemin/vers/dossier",
    "bases":  "/chemin/vers/dossier_bases",
    "nom":    "hashes.b3"
}
```

| Champ | Requis | Description |
|---|---|---|
| `op` | Oui | `"compute"` |
| `source` | Oui | Dossier à indexer. `runner.sh` fait `cd` dans ce dossier avant le compute - les chemins dans la base seront relatifs. |
| `bases` | Oui | Dossier où enregistrer le fichier `.b3`. Créé automatiquement si inexistant. |
| `nom` | Oui | Nom du fichier `.b3` à créer dans `bases`. |

**Comportement interne :** `cd "$source"` puis `integrity.sh compute . "$bases/$nom"`. Le `.` garantit des chemins relatifs dans la base.

### Opération `verify`

Vérifie l'intégrité d'un dossier contre une base `.b3`.

```json
{
    "op":     "verify",
    "source": "/chemin/vers/dossier",
    "base":   "/chemin/vers/hashes.b3"
}
```

| Champ | Requis | Description |
|---|---|---|
| `op` | Oui | `"verify"` |
| `source` | Oui | Répertoire de travail d'origine (celui depuis lequel le `compute` a été fait). |
| `base` | Oui | Chemin complet du fichier `.b3`. |

**Comportement interne :** résolution du chemin absolu de `base`, puis `cd "$source"`, puis `integrity.sh verify "$base_abs"`.

### Opération `compare`

Compare deux bases `.b3`.

```json
{
    "op":        "compare",
    "base_a":    "/chemin/vers/ancienne.b3",
    "base_b":    "/chemin/vers/nouvelle.b3",
    "resultats": "/chemin/vers/dossier_resultats"
}
```

| Champ | Requis | Description |
|---|---|---|
| `op` | Oui | `"compare"` |
| `base_a` | Oui | Ancienne base (référence). |
| `base_b` | Oui | Nouvelle base (à comparer). |
| `resultats` | Non | Dossier de destination des résultats. Surcharge `RESULTATS_DIR` pour ce seul bloc. Créé automatiquement si inexistant. |

**Champ `resultats` :** l'isolation est garantie par un sous-shell - `RESULTATS_DIR` du processus parent n'est pas modifié. Les autres blocs du pipeline continuent d'utiliser la valeur globale de `RESULTATS_DIR`.

---

## Exemple complet - VeraCrypt multi-disques

```json
{
    "pipeline": [

        {
            "op":     "compute",
            "source": "/mnt/a/dossier_disque_1",
            "bases":  "/mnt/c/Users/TonNom/Desktop/bases",
            "nom":    "hashes_disque_1.b3"
        },

        {
            "op":     "compute",
            "source": "/mnt/i/dossier_disque_2",
            "bases":  "/mnt/c/Users/TonNom/Desktop/bases",
            "nom":    "hashes_disque_2.b3"
        },

        {
            "op":     "verify",
            "source": "/mnt/a/dossier_disque_1",
            "base":   "/mnt/c/Users/TonNom/Desktop/bases/hashes_disque_1.b3"
        },

        {
            "op":        "compare",
            "base_a":    "/mnt/c/Users/TonNom/Desktop/bases/hashes_disque_1.b3",
            "base_b":    "/mnt/c/Users/TonNom/Desktop/bases/hashes_disque_2.b3",
            "resultats": "/mnt/c/Users/TonNom/Desktop/rapports/compare_1_vs_2"
        }

    ]
}
```

---

## Validation et messages d'erreur

`runner.sh` valide la configuration avant d'exécuter quoi que ce soit :

| Problème | Message |
|---|---|
| JSON invalide | `ERREUR : JSON invalide : /chemin/pipeline.json` |
| Clé `.pipeline` absente | `ERREUR : tableau .pipeline vide ou absent` |
| Champ requis manquant | `ERREUR : Bloc #2 : champ 'nom' manquant ou vide.` |
| Opération inconnue | `ERREUR : Bloc #3 : opération inconnue : 'migrate'` |
| Dossier source introuvable | `ERREUR : Bloc #1 compute : dossier source introuvable : /mnt/a/...` |
| Base `.b3` introuvable | `ERREUR : Bloc #2 verify : base .b3 introuvable : /mnt/c/...` |

Tous les messages d'erreur incluent le numéro de bloc pour faciliter le débogage.

---

## Variables d'environnement

### `RESULTATS_DIR`

Dossier de résultats global pour tous les blocs `verify` et `compare` sans champ `resultats` explicite.

```bash
export RESULTATS_DIR=/srv/rapports
./runner.sh
```

Défaut : `~/integrity_resultats` (hérité de `integrity.sh`).

---

## Exit codes

| Code | Signification |
|---|---|
| `0` | Pipeline exécuté entièrement sans erreur |
| `1` | Erreur sur un bloc (bloc suivant non exécuté) |

---

## Lancement depuis Windows

Créer un fichier `.bat` sur le bureau :

```bat
@echo off
wsl bash /mnt/c/Users/TonNom/Desktop/hash_tool/runner.sh
pause
```

Double-clic pour exécuter. La fenêtre reste ouverte après exécution grâce à `pause`.

Pour un pipeline explicite :

```bat
@echo off
wsl bash /mnt/c/Users/TonNom/Desktop/hash_tool/runner.sh ^
    /mnt/c/Users/TonNom/Desktop/mon-pipeline.json
pause
```

---

## Isolation des sous-shells

`runner.sh` utilise des sous-shells `( )` pour isoler les `cd` :

```bash
# Le cd ne fuite pas vers les blocs suivants
( cd "$source" && integrity.sh compute . "$bases/$nom" )
```

Chaque bloc `compute` et `verify` démarre dans le répertoire courant du processus principal, quels que soient les `cd` des blocs précédents. La variable `RESULTATS_DIR` est de même isolée pour les blocs `compare` avec un champ `resultats` explicite.


