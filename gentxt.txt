# === Arborescence du dossier ===

hash_tool
├── docker
│   └── entrypoint.sh
├── docs
│   ├── docker.md
│   ├── explication-run-tests.md
│   ├── hash_tool-docker-documentation.docx
│   ├── hash_tool-docker-documentation.pdf
│   ├── hash_tool-positionnement-open-source.docx
│   ├── hash_tool-positionnement-open-source.pdf
│   ├── hash_tool-presentation.docx
│   ├── hash_tool-presentation.pdf
│   ├── manuel.md
│   └── progression-eta.md
├── mon_dossier
│   ├── bases
│   │   ├── hashes_dossier_1.b3
│   │   └── hashes_dossier_2.b3
│   ├── destination
│   │   ├── fichier (1).txt
│   │   ├── fichier (2).txt
│   │   ├── fichier (3).txt
│   │   └── fichier (4).txt
│   ├── result
│   │   ├── resultats_hashes_dossier_1
│   │   │   ├── disparus.txt
│   │   │   ├── modifies.b3
│   │   │   ├── nouveaux.txt
│   │   │   ├── recap.txt
│   │   │   └── report.html
│   │   └── resultats_hashes_dossier_1_20260222-100613
│   │       ├── disparus.txt
│   │       ├── modifies.b3
│   │       ├── nouveaux.txt
│   │       ├── recap.txt
│   │       └── report.html
│   └── source
│       ├── fichier (1).txt
│       ├── fichier (2).txt
│       ├── fichier (3).txt
│       └── fichier (4).txt
├── pipelines
│   ├── pipeline full.json
│   └── pipeline.json
├── reports
│   └── template.html
├── src
│   ├── lib
│   │   └── report.sh
│   └── integrity.sh
├── tests
│   ├── run_tests.sh
│   ├── run_tests_pipeline.sh
│   └── validation.md
├── .dockerignore
├── .gitignore
├── CHANGELOG.md
├── Dockerfile
├── README.md
├── docker-compose.yml
├── runner.sh
└── temp.txt


# === Contenu des fichiers ===

--- Fichier : .dockerignore ---
# .dockerignore — hash_tool
#
# Exclut du contexte de build Docker ce qui n'est pas nécessaire.
# Réduit la taille du contexte envoyé au daemon.

# Données utilisateur — jamais dans l'image
mon_dossier/
*.b3

# Résultats
resultats/
~/integrity_resultats/

# Tests — non requis dans l'image de production
tests/

# Documentation — non requise dans l'image
docs/
reports/
*.md
!README.md

# Fichiers temporaires
temp.txt
*.tmp
*.log

# Outils de développement
.git/
.gitignore


--- Fichier : .gitignore ---
# ── Données utilisateur ───────────────────────────────────────────────────────
autre/
*.b3

# ── Résultats ─────────────────────────────────────────────────────────────────
resultats/
integrity_resultats/

# ── Docker ────────────────────────────────────────────────────────────────────
# Ne pas ignorer : Dockerfile, .dockerignore, docker-compose.yml, docker/
# Ignorer les artefacts de build local
.docker/

# ── Fichiers temporaires ──────────────────────────────────────────────────────
temp.txt
*.tmp
*.log
*.bak

# ── OS ────────────────────────────────────────────────────────────────────────
.DS_Store
Thumbs.db
desktop.ini

# ── Éditeurs ─────────────────────────────────────────────────────────────────
.vscode/
.idea/
*.swp
*.swo
*~

--- Fichier : CHANGELOG.md ---
# Changelog — hash_tool / integrity.sh

## [0.12] — Dockerisation

### Ajouté

- `Dockerfile` : image multi-stage basée sur Alpine 3.19.
  - Stage `fetcher` : télécharge le binaire officiel `b3sum` musl depuis GitHub Releases, le vérifie (auto-vérification via `b3sum --check`). Supporte `amd64`, `arm64`, `armv7`.
  - Stage final : Alpine + `bash` + `jq` + `coreutils` + `findutils` + binaire `b3sum` copié. Image finale ~14 Mo sans toolchain Rust.
  - `ARG B3SUM_VERSION` : version b3sum paramétrable au build.

- `docker/entrypoint.sh` : dispatcher des commandes.
  - `compute`, `verify`, `compare` → délégués à `src/integrity.sh`.
  - `runner [pipeline.json]` → délégué à `runner.sh` (défaut : `/pipelines/pipeline.json`).
  - `shell` / `bash` → shell interactif debug.
  - `help`, `version` → affichage inline.
  - `--quiet` supporté en premier argument.

- `docker-compose.yml` : trois services.
  - `integrity` : commandes ponctuelles (compute/verify/compare).
  - `pipeline` : exécution de `runner.sh` avec `pipeline.json` monté.
  - `cron` : profil optionnel (`--profile cron`) pour vérification périodique.
  - Section `x-volumes` : chemins à adapter en un seul endroit.

- `.dockerignore` : exclut données, résultats, tests, docs du contexte de build.

- `docs/docker.md` : guide complet — build, commandes, volumes, NAS Synology, cron Debian, taille image, mise à jour b3sum.

### Volumes conventionnels

| Volume conteneur | Usage |
|---|---|
| `/data` | Données à hacher (`:ro` recommandé) |
| `/bases` | Fichiers `.b3` |
| `/pipelines` | Fichiers `pipeline.json` |
| `/resultats` | Résultats compare/verify |

`RESULTATS_DIR=/resultats` est défini par défaut dans l'image.

---

 — Restructuration + rapport HTML compare

### Restructuration du projet

```
hash_tool/
├── runner.sh                  ← inchangé (point d'entrée)
├── src/
│   ├── integrity.sh           ← déplacé depuis la racine
│   └── lib/
│       └── report.sh          ← nouveau, extrait de integrity.sh
├── pipelines/
│   ├── pipeline.json          ← déplacé depuis la racine
│   └── pipeline-full.json     ← renommé depuis "pipeline full.json"
└── reports/
    └── template.html          ← nouveau, barebone HTML de référence
```

Motivations :
- `src/` isole le code des fichiers de configuration et de données.
- `src/lib/` prépare l'extension à d'autres modules (ex. `notify.sh`, `export.sh`).
- `pipelines/` centralise les configurations de pipeline, évite la pollution de la racine.
- `reports/` documente la structure HTML attendue, sert de référence pour la personnalisation.

### Modifié

- `runner.sh`
  - Chemin `INTEGRITY` mis à jour : `$SCRIPT_DIR/src/integrity.sh`.
  - Chemin `CONFIG` par défaut mis à jour : `$SCRIPT_DIR/pipelines/pipeline.json`.
  - `run_compare()` : lecture du champ optionnel `resultats` dans le bloc JSON. Si présent, exporte `RESULTATS_DIR` avec cette valeur pour le seul appel à `integrity.sh compare`. Isolation par sous-shell : le `RESULTATS_DIR` global du processus parent n'est pas modifié.
  - `run_compute()` et `run_verify()` : isolation du `cd` dans un sous-shell `( )` — le répertoire courant ne fuite plus vers les blocs suivants du pipeline.

- `src/integrity.sh`
  - Chargement de `src/lib/report.sh` via `source` au démarrage.
  - `run_compare()` : délègue la génération HTML à `generate_compare_html()` (définie dans `lib/report.sh`).

### Ajouté

- `src/lib/report.sh` : bibliothèque de génération de rapports.
  - `generate_compare_html()` : produit `report.html` autonome (CSS inline, sans dépendance externe) à partir des fichiers `modifies.b3`, `disparus.txt`, `nouveaux.txt`. Thème sombre, police monospace, compteurs par catégorie, badge statut IDENTIQUES / DIFFÉRENCES DÉTECTÉES.

- `reports/template.html` : barebone HTML statique de référence. Documente les placeholders injectés par `generate_compare_html()` et la structure attendue du dossier de résultats.

- `pipeline.json` (et `pipeline-full.json`) : champ optionnel `"resultats"` sur les blocs `compare`.

  ```json
  {
      "op":       "compare",
      "base_a":   "/chemin/hashes_1.b3",
      "base_b":   "/chemin/hashes_2.b3",
      "resultats": "/chemin/vers/dossier_resultats"
  }
  ```

  Sans ce champ, comportement inchangé : résultats dans `RESULTATS_DIR` (défaut `~/integrity_resultats`).

- `tests/run_tests_pipeline.sh` : cas TP10b — vérifie que le champ `resultats` redirige bien les résultats dans le dossier personnalisé et n'écrit rien dans `RESULTATS_DIR` par défaut.

### Couverture tests mise à jour

| Suite | Cas | Description |
|---|---|---|
| `run_tests.sh` | T00–T14 | Inchangée — `INTEGRITY` mis à jour vers `../src/integrity.sh` |
| `run_tests_pipeline.sh` | TP01–TP12 | Inchangée dans la logique |
| `run_tests_pipeline.sh` | **TP10b** | Nouveau — champ `resultats` personnalisé et isolation |

---


## [0.11] — Restructuration + rapport HTML compare

### Restructuration du projet

```
hash_tool/
├── runner.sh                  ← inchangé (point d'entrée)
├── src/
│   ├── integrity.sh           ← déplacé depuis la racine
│   └── lib/
│       └── report.sh          ← nouveau, extrait de integrity.sh
├── pipelines/
│   ├── pipeline.json          ← déplacé depuis la racine
│   └── pipeline-full.json     ← renommé depuis "pipeline full.json"
└── reports/
    └── template.html          ← nouveau, barebone HTML de référence
```

Motivations :
- `src/` isole le code des fichiers de configuration et de données.
- `src/lib/` prépare l'extension à d'autres modules (ex. `notify.sh`, `export.sh`).
- `pipelines/` centralise les configurations de pipeline, évite la pollution de la racine.
- `reports/` documente la structure HTML attendue, sert de référence pour la personnalisation.

### Modifié

- `runner.sh`
  - Chemin `INTEGRITY` mis à jour : `$SCRIPT_DIR/src/integrity.sh`.
  - Chemin `CONFIG` par défaut mis à jour : `$SCRIPT_DIR/pipelines/pipeline.json`.
  - `run_compare()` : lecture du champ optionnel `resultats` dans le bloc JSON. Si présent, exporte `RESULTATS_DIR` avec cette valeur pour le seul appel à `integrity.sh compare`. Isolation par sous-shell : le `RESULTATS_DIR` global du processus parent n'est pas modifié.
  - `run_compute()` et `run_verify()` : isolation du `cd` dans un sous-shell `( )` — le répertoire courant ne fuite plus vers les blocs suivants du pipeline.

- `src/integrity.sh`
  - Chargement de `src/lib/report.sh` via `source` au démarrage.
  - `run_compare()` : délègue la génération HTML à `generate_compare_html()` (définie dans `lib/report.sh`).

### Ajouté

- `src/lib/report.sh` : bibliothèque de génération de rapports.
  - `generate_compare_html()` : produit `report.html` autonome (CSS inline, sans dépendance externe) à partir des fichiers `modifies.b3`, `disparus.txt`, `nouveaux.txt`. Thème sombre, police monospace, compteurs par catégorie, badge statut IDENTIQUES / DIFFÉRENCES DÉTECTÉES.

- `reports/template.html` : barebone HTML statique de référence. Documente les placeholders injectés par `generate_compare_html()` et la structure attendue du dossier de résultats.

- `pipeline.json` (et `pipeline-full.json`) : champ optionnel `"resultats"` sur les blocs `compare`.

  ```json
  {
      "op":       "compare",
      "base_a":   "/chemin/hashes_1.b3",
      "base_b":   "/chemin/hashes_2.b3",
      "resultats": "/chemin/vers/dossier_resultats"
  }
  ```

  Sans ce champ, comportement inchangé : résultats dans `RESULTATS_DIR` (défaut `~/integrity_resultats`).

- `tests/run_tests_pipeline.sh` : cas TP10b — vérifie que le champ `resultats` redirige bien les résultats dans le dossier personnalisé et n'écrit rien dans `RESULTATS_DIR` par défaut.

### Couverture tests mise à jour

| Suite | Cas | Description |
|---|---|---|
| `run_tests.sh` | T00–T14 | Inchangée — `INTEGRITY` mis à jour vers `../src/integrity.sh` |
| `run_tests_pipeline.sh` | TP01–TP12 | Inchangée dans la logique |
| `run_tests_pipeline.sh` | **TP10b** | Nouveau — champ `resultats` personnalisé et isolation |

---



## [0.10] — Pipeline JSON + tests pipeline

### Modifié

- `pipeline.json` (ex `config.txt`) : format migré de la syntaxe custom vers JSON standard. Champ `op` remplace les noms de blocs. Parsé par `jq` — validation syntaxique native, interopérable avec tout outil JSON.
- `runner.sh` : réécriture du parser. Suppression du parser bash custom (`IFS`, regex, `local -n`). Remplacement par `jq` pour l'extraction des champs. Validation JSON en entrée (`jq empty`), détection des champs manquants et des opérations inconnues avec messages d'erreur explicites incluant le numéro de bloc.

### Ajouté

- `tests/run_tests_pipeline.sh` : suite de tests dédiée au pipeline. 12 cas TP01–TP12.

### Format pipeline.json

```json
{
    "pipeline": [
        {
            "op":     "compute",
            "source": "/mnt/a/dossier",
            "bases":  "/mnt/c/bases",
            "nom":    "hashes.b3"
        },
        {
            "op":     "verify",
            "source": "/mnt/a/dossier",
            "base":   "/mnt/c/bases/hashes.b3"
        },
        {
            "op":     "compare",
            "base_a": "/mnt/c/bases/hashes_1.b3",
            "base_b": "/mnt/c/bases/hashes_2.b3"
        }
    ]
}
```

### Couverture run_tests_pipeline.sh

| Cas | Description |
|---|---|
| TP01 | JSON invalide — erreur propre sans stacktrace jq |
| TP02 | Clé `.pipeline` absente |
| TP03 | Champ manquant dans un bloc (`nom`) |
| TP04 | Opération inconnue |
| TP05 | Compute — cd correct, chemins relatifs dans la base, comptage fichiers |
| TP06 | Compute — dossier source absent |
| TP07 | Verify — bon répertoire de travail, OK détecté |
| TP08 | Verify — corruption détectée |
| TP09 | Verify — base .b3 absente |
| TP10 | Compare — fichiers de résultats produits |
| TP11 | Compare — base_a absente |
| TP12 | Pipeline complet compute + verify + compare |

---


## [0.9] — Pipeline batch : runner.sh + config.txt

### Ajouté

- `runner.sh` : exécuteur de pipeline batch. Lit `config.txt`, parse les blocs `compute`, `verify`, `compare` et appelle `integrity.sh` avec les arguments corrects. Gère le `cd` automatique avant chaque `compute` et `verify` pour garantir des chemins relatifs dans les bases `.b3`.
- `config.txt` : déclaration du pipeline au format structuré `pipeline = { ... }`. Chaque opération est un bloc nommé avec des champs `clé = "valeur"`. Supporte les commentaires `#` et les lignes vides.
- `runner.bat` : lanceur Windows pour double-clic depuis le bureau. Appelle `runner.sh` via WSL. Paramètre `pause` final pour garder la fenêtre ouverte.

### Format config.txt

```
pipeline = {

    compute {
        source = "/mnt/a/dossier",
        bases  = "/mnt/c/bases",
        nom    = "hashes.b3"
    }

    verify {
        source = "/mnt/a/dossier",
        base   = "/mnt/c/bases/hashes.b3"
    }

    compare {
        base_a = "/mnt/c/bases/hashes_1.b3",
        base_b = "/mnt/c/bases/hashes_2.b3"
    }

}
```

### Comportement runner.sh

- `compute` : `cd` dans `source`, puis `integrity.sh compute . bases/nom` — chemin relatif garanti.
- `verify` : `cd` dans `source`, puis `integrity.sh verify base` — répertoire de travail correct.
- `compare` : appel direct `integrity.sh compare base_a base_b`.
- Crée `bases/` automatiquement si inexistant (`mkdir -p`).
- `set -e` : arrêt immédiat sur toute erreur.

---

## [0.8] — Fonctionnalité batch_compute.sh

### Ajouté

- `batch_compute.sh` : permet de lancer plusieurs commandes `compute` avec un seul script. Remplacé par `runner.sh` + `config.txt` dans la version 0.9.


---

## [0.7] — Robustesse compare : chemins avec espaces

### Corrigé
- `integrity.sh`
  - Bug critique dans `run_compare()` : `sort -k2,2`, `join -1 2 -2 2` et `awk '{print $2}'` utilisent le blanc comme séparateur de champ. Un chemin contenant des espaces est fragmenté en plusieurs champs, ce qui corrompt le tri, le join et l'extraction — produisant des faux positifs massifs (ex. 26569 modifiés pour 163 fichiers dont 1 seul a changé).
  - Correction : conversion préalable de chaque ligne en `chemin\thash` via `awk '{ print substr($0,67) "\t" substr($0,1,64) }'` — le hash b3sum étant toujours exactement 64 caractères, l'offset 67 est garanti par le format. Toutes les opérations suivantes utilisent `-t $'\t'` comme séparateur explicite : `sort -t $'\t' -k1,1`, `join -t $'\t' -1 1 -2 1`, `cut -f1`.
  - `modifies.b3` : format de sortie préservé (`hash  chemin`) via `awk -F $'\t' '$2 != $3 { print $3 "  " $1 }'`.

## [0.6] — Robustesse et mode silencieux

### Ajouté
- `integrity.sh`
  - Flag `--quiet` : supprime toute sortie terminal, écrit uniquement dans les fichiers de résultats (`recap.txt`, `failed.txt`). Exit code propagé pour usage CI/cron.
  - Fonction `say()` : point d'entrée unique pour toute sortie terminal, désactivée si `--quiet`.
  - Fonction `file_size()` : abstraction portable `stat -c%s` (GNU/Linux) / `stat -f%z` (BSD/macOS).
  - Vérification version bash en tête de script : `bash >= 4` requis, exit explicite avec message si non respecté.
  - `make_result_dir()` : horodatage automatique des dossiers de résultats en cas de collision (`_YYYYMMDD-HHMMSS`), plus d'écrasement silencieux.
  - `trap EXIT` dans `run_compare()` : nettoyage garanti des fichiers temporaires même en cas d'erreur intermédiaire.
  - Redirection ETA sur `/dev/tty` dans `compute_with_progress()` : garantit que la progression n'est jamais écrite dans le fichier `.b3`.
- `tests/run_tests.sh`
  - `set -euo pipefail` : mode strict complet activé (ajout de `-e`).
  - Fonction `assert_file_absent()` : helper dédié pour les assertions d'absence de fichier.
  - T00 : ShellCheck sur `integrity.sh` et `run_tests.sh` (SKIP propre si non installé).
  - T12 : couverture exhaustive du mode `--quiet` (stdout vide, fichiers produits, exit code propagé).
  - T13 : vérifie l'horodatage automatique des dossiers de résultats sur collision.
  - T14 : détection d'un argument `[dossier]` invalide pour `verify`.
- `README.md`
  - Section `--quiet` avec exemples CI/cron.
  - Section Tests avec instructions d'exécution et comptage des cas (14 tests).
  - Mention horodatage automatique dans l'arborescence des résultats.

### Modifié
- `integrity.sh`
  - `assert_target_valid()` : `find -print0 | grep -zc ''` au lieu de `find | wc -l` — robuste aux noms de fichiers contenant des newlines.
  - `run_verify()` : comptage de lignes via `grep -c '^'` au lieu de `grep -c '.'` — correction du bug de comptage sur flux vide.
  - `run_compare()` : `sort -k2,2` au lieu de `sort -k2` — clé de tri limitée strictement au champ chemin, sans déborder sur le hash.
  - `run_verify()` : propagation de l'exit code de `b3sum --check` via `return $exit_code` — utilisable en scripting avec `|| alert`.
  - `failed.txt` : suppression explicite via `rm -f` si `nb_failed == 0` après une vérification OK suivant un échec précédent.
- `tests/run_tests.sh`
  - Résolution dynamique des `outdir` via `ls -d ... | tail -1` : compatible avec l'horodatage des dossiers de résultats.
  - T02, T03, T05, T06, T07 : assertions adaptées à la résolution dynamique des dossiers.
- `README.md`
  - Dépendances : mention explicite de `bash >= 4`.
  - Usage : exemple `--quiet` ajouté.

### Corrigé
- `integrity.sh`
  - Bug comptage lignes dans `run_verify()` : `grep -c '.'` sur flux vide retournait 0 mais ne capturait pas correctement les lignes non vides. Remplacé par `grep -c '^'`.
  - Bug tri ambigü dans `run_compare()` : `sort -k2` triait du champ 2 à la fin de ligne, incluant potentiellement le hash. `sort -k2,2` limite la clé au seul champ 2.
  - Bug nettoyage tmpfiles : `run_compare()` laissait des fichiers temporaires en cas d'erreur intermédiaire. Ajout de `trap 'rm -f ...' EXIT`.
  - Bug portabilité `stat` : `stat -c%s` est GNU-only. Ajout de `file_size()` avec fallback BSD `stat -f%z`.
  - Bug comptage fichiers avec newlines : `assert_target_valid()` utilisait `find | wc -l`. Corrigé avec `find -print0 | grep -zc ''`.
- `tests/run_tests.sh`
  - T10 : pattern `"^/"` remplacé par `"  /"` — `grep` opérait sur une chaîne, l'ancre `^` ne matchait pas la deuxième colonne.

---

## [0.5] — Documentation

### Modifié
- `README.md` — règle répertoire de travail pour `verify` précisée : l'argument `[dossier]` est le répertoire d'origine du compute, pas le dossier haché. Exemples correct/incorrect ajoutés.
- `docs/manuel.md` — section `verify` mise à jour avec le même avertissement et les exemples.

---

## [0.4] — Gardes-fous et signalisation des erreurs

### Modifié
- `integrity.sh`
  - Ajout de `die()` : point de sortie unique pour toutes les erreurs, message sur stderr.
  - Ajout de `assert_b3_valid()` : vérifie existence, type fichier, non-vide, format b3sum valide.
  - Ajout de `assert_target_valid()` : vérifie existence du dossier cible et présence d'au moins un fichier.
  - Validation explicite des arguments dans chaque branche du `case` avant tout traitement.
  - `verify` accepte un argument optionnel `[dossier]` : fait `cd` avant `b3sum --check`.
  - Résolution du chemin absolu du `.b3` avant `cd` (correction bug : chemin relatif invalide après changement de répertoire).
  - `RESULTATS_DIR` : `${RESULTATS_DIR:-...}` au lieu d'assignation inconditionnelle — respecte la valeur exportée par l'environnement (fix tests).
  - Suppression de `local hashfile_abs` hors fonction (illégal en bash hors contexte fonction).
  - `run_verify()` : refonte de la signalisation.
    - Trois états distincts : `OK`, `ECHEC`, `ERREUR`.
    - Terminal : affichage sobre si OK, bloc `████` visible si échec ou erreur.
    - `recap.txt` : compteur `FAILED` affiché uniquement si > 0 ; section erreurs b3sum séparée.
    - `failed.txt` : créé uniquement si `nb_failed > 0` ou erreurs b3sum présentes. Supprimé si tout est OK.
- `tests/run_tests.sh`
  - T02 : assertion `failed.txt absent si 0 échec` (logique inversée par rapport à l'ancienne version).
  - T03 : patterns mis à jour (`ECHEC`, `FAILED`) alignés sur le nouveau format de sortie.

---

## [0.3] — Dossiers de résultats (verify et compare)

### Modifié
- `integrity.sh`
  - Ajout de `RESULTATS_DIR` (configurable, défaut `~/integrity_resultats`).
  - Ajout de `make_result_dir()` : crée `resultats_<nom_base>/` sous `RESULTATS_DIR`.
  - `verify` : délègue à `run_verify()` — produit `recap.txt` et `failed.txt`.
  - `compare` : délègue à `run_compare()` — produit `recap.txt`, `modifies.b3`, `disparus.txt`, `nouveaux.txt`.
  - Fichiers temporaires de `compare` passent par `mktemp` (plus de `/tmp/_old.b3` en dur).
  - Signature `verify` simplifiée : `<base.b3>` uniquement (le dossier n'était pas utilisé par `b3sum --check`).
- `README.md` — usage `verify` et `compare` mis à jour ; section Configuration ajoutée avec arbre des fichiers produits.
- `docs/manuel.md` — sections `verify` et `compare` mises à jour ; arbre de décision et référence rapide alignés.
- `tests/run_tests.sh`
  - `RESULTATS_DIR` exporté vers `WORKDIR` pour isoler les résultats des tests.
  - Ajout de `assert_file_exists()`.
  - T02–T07 : assertions sur la présence et le contenu des fichiers de résultats.

---

## [0.2] — Intégration ETA et tests automatisés

### Modifié
- `integrity.sh`
  - Suppression de `detect_parallelism()` et de la logique SSD/parallélisme (hors périmètre HDD gros volumes).
  - Mode `compute` : délègue à `compute_with_progress()`.
  - Ajout de `compute_with_progress()` : boucle fichier par fichier avec affichage progression et ETA.
    - `mapfile -d ''` remplace `FILES=($(find ...))` — gestion correcte des noms avec espaces.
    - `printf "\r%*s\r"` efface proprement la ligne de progression avant le message final.
  - `df` retiré des dépendances.
- `README.md` — dépendances mises à jour (`df` supprimé, `stat` et `du` ajoutés).
- `docs/manuel.md`
  - Section `detect_parallelism` supprimée.
  - Section `compute` réécrite autour de `compute_with_progress`.
  - Section performances : stratégie SSD/NVMe retirée, focus HDD séquentiel.
- `docs/progression-eta.md` — implémentation finale documentée ; note `mapfile -d ''` vs substitution de commande.
- `tests/run_tests.sh` — T11 ajouté : vérifie que la base produite par `compute_with_progress` est bit-à-bit identique à une base de référence, sans artefact ETA ni `\r`.
- `docs/explication-run-tests.md` — comptage corrigé (10 → 11 cas) ; section T11 ajoutée.

### Corrigé
- `tests/run_tests.sh` T10 : pattern `"^/"` remplacé par `"  /"` — `grep` opère sur une chaîne, pas un fichier, l'ancre `^` ne matchait pas la deuxième colonne.

---

## [0.1] — Structure initiale du projet

### Ajouté
- `integrity.sh` — script principal BLAKE3 avec trois modes : `compute`, `verify`, `compare`.
  - `set -euo pipefail` — mode strict.
  - `detect_parallelism()` — détection SSD/HDD via `/sys/block/.../queue/rotational`.
  - Mode `compute` : pipeline `find | sort -z | xargs b3sum`, parallélisme `-P 4` sur SSD.
  - Mode `verify` : délègue à `b3sum --check`.
  - Mode `compare` : tri sur colonne 2, `join` pour les modifiés, `comm` pour disparus/nouveaux, rapport `tee`.
- `README.md` — point d'entrée : dépendances, usage en 3 commandes, arbre de décision, règles critiques.
- `docs/manuel.md` — référence technique complète : algorithmes, structure `.b3`, workflow, explication du script, performances, limites, référence rapide, annexe FIM.
- `docs/progression-eta.md` — analyse du problème ETA sur pipeline `xargs`, deux approches (`pv` invalide, boucle bash), mécanique de l'estimation, tableau de comparaison des performances.
- `docs/explication-run-tests.md` — documentation du code `run_tests.sh` : chemins, compteurs, assertions, setup/teardown, structure d'un cas de test, prérequis, exit code CI.
- `tests/run_tests.sh` — suite de tests automatisée bash pur, 11 cas T01–T11, isolation via `mktemp`, teardown systématique, exit code CI-compatible.
- `tests/validation.md` — protocole de test manuel : 10 cas T01–T10 avec commandes exactes et résultats attendus, critères de qualité globaux.


--- Fichier : Dockerfile ---
# ─────────────────────────────────────────────────────────────────────────────
# hash_tool — Dockerfile
#
# Image Alpine légère (~15 Mo) avec b3sum et jq.
# Supporte linux/amd64 et linux/arm64 (NAS Synology, Raspberry Pi, etc.)
#
# b3sum est installé depuis les packages Alpine (community) — plus fiable
# que le téléchargement manuel depuis GitHub Releases.
#
# Build :
#   docker build -t hash_tool .
#   docker build --platform linux/arm64 -t hash_tool:arm64 .
#
# Utilisation :
#   docker run --rm -v /mes/donnees:/data hash_tool verify /data/base.b3
#   docker run --rm -v /mes/donnees:/data -v /mes/bases:/bases hash_tool compute /data /bases/hashes.b3
#   docker run --rm -v /chemin/pipeline.json:/pipelines/pipeline.json \
#              -v /mes/donnees:/data -v /mes/bases:/bases -v /mes/resultats:/resultats \
#              hash_tool runner /pipelines/pipeline.json
# ─────────────────────────────────────────────────────────────────────────────

FROM alpine:3.19

LABEL maintainer="hash_tool" \
      description="Vérification d'intégrité BLAKE3 — integrity.sh + runner.sh" \
      org.opencontainers.image.source="https://github.com/hash_tool"

# Toutes les dépendances depuis apk — pas de wget, pas de binaire externe
# b3sum est dans Alpine community depuis v3.15
RUN apk add --no-cache \
      bash \
      jq \
      b3sum \
      coreutils \
      findutils \
    && rm -rf /var/cache/apk/*

# ── Copie des scripts ────────────────────────────────────────────────────────

WORKDIR /app

COPY runner.sh           ./runner.sh
COPY src/integrity.sh    ./src/integrity.sh
COPY src/lib/report.sh   ./src/lib/report.sh

RUN chmod +x runner.sh src/integrity.sh src/lib/report.sh

# ── Entrypoint ───────────────────────────────────────────────────────────────

COPY docker/entrypoint.sh /entrypoint.sh
RUN chmod +x /entrypoint.sh

# ── Volumes ──────────────────────────────────────────────────────────────────
#
# /data       → données à hacher (montage en lecture seule recommandé)
# /bases      → fichiers .b3 (lecture/écriture)
# /pipelines  → fichiers pipeline.json
# /resultats  → résultats compare/verify
#
VOLUME ["/data", "/bases", "/pipelines", "/resultats"]

# RESULTATS_DIR par défaut redirigé vers /resultats (volume monté)
ENV RESULTATS_DIR=/resultats

ENTRYPOINT ["/entrypoint.sh"]
CMD ["help"]

--- Fichier : README.md ---
# integrity.sh — Vérification d'intégrité BLAKE3

Détection de corruption silencieuse et d'erreurs de transfert sur disque, par hachage BLAKE3.

**Dépendances :** `b3sum`, `bash >= 4`, `find`, `sort`, `awk`, `comm`, `join`, `stat`, `du`

---

## Usage

```bash
# Créer une base de hachage pour un dossier
./src/integrity.sh compute ./mon_dossier hashes_2024-01-15.b3

# Vérifier l'intégrité — lancer depuis le répertoire où le compute a été fait
./src/integrity.sh verify hashes_2024-01-15.b3

# Idem depuis un répertoire différent — passer le répertoire de travail d'origine
./src/integrity.sh verify /data/hashes_2024-01-15.b3 /data

# Comparer deux bases → résultats dans $RESULTATS_DIR/
./src/integrity.sh compare hashes_2024-01-15.b3 hashes_2024-02-01.b3

# Mode silencieux pour CI/cron
./src/integrity.sh --quiet verify hashes_2024-01-15.b3
```

---

## Pipeline batch — runner.sh + pipeline.json

Pour lancer plusieurs opérations en une seule commande. Dépendance supplémentaire : `jq`.

```bash
./runner.sh                              # lit pipelines/pipeline.json
./runner.sh /chemin/vers/pipeline.json   # config explicite
```

**Dépendance :** `jq` (`apt install jq`)

### pipelines/pipeline.json

```json
{
    "pipeline": [

        {
            "op":     "compute",
            "source": "/mnt/a/dossier_disque_1",
            "bases":  "/mnt/c/Users/TonNom/Desktop/bases",
            "nom":    "hashes_dossier_1.b3"
        },

        {
            "op":     "verify",
            "source": "/mnt/a/dossier_disque_1",
            "base":   "/mnt/c/Users/TonNom/Desktop/bases/hashes_dossier_1.b3"
        },

        {
            "op":       "compare",
            "base_a":   "/mnt/c/Users/TonNom/Desktop/bases/hashes_dossier_1.b3",
            "base_b":   "/mnt/c/Users/TonNom/Desktop/bases/hashes_dossier_2.b3",
            "resultats": "/mnt/c/Users/TonNom/Desktop/rapports/compare_1_vs_2"
        }

    ]
}
```

Champs par opération :

| `op` | Champs requis | Champs optionnels |
|---|---|---|
| `compute` | `source`, `bases`, `nom` | — |
| `verify` | `source`, `base` | — |
| `compare` | `base_a`, `base_b` | `resultats` — dossier de destination des résultats |

Le champ `resultats` sur `compare` surcharge `RESULTATS_DIR` pour ce seul bloc. Sans ce champ, les résultats sont créés dans `RESULTATS_DIR` (défaut : `~/integrity_resultats`).

### Lancement depuis Windows (double-clic)

```bat
@echo off
wsl bash /mnt/c/Users/TonNom/Desktop/hash_tool/runner.sh
pause
```

---

## Mode `--quiet`

Supprime toute sortie terminal, écrit uniquement dans les fichiers de résultats. Exit code propagé.

```bash
# Hook pre-commit git
./src/integrity.sh --quiet verify base.b3 || { echo "Corruption détectée"; exit 1; }

# Monitoring cron
0 3 * * * /opt/hash_tool/src/integrity.sh --quiet verify /data/base.b3 || mail -s "ALERT" admin@example.com
```

---

## Configuration

`RESULTATS_DIR` dans `src/integrity.sh` définit le dossier racine des résultats (défaut : `~/integrity_resultats`). Peut être surchargé par variable d'environnement, ou par le champ `resultats` dans `pipeline.json` pour un bloc `compare` spécifique.

Chaque exécution `verify` ou `compare` crée un sous-dossier horodaté si le dossier existe déjà :

```
<resultats>/
└── resultats_hashes_2024-01-15/
    ├── recap.txt
    ├── failed.txt        ← verify uniquement, absent si 0 échec
    ├── modifies.b3       ← compare uniquement
    ├── disparus.txt      ← compare uniquement
    ├── nouveaux.txt      ← compare uniquement
    └── report.html       ← compare uniquement, rapport visuel
```

---

## Structure du projet

```
hash_tool/
├── runner.sh                      ← point d'entrée pipeline
├── README.md
├── CHANGELOG.md
├── src/
│   ├── integrity.sh               ← script principal (compute / verify / compare)
│   └── lib/
│       └── report.sh              ← génération rapports (HTML)
├── pipelines/
│   ├── pipeline.json              ← pipeline de test local
│   └── pipeline-full.json         ← pipeline VeraCrypt multi-disques
├── reports/
│   └── template.html              ← barebone HTML de référence
├── docs/
│   ├── manuel.md
│   ├── progression-eta.md
│   └── explication-run-tests.md
└── tests/
    ├── run_tests.sh               ← tests integrity.sh (T00–T14)
    ├── run_tests_pipeline.sh      ← tests runner.sh (TP01–TP12b)
    └── validation.md
```

---

## Règles d'utilisation critiques

- **Chemins relatifs** dans les bases `.b3`. `runner.sh` gère le `cd` automatiquement.
- **Répertoire de travail** : lancer `verify` depuis le même répertoire qu'au `compute`, ou passer ce répertoire en second argument.
- **Stockage séparé** : stocker les `.b3` sur un support distinct des données — sur VeraCrypt, stocker sur `C:`.
- **Nommage daté** : `hashes_2024-01-15.b3`, jamais `hashes_latest.b3`.

---

## Docker

Aucune dépendance à installer sur l'hôte. Fonctionne sur Windows, NAS Synology, serveur Debian.

```bash
# Build
docker build -t hash_tool .

# Compute
docker run --rm -v /mes/donnees:/data:ro -v /mes/bases:/bases \
  hash_tool compute /data /bases/hashes_$(date +%Y-%m-%d).b3

# Verify
docker run --rm -v /mes/donnees:/data:ro -v /mes/bases:/bases:ro \
  -v /mes/resultats:/resultats \
  hash_tool verify /bases/hashes.b3 /data

# Compare
docker run --rm -v /mes/bases:/bases:ro -v /mes/resultats:/resultats \
  hash_tool compare /bases/old.b3 /bases/new.b3

# Pipeline complet
docker run --rm \
  -v /mes/donnees:/data:ro -v /mes/bases:/bases \
  -v /mes/resultats:/resultats \
  -v /chemin/pipeline.json:/pipelines/pipeline.json:ro \
  hash_tool runner
```

Voir `docs/docker.md` pour la documentation complète (NAS, cron, ARM64, Compose).

---

## Tests

```bash
# Tests integrity.sh
cd tests && ./run_tests.sh

# Tests runner.sh + pipeline.json
cd tests && ./run_tests_pipeline.sh

# Avec ShellCheck (recommandé)
apt install shellcheck && ./run_tests.sh
```

- `run_tests.sh` : 15 cas T00–T14
- `run_tests_pipeline.sh` : 13 cas TP01–TP12b (dont TP10b : champ `resultats` personnalisé)

---

## Arbre de décision

| Situation | Commande |
|---|---|
| Première indexation | `compute` |
| Vérifier après transfert / stockage | `verify` |
| Comparer deux snapshots | `compare` |
| Pipeline multi-dossiers / VeraCrypt | `runner.sh` + `pipeline.json` |
| Contrôle ad hoc d'un fichier unique | `b3sum fichier.bin` |
| Intégration CI/cron | `--quiet verify` |


--- Fichier : docker-compose.yml ---
# docker-compose.yml — hash_tool
#
# Cas d'usage typiques :
#   docker compose run --rm integrity compute /data /bases/hashes.b3
#   docker compose run --rm integrity verify  /bases/hashes.b3 /data
#   docker compose run --rm integrity compare /bases/old.b3 /bases/new.b3
#   docker compose run --rm pipeline
#
# Adapter les volumes (section x-volumes) selon l'environnement :
#   - Windows/WSL   : /mnt/c/Users/TonNom/...
#   - NAS Synology  : /volume1/...
#   - Serveur Debian: /srv/...

# ── Chemins à adapter ────────────────────────────────────────────────────────
x-volumes:
  data:      &vol-data      /chemin/vers/donnees     # données à hacher (lecture seule)
  bases:     &vol-bases     /chemin/vers/bases        # fichiers .b3
  pipelines: &vol-pipelines /chemin/vers/pipelines   # fichiers pipeline.json
  resultats: &vol-resultats /chemin/vers/resultats   # résultats compare/verify

# ── Services ─────────────────────────────────────────────────────────────────
services:

  # Service principal — compute / verify / compare
  integrity:
    image: hash_tool
    build:
      context: .
      dockerfile: Dockerfile
    volumes:
      - *vol-data:/data:ro
      - *vol-bases:/bases
      - *vol-resultats:/resultats
    environment:
      - RESULTATS_DIR=/resultats
    # Pas de commande par défaut — passer la commande à docker compose run
    # Ex : docker compose run --rm integrity verify /bases/hashes.b3 /data

  # Service pipeline — exécute runner.sh avec pipeline.json monté
  pipeline:
    image: hash_tool
    build:
      context: .
      dockerfile: Dockerfile
    volumes:
      - *vol-data:/data:ro
      - *vol-bases:/bases
      - *vol-pipelines:/pipelines
      - *vol-resultats:/resultats
    environment:
      - RESULTATS_DIR=/resultats
    command: ["runner", "/pipelines/pipeline.json"]

  # Service cron — vérification périodique (optionnel)
  # Nécessite : docker compose up -d cron
  cron:
    image: hash_tool
    build:
      context: .
      dockerfile: Dockerfile
    volumes:
      - *vol-data:/data:ro
      - *vol-bases:/bases:ro
      - *vol-resultats:/resultats
    environment:
      - RESULTATS_DIR=/resultats
      - CRON_SCHEDULE=0 3 * * *       # 03h00 chaque nuit
      - CRON_BASE=/bases/hashes.b3    # base à vérifier
    # Le service cron tourne en boucle — nécessite l'image étendue avec crond
    # Voir docs/docker-cron.md pour le setup complet
    command: ["shell"]
    profiles: ["cron"]   # non démarré par défaut (docker compose --profile cron up)
    restart: unless-stopped


--- Fichier : runner.sh ---
#!/usr/bin/env bash
# runner.sh — Exécuteur de pipeline integrity.sh depuis pipeline.json
#
# Usage :
#   ./runner.sh                          # lit pipelines/pipeline.json
#   ./runner.sh /chemin/pipeline.json    # config explicite
#
# Dépendances : bash >= 4, jq, src/integrity.sh

set -euo pipefail

# ── Chemins ───────────────────────────────────────────────────────────────────

SCRIPT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"
INTEGRITY="$SCRIPT_DIR/src/integrity.sh"
CONFIG="${1:-$SCRIPT_DIR/pipelines/pipeline.json}"

# ── Prérequis ─────────────────────────────────────────────────────────────────

(( BASH_VERSINFO[0] >= 4 )) || { echo "ERREUR : bash >= 4 requis" >&2; exit 1; }

command -v jq &>/dev/null  || { echo "ERREUR : jq non trouvé (apt install jq)" >&2; exit 1; }
[ -f "$INTEGRITY" ]        || { echo "ERREUR : src/integrity.sh introuvable : $INTEGRITY" >&2; exit 1; }
[ -f "$CONFIG" ]           || { echo "ERREUR : config introuvable : $CONFIG" >&2; exit 1; }

# ── Validation JSON ───────────────────────────────────────────────────────────

jq empty "$CONFIG" 2>/dev/null || { echo "ERREUR : JSON invalide : $CONFIG" >&2; exit 1; }

nb_ops=$(jq '.pipeline | length' "$CONFIG")
(( nb_ops > 0 )) || { echo "ERREUR : tableau .pipeline vide ou absent" >&2; exit 1; }

# ── Fonctions utilitaires ─────────────────────────────────────────────────────

die() { echo "ERREUR : $*" >&2; exit 1; }

# Lit un champ JSON obligatoire — exit si absent ou null
require_field() {
  local idx="$1" field="$2"
  local val
  val=$(jq -r --argjson i "$idx" '.pipeline[$i].'"$field" "$CONFIG")
  [ "$val" != "null" ] && [ -n "$val" ] || die "Bloc #$((idx+1)) : champ '$field' manquant ou vide."
  echo "$val"
}

# Lit un champ JSON optionnel — retourne "" si absent
optional_field() {
  local idx="$1" field="$2"
  local val
  val=$(jq -r --argjson i "$idx" '.pipeline[$i].'"$field // empty" "$CONFIG" 2>/dev/null || true)
  echo "${val:-}"
}

# ── Opérations ────────────────────────────────────────────────────────────────

run_compute() {
  local i="$1"
  local source bases nom
  source=$(require_field "$i" "source")
  bases=$(require_field "$i" "bases")
  nom=$(require_field "$i" "nom")

  echo "=== COMPUTE : $source ==="
  [ -d "$source" ] || die "Bloc #$((i+1)) compute : dossier source introuvable : $source"

  mkdir -p "$bases"
  local bases_abs
  bases_abs="$(cd "$bases" && pwd)"
  # Sous-shell : le cd ne fuite pas vers les blocs suivants
  ( cd "$source" && "$INTEGRITY" compute . "$bases_abs/$nom" )
}

run_verify() {
  local i="$1"
  local source base
  source=$(require_field "$i" "source")
  base=$(require_field "$i" "base")

  echo "=== VERIFY : $source ==="
  [ -d "$source" ] || die "Bloc #$((i+1)) verify : dossier source introuvable : $source"
  [ -f "$base" ]   || die "Bloc #$((i+1)) verify : base .b3 introuvable : $base"

  local base_abs
  base_abs="$(cd "$(dirname "$base")" && pwd)/$(basename "$base")"
  ( cd "$source" && "$INTEGRITY" verify "$base_abs" )
}

run_compare() {
  local i="$1"
  local base_a base_b
  base_a=$(require_field "$i" "base_a")
  base_b=$(require_field "$i" "base_b")

  echo "=== COMPARE : $(basename "$base_a") vs $(basename "$base_b") ==="
  [ -f "$base_a" ] || die "Bloc #$((i+1)) compare : base_a introuvable : $base_a"
  [ -f "$base_b" ] || die "Bloc #$((i+1)) compare : base_b introuvable : $base_b"

  # Champ optionnel "resultats" : surcharge RESULTATS_DIR pour ce bloc uniquement
  local resultats_dir
  resultats_dir=$(optional_field "$i" "resultats")

  if [ -n "$resultats_dir" ]; then
    mkdir -p "$resultats_dir"
    local resultats_abs
    resultats_abs="$(cd "$resultats_dir" && pwd)"
    echo "    → résultats dans : $resultats_abs"
    RESULTATS_DIR="$resultats_abs" "$INTEGRITY" compare "$base_a" "$base_b"
  else
    "$INTEGRITY" compare "$base_a" "$base_b"
  fi
}

# ── Main ──────────────────────────────────────────────────────────────────────

echo "=== PIPELINE DÉMARRÉ : $(date) ==="
echo "=== Config : $CONFIG ($nb_ops opération(s)) ==="
echo ""

for (( i=0; i<nb_ops; i++ )); do
  op=$(jq -r --argjson i "$i" '.pipeline[$i].op' "$CONFIG")
  [ "$op" != "null" ] && [ -n "$op" ] || die "Bloc #$((i+1)) : champ 'op' manquant."

  case "$op" in
    compute) run_compute "$i" ;;
    verify)  run_verify  "$i" ;;
    compare) run_compare "$i" ;;
    *)       die "Bloc #$((i+1)) : opération inconnue : '$op'" ;;
  esac

  echo ""
done

echo "=== PIPELINE TERMINÉ : $(date) ==="

--- Fichier : temp.txt ---


bash ./integrity.sh compute "/media/veracrypt1/partition_laptop/a ranger" hash_1.b3

bash ./integrity.sh compare hash_1.b3 hash_2.b3



--- Fichier : mon_dossier/destination/fichier (1).txt ---
Contrary to popular belief, Lorem Ipsum is not simply random text. It has roots in a piece of classical Latin literature from 45 BC, making it over 2000 years old. Richard McClintock, a Latin professor at Hampden-Sydney College in Virginia, looked up one of the more obscure Latin words, consectetur, from a Lorem Ipsum passage, and going through the cites of the word in classical literature, discovered the undoubtable source. Lorem Ipsum comes from sections 1.10.32 and 1.10.33 of "de Finibus Bonorum et Malorum" (The Extremes of Good and Evil) by Cicero, written in 45 BC. This book is a treatise on the theory of ethics, very popular during the Renaissance. The first line of Lorem Ipsum, "Lorem ipsum dolor sit amet..", comes from a line in section 1.10.32.



--- Fichier : mon_dossier/destination/fichier (2).txt ---
There are many variations of passages of Lorem Ipsum available, but the majority have suffered alteration in some form, by injected humour, or randomised words which don't look even slightly believable. If you are going to use a passage of Lorem Ipsum, you need to be sure there isn't anything embarrassing hidden in the middle of text. All the Lorem Ipsum generators on the Internet tend to repeat predefined chunks as necessary, making this the first true generator on the Internet. It uses a dictionary of over 200 Latin words, combined with a handful of model sentence structures, to generate Lorem Ipsum which looks reasonable. The generated Lorem Ipsum is therefore always free from repetition, injected humour, or non-characteristic words etc.



--- Fichier : mon_dossier/destination/fichier (3).txt ---
Lorem Ipsum is simply dummy text of the printing and typesetting industry. Lorem Ipsum has been the industry's standard dummy text ever since the 1500s, when an unknown printer took a galley of type and scrambled it to make a type specimen book. It has survived not only five centuries, but also the leap into electronic typesetting, remaining essentially unchanged. It was popularised in the 1960s with the release of Letraset sheets containing Lorem Ipsum passages, and more recently with desktop publishing software like Aldus PageMaker including versions of Lorem Ipsum.



--- Fichier : mon_dossier/destination/fichier (4).txt ---
It is a long established fact that a reader will be distracted by the readable content of a page when looking at its layout. The point of using Lorem Ipsum is that it has a more-or-less normal distribution of letters, as opposed to using 'Content here, content here', making it look like readable English. Many desktop publishing packages and web page editors now use Lorem Ipsum as their default model text, and a search for 'lorem ipsum' will uncover many web sites still in their infancy. Various versions have evolved over the years, sometimes by accident, sometimes on purpose (injected humour and the like).



--- Fichier : mon_dossier/result/resultats_hashes_dossier_1_20260222-100613/disparus.txt ---


--- Fichier : mon_dossier/result/resultats_hashes_dossier_1_20260222-100613/nouveaux.txt ---


--- Fichier : mon_dossier/result/resultats_hashes_dossier_1_20260222-100613/recap.txt ---
Commande      : integrity.sh compare hashes_dossier_1.b3 hashes_dossier_2.b3
Date          : dim. 22 févr. 2026 10:06:13 CET
Ancienne base : ./mon_dossier/bases/hashes_dossier_1.b3
Nouvelle base : ./mon_dossier/bases/hashes_dossier_2.b3

Modifiés      : 1
Disparus      : 0
Nouveaux      : 0


--- Fichier : mon_dossier/result/resultats_hashes_dossier_1_20260222-100613/report.html ---
<!DOCTYPE html>
<html lang="fr">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Rapport — hashes_dossier_1.b3 vs hashes_dossier_2.b3</title>
  <style>
    /* ── Tokens ──────────────────────────────────────────────────── */
    :root {
      --bg:          #0f1117;
      --bg-card:     #161b27;
      --bg-card-alt: #1c2233;
      --border:      #252d3f;
      --border-glow: #2e3d5a;
      --text:        #c8d4e8;
      --text-dim:    #5a6a85;
      --text-head:   #e8eef8;
      --mono:        'JetBrains Mono', 'Fira Code', 'Cascadia Code', monospace;
      --sans:        'DM Sans', 'Outfit', system-ui, sans-serif;
      --accent-ok:   #22c55e;
      --accent-diff: #f59e0b;
      --accent-mod:  #e879f9;
      --accent-dis:  #f87171;
      --accent-nou:  #34d399;
      --radius:      8px;
      --radius-lg:   14px;
    }

    /* ── Reset & base ─────────────────────────────────────────────── */
    *, *::before, *::after { box-sizing: border-box; margin: 0; padding: 0; }

    @import url('https://fonts.googleapis.com/css2?family=DM+Sans:wght@300;400;500;600&family=JetBrains+Mono:wght@400;500&display=swap');

    body {
      background: var(--bg);
      color: var(--text);
      font-family: var(--sans);
      font-size: 14px;
      line-height: 1.6;
      min-height: 100vh;
      padding: 0 0 64px;
    }

    /* ── Header ───────────────────────────────────────────────────── */
    .header {
      background: var(--bg-card);
      border-bottom: 1px solid var(--border);
      padding: 28px 40px 24px;
      display: flex;
      align-items: flex-start;
      justify-content: space-between;
      gap: 24px;
    }

    .header-left h1 {
      font-family: var(--mono);
      font-size: 13px;
      font-weight: 500;
      color: var(--text-dim);
      letter-spacing: .08em;
      text-transform: uppercase;
      margin-bottom: 8px;
    }

    .bases-compare {
      display: flex;
      align-items: center;
      gap: 12px;
      flex-wrap: wrap;
    }

    .base-name {
      font-family: var(--mono);
      font-size: 14px;
      font-weight: 500;
      color: var(--text-head);
      background: var(--bg-card-alt);
      border: 1px solid var(--border-glow);
      border-radius: var(--radius);
      padding: 5px 12px;
    }

    .arrow {
      color: var(--text-dim);
      font-size: 16px;
    }

    .meta {
      font-size: 12px;
      color: var(--text-dim);
      margin-top: 10px;
      font-family: var(--mono);
    }

    /* ── Status badge ─────────────────────────────────────────────── */
    .status-badge {
      font-family: var(--mono);
      font-size: 11px;
      font-weight: 500;
      letter-spacing: .1em;
      text-transform: uppercase;
      padding: 6px 14px;
      border-radius: 100px;
      border: 1px solid;
      white-space: nowrap;
      align-self: flex-start;
      margin-top: 4px;
    }

    .status-ok   { color: var(--accent-ok);   border-color: var(--accent-ok);   background: rgba(34,197,94,.08);  }
    .status-diff { color: var(--accent-diff);  border-color: var(--accent-diff); background: rgba(245,158,11,.08); }

    /* ── Stats bar ────────────────────────────────────────────────── */
    .stats-bar {
      display: grid;
      grid-template-columns: repeat(3, 1fr);
      gap: 1px;
      background: var(--border);
      border-bottom: 1px solid var(--border);
    }

    .stat {
      background: var(--bg-card);
      padding: 20px 32px;
      display: flex;
      flex-direction: column;
      gap: 4px;
    }

    .stat-label {
      font-size: 11px;
      letter-spacing: .08em;
      text-transform: uppercase;
      color: var(--text-dim);
    }

    .stat-value {
      font-family: var(--mono);
      font-size: 28px;
      font-weight: 500;
      line-height: 1;
    }

    .stat-modifies .stat-value { color: var(--accent-mod); }
    .stat-disparus .stat-value { color: var(--accent-dis); }
    .stat-nouveaux .stat-value { color: var(--accent-nou); }

    /* ── Sections ─────────────────────────────────────────────────── */
    .main {
      max-width: 1100px;
      margin: 0 auto;
      padding: 36px 40px 0;
      display: grid;
      gap: 20px;
    }

    .section {
      background: var(--bg-card);
      border: 1px solid var(--border);
      border-radius: var(--radius-lg);
      overflow: hidden;
    }

    .section-header {
      display: flex;
      align-items: center;
      gap: 10px;
      padding: 14px 20px;
      border-bottom: 1px solid var(--border);
    }

    .section-dot {
      width: 8px;
      height: 8px;
      border-radius: 50%;
      flex-shrink: 0;
    }

    .section-modifies .section-dot { background: var(--accent-mod); }
    .section-disparus .section-dot { background: var(--accent-dis); }
    .section-nouveaux .section-dot { background: var(--accent-nou); }

    .section-title {
      font-size: 12px;
      font-weight: 600;
      letter-spacing: .06em;
      text-transform: uppercase;
      color: var(--text-head);
    }

    .section-count {
      margin-left: auto;
      font-family: var(--mono);
      font-size: 12px;
      color: var(--text-dim);
      background: var(--bg-card-alt);
      border: 1px solid var(--border);
      border-radius: 100px;
      padding: 2px 10px;
    }

    .section-body {
      padding: 16px 20px;
    }

    .section-body ul {
      list-style: none;
      display: flex;
      flex-direction: column;
      gap: 4px;
    }

    .section-body li {
      padding: 6px 10px;
      border-radius: var(--radius);
      background: var(--bg-card-alt);
      border: 1px solid transparent;
      transition: border-color .15s;
    }

    .section-body li:hover {
      border-color: var(--border-glow);
    }

    .section-body code {
      font-family: var(--mono);
      font-size: 12px;
      color: var(--text);
      word-break: break-all;
    }

    .empty {
      font-style: italic;
      color: var(--text-dim);
      font-size: 13px;
      padding: 4px 0;
    }

    /* ── Footer ───────────────────────────────────────────────────── */
    .footer {
      text-align: center;
      padding-top: 40px;
      font-size: 11px;
      color: var(--text-dim);
      font-family: var(--mono);
    }

    @media (max-width: 680px) {
      .header        { padding: 20px; flex-direction: column; }
      .stats-bar     { grid-template-columns: 1fr; }
      .main          { padding: 20px; }
    }
  </style>
</head>
<body>

  <!-- ── En-tête ──────────────────────────────────────────────────────── -->
  <header class="header">
    <div class="header-left">
      <h1>Rapport de comparaison — hash_tool</h1>
      <div class="bases-compare">
        <span class="base-name">hashes_dossier_1.b3</span>
        <span class="arrow">→</span>
        <span class="base-name">hashes_dossier_2.b3</span>
      </div>
      <div class="meta">Généré le 2026-02-22 10:06:13</div>
    </div>
    <div class="status-badge status-diff">DIFFÉRENCES DÉTECTÉES</div>
  </header>

  <!-- ── Compteurs ────────────────────────────────────────────────────── -->
  <div class="stats-bar">
    <div class="stat stat-modifies">
      <span class="stat-label">Modifiés</span>
      <span class="stat-value">1</span>
    </div>
    <div class="stat stat-disparus">
      <span class="stat-label">Disparus</span>
      <span class="stat-value">0</span>
    </div>
    <div class="stat stat-nouveaux">
      <span class="stat-label">Nouveaux</span>
      <span class="stat-value">0</span>
    </div>
  </div>

  <!-- ── Listes ───────────────────────────────────────────────────────── -->
  <main class="main">

    <div class="section section-modifies">
      <div class="section-header">
        <div class="section-dot"></div>
        <span class="section-title">Fichiers modifiés</span>
        <span class="section-count">1</span>
      </div>
      <div class="section-body">
    <ul>
      <li><code>./fichier (1).txt</code></li>
    </ul>
      </div>
    </div>

    <div class="section section-disparus">
      <div class="section-header">
        <div class="section-dot"></div>
        <span class="section-title">Fichiers disparus</span>
        <span class="section-count">0</span>
      </div>
      <div class="section-body">
    <p class="empty">Aucun fichier disparu</p>
      </div>
    </div>

    <div class="section section-nouveaux">
      <div class="section-header">
        <div class="section-dot"></div>
        <span class="section-title">Nouveaux fichiers</span>
        <span class="section-count">0</span>
      </div>
      <div class="section-body">
    <p class="empty">Aucun nouveau fichier</p>
      </div>
    </div>

  </main>

  <footer class="footer">
    integrity.sh · BLAKE3 · 2026-02-22 10:06:13
  </footer>

</body>
</html>


--- Fichier : mon_dossier/result/resultats_hashes_dossier_1/disparus.txt ---


--- Fichier : mon_dossier/result/resultats_hashes_dossier_1/nouveaux.txt ---


--- Fichier : mon_dossier/result/resultats_hashes_dossier_1/recap.txt ---
Commande      : integrity.sh compare hashes_dossier_1.b3 hashes_dossier_2.b3
Date          : dim. 22 févr. 2026 10:05:31 CET
Ancienne base : ./mon_dossier/bases/hashes_dossier_1.b3
Nouvelle base : ./mon_dossier/bases/hashes_dossier_2.b3

Modifiés      : 4
Disparus      : 0
Nouveaux      : 0


--- Fichier : mon_dossier/result/resultats_hashes_dossier_1/report.html ---
<!DOCTYPE html>
<html lang="fr">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Rapport — hashes_dossier_1.b3 vs hashes_dossier_2.b3</title>
  <style>
    /* ── Tokens ──────────────────────────────────────────────────── */
    :root {
      --bg:          #0f1117;
      --bg-card:     #161b27;
      --bg-card-alt: #1c2233;
      --border:      #252d3f;
      --border-glow: #2e3d5a;
      --text:        #c8d4e8;
      --text-dim:    #5a6a85;
      --text-head:   #e8eef8;
      --mono:        'JetBrains Mono', 'Fira Code', 'Cascadia Code', monospace;
      --sans:        'DM Sans', 'Outfit', system-ui, sans-serif;
      --accent-ok:   #22c55e;
      --accent-diff: #f59e0b;
      --accent-mod:  #e879f9;
      --accent-dis:  #f87171;
      --accent-nou:  #34d399;
      --radius:      8px;
      --radius-lg:   14px;
    }

    /* ── Reset & base ─────────────────────────────────────────────── */
    *, *::before, *::after { box-sizing: border-box; margin: 0; padding: 0; }

    @import url('https://fonts.googleapis.com/css2?family=DM+Sans:wght@300;400;500;600&family=JetBrains+Mono:wght@400;500&display=swap');

    body {
      background: var(--bg);
      color: var(--text);
      font-family: var(--sans);
      font-size: 14px;
      line-height: 1.6;
      min-height: 100vh;
      padding: 0 0 64px;
    }

    /* ── Header ───────────────────────────────────────────────────── */
    .header {
      background: var(--bg-card);
      border-bottom: 1px solid var(--border);
      padding: 28px 40px 24px;
      display: flex;
      align-items: flex-start;
      justify-content: space-between;
      gap: 24px;
    }

    .header-left h1 {
      font-family: var(--mono);
      font-size: 13px;
      font-weight: 500;
      color: var(--text-dim);
      letter-spacing: .08em;
      text-transform: uppercase;
      margin-bottom: 8px;
    }

    .bases-compare {
      display: flex;
      align-items: center;
      gap: 12px;
      flex-wrap: wrap;
    }

    .base-name {
      font-family: var(--mono);
      font-size: 14px;
      font-weight: 500;
      color: var(--text-head);
      background: var(--bg-card-alt);
      border: 1px solid var(--border-glow);
      border-radius: var(--radius);
      padding: 5px 12px;
    }

    .arrow {
      color: var(--text-dim);
      font-size: 16px;
    }

    .meta {
      font-size: 12px;
      color: var(--text-dim);
      margin-top: 10px;
      font-family: var(--mono);
    }

    /* ── Status badge ─────────────────────────────────────────────── */
    .status-badge {
      font-family: var(--mono);
      font-size: 11px;
      font-weight: 500;
      letter-spacing: .1em;
      text-transform: uppercase;
      padding: 6px 14px;
      border-radius: 100px;
      border: 1px solid;
      white-space: nowrap;
      align-self: flex-start;
      margin-top: 4px;
    }

    .status-ok   { color: var(--accent-ok);   border-color: var(--accent-ok);   background: rgba(34,197,94,.08);  }
    .status-diff { color: var(--accent-diff);  border-color: var(--accent-diff); background: rgba(245,158,11,.08); }

    /* ── Stats bar ────────────────────────────────────────────────── */
    .stats-bar {
      display: grid;
      grid-template-columns: repeat(3, 1fr);
      gap: 1px;
      background: var(--border);
      border-bottom: 1px solid var(--border);
    }

    .stat {
      background: var(--bg-card);
      padding: 20px 32px;
      display: flex;
      flex-direction: column;
      gap: 4px;
    }

    .stat-label {
      font-size: 11px;
      letter-spacing: .08em;
      text-transform: uppercase;
      color: var(--text-dim);
    }

    .stat-value {
      font-family: var(--mono);
      font-size: 28px;
      font-weight: 500;
      line-height: 1;
    }

    .stat-modifies .stat-value { color: var(--accent-mod); }
    .stat-disparus .stat-value { color: var(--accent-dis); }
    .stat-nouveaux .stat-value { color: var(--accent-nou); }

    /* ── Sections ─────────────────────────────────────────────────── */
    .main {
      max-width: 1100px;
      margin: 0 auto;
      padding: 36px 40px 0;
      display: grid;
      gap: 20px;
    }

    .section {
      background: var(--bg-card);
      border: 1px solid var(--border);
      border-radius: var(--radius-lg);
      overflow: hidden;
    }

    .section-header {
      display: flex;
      align-items: center;
      gap: 10px;
      padding: 14px 20px;
      border-bottom: 1px solid var(--border);
    }

    .section-dot {
      width: 8px;
      height: 8px;
      border-radius: 50%;
      flex-shrink: 0;
    }

    .section-modifies .section-dot { background: var(--accent-mod); }
    .section-disparus .section-dot { background: var(--accent-dis); }
    .section-nouveaux .section-dot { background: var(--accent-nou); }

    .section-title {
      font-size: 12px;
      font-weight: 600;
      letter-spacing: .06em;
      text-transform: uppercase;
      color: var(--text-head);
    }

    .section-count {
      margin-left: auto;
      font-family: var(--mono);
      font-size: 12px;
      color: var(--text-dim);
      background: var(--bg-card-alt);
      border: 1px solid var(--border);
      border-radius: 100px;
      padding: 2px 10px;
    }

    .section-body {
      padding: 16px 20px;
    }

    .section-body ul {
      list-style: none;
      display: flex;
      flex-direction: column;
      gap: 4px;
    }

    .section-body li {
      padding: 6px 10px;
      border-radius: var(--radius);
      background: var(--bg-card-alt);
      border: 1px solid transparent;
      transition: border-color .15s;
    }

    .section-body li:hover {
      border-color: var(--border-glow);
    }

    .section-body code {
      font-family: var(--mono);
      font-size: 12px;
      color: var(--text);
      word-break: break-all;
    }

    .empty {
      font-style: italic;
      color: var(--text-dim);
      font-size: 13px;
      padding: 4px 0;
    }

    /* ── Footer ───────────────────────────────────────────────────── */
    .footer {
      text-align: center;
      padding-top: 40px;
      font-size: 11px;
      color: var(--text-dim);
      font-family: var(--mono);
    }

    @media (max-width: 680px) {
      .header        { padding: 20px; flex-direction: column; }
      .stats-bar     { grid-template-columns: 1fr; }
      .main          { padding: 20px; }
    }
  </style>
</head>
<body>

  <!-- ── En-tête ──────────────────────────────────────────────────────── -->
  <header class="header">
    <div class="header-left">
      <h1>Rapport de comparaison — hash_tool</h1>
      <div class="bases-compare">
        <span class="base-name">hashes_dossier_1.b3</span>
        <span class="arrow">→</span>
        <span class="base-name">hashes_dossier_2.b3</span>
      </div>
      <div class="meta">Généré le 2026-02-22 10:05:32</div>
    </div>
    <div class="status-badge status-diff">DIFFÉRENCES DÉTECTÉES</div>
  </header>

  <!-- ── Compteurs ────────────────────────────────────────────────────── -->
  <div class="stats-bar">
    <div class="stat stat-modifies">
      <span class="stat-label">Modifiés</span>
      <span class="stat-value">4</span>
    </div>
    <div class="stat stat-disparus">
      <span class="stat-label">Disparus</span>
      <span class="stat-value">0</span>
    </div>
    <div class="stat stat-nouveaux">
      <span class="stat-label">Nouveaux</span>
      <span class="stat-value">0</span>
    </div>
  </div>

  <!-- ── Listes ───────────────────────────────────────────────────────── -->
  <main class="main">

    <div class="section section-modifies">
      <div class="section-header">
        <div class="section-dot"></div>
        <span class="section-title">Fichiers modifiés</span>
        <span class="section-count">4</span>
      </div>
      <div class="section-body">
    <ul>
      <li><code>./fichier (1).txt</code></li>
      <li><code>./fichier (1).txt</code></li>
      <li><code>./fichier (1).txt</code></li>
      <li><code>./fichier (1).txt</code></li>
    </ul>
      </div>
    </div>

    <div class="section section-disparus">
      <div class="section-header">
        <div class="section-dot"></div>
        <span class="section-title">Fichiers disparus</span>
        <span class="section-count">0</span>
      </div>
      <div class="section-body">
    <p class="empty">Aucun fichier disparu</p>
      </div>
    </div>

    <div class="section section-nouveaux">
      <div class="section-header">
        <div class="section-dot"></div>
        <span class="section-title">Nouveaux fichiers</span>
        <span class="section-count">0</span>
      </div>
      <div class="section-body">
    <p class="empty">Aucun nouveau fichier</p>
      </div>
    </div>

  </main>

  <footer class="footer">
    integrity.sh · BLAKE3 · 2026-02-22 10:05:32
  </footer>

</body>
</html>


--- Fichier : mon_dossier/source/fichier (1).txt ---
Contrary to popular belief, Lorem Ipsum is not simply random text. It has roots in a piece of classical Latin literature from 45 BC, making it over 2000 years old. Richard McClintock, a Latin professor at Hampden-Sydney College in Virginia, looked up one of the more obscure Latin words, consectetur, from a Lorem Ipsum passage, and going through the cites of the word in classical literature, discovered the undoubtable source. Lorem Ipsum comes from sections 1.10.32 and 1.10.33 of "de Finibus Bonorum et Malorum" (The Extremes of Good and Evil) by Cicero, written in 45 BC. This book is a treatise on the theory of ethics, very popular during the Renaissance. The first line of Lorem Ipsum, "Lorem ipsum dolor sit amet..", comes from a line in section 1.10.32.

fichier modifié



--- Fichier : mon_dossier/source/fichier (2).txt ---
There are many variations of passages of Lorem Ipsum available, but the majority have suffered alteration in some form, by injected humour, or randomised words which don't look even slightly believable. If you are going to use a passage of Lorem Ipsum, you need to be sure there isn't anything embarrassing hidden in the middle of text. All the Lorem Ipsum generators on the Internet tend to repeat predefined chunks as necessary, making this the first true generator on the Internet. It uses a dictionary of over 200 Latin words, combined with a handful of model sentence structures, to generate Lorem Ipsum which looks reasonable. The generated Lorem Ipsum is therefore always free from repetition, injected humour, or non-characteristic words etc.



--- Fichier : mon_dossier/source/fichier (3).txt ---
Lorem Ipsum is simply dummy text of the printing and typesetting industry. Lorem Ipsum has been the industry's standard dummy text ever since the 1500s, when an unknown printer took a galley of type and scrambled it to make a type specimen book. It has survived not only five centuries, but also the leap into electronic typesetting, remaining essentially unchanged. It was popularised in the 1960s with the release of Letraset sheets containing Lorem Ipsum passages, and more recently with desktop publishing software like Aldus PageMaker including versions of Lorem Ipsum.



--- Fichier : mon_dossier/source/fichier (4).txt ---
It is a long established fact that a reader will be distracted by the readable content of a page when looking at its layout. The point of using Lorem Ipsum is that it has a more-or-less normal distribution of letters, as opposed to using 'Content here, content here', making it look like readable English. Many desktop publishing packages and web page editors now use Lorem Ipsum as their default model text, and a search for 'lorem ipsum' will uncover many web sites still in their infancy. Various versions have evolved over the years, sometimes by accident, sometimes on purpose (injected humour and the like).



--- Fichier : tests/run_tests.sh ---
#!/usr/bin/env bash
# run_tests.sh — suite de tests automatisée pour integrity.sh
# Usage    : cd tests && ./run_tests.sh
# Prérequis: b3sum, stat, du ; integrity.sh dans ../src/

set -euo pipefail

SCRIPT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"
INTEGRITY="$SCRIPT_DIR/../src/integrity.sh"
WORKDIR="$(mktemp -d /tmp/integrity-test.XXXXXX)"
export RESULTATS_DIR="$WORKDIR/resultats"

GREEN='\033[0;32m'
RED='\033[0;31m'
NC='\033[0m'

PASS=0; FAIL=0; TOTAL=0

pass() { echo -e "${GREEN}  PASS${NC} — $1"; ((PASS++)); ((TOTAL++)); }
fail() { echo -e "${RED}  FAIL${NC} — $1"; ((FAIL++)); ((TOTAL++)); }

assert_exit_zero()    { local l="$1"; shift; if "$@" >/dev/null 2>&1;  then pass "$l"; else fail "$l"; fi; }
assert_exit_nonzero() { local l="$1"; shift; if ! "$@" >/dev/null 2>&1; then pass "$l"; else fail "$l"; fi; }

assert_contains() {
  local label="$1" pattern="$2" output="$3"
  if echo "$output" | grep -q "$pattern"; then pass "$label"; else fail "$label (pattern: '$pattern' absent)"; fi
}

assert_not_contains() {
  local label="$1" pattern="$2" output="$3"
  if ! echo "$output" | grep -q "$pattern"; then pass "$label"; else fail "$label (pattern: '$pattern' présent à tort)"; fi
}

assert_line_count() {
  local label="$1" expected="$2" file="$3"
  local actual; actual=$(wc -l < "$file")
  if [ "$actual" -eq "$expected" ]; then pass "$label"; else fail "$label (attendu: $expected, obtenu: $actual)"; fi
}

assert_file_exists() {
  local label="$1" file="$2"
  if [ -f "$file" ]; then pass "$label"; else fail "$label (absent : $file)"; fi
}

assert_file_absent() {
  local label="$1" file="$2"
  if [ ! -f "$file" ]; then pass "$label"; else fail "$label (présent à tort : $file)"; fi
}

setup() {
  mkdir -p "$WORKDIR/data/sub"
  echo "contenu alpha" > "$WORKDIR/data/alpha.txt"
  echo "contenu beta"  > "$WORKDIR/data/beta.txt"
  echo "contenu gamma" > "$WORKDIR/data/gamma.txt"
  echo "contenu delta" > "$WORKDIR/data/sub/delta.txt"
}

teardown() { rm -rf "$WORKDIR"; }

run_tests() {
  cd "$WORKDIR"

  echo ""
  echo "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━"
  echo "  integrity.sh — suite de tests"
  echo "  Workdir : $WORKDIR"
  echo "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━"
  echo ""

  echo "T00 — ShellCheck"
  if command -v shellcheck &>/dev/null; then
    assert_exit_zero "ShellCheck integrity.sh"  shellcheck "$INTEGRITY"
    assert_exit_zero "ShellCheck run_tests.sh"  shellcheck "$0"
  else
    echo "  SKIP — shellcheck non installé"
  fi
  echo ""

  echo "T01 — Compute de base"
  bash "$INTEGRITY" compute ./data base_t01.b3 >/dev/null 2>&1
  assert_line_count "base_t01.b3 contient 4 lignes" 4 base_t01.b3
  assert_contains   "format <hash>  <chemin>"       "  ./data/" "$(head -1 base_t01.b3)"
  echo ""

  echo "T02 — Verify sans modification"
  local out_t02; out_t02=$(bash "$INTEGRITY" verify base_t01.b3 2>&1 || true)
  assert_not_contains "aucun FAILED" "FAILED" "$out_t02"
  assert_contains     "terminal OK"  "OK"     "$out_t02"
  local outdir_t02; outdir_t02=$(ls -d "${RESULTATS_DIR}/resultats_base_t01"* 2>/dev/null | tail -1)
  assert_file_exists  "recap.txt créé"              "${outdir_t02}/recap.txt"
  assert_file_absent  "failed.txt absent si 0 échec" "${outdir_t02}/failed.txt"
  echo ""

  echo "T03 — Verify après corruption"
  echo "contenu modifié" > data/beta.txt
  local out_t03; out_t03=$(bash "$INTEGRITY" verify base_t01.b3 2>&1 || true)
  assert_contains "ECHEC affiché"    "ECHEC"   "$out_t03"
  assert_contains "beta.txt FAILED"  "FAILED"  "$out_t03"
  local outdir_t03; outdir_t03=$(ls -d "${RESULTATS_DIR}/resultats_base_t01"* 2>/dev/null | tail -1)
  assert_file_exists "failed.txt créé"    "${outdir_t03}/failed.txt"
  assert_contains    "failed.txt beta"    "beta.txt" "$(cat "${outdir_t03}/failed.txt")"
  echo "contenu beta" > data/beta.txt
  echo ""

  echo "T04 — Verify après suppression"
  rm data/gamma.txt
  local out_t04; out_t04=$(bash "$INTEGRITY" verify base_t01.b3 2>&1 || true)
  assert_contains "gamma.txt FAILED" "FAILED" "$out_t04"
  echo "contenu gamma" > data/gamma.txt
  echo ""

  echo "T05 — Compare : aucune différence"
  bash "$INTEGRITY" compute ./data base_t05.b3 >/dev/null 2>&1
  bash "$INTEGRITY" compare base_t01.b3 base_t05.b3 >/dev/null 2>&1
  local outdir_t05; outdir_t05=$(ls -d "${RESULTATS_DIR}/resultats_base_t01"* 2>/dev/null | tail -1)
  assert_file_exists "recap.txt"    "${outdir_t05}/recap.txt"
  assert_file_exists "modifies.b3"  "${outdir_t05}/modifies.b3"
  assert_file_exists "report.html"  "${outdir_t05}/report.html"
  assert_line_count  "modifies vide" 0 "${outdir_t05}/modifies.b3"
  assert_line_count  "disparus vide" 0 "${outdir_t05}/disparus.txt"
  assert_line_count  "nouveaux vide" 0 "${outdir_t05}/nouveaux.txt"
  echo ""

  echo "T06 — Compare : fichier modifié"
  echo "contenu beta modifié" > data/beta.txt
  bash "$INTEGRITY" compute ./data base_t06.b3 >/dev/null 2>&1
  bash "$INTEGRITY" compare base_t01.b3 base_t06.b3 >/dev/null 2>&1
  local outdir_t06; outdir_t06=$(ls -d "${RESULTATS_DIR}/resultats_base_t01"* 2>/dev/null | tail -1)
  assert_contains "modifies contient beta" "beta.txt" "$(cat "${outdir_t06}/modifies.b3")"
  assert_file_exists "report.html généré" "${outdir_t06}/report.html"
  assert_contains    "report.html contient beta" "beta" "$(cat "${outdir_t06}/report.html")"
  echo "contenu beta" > data/beta.txt
  echo ""

  echo "T07 — Compare : suppression + ajout"
  bash "$INTEGRITY" compute ./data base_t07_old.b3 >/dev/null 2>&1
  rm data/alpha.txt
  echo "contenu epsilon" > data/epsilon.txt
  bash "$INTEGRITY" compute ./data base_t07_new.b3 >/dev/null 2>&1
  bash "$INTEGRITY" compare base_t07_old.b3 base_t07_new.b3 >/dev/null 2>&1
  local outdir_t07; outdir_t07=$(ls -d "${RESULTATS_DIR}/resultats_base_t07_old"* 2>/dev/null | tail -1)
  assert_contains "disparus alpha"   "alpha.txt"   "$(cat "${outdir_t07}/disparus.txt")"
  assert_contains "nouveaux epsilon" "epsilon.txt" "$(cat "${outdir_t07}/nouveaux.txt")"
  echo "contenu alpha" > data/alpha.txt
  rm data/epsilon.txt
  echo ""

  echo "T08 — Robustesse : fichier avec espace"
  echo "contenu espace" > "data/fichier avec espace.txt"
  bash "$INTEGRITY" compute ./data base_t08.b3 >/dev/null 2>&1
  local out_t08; out_t08=$(bash "$INTEGRITY" verify base_t08.b3 2>&1 || true)
  assert_not_contains "aucun FAILED" "FAILED" "$out_t08"
  rm "data/fichier avec espace.txt"
  echo ""

  echo "T09 — Limite : dossier vide ignoré"
  mkdir data/dossier_vide
  bash "$INTEGRITY" compute ./data base_t09.b3 >/dev/null 2>&1
  assert_not_contains "dossier_vide absent" "dossier_vide" "$(cat base_t09.b3)"
  pass "comportement conforme"
  rmdir data/dossier_vide
  echo ""

  echo "T10 — Chemin absolu vs relatif"
  find "$WORKDIR/data" -type f -print0 | sort -z | xargs -0 b3sum > base_absolu.b3
  find ./data          -type f -print0 | sort -z | xargs -0 b3sum > base_relatif.b3
  assert_contains     "base absolue → chemin absolu"   "  /"      "$(head -1 base_absolu.b3)"
  assert_contains     "base relative → chemin relatif" "\./data/" "$(head -1 base_relatif.b3)"
  assert_not_contains "bases non interchangeables"     "$(head -1 base_absolu.b3)" "$(head -1 base_relatif.b3)"
  echo ""

  echo "T11 — ETA : base identique à référence"
  find ./data -type f -print0 | sort -z | xargs -0 b3sum > base_ref.b3
  bash "$INTEGRITY" compute ./data base_eta.b3 >/dev/null 2>&1
  assert_exit_zero    "base ETA == référence" diff base_ref.b3 base_eta.b3
  assert_not_contains "pas de ligne ETA"      "ETA" "$(cat base_eta.b3)"
  assert_not_contains "pas de \\r"            $'\r' "$(cat base_eta.b3)"
  echo ""

  echo "T12 — Mode --quiet"
  bash "$INTEGRITY" compute ./data base_t12.b3 >/dev/null 2>&1
  local out_quiet_ok; out_quiet_ok=$(bash "$INTEGRITY" --quiet verify base_t12.b3 2>&1 || true)
  assert_not_contains "--quiet OK : pas de stdout" "OK"        "$out_quiet_ok"
  assert_not_contains "--quiet OK : pas de stdout" "Résultats" "$out_quiet_ok"
  local outdir_t12; outdir_t12=$(ls -d "${RESULTATS_DIR}/resultats_base_t12"* 2>/dev/null | tail -1)
  assert_file_exists  "recap.txt produit --quiet" "${outdir_t12}/recap.txt"

  echo "contenu corrompu" > data/beta.txt
  local exit_quiet; bash "$INTEGRITY" --quiet verify base_t12.b3 >/dev/null 2>&1 && exit_quiet=0 || exit_quiet=$?
  if (( exit_quiet != 0 )); then pass "--quiet propage exit code"; else fail "--quiet propage exit code"; fi
  echo "contenu beta" > data/beta.txt

  local out_quiet_cmp; out_quiet_cmp=$(bash "$INTEGRITY" --quiet compute ./data base_t12c.b3 2>&1 || true)
  assert_not_contains "--quiet compute : pas de stdout" "Base enregistrée" "$out_quiet_cmp"
  echo ""

  echo "T13 — Horodatage anti-écrasement"
  bash "$INTEGRITY" compute ./data base_t13.b3 >/dev/null 2>&1
  bash "$INTEGRITY" verify base_t13.b3 >/dev/null 2>&1 || true
  sleep 1
  bash "$INTEGRITY" verify base_t13.b3 >/dev/null 2>&1 || true
  local nb_r; nb_r=$(ls -d "${RESULTATS_DIR}/resultats_base_t13"* 2>/dev/null | wc -l)
  if (( nb_r >= 2 )); then pass "deux dossiers distincts"; else fail "écrasement détecté ($nb_r dossier(s))"; fi
  echo ""

  echo "T14 — verify : dossier argument invalide"
  local out_t14; out_t14=$(bash "$INTEGRITY" verify base_t01.b3 /chemin/inexistant 2>&1 || true)
  assert_contains "ERREUR si dossier invalide" "ERREUR" "$out_t14"
  echo ""
}

# ── Main ──────────────────────────────────────────────────────────────────────

command -v b3sum &>/dev/null || { echo -e "${RED}ERREUR${NC} : b3sum non trouvé."; exit 1; }
[ -f "$INTEGRITY" ]          || { echo -e "${RED}ERREUR${NC} : integrity.sh introuvable : $INTEGRITY"; exit 1; }

setup
run_tests
teardown

echo "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━"
if [ "$FAIL" -eq 0 ]; then
  echo -e "  ${GREEN}$PASS/$TOTAL tests passés${NC}"
else
  echo -e "  ${GREEN}$PASS${NC}/${TOTAL} passés — ${RED}$FAIL échec(s)${NC}"
fi
echo "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━"
echo ""

[ "$FAIL" -eq 0 ]

--- Fichier : tests/run_tests_pipeline.sh ---
#!/usr/bin/env bash
# run_tests_pipeline.sh — Tests automatisés pour runner.sh + pipeline.json
#
# Couvre : parsing JSON, compute, verify, compare, champ resultats, erreurs
#
# Prérequis : bash >= 4, jq, b3sum
#             runner.sh    à ../
#             integrity.sh à ../src/
# Usage     : cd tests && ./run_tests_pipeline.sh

set -euo pipefail

SCRIPT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"
RUNNER="$SCRIPT_DIR/../runner.sh"
INTEGRITY="$SCRIPT_DIR/../src/integrity.sh"
WORKDIR="$(mktemp -d /tmp/integrity-pipeline-test.XXXXXX)"
export RESULTATS_DIR="$WORKDIR/resultats"

GREEN='\033[0;32m'
RED='\033[0;31m'
NC='\033[0m'

PASS=0; FAIL=0; TOTAL=0

pass() { echo -e "${GREEN}  PASS${NC} — $1"; (( PASS++ )); (( TOTAL++ )); }
fail() { echo -e "${RED}  FAIL${NC} — $1"; (( FAIL++ )); (( TOTAL++ )); }

assert_contains() {
    local label="$1" pattern="$2" output="$3"
    if echo "$output" | grep -q "$pattern"; then pass "$label"; else fail "$label (pattern '$pattern' absent)"; fi
}

assert_not_contains() {
    local label="$1" pattern="$2" output="$3"
    if ! echo "$output" | grep -q "$pattern"; then pass "$label"; else fail "$label (pattern '$pattern' présent à tort)"; fi
}

assert_file_exists() {
    local label="$1" file="$2"
    if [ -f "$file" ]; then pass "$label"; else fail "$label (absent : $file)"; fi
}

assert_file_absent() {
    local label="$1" file="$2"
    if [ ! -f "$file" ]; then pass "$label"; else fail "$label (présent à tort : $file)"; fi
}

assert_line_count() {
    local label="$1" expected="$2" file="$3"
    local actual; actual=$(wc -l < "$file")
    if [ "$actual" -eq "$expected" ]; then pass "$label"; else fail "$label (attendu $expected, obtenu $actual)"; fi
}

write_config() {
    local path="$WORKDIR/pipeline.json"
    cat > "$path"
    echo "$path"
}

setup() {
    mkdir -p "$WORKDIR"/{src_a,src_b,bases,resultats}

    echo "alpha content" > "$WORKDIR/src_a/alpha.txt"
    echo "beta content"  > "$WORKDIR/src_a/beta.txt"
    mkdir -p "$WORKDIR/src_a/sub"
    echo "delta content" > "$WORKDIR/src_a/sub/delta.txt"

    echo "gamma content" > "$WORKDIR/src_b/gamma.txt"
    echo "delta content" > "$WORKDIR/src_b/delta.txt"
}

teardown() { rm -rf "$WORKDIR"; }

run_tests() {
    cd "$WORKDIR"

    echo ""
    echo "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━"
    echo "  runner.sh — suite de tests"
    echo "  Workdir : $WORKDIR"
    echo "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━"
    echo ""

    # ── TP01 : JSON invalide ──────────────────────────────────────────────────
    echo "TP01 — JSON invalide : erreur propre sans stacktrace jq"
    local cfg_invalid="$WORKDIR/invalid.json"
    echo "{ pipeline: [ BROKEN" > "$cfg_invalid"
    local out_tp01; out_tp01=$(bash "$RUNNER" "$cfg_invalid" 2>&1 || true)
    assert_contains     "ERREUR signalée"         "ERREUR"      "$out_tp01"
    assert_not_contains "pas de stacktrace jq"    "parse error" "$out_tp01"
    echo ""

    # ── TP02 : .pipeline absent ───────────────────────────────────────────────
    echo "TP02 — .pipeline absent"
    local cfg_no_pipeline
    cfg_no_pipeline=$(write_config <<'EOF'
{ "config": [] }
EOF
)
    local out_tp02; out_tp02=$(bash "$RUNNER" "$cfg_no_pipeline" 2>&1 || true)
    assert_contains "ERREUR si .pipeline absent" "ERREUR" "$out_tp02"
    echo ""

    # ── TP03 : champ manquant ─────────────────────────────────────────────────
    echo "TP03 — Champ 'nom' manquant dans compute"
    local cfg_missing
    cfg_missing=$(write_config <<EOF
{
    "pipeline": [
        { "op": "compute", "source": "$WORKDIR/src_a", "bases": "$WORKDIR/bases" }
    ]
}
EOF
)
    local out_tp03; out_tp03=$(bash "$RUNNER" "$cfg_missing" 2>&1 || true)
    assert_contains "ERREUR signalée"       "ERREUR" "$out_tp03"
    assert_contains "champ 'nom' mentionné" "nom"    "$out_tp03"
    echo ""

    # ── TP04 : opération inconnue ─────────────────────────────────────────────
    echo "TP04 — Opération inconnue"
    local cfg_unknown
    cfg_unknown=$(write_config <<'EOF'
{ "pipeline": [ { "op": "migrate", "source": "/tmp" } ] }
EOF
)
    local out_tp04; out_tp04=$(bash "$RUNNER" "$cfg_unknown" 2>&1 || true)
    assert_contains "ERREUR signalée"           "ERREUR"   "$out_tp04"
    assert_contains "nom de l'op dans l'erreur" "migrate"  "$out_tp04"
    echo ""

    # ── TP05 : compute — chemins relatifs ─────────────────────────────────────
    echo "TP05 — Compute : cd correct, chemins relatifs dans la base"
    local cfg_compute
    cfg_compute=$(write_config <<EOF
{
    "pipeline": [
        { "op": "compute", "source": "$WORKDIR/src_a", "bases": "$WORKDIR/bases", "nom": "hashes_a.b3" }
    ]
}
EOF
)
    bash "$RUNNER" "$cfg_compute" >/dev/null 2>&1
    assert_file_exists "base hashes_a.b3 créée" "$WORKDIR/bases/hashes_a.b3"
    local first_path; first_path=$(awk '{print $2}' "$WORKDIR/bases/hashes_a.b3" | head -1)
    assert_contains     "chemin relatif (./) dans base"    "./"       "$first_path"
    assert_not_contains "pas de chemin absolu dans base"   "$WORKDIR" "$first_path"
    assert_line_count   "3 fichiers indexés"               3          "$WORKDIR/bases/hashes_a.b3"
    echo ""

    # ── TP06 : compute — source absente ──────────────────────────────────────
    echo "TP06 — Compute : source absente → erreur"
    local cfg_absent
    cfg_absent=$(write_config <<EOF
{
    "pipeline": [
        { "op": "compute", "source": "$WORKDIR/inexistant", "bases": "$WORKDIR/bases", "nom": "ko.b3" }
    ]
}
EOF
)
    local out_tp06; out_tp06=$(bash "$RUNNER" "$cfg_absent" 2>&1 || true)
    assert_contains    "ERREUR signalée"              "ERREUR"  "$out_tp06"
    assert_file_absent "pas de base créée si source KO" "$WORKDIR/bases/ko.b3"
    echo ""

    # ── TP07 : verify — OK ───────────────────────────────────────────────────
    echo "TP07 — Verify : répertoire de travail correct, vérification OK"
    local cfg_verify
    cfg_verify=$(write_config <<EOF
{
    "pipeline": [
        { "op": "verify", "source": "$WORKDIR/src_a", "base": "$WORKDIR/bases/hashes_a.b3" }
    ]
}
EOF
)
    local out_tp07; out_tp07=$(bash "$RUNNER" "$cfg_verify" 2>&1 || true)
    assert_contains     "verify OK"     "OK"     "$out_tp07"
    assert_not_contains "aucun FAILED"  "FAILED" "$out_tp07"
    local outdir_tp07; outdir_tp07=$(ls -d "${RESULTATS_DIR}/resultats_hashes_a"* 2>/dev/null | tail -1)
    assert_file_exists  "recap.txt produit" "${outdir_tp07}/recap.txt"
    echo ""

    # ── TP08 : verify — corruption ───────────────────────────────────────────
    echo "TP08 — Verify : corruption détectée"
    echo "contenu corrompu" > "$WORKDIR/src_a/alpha.txt"
    local out_tp08; out_tp08=$(bash "$RUNNER" "$cfg_verify" 2>&1 || true)
    assert_contains "ECHEC détecté" "ECHEC" "$out_tp08"
    echo "alpha content"   > "$WORKDIR/src_a/alpha.txt"
    echo ""

    # ── TP09 : verify — base absente ─────────────────────────────────────────
    echo "TP09 — Verify : base .b3 absente → erreur"
    local cfg_verify_bad
    cfg_verify_bad=$(write_config <<EOF
{
    "pipeline": [
        { "op": "verify", "source": "$WORKDIR/src_a", "base": "$WORKDIR/bases/fantome.b3" }
    ]
}
EOF
)
    local out_tp09; out_tp09=$(bash "$RUNNER" "$cfg_verify_bad" 2>&1 || true)
    assert_contains "ERREUR si base absente" "ERREUR" "$out_tp09"
    echo ""

    # ── TP10 : compare — résultats produits (RESULTATS_DIR par défaut) ────────
    echo "TP10 — Compare : fichiers de résultats produits (sans champ resultats)"
    local cfg_compute_b
    cfg_compute_b=$(write_config <<EOF
{
    "pipeline": [
        { "op": "compute", "source": "$WORKDIR/src_b", "bases": "$WORKDIR/bases", "nom": "hashes_b.b3" }
    ]
}
EOF
)
    bash "$RUNNER" "$cfg_compute_b" >/dev/null 2>&1

    local cfg_compare
    cfg_compare=$(write_config <<EOF
{
    "pipeline": [
        { "op": "compare", "base_a": "$WORKDIR/bases/hashes_a.b3", "base_b": "$WORKDIR/bases/hashes_b.b3" }
    ]
}
EOF
)
    bash "$RUNNER" "$cfg_compare" >/dev/null 2>&1
    local outdir_tp10; outdir_tp10=$(ls -d "${RESULTATS_DIR}/resultats_hashes_a"* 2>/dev/null | tail -1)
    assert_file_exists "recap.txt"    "${outdir_tp10}/recap.txt"
    assert_file_exists "modifies.b3"  "${outdir_tp10}/modifies.b3"
    assert_file_exists "disparus.txt" "${outdir_tp10}/disparus.txt"
    assert_file_exists "nouveaux.txt" "${outdir_tp10}/nouveaux.txt"
    assert_file_exists "report.html"  "${outdir_tp10}/report.html"
    echo ""

    # ── TP10b : compare — champ resultats personnalisé ───────────────────────
    echo "TP10b — Compare : champ 'resultats' personnalisé dans pipeline.json"
    local custom_dir="$WORKDIR/mon_rapport_custom"
    local cfg_compare_custom
    cfg_compare_custom=$(write_config <<EOF
{
    "pipeline": [
        {
            "op":       "compare",
            "base_a":   "$WORKDIR/bases/hashes_a.b3",
            "base_b":   "$WORKDIR/bases/hashes_b.b3",
            "resultats": "$custom_dir"
        }
    ]
}
EOF
)
    bash "$RUNNER" "$cfg_compare_custom" >/dev/null 2>&1
    local outdir_custom; outdir_custom=$(ls -d "${custom_dir}/resultats_hashes_a"* 2>/dev/null | tail -1)
    assert_file_exists "rapport dans dossier custom"            "${outdir_custom}/recap.txt"
    assert_file_exists "report.html dans dossier custom"        "${outdir_custom}/report.html"
    # Vérifier que le dossier par défaut n'a PAS reçu ce résultat
    local nb_before; nb_before=$(ls -d "${RESULTATS_DIR}/resultats_hashes_a"* 2>/dev/null | wc -l)
    bash "$RUNNER" "$cfg_compare_custom" >/dev/null 2>&1
    local nb_after; nb_after=$(ls -d "${RESULTATS_DIR}/resultats_hashes_a"* 2>/dev/null | wc -l)
    if [ "$nb_before" -eq "$nb_after" ]; then
        pass "champ resultats isolé : RESULTATS_DIR par défaut non pollué"
    else
        fail "champ resultats isolé : RESULTATS_DIR par défaut non pollué"
    fi
    echo ""

    # ── TP11 : compare — base_a absente ──────────────────────────────────────
    echo "TP11 — Compare : base_a absente → erreur"
    local cfg_compare_bad
    cfg_compare_bad=$(write_config <<EOF
{
    "pipeline": [
        { "op": "compare", "base_a": "$WORKDIR/bases/fantome.b3", "base_b": "$WORKDIR/bases/hashes_b.b3" }
    ]
}
EOF
)
    local out_tp11; out_tp11=$(bash "$RUNNER" "$cfg_compare_bad" 2>&1 || true)
    assert_contains "ERREUR si base_a absente" "ERREUR" "$out_tp11"
    echo ""

    # ── TP12 : pipeline complet ───────────────────────────────────────────────
    echo "TP12 — Pipeline complet : compute × 2 + verify + compare"
    rm -f "$WORKDIR/bases/hashes_a.b3" "$WORKDIR/bases/hashes_b.b3"
    local cfg_full
    cfg_full=$(write_config <<EOF
{
    "pipeline": [
        { "op": "compute", "source": "$WORKDIR/src_a", "bases": "$WORKDIR/bases", "nom": "hashes_a.b3" },
        { "op": "compute", "source": "$WORKDIR/src_b", "bases": "$WORKDIR/bases", "nom": "hashes_b.b3" },
        { "op": "verify",  "source": "$WORKDIR/src_a", "base":  "$WORKDIR/bases/hashes_a.b3" },
        { "op": "compare", "base_a": "$WORKDIR/bases/hashes_a.b3", "base_b": "$WORKDIR/bases/hashes_b.b3",
          "resultats": "$WORKDIR/resultats_pipeline" }
    ]
}
EOF
)
    local out_tp12; out_tp12=$(bash "$RUNNER" "$cfg_full" 2>&1 || true)
    assert_contains     "COMPUTE mentionné"     "COMPUTE" "$out_tp12"
    assert_contains     "VERIFY mentionné"      "VERIFY"  "$out_tp12"
    assert_contains     "COMPARE mentionné"     "COMPARE" "$out_tp12"
    assert_file_exists  "hashes_a.b3 créée"     "$WORKDIR/bases/hashes_a.b3"
    assert_file_exists  "hashes_b.b3 créée"     "$WORKDIR/bases/hashes_b.b3"
    assert_not_contains "pas d'ERREUR"          "ERREUR"  "$out_tp12"
    local outdir_tp12; outdir_tp12=$(ls -d "${WORKDIR}/resultats_pipeline/resultats_hashes_a"* 2>/dev/null | tail -1)
    assert_file_exists  "report.html pipeline complet" "${outdir_tp12}/report.html"
    echo ""
}

# ── Main ──────────────────────────────────────────────────────────────────────

for dep in jq b3sum; do
    command -v "$dep" &>/dev/null || { echo -e "${RED}ERREUR${NC} : $dep non trouvé."; exit 1; }
done

[ -f "$RUNNER" ]    || { echo -e "${RED}ERREUR${NC} : runner.sh introuvable : $RUNNER";      exit 1; }
[ -f "$INTEGRITY" ] || { echo -e "${RED}ERREUR${NC} : src/integrity.sh introuvable : $INTEGRITY"; exit 1; }

setup
run_tests
teardown

echo "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━"
if [ "$FAIL" -eq 0 ]; then
    echo -e "  ${GREEN}$PASS/$TOTAL tests passés${NC}"
else
    echo -e "  ${GREEN}$PASS${NC}/${TOTAL} passés — ${RED}$FAIL échec(s)${NC}"
fi
echo "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━"
echo ""

[ "$FAIL" -eq 0 ]

--- Fichier : tests/validation.md ---
# Tests et validation - integrity.sh

**Niveau d'exigence :** production, admin système. Chaque cas doit être exécuté et son résultat vérifié explicitement.

---

## Environnement de test

```bash
# Créer un environnement de test isolé
mkdir -p /tmp/integrity-test/{data,output}
cd /tmp/integrity-test

# Créer des fichiers de test avec contenu connu
echo "contenu alpha" > data/alpha.txt
echo "contenu beta"  > data/beta.txt
echo "contenu gamma" > data/gamma.txt
mkdir -p data/sub
echo "contenu delta" > data/sub/delta.txt
```

---

## Cas de test

### T01 - Compute de base

```bash
./integrity.sh compute ./data base_t01.b3
```

**Résultat attendu :**

- Fichier `base_t01.b3` créé avec 4 lignes (une par fichier).
- Message `Base enregistrée : base_t01.b3 (4 fichiers)`.
- Chaque ligne au format `<hash64chars>  ./data/<chemin>`.

```bash
# Vérification
wc -l base_t01.b3           # → 4
head -1 base_t01.b3         # → hash + chemin lisibles
```

---

### T02 - Verify sans modification

```bash
b3sum --check base_t01.b3
```

**Résultat attendu :** 4 lignes `OK`, aucun `FAILED`, exit code 0.

```bash
echo $?   # → 0
```

---

### T03 - Verify après corruption d'un fichier

```bash
echo "contenu modifié" > data/beta.txt
b3sum --check base_t01.b3
```

**Résultat attendu :**

- `./data/beta.txt: FAILED`
- `b3sum: WARNING: 1 computed checksum did NOT match`
- Exit code non nul.

```bash
echo $?   # → 1
b3sum --check base_t01.b3 2>&1 | grep FAILED   # → ./data/beta.txt: FAILED
```

---

### T04 - Verify après suppression d'un fichier

```bash
# Restaurer l'état T01 d'abord
echo "contenu beta" > data/beta.txt

# Supprimer un fichier
rm data/gamma.txt
b3sum --check base_t01.b3
```

**Résultat attendu :**

- `./data/gamma.txt: FAILED` (No such file or directory)
- Exit code non nul.

---

### T05 - Compare : aucune différence

```bash
# Restaurer l'état T01
echo "contenu gamma" > data/gamma.txt

# Créer une seconde base identique
./integrity.sh compute ./data base_t05.b3
./integrity.sh compare base_t01.b3 base_t05.b3
```

**Résultat attendu :** sections `MODIFIÉS`, `DISPARUS`, `NOUVEAUX` toutes vides. Rapport sauvegardé.

---

### T06 - Compare : fichier modifié

```bash
echo "contenu beta modifié" > data/beta.txt
./integrity.sh compute ./data base_t06.b3
./integrity.sh compare base_t01.b3 base_t06.b3
```

**Résultat attendu :**

- Section `FICHIERS MODIFIÉS` contient `./data/beta.txt` avec ancien et nouveau hash.
- Sections `DISPARUS` et `NOUVEAUX` vides.

---

### T07 - Compare : fichier supprimé + fichier ajouté

```bash
# Repartir d'une base propre
echo "contenu beta" > data/beta.txt
./integrity.sh compute ./data base_t07_old.b3

# Modifier l'état
rm data/alpha.txt
echo "contenu epsilon" > data/epsilon.txt
./integrity.sh compute ./data base_t07_new.b3

./integrity.sh compare base_t07_old.b3 base_t07_new.b3
```

**Résultat attendu :**

- `DISPARUS` : `./data/alpha.txt`
- `NOUVEAUX` : `./data/epsilon.txt`
- `MODIFIÉS` : vide

---

### T08 - Robustesse : fichier avec espace dans le nom

```bash
echo "contenu avec espace" > "data/fichier avec espace.txt"
./integrity.sh compute ./data base_t08.b3
b3sum --check base_t08.b3
```

**Résultat attendu :** tous les fichiers `OK`, y compris `fichier avec espace.txt`.

---

### T09 - Robustesse : dossier vide (limite connue)

```bash
mkdir data/dossier_vide
./integrity.sh compute ./data base_t09.b3
```

**Résultat attendu :** `dossier_vide` absent de `base_t09.b3`. Comportement normal et documenté - `find -type f` n'indexe pas les dossiers vides.

---

### T10 - Chemin absolu vs relatif (piège critique)

```bash
# Calculer avec chemin absolu - mauvaise pratique
b3sum $(find /tmp/integrity-test/data -type f) > base_absolu.b3
head -1 base_absolu.b3   # → chemin absolu /tmp/integrity-test/data/...

# Calculer avec chemin relatif - bonne pratique
cd /tmp/integrity-test
find ./data -type f -print0 | sort -z | xargs -0 b3sum > base_relatif.b3
head -1 base_relatif.b3  # → chemin relatif ./data/...
```

**Résultat attendu :** les deux bases sont incompatibles entre elles. Confirme que les chemins absolus cassent la portabilité.

---

## Nettoyage

```bash
rm -rf /tmp/integrity-test
```

---

## Critères de qualité globaux

| Critère | Exigence |
|---|---|
| Détection corruption | 100 % des fichiers modifiés détectés (T03) |
| Détection suppression | 100 % des fichiers manquants détectés (T04) |
| Faux positifs | Zéro - verify sur base intacte = 100 % OK (T02) |
| Noms avec espaces | Traités sans erreur (T08) |
| Rapport compare | Sauvegardé sur disque, horodaté (T05–T07) |
| Exit code | Non nul si au moins un FAILED (T03, T04) |
| Mode strict `-euo pipefail` | Le script s'arrête sur toute erreur non gérée |


--- Fichier : reports/template.html ---
<!DOCTYPE html>
<html lang="fr">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Rapport — [BASE_A] vs [BASE_B]</title>
  <!--
    ══════════════════════════════════════════════════════════════════
    reports/template.html — Barebone rapport de comparaison hash_tool
    ══════════════════════════════════════════════════════════════════

    Ce fichier est un template statique de référence.
    Le rapport réel est généré automatiquement par src/lib/report.sh
    dans le dossier "resultats" défini dans pipeline.json.

    Structure du rapport généré :
      <resultats>/
        ├── report.html      ← rapport visuel (ce template rempli)
        ├── recap.txt        ← résumé texte
        ├── modifies.b3      ← fichiers avec hash différent
        ├── disparus.txt     ← fichiers présents dans A, absents de B
        └── nouveaux.txt     ← fichiers absents de A, présents dans B

    Pour personnaliser le rendu HTML : modifier src/lib/report.sh
    (fonction generate_compare_html).

    Placeholders utilisés dans report.sh :
      [BASE_A]       nom du fichier .b3 ancienne base
      [BASE_B]       nom du fichier .b3 nouvelle base
      [DATE]         date de génération
      [STATUT]       IDENTIQUES | DIFFÉRENCES DÉTECTÉES
      [NB_MODIFIES]  nombre de fichiers modifiés
      [NB_DISPARUS]  nombre de fichiers disparus
      [NB_NOUVEAUX]  nombre de nouveaux fichiers
      [LIST_*]       listes HTML injectées par _render_file_list()
    ══════════════════════════════════════════════════════════════════
  -->
  <style>
    /* → Voir src/lib/report.sh pour le CSS complet injecté dans les rapports générés */

    :root {
      --bg:       #0f1117;
      --bg-card:  #161b27;
      --border:   #252d3f;
      --text:     #c8d4e8;
      --text-dim: #5a6a85;
      --mono:     monospace;
      --sans:     system-ui, sans-serif;
    }

    body {
      background: var(--bg);
      color: var(--text);
      font-family: var(--sans);
      font-size: 14px;
      display: flex;
      align-items: center;
      justify-content: center;
      min-height: 100vh;
      padding: 40px;
    }

    .placeholder {
      max-width: 560px;
      text-align: center;
    }

    .placeholder h1 {
      font-family: var(--mono);
      font-size: 12px;
      letter-spacing: .1em;
      text-transform: uppercase;
      color: var(--text-dim);
      margin-bottom: 24px;
    }

    .placeholder p {
      color: var(--text-dim);
      line-height: 1.7;
      font-size: 13px;
      margin-bottom: 12px;
    }

    code {
      font-family: var(--mono);
      font-size: 12px;
      background: var(--bg-card);
      border: 1px solid var(--border);
      border-radius: 4px;
      padding: 2px 6px;
      color: var(--text);
    }
  </style>
</head>
<body>
  <div class="placeholder">
    <h1>hash_tool · template.html</h1>
    <p>Ce fichier est le template de référence du rapport de comparaison.</p>
    <p>
      Les rapports réels sont générés automatiquement dans le dossier
      <code>resultats</code> défini par le champ
      <code>"resultats"</code> dans <code>pipeline.json</code>.
    </p>
    <p>
      Pour personnaliser le rendu : modifier
      <code>src/lib/report.sh</code> → fonction
      <code>generate_compare_html()</code>.
    </p>
  </div>
</body>
</html>

--- Fichier : src/integrity.sh ---
#!/usr/bin/env bash
# integrity.sh — vérification d'intégrité par hachage BLAKE3
#
# Usage :
#   ./integrity.sh compute <dossier> <base.b3>
#   ./integrity.sh verify  <base.b3> [dossier]
#   ./integrity.sh compare <ancienne.b3> <nouvelle.b3>
#
# Options :
#   --quiet   Supprime toute sortie terminal ; écrit uniquement dans les
#             fichiers de résultats (recap.txt, failed.txt, report.html, etc.).
#             Utile pour usage en CI/cron/script parent.
#
# Dépendances : b3sum, find, sort, awk, comm, join, stat, du

set -euo pipefail

# ── Vérification version bash ──────────────────────────────────────────────────

(( BASH_VERSINFO[0] >= 4 )) || {
  echo "ERREUR : bash >= 4 requis (actuel : $BASH_VERSION)" >&2
  exit 1
}

# ── Résolution du répertoire du script ────────────────────────────────────────

SCRIPT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"

# ── Chargement de la bibliothèque de rapports ─────────────────────────────────

LIB_REPORT="$SCRIPT_DIR/lib/report.sh"
[ -f "$LIB_REPORT" ] || {
  echo "ERREUR : lib/report.sh introuvable : $LIB_REPORT" >&2
  exit 1
}
# shellcheck source=lib/report.sh
source "$LIB_REPORT"

# ── Parsing des arguments ──────────────────────────────────────────────────────

QUIET=0
ARGS=()

for arg in "$@"; do
  case "$arg" in
    --quiet) QUIET=1 ;;
    *)       ARGS+=("$arg") ;;
  esac
done

MODE="${ARGS[0]:-}"
ARG2="${ARGS[1]:-}"
ARG3="${ARGS[2]:-}"

# ── Configuration ──────────────────────────────────────────────────────────────

# Dossier racine où seront créés les sous-dossiers de résultats.
# Peut être surchargé par l'environnement (ex : runner.sh via export RESULTATS_DIR).
RESULTATS_DIR="${RESULTATS_DIR:-${HOME}/integrity_resultats}"

# ── Fonctions utilitaires ──────────────────────────────────────────────────────

die() {
  echo "ERREUR : $*" >&2
  exit 1
}

say() {
  (( QUIET )) || echo "$@"
}

assert_b3_valid() {
  local file="$1"
  local label="${2:-$file}"

  [ -e "$file" ] || die "$label : fichier introuvable."
  [ -f "$file" ] || die "$label : est un dossier, pas un fichier .b3."
  [ -s "$file" ] || die "$label : fichier vide — aucun hash à traiter."

  local first_valid
  first_valid=$(grep -m1 -E '^[0-9a-f]{64}  .+' "$file" || true)
  [ -n "$first_valid" ] || die "$label : format invalide — aucune ligne au format b3sum détectée."
}

assert_target_valid() {
  local dir="$1"

  [ -e "$dir" ] || die "Dossier cible introuvable : $dir"
  [ -d "$dir" ] || die "Le chemin cible n'est pas un dossier : $dir"

  local nb_files
  nb_files=$(find "$dir" -type f -print0 | grep -zc '' || echo 0)
  (( nb_files > 0 )) || die "Le dossier $dir ne contient aucun fichier — rien à hacher."
}

file_size() {
  local f="$1"
  if stat -c%s "$f" 2>/dev/null; then
    return
  fi
  stat -f%z "$f"
}

# ── Fonctions principales ──────────────────────────────────────────────────────

compute_with_progress() {
  local target="$1"
  local hashfile="$2"

  local -a files
  mapfile -d '' files < <(find "$target" -type f -print0 | sort -z)

  local total_files=${#files[@]}
  local total_bytes
  total_bytes=$(du -sb "$target" | awk '{print $1}')

  local bytes_done=0
  local t_start
  t_start=$(date +%s)

  local i=0
  for file in "${files[@]}"; do
    b3sum "$file" >> "$hashfile"

    bytes_done=$(( bytes_done + $(file_size "$file") ))
    i=$(( i + 1 ))

    if (( ! QUIET )); then
      local t_now elapsed
      t_now=$(date +%s)
      elapsed=$(( t_now - t_start ))

      if (( bytes_done > 0 && elapsed > 0 )); then
        local speed remaining
        speed=$(( bytes_done / elapsed ))
        remaining=$(( (total_bytes - bytes_done) / speed ))
        printf "\r[%d/%d] ETA : %dm %02ds   " \
          "$i" "$total_files" $(( remaining / 60 )) $(( remaining % 60 )) > /dev/tty
      fi
    fi
  done

  if (( ! QUIET )); then
    printf "\r%*s\r" 40 "" > /dev/tty
  fi
}

make_result_dir() {
  local b3file="$1"
  local basename_noext
  basename_noext=$(basename "$b3file" .b3)
  local outdir="${RESULTATS_DIR}/resultats_${basename_noext}"

  if [ -d "$outdir" ]; then
    outdir="${outdir}_$(date +%Y%m%d-%H%M%S)"
  fi

  mkdir -p "$outdir"
  echo "$outdir"
}

run_verify() {
  local hashfile="$1"
  local outdir
  outdir=$(make_result_dir "$hashfile")

  local raw exit_code
  raw=$(b3sum --check "$hashfile" 2>&1) && exit_code=0 || exit_code=$?

  local lines_ok lines_failed lines_error
  lines_ok=$(echo    "$raw" | grep ': OK$'    || true)
  lines_failed=$(echo "$raw" | grep ': FAILED' || true)
  lines_error=$(echo  "$raw" | grep -Ev ': (OK|FAILED)' | grep -v '^$' || true)

  local nb_ok nb_failed
  if [ -n "$lines_ok" ];     then nb_ok=$(echo "$lines_ok"     | grep -c '^'); else nb_ok=0;     fi
  if [ -n "$lines_failed" ]; then nb_failed=$(echo "$lines_failed" | grep -c '^'); else nb_failed=0; fi

  local statut
  if [ -n "$lines_error" ];   then statut="ERREUR"
  elif (( nb_failed > 0 ));   then statut="ECHEC"
  else                              statut="OK"
  fi

  # ── recap.txt ─────────────────────────────────────────────────────────────
  {
    echo "════════════════════════════════════════"
    echo "  STATUT : $statut"
    echo "════════════════════════════════════════"
    echo ""
    echo "Commande  : integrity.sh verify $(basename "$hashfile")"
    echo "Date      : $(date)"
    echo "Base      : $hashfile"
    echo ""
    echo "OK        : $nb_ok"
    if (( nb_failed > 0 )); then
      echo "FAILED    : $nb_failed  ← voir failed.txt"
    fi
    if [ -n "$lines_error" ]; then
      echo ""
      echo "── Erreurs b3sum ──────────────────────"
      echo "$lines_error"
    fi
  } > "${outdir}/recap.txt"

  # ── failed.txt ────────────────────────────────────────────────────────────
  if (( nb_failed > 0 )) || [ -n "$lines_error" ]; then
    {
      echo "════════════════════════════════════════"
      echo "  FICHIERS EN ECHEC"
      echo "════════════════════════════════════════"
      echo ""
      if (( nb_failed > 0 )); then echo "$lines_failed"; fi
      if [ -n "$lines_error" ]; then
        echo ""
        echo "── Erreurs ────────────────────────────"
        echo "$lines_error"
      fi
    } > "${outdir}/failed.txt"
  else
    rm -f "${outdir}/failed.txt"
  fi

  # ── Affichage terminal ────────────────────────────────────────────────────
  if [ "$statut" = "OK" ]; then
    say "Vérification OK — $nb_ok fichiers intègres."
  else
    say ""
    say "████████████████████████████████████████"
    if [ "$statut" = "ERREUR" ]; then
      say "  ERREUR lors de la vérification"
    else
      say "  ECHEC : $nb_failed fichier(s) corrompu(s) ou manquant(s)"
    fi
    say "████████████████████████████████████████"
    say ""
    if (( nb_failed > 0 )); then say "$lines_failed"; fi
    if [ -n "$lines_error" ]; then say "$lines_error"; fi
    say ""
  fi

  say "Résultats dans : $outdir"
  say "  recap.txt"
  if (( nb_failed > 0 )) || [ -n "$lines_error" ]; then
    say "  failed.txt"
  fi

  return $exit_code
}

run_compare() {
  local old="$1"
  local new="$2"
  local outdir
  outdir=$(make_result_dir "$old")

  local tmp_old tmp_new
  tmp_old=$(mktemp)
  tmp_new=$(mktemp)

  trap 'rm -f "$tmp_old" "$tmp_new"' EXIT

  b3_to_path_hash() {
    awk '{ print substr($0,67) "\t" substr($0,1,64) }' "$1" | sort -t $'\t' -k1,1
  }

  b3_to_path_hash "$old" > "$tmp_old"
  b3_to_path_hash "$new" > "$tmp_new"

  join -t $'\t' -1 1 -2 1 "$tmp_old" "$tmp_new" \
    | awk -F $'\t' '$2 != $3 { print $3 "  " $1 }' \
    > "${outdir}/modifies.b3"

  comm -23 <(cut -f1 "$tmp_old") <(cut -f1 "$tmp_new") > "${outdir}/disparus.txt"
  comm -13 <(cut -f1 "$tmp_old") <(cut -f1 "$tmp_new") > "${outdir}/nouveaux.txt"

  local nb_modifies nb_disparus nb_nouveaux
  nb_modifies=$(wc -l < "${outdir}/modifies.b3")
  nb_disparus=$(wc -l < "${outdir}/disparus.txt")
  nb_nouveaux=$(wc -l < "${outdir}/nouveaux.txt")

  # ── recap.txt ─────────────────────────────────────────────────────────────
  {
    echo "Commande      : integrity.sh compare $(basename "$old") $(basename "$new")"
    echo "Date          : $(date)"
    echo "Ancienne base : $old"
    echo "Nouvelle base : $new"
    echo ""
    echo "Modifiés      : $nb_modifies"
    echo "Disparus      : $nb_disparus"
    echo "Nouveaux      : $nb_nouveaux"
  } > "${outdir}/recap.txt"

  # ── report.html — délégué à lib/report.sh ─────────────────────────────────
  generate_compare_html \
    "$old" "$new" \
    "$nb_modifies" "$nb_disparus" "$nb_nouveaux" \
    "${outdir}/modifies.b3" "${outdir}/disparus.txt" "${outdir}/nouveaux.txt" \
    "${outdir}/report.html"

  rm -f "$tmp_old" "$tmp_new"
  trap - EXIT

  say "Résultats enregistrés dans : $outdir"
  say "  recap.txt     — modifiés: $nb_modifies, disparus: $nb_disparus, nouveaux: $nb_nouveaux"
  say "  modifies.b3   — $nb_modifies fichiers"
  say "  disparus.txt  — $nb_disparus fichiers"
  say "  nouveaux.txt  — $nb_nouveaux fichiers"
  say "  report.html   — rapport visuel"
}

# ── Dispatch ──────────────────────────────────────────────────────────────────

case "$MODE" in
  compute)
    [ -n "$ARG2" ] || die "compute : dossier cible manquant.\nUsage : $0 compute <dossier> <base.b3>"
    [ -n "$ARG3" ] || die "compute : fichier de sortie .b3 manquant.\nUsage : $0 compute <dossier> <base.b3>"
    [ ! -d "$ARG3" ] || die "compute : '$ARG3' est un dossier. Le fichier .b3 de sortie doit être un chemin de fichier."
    assert_target_valid "$ARG2"
    compute_with_progress "$ARG2" "$ARG3"
    say "Base enregistrée : $ARG3 ($(wc -l < "$ARG3") fichiers)"
    ;;

  verify)
    [ -n "$ARG2" ] || die "verify : fichier .b3 manquant.\nUsage : $0 verify <base.b3> [dossier]"
    assert_b3_valid "$ARG2" "base"
    HASHFILE_ABS="$(cd "$(dirname "$ARG2")" && pwd)/$(basename "$ARG2")"
    if [ -n "$ARG3" ]; then
      [ -d "$ARG3" ] || die "verify : '$ARG3' n'est pas un dossier valide."
      cd "$ARG3"
    fi
    run_verify "$HASHFILE_ABS"
    ;;

  compare)
    [ -n "$ARG2" ] || die "compare : fichier ancienne base manquant.\nUsage : $0 compare <ancienne.b3> <nouvelle.b3>"
    [ -n "$ARG3" ] || die "compare : fichier nouvelle base manquant.\nUsage : $0 compare <ancienne.b3> <nouvelle.b3>"
    assert_b3_valid "$ARG2" "ancienne base"
    assert_b3_valid "$ARG3" "nouvelle base"
    run_compare "$ARG2" "$ARG3"
    ;;

  *)
    echo "Usage:"
    echo "  $0 [--quiet] compute <dossier> <base.b3>"
    echo "  $0 [--quiet] verify  <base.b3> [dossier]"
    echo "  $0 [--quiet] compare <ancienne.b3> <nouvelle.b3>"
    echo ""
    echo "Options:"
    echo "  --quiet   Silencieux : écrit uniquement dans les fichiers de résultats."
    exit 1
    ;;
esac

--- Fichier : src/lib/report.sh ---
#!/usr/bin/env bash
# lib/report.sh — Génération des rapports de résultats
#
# Sourcé par integrity.sh. Ne pas exécuter directement.
#
# Fonctions exportées :
#   generate_compare_html  <old> <new> <nb_mod> <nb_dis> <nb_nou>
#                          <modifies.b3> <disparus.txt> <nouveaux.txt>
#                          <output.html>

# ── Génération du rapport HTML pour compare ───────────────────────────────────
#
# Produit un fichier HTML autonome (CSS inline, pas de dépendance externe).
# Les listes de fichiers sont injectées depuis les fichiers texte produits
# par run_compare(). Le fichier est lisible hors ligne.
#
# Usage :
#   generate_compare_html \
#     "$old_b3" "$new_b3" \
#     "$nb_modifies" "$nb_disparus" "$nb_nouveaux" \
#     "$modifies_file" "$disparus_file" "$nouveaux_file" \
#     "$output_html"

generate_compare_html() {
  local old_b3="$1"
  local new_b3="$2"
  local nb_modifies="$3"
  local nb_disparus="$4"
  local nb_nouveaux="$5"
  local modifies_file="$6"
  local disparus_file="$7"
  local nouveaux_file="$8"
  local output_html="$9"

  local date_rapport
  date_rapport=$(date '+%Y-%m-%d %H:%M:%S')

  local nom_old nom_new
  nom_old=$(basename "$old_b3")
  nom_new=$(basename "$new_b3")

  # Statut global
  local statut statut_class
  if (( nb_modifies == 0 && nb_disparus == 0 && nb_nouveaux == 0 )); then
    statut="IDENTIQUES"
    statut_class="status-ok"
  else
    statut="DIFFÉRENCES DÉTECTÉES"
    statut_class="status-diff"
  fi

  # Lecture des listes de fichiers → HTML
  _render_file_list() {
    local file="$1"
    local empty_msg="$2"
    if [ ! -s "$file" ]; then
      echo "    <p class=\"empty\">$empty_msg</p>"
      return
    fi
    echo "    <ul>"
    while IFS= read -r line; do
      [ -n "$line" ] || continue
      # Pour modifies.b3 : "hash  chemin" → on affiche juste le chemin
      local display
      display=$(echo "$line" | awk '{ if (NF >= 2) { $1=""; print substr($0,2) } else { print $0 } }')
      echo "      <li><code>$(html_escape "$display")</code></li>"
    done < "$file"
    echo "    </ul>"
  }

  html_escape() {
    local s="$1"
    s="${s//&/&amp;}"
    s="${s//</&lt;}"
    s="${s//>/&gt;}"
    echo "$s"
  }

  local list_modifies list_disparus list_nouveaux
  list_modifies=$(_render_file_list "$modifies_file" "Aucun fichier modifié")
  list_disparus=$(_render_file_list "$disparus_file" "Aucun fichier disparu")
  list_nouveaux=$(_render_file_list "$nouveaux_file" "Aucun nouveau fichier")

  cat > "$output_html" <<HTML
<!DOCTYPE html>
<html lang="fr">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Rapport — ${nom_old} vs ${nom_new}</title>
  <style>
    /* ── Tokens ──────────────────────────────────────────────────── */
    :root {
      --bg:          #0f1117;
      --bg-card:     #161b27;
      --bg-card-alt: #1c2233;
      --border:      #252d3f;
      --border-glow: #2e3d5a;
      --text:        #c8d4e8;
      --text-dim:    #5a6a85;
      --text-head:   #e8eef8;
      --mono:        'JetBrains Mono', 'Fira Code', 'Cascadia Code', monospace;
      --sans:        'DM Sans', 'Outfit', system-ui, sans-serif;
      --accent-ok:   #22c55e;
      --accent-diff: #f59e0b;
      --accent-mod:  #e879f9;
      --accent-dis:  #f87171;
      --accent-nou:  #34d399;
      --radius:      8px;
      --radius-lg:   14px;
    }

    /* ── Reset & base ─────────────────────────────────────────────── */
    *, *::before, *::after { box-sizing: border-box; margin: 0; padding: 0; }

    @import url('https://fonts.googleapis.com/css2?family=DM+Sans:wght@300;400;500;600&family=JetBrains+Mono:wght@400;500&display=swap');

    body {
      background: var(--bg);
      color: var(--text);
      font-family: var(--sans);
      font-size: 14px;
      line-height: 1.6;
      min-height: 100vh;
      padding: 0 0 64px;
    }

    /* ── Header ───────────────────────────────────────────────────── */
    .header {
      background: var(--bg-card);
      border-bottom: 1px solid var(--border);
      padding: 28px 40px 24px;
      display: flex;
      align-items: flex-start;
      justify-content: space-between;
      gap: 24px;
    }

    .header-left h1 {
      font-family: var(--mono);
      font-size: 13px;
      font-weight: 500;
      color: var(--text-dim);
      letter-spacing: .08em;
      text-transform: uppercase;
      margin-bottom: 8px;
    }

    .bases-compare {
      display: flex;
      align-items: center;
      gap: 12px;
      flex-wrap: wrap;
    }

    .base-name {
      font-family: var(--mono);
      font-size: 14px;
      font-weight: 500;
      color: var(--text-head);
      background: var(--bg-card-alt);
      border: 1px solid var(--border-glow);
      border-radius: var(--radius);
      padding: 5px 12px;
    }

    .arrow {
      color: var(--text-dim);
      font-size: 16px;
    }

    .meta {
      font-size: 12px;
      color: var(--text-dim);
      margin-top: 10px;
      font-family: var(--mono);
    }

    /* ── Status badge ─────────────────────────────────────────────── */
    .status-badge {
      font-family: var(--mono);
      font-size: 11px;
      font-weight: 500;
      letter-spacing: .1em;
      text-transform: uppercase;
      padding: 6px 14px;
      border-radius: 100px;
      border: 1px solid;
      white-space: nowrap;
      align-self: flex-start;
      margin-top: 4px;
    }

    .status-ok   { color: var(--accent-ok);   border-color: var(--accent-ok);   background: rgba(34,197,94,.08);  }
    .status-diff { color: var(--accent-diff);  border-color: var(--accent-diff); background: rgba(245,158,11,.08); }

    /* ── Stats bar ────────────────────────────────────────────────── */
    .stats-bar {
      display: grid;
      grid-template-columns: repeat(3, 1fr);
      gap: 1px;
      background: var(--border);
      border-bottom: 1px solid var(--border);
    }

    .stat {
      background: var(--bg-card);
      padding: 20px 32px;
      display: flex;
      flex-direction: column;
      gap: 4px;
    }

    .stat-label {
      font-size: 11px;
      letter-spacing: .08em;
      text-transform: uppercase;
      color: var(--text-dim);
    }

    .stat-value {
      font-family: var(--mono);
      font-size: 28px;
      font-weight: 500;
      line-height: 1;
    }

    .stat-modifies .stat-value { color: var(--accent-mod); }
    .stat-disparus .stat-value { color: var(--accent-dis); }
    .stat-nouveaux .stat-value { color: var(--accent-nou); }

    /* ── Sections ─────────────────────────────────────────────────── */
    .main {
      max-width: 1100px;
      margin: 0 auto;
      padding: 36px 40px 0;
      display: grid;
      gap: 20px;
    }

    .section {
      background: var(--bg-card);
      border: 1px solid var(--border);
      border-radius: var(--radius-lg);
      overflow: hidden;
    }

    .section-header {
      display: flex;
      align-items: center;
      gap: 10px;
      padding: 14px 20px;
      border-bottom: 1px solid var(--border);
    }

    .section-dot {
      width: 8px;
      height: 8px;
      border-radius: 50%;
      flex-shrink: 0;
    }

    .section-modifies .section-dot { background: var(--accent-mod); }
    .section-disparus .section-dot { background: var(--accent-dis); }
    .section-nouveaux .section-dot { background: var(--accent-nou); }

    .section-title {
      font-size: 12px;
      font-weight: 600;
      letter-spacing: .06em;
      text-transform: uppercase;
      color: var(--text-head);
    }

    .section-count {
      margin-left: auto;
      font-family: var(--mono);
      font-size: 12px;
      color: var(--text-dim);
      background: var(--bg-card-alt);
      border: 1px solid var(--border);
      border-radius: 100px;
      padding: 2px 10px;
    }

    .section-body {
      padding: 16px 20px;
    }

    .section-body ul {
      list-style: none;
      display: flex;
      flex-direction: column;
      gap: 4px;
    }

    .section-body li {
      padding: 6px 10px;
      border-radius: var(--radius);
      background: var(--bg-card-alt);
      border: 1px solid transparent;
      transition: border-color .15s;
    }

    .section-body li:hover {
      border-color: var(--border-glow);
    }

    .section-body code {
      font-family: var(--mono);
      font-size: 12px;
      color: var(--text);
      word-break: break-all;
    }

    .empty {
      font-style: italic;
      color: var(--text-dim);
      font-size: 13px;
      padding: 4px 0;
    }

    /* ── Footer ───────────────────────────────────────────────────── */
    .footer {
      text-align: center;
      padding-top: 40px;
      font-size: 11px;
      color: var(--text-dim);
      font-family: var(--mono);
    }

    @media (max-width: 680px) {
      .header        { padding: 20px; flex-direction: column; }
      .stats-bar     { grid-template-columns: 1fr; }
      .main          { padding: 20px; }
    }
  </style>
</head>
<body>

  <!-- ── En-tête ──────────────────────────────────────────────────────── -->
  <header class="header">
    <div class="header-left">
      <h1>Rapport de comparaison — hash_tool</h1>
      <div class="bases-compare">
        <span class="base-name">$(html_escape "$nom_old")</span>
        <span class="arrow">→</span>
        <span class="base-name">$(html_escape "$nom_new")</span>
      </div>
      <div class="meta">Généré le ${date_rapport}</div>
    </div>
    <div class="status-badge ${statut_class}">${statut}</div>
  </header>

  <!-- ── Compteurs ────────────────────────────────────────────────────── -->
  <div class="stats-bar">
    <div class="stat stat-modifies">
      <span class="stat-label">Modifiés</span>
      <span class="stat-value">${nb_modifies}</span>
    </div>
    <div class="stat stat-disparus">
      <span class="stat-label">Disparus</span>
      <span class="stat-value">${nb_disparus}</span>
    </div>
    <div class="stat stat-nouveaux">
      <span class="stat-label">Nouveaux</span>
      <span class="stat-value">${nb_nouveaux}</span>
    </div>
  </div>

  <!-- ── Listes ───────────────────────────────────────────────────────── -->
  <main class="main">

    <div class="section section-modifies">
      <div class="section-header">
        <div class="section-dot"></div>
        <span class="section-title">Fichiers modifiés</span>
        <span class="section-count">${nb_modifies}</span>
      </div>
      <div class="section-body">
${list_modifies}
      </div>
    </div>

    <div class="section section-disparus">
      <div class="section-header">
        <div class="section-dot"></div>
        <span class="section-title">Fichiers disparus</span>
        <span class="section-count">${nb_disparus}</span>
      </div>
      <div class="section-body">
${list_disparus}
      </div>
    </div>

    <div class="section section-nouveaux">
      <div class="section-header">
        <div class="section-dot"></div>
        <span class="section-title">Nouveaux fichiers</span>
        <span class="section-count">${nb_nouveaux}</span>
      </div>
      <div class="section-body">
${list_nouveaux}
      </div>
    </div>

  </main>

  <footer class="footer">
    integrity.sh · BLAKE3 · ${date_rapport}
  </footer>

</body>
</html>
HTML
}

--- Fichier : docker/entrypoint.sh ---
#!/usr/bin/env bash
# /entrypoint.sh — Point d'entrée Docker pour hash_tool
#
# Dispatche les commandes vers integrity.sh ou runner.sh.
# Toutes les commandes de integrity.sh sont supportées directement.
#
# Exemples :
#   docker run hash_tool help
#   docker run hash_tool compute /data /bases/hashes.b3
#   docker run hash_tool verify  /bases/hashes.b3
#   docker run hash_tool compare /bases/old.b3 /bases/new.b3
#   docker run hash_tool runner  /pipelines/pipeline.json
#   docker run hash_tool runner                              # lit /pipelines/pipeline.json
#   docker run -it hash_tool shell                           # bash interactif (debug)

set -euo pipefail

APP="/app"
INTEGRITY="$APP/src/integrity.sh"
RUNNER="$APP/runner.sh"

# ── Aide ─────────────────────────────────────────────────────────────────────

print_help() {
  cat <<'EOF'
hash_tool — Vérification d'intégrité BLAKE3

Usage :
  docker run [--rm] [-v ...] hash_tool <commande> [arguments...]

Commandes :
  compute <dossier> <base.b3>       Calcule les hashes d'un dossier
  verify  <base.b3> [dossier]       Vérifie l'intégrité
  compare <ancienne.b3> <nouvelle.b3>  Compare deux bases
  runner  [pipeline.json]           Exécute un pipeline (défaut : /pipelines/pipeline.json)
  shell                             Lance un shell bash interactif (debug)
  help                              Affiche cette aide

Options globales (à placer avant la commande) :
  --quiet                           Supprime la sortie terminal

Volumes conventionnels :
  /data        → données à hacher        (-v /mes/donnees:/data)
  /bases       → fichiers .b3            (-v /mes/bases:/bases)
  /pipelines   → fichiers pipeline.json  (-v /chemin/pipeline.json:/pipelines/pipeline.json)
  /resultats   → résultats               (-v /mes/resultats:/resultats)

Variable d'environnement :
  RESULTATS_DIR  Dossier de résultats (défaut dans le conteneur : /resultats)

Exemples :
  # Calculer les hashes de /data, stocker dans /bases
  docker run --rm \
    -v /mes/donnees:/data:ro \
    -v /mes/bases:/bases \
    hash_tool compute /data /bases/hashes_$(date +%Y-%m-%d).b3

  # Vérifier depuis le dossier d'origine
  docker run --rm \
    -v /mes/donnees:/data:ro \
    -v /mes/bases:/bases:ro \
    -v /mes/resultats:/resultats \
    hash_tool verify /bases/hashes_2024-01-15.b3 /data

  # Comparer deux snapshots
  docker run --rm \
    -v /mes/bases:/bases:ro \
    -v /mes/resultats:/resultats \
    hash_tool compare /bases/hashes_2024-01-15.b3 /bases/hashes_2024-02-01.b3

  # Pipeline complet depuis un fichier JSON
  docker run --rm \
    -v /mes/donnees:/data:ro \
    -v /mes/bases:/bases \
    -v /mes/resultats:/resultats \
    -v /chemin/vers/pipeline.json:/pipelines/pipeline.json:ro \
    hash_tool runner

  # Mode silencieux (CI/cron)
  docker run --rm \
    -v /mes/donnees:/data:ro \
    -v /mes/bases:/bases:ro \
    -v /mes/resultats:/resultats \
    hash_tool --quiet verify /bases/hashes.b3 /data

EOF
}

# ── Vérification des outils ───────────────────────────────────────────────────

check_deps() {
  local ok=1
  command -v b3sum &>/dev/null || { echo "ERREUR : b3sum introuvable" >&2; ok=0; }
  command -v jq    &>/dev/null || { echo "ERREUR : jq introuvable"    >&2; ok=0; }
  [ -f "$INTEGRITY" ]          || { echo "ERREUR : $INTEGRITY introuvable" >&2; ok=0; }
  [ -f "$RUNNER" ]             || { echo "ERREUR : $RUNNER introuvable"    >&2; ok=0; }
  (( ok )) || exit 1
}

# ── Dispatch ──────────────────────────────────────────────────────────────────

# Extraire --quiet en tête s'il est présent
QUIET_FLAG=""
if [ "${1:-}" = "--quiet" ]; then
  QUIET_FLAG="--quiet"
  shift
fi

CMD="${1:-help}"
shift || true

case "$CMD" in

  compute|verify|compare)
    check_deps
    exec bash "$INTEGRITY" $QUIET_FLAG "$CMD" "$@"
    ;;

  runner)
    check_deps
    PIPELINE="${1:-/pipelines/pipeline.json}"
    if [ ! -f "$PIPELINE" ]; then
      echo "ERREUR : pipeline.json introuvable : $PIPELINE" >&2
      echo "Monter le fichier avec : -v /chemin/pipeline.json:/pipelines/pipeline.json" >&2
      exit 1
    fi
    exec bash "$RUNNER" "$PIPELINE"
    ;;

  shell|bash)
    echo "hash_tool — shell interactif (debug)"
    echo "  b3sum    : $(b3sum --version 2>/dev/null || echo 'non trouvé')"
    echo "  jq       : $(jq --version 2>/dev/null || echo 'non trouvé')"
    echo "  bash     : $BASH_VERSION"
    echo ""
    exec /bin/bash
    ;;

  help|--help|-h)
    print_help
    ;;

  version|--version|-v)
    echo "hash_tool"
    echo "  b3sum : $(b3sum --version 2>/dev/null || echo 'non trouvé')"
    echo "  jq    : $(jq --version 2>/dev/null || echo 'non trouvé')"
    echo "  bash  : $BASH_VERSION"
    ;;

  *)
    echo "ERREUR : commande inconnue : '$CMD'" >&2
    echo "Lancer 'docker run hash_tool help' pour la liste des commandes." >&2
    exit 1
    ;;

esac


--- Fichier : pipelines/pipeline full.json ---
{
    "pipeline": [

        {
            "op":     "compute",
            "source": "/mnt/a/dossier_disque_1",
            "bases":  "/mnt/c/Users/TonNom/Desktop/bases",
            "nom":    "hashes_dossier_1.b3"
        },

        {
            "op":     "compute",
            "source": "/mnt/i/dossier_disque_2",
            "bases":  "/mnt/c/Users/TonNom/Desktop/bases",
            "nom":    "hashes_dossier_2.b3"
        },

        {
            "op":     "compute",
            "source": "/mnt/h/dossier_disque_3",
            "bases":  "/mnt/c/Users/TonNom/Desktop/bases",
            "nom":    "hashes_dossier_3.b3"
        },

        {
            "op":     "verify",
            "source": "/mnt/a/dossier_disque_1",
            "base":   "/mnt/c/Users/TonNom/Desktop/bases/hashes_dossier_1.b3"
        },

        {
            "op":       "compare",
            "base_a":   "/mnt/c/Users/TonNom/Desktop/bases/hashes_dossier_1.b3",
            "base_b":   "/mnt/c/Users/TonNom/Desktop/bases/hashes_dossier_2.b3",
            "resultats": "/mnt/c/Users/TonNom/Desktop/rapports/compare_1_vs_2"
        }

    ]
}

--- Fichier : pipelines/pipeline.json ---
{
    "pipeline": [

        {
            "op":     "compute",
            "source": "./mon_dossier/source",
            "bases":  "./mon_dossier/bases",
            "nom":    "hashes_dossier_1.b3"
        },

        {
            "op":     "compute",
            "source": "./mon_dossier/destination",
            "bases":  "./mon_dossier/bases",
            "nom":    "hashes_dossier_2.b3"
        },

        {
            "op":       "compare",
            "base_a":   "./mon_dossier/bases/hashes_dossier_1.b3",
            "base_b":   "./mon_dossier/bases/hashes_dossier_2.b3",
            "resultats": "./mon_dossier/result"
        }

    ]
}

--- Fichier : docs/docker.md ---
# Docker — hash_tool

Utilisation de hash_tool via Docker — aucune dépendance à installer sur l'hôte.

---

## Prérequis

- Docker >= 20.10 (support multi-platform)
- Optionnel : Docker Compose v2

---

## Build

```bash
# Build standard (amd64)
docker build -t hash_tool .

# Build pour ARM64 (NAS Synology DS923+, Raspberry Pi, Apple Silicon)
docker build --platform linux/arm64 -t hash_tool:arm64 .

# Build avec version b3sum spécifique
docker build --build-arg B3SUM_VERSION=1.5.4 -t hash_tool .
```

---

## Commandes disponibles

```
docker run [--rm] [-v ...] hash_tool <commande> [args]

  compute <dossier> <base.b3>           Calcule les hashes
  verify  <base.b3> [dossier]           Vérifie l'intégrité
  compare <ancienne.b3> <nouvelle.b3>   Compare deux bases
  runner  [pipeline.json]               Exécute un pipeline JSON
  shell                                 Shell bash interactif (debug)
  help                                  Aide
  version                               Versions des outils
```

---

## Exemples d'utilisation

### Compute — indexer un dossier

```bash
docker run --rm \
  -v /mes/donnees:/data:ro \
  -v /mes/bases:/bases \
  hash_tool compute /data /bases/hashes_$(date +%Y-%m-%d).b3
```

### Verify — vérifier l'intégrité

```bash
# Depuis le répertoire d'origine (même montage /data qu'au compute)
docker run --rm \
  -v /mes/donnees:/data:ro \
  -v /mes/bases:/bases:ro \
  -v /mes/resultats:/resultats \
  hash_tool verify /bases/hashes_2024-01-15.b3 /data
```

Le résultat (`recap.txt`, `failed.txt` si échec) est écrit dans `/resultats` sur l'hôte.

### Compare — deux snapshots

```bash
docker run --rm \
  -v /mes/bases:/bases:ro \
  -v /mes/resultats:/resultats \
  hash_tool compare /bases/hashes_2024-01-15.b3 /bases/hashes_2024-02-01.b3
```

Produit `recap.txt`, `modifies.b3`, `disparus.txt`, `nouveaux.txt`, `report.html`.

### Pipeline JSON complet

```bash
docker run --rm \
  -v /mes/donnees:/data:ro \
  -v /mes/bases:/bases \
  -v /mes/resultats:/resultats \
  -v /chemin/vers/pipeline.json:/pipelines/pipeline.json:ro \
  hash_tool runner
```

### Mode silencieux — CI/cron

```bash
# Exit code 0 si OK, non-nul si FAILED
docker run --rm \
  -v /mes/donnees:/data:ro \
  -v /mes/bases:/bases:ro \
  -v /mes/resultats:/resultats \
  hash_tool --quiet verify /bases/hashes.b3 /data \
  || echo "ALERTE : corruption détectée"
```

### Debug interactif

```bash
docker run --rm -it \
  -v /mes/donnees:/data \
  -v /mes/bases:/bases \
  hash_tool shell
```

---

## Volumes

| Volume | Usage | Recommandation |
|---|---|---|
| `/data` | Données à hacher | `:ro` (lecture seule) |
| `/bases` | Fichiers `.b3` | Lecture/écriture pour `compute` |
| `/pipelines` | Fichiers `pipeline.json` | `:ro` |
| `/resultats` | Résultats `verify`/`compare` | Lecture/écriture |

---

## Variable d'environnement

`RESULTATS_DIR` — dossier de résultats dans le conteneur (défaut : `/resultats`).

```bash
docker run --rm \
  -v /mes/resultats:/mon_dossier_custom \
  -e RESULTATS_DIR=/mon_dossier_custom \
  hash_tool verify /bases/hashes.b3
```

---

## Docker Compose

Adapter les chemins dans `docker-compose.yml` (section `x-volumes`), puis :

```bash
# Commande ponctuelle
docker compose run --rm integrity verify /bases/hashes.b3 /data
docker compose run --rm integrity compute /data /bases/hashes.b3

# Pipeline complet
docker compose run --rm pipeline

# Build et run pipeline
docker compose build && docker compose run --rm pipeline
```

---

## NAS Synology

Sur DSM 7.x avec Docker Manager ou Portainer :

```bash
# Chemin type sur Synology
docker run --rm \
  -v /volume1/data:/data:ro \
  -v /volume1/bases:/bases \
  -v /volume1/resultats:/resultats \
  hash_tool verify /bases/hashes.b3 /data
```

Pour ARM64 (DS220+, DS923+) : builder avec `--platform linux/arm64` ou utiliser une image pré-buildée.

---

## Cron sur serveur Debian

```bash
# /etc/cron.d/hash-integrity
0 3 * * * root docker run --rm \
  -v /srv/data:/data:ro \
  -v /srv/bases:/bases:ro \
  -v /srv/resultats:/resultats \
  hash_tool --quiet verify /bases/hashes.b3 /data \
  >> /var/log/hash-integrity.log 2>&1 \
  || mail -s "ALERTE intégrité $(hostname)" admin@example.com
```

---

## Taille de l'image

| Couche | Taille approx. |
|---|---|
| Alpine 3.19 base | ~7 Mo |
| bash + jq + coreutils + findutils | ~5 Mo |
| b3sum binaire musl | ~2 Mo |
| Scripts hash_tool | <100 Ko |
| **Total** | **~14 Mo** |

L'utilisation d'un binaire musl pré-compilé (stage `fetcher`) évite d'embarquer la toolchain Rust (~700 Mo) dans l'image finale.

---

## Mise à jour de b3sum

Modifier `ARG B3SUM_VERSION` dans le `Dockerfile` et rebuilder :

```bash
docker build --build-arg B3SUM_VERSION=1.6.0 -t hash_tool .
```

Les URLs de release suivent le pattern :
```
https://github.com/BLAKE3-team/BLAKE3/releases/download/<version>/b3sum_linux_amd64_musl
https://github.com/BLAKE3-team/BLAKE3/releases/download/<version>/b3sum_linux_aarch64_musl
```

La signature `.b3` est vérifiée automatiquement au build (le binaire se vérifie lui-même).


--- Fichier : docs/explication-run-tests.md ---
# Explication du code — run_tests.sh + run_tests_pipeline.sh

---

## Vue d'ensemble

Deux suites de tests indépendantes, bash pur, sans framework externe.

```
tests/
├── run_tests.sh            ← integrity.sh — 15 cas T00–T14
└── run_tests_pipeline.sh   ← runner.sh + pipeline.json — 12 cas TP01–TP12
```

Chaque suite : prérequis → setup → tests → teardown → rapport + exit code CI.

---

## PARTIE 1 — run_tests.sh (integrity.sh)

### 1.1 Configuration et chemins

```bash
SCRIPT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"
INTEGRITY="$SCRIPT_DIR/../integrity.sh"
WORKDIR="$(mktemp -d /tmp/integrity-test.XXXXXX)"
```

- `SCRIPT_DIR` : répertoire absolu du script, indépendant du `pwd` appelant.
- `INTEGRITY` : chemin relatif à `run_tests.sh` — déplaçables ensemble sans modifier les chemins.
- `WORKDIR` : répertoire temporaire isolé par `mktemp`, suffix aléatoire 6 chars.

### 1.2 Système de comptage

```bash
PASS=0; FAIL=0; TOTAL=0
pass() { echo -e "${GREEN}  PASS${NC} — $1"; (( PASS++ )); (( TOTAL++ )); }
fail() { echo -e "${RED}  FAIL${NC} — $1"; (( FAIL++ )); (( TOTAL++ )); }
```

`TOTAL` permet de détecter un test sauté silencieusement.

### 1.3 Fonctions d'assertion

**`assert_exit_zero` / `assert_exit_nonzero`** : exécute une commande, vérifie le code de retour. `> /dev/null 2>&1` supprime toute sortie. `shift` consomme le label pour que `"$@"` ne contienne que la commande.

**`assert_contains` / `assert_not_contains`** : cherche un pattern dans une chaîne capturée. La capture via `local out=$(commande)` avant l'assertion permet plusieurs inspections sans relancer la commande.

**`assert_line_count`** : `wc -l < fichier` (sans le nom) — pas d'affichage du nom par `wc`.

**`assert_file_exists` / `assert_file_absent`** : présence ou absence d'un fichier régulier.

### 1.4 Setup / Teardown

4 fichiers déterministes (contenu connu → hashes reproductibles). `sub/delta.txt` valide la récursivité de `find`. `teardown()` supprime `WORKDIR` entier.

### 1.5 Pattern || true

```bash
local out
out=$(commande 2>&1 || true)
```

Critique : sans `|| true`, un code de retour non nul sous `-euo pipefail` interrompt le script avant que l'assertion enregistre l'échec.

### 1.6 Cas de test spécifiques

**T00 — ShellCheck** : analyse statique sur `integrity.sh` et `run_tests.sh`. `SKIP` propre si non installé.

**T11 — Intégrité base avec ETA** : vérifie que `compute_with_progress` produit une base bit-à-bit identique à `find | sort | xargs b3sum`, sans artefact `ETA` ni `\r`.

**T12 — Mode `--quiet`** : stdout vide sur verify OK, verify ECHEC, et compute. Exit code non nul propagé. Fichiers de résultats produits malgré `--quiet`.

**T13 — Horodatage** : deux `verify` successifs sur la même base → deux dossiers distincts (pas d'écrasement). `sleep 1` garantit des timestamps différents.

**T14 — Argument invalide** : `verify base.b3 /chemin/inexistant` → `ERREUR` explicite.

### 1.7 Tableau des cas

| Cas | Description |
|---|---|
| T00 | ShellCheck (analyse statique) |
| T01 | Compute de base |
| T02 | Verify sans modification |
| T03 | Verify après corruption |
| T04 | Verify après suppression |
| T05 | Compare sans différence |
| T06 | Compare avec fichier modifié |
| T07 | Compare avec fichier supprimé + ajouté |
| T08 | Noms de fichiers avec espaces |
| T09 | Dossiers vides ignorés |
| T10 | Chemins absolus vs relatifs |
| T11 | Intégrité base avec ETA |
| T12 | Mode `--quiet` |
| T13 | Horodatage anti-écrasement |
| T14 | Argument invalide pour verify |

---

## PARTIE 2 — run_tests_pipeline.sh (runner.sh + pipeline.json)

### 2.1 Configuration et chemins

```bash
SCRIPT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"
RUNNER="$SCRIPT_DIR/../runner.sh"
INTEGRITY="$SCRIPT_DIR/../integrity.sh"
WORKDIR="$(mktemp -d /tmp/integrity-pipeline-test.XXXXXX)"
export RESULTATS_DIR="$WORKDIR/resultats"
```

`RESULTATS_DIR` est exporté pour que `integrity.sh` (appelé par `runner.sh`) redirige ses résultats dans le `WORKDIR` isolé — pas dans `~/integrity_resultats`.

### 2.2 Helper write_config

```bash
write_config() {
    local path="$WORKDIR/pipeline.json"
    cat > "$path"
    echo "$path"
}
```

Lit le JSON depuis stdin (heredoc), l'écrit dans `WORKDIR/pipeline.json`, retourne le chemin. Permet de générer un `pipeline.json` différent par test sans fichiers temporaires nommés à la main.

Usage :

```bash
local cfg
cfg=$(write_config <<EOF
{ "pipeline": [ { "op": "compute", ... } ] }
EOF
)
bash "$RUNNER" "$cfg"
```

### 2.3 Stratégie de test par cas

**TP01–TP04 (parsing)** : tests négatifs — chaque test passe un JSON ou une config invalide et vérifie que `runner.sh` échoue avec un message `ERREUR` explicite, sans stacktrace `jq` brute ni crash silencieux.

**TP05–TP06 (compute)** : TP05 vérifie trois invariants sur la base produite — existence, chemins relatifs (`./ `en début de chemin), comptage exact de fichiers. TP06 vérifie l'échec propre sur source absente.

**TP07–TP09 (verify)** : TP07 vérifie le bon répertoire de travail (vérification OK, `recap.txt` produit). TP08 vérifie la détection de corruption. TP09 vérifie l'échec propre sur base absente.

**TP10–TP11 (compare)** : TP10 vérifie les quatre fichiers de résultats produits. TP11 vérifie l'échec propre sur `base_a` absente.

**TP12 (pipeline complet)** : test d'intégration — compute × 2 + verify + compare dans un seul `pipeline.json`. Vérifie les labels dans la sortie, les bases créées, et l'absence d'erreur.

### 2.4 Résolution des dossiers de résultats

```bash
outdir_tp07=$(ls -d "${RESULTATS_DIR}/resultats_hashes_a"* 2>/dev/null | tail -1)
```

`tail -1` récupère le dossier le plus récent — compatible avec l'horodatage automatique de `make_result_dir()`. Sans `tail -1`, si un dossier `resultats_hashes_a` existe déjà d'un test précédent, `ls` retourne plusieurs lignes et l'assertion porte sur la mauvaise.

### 2.5 Prérequis et exécution

```bash
cd tests
./run_tests_pipeline.sh
```

Prérequis : `jq`, `b3sum`, `bash >= 4`, `runner.sh` et `integrity.sh` dans le répertoire parent. Exit code CI-compatible : 0 si tous passent, 1 si au moins un échec.

### 2.6 Tableau des cas

| Cas | Description |
|---|---|
| TP01 | JSON invalide — erreur propre sans stacktrace jq |
| TP02 | Clé `.pipeline` absente |
| TP03 | Champ `nom` manquant dans compute |
| TP04 | Opération inconnue |
| TP05 | Compute — cd correct, chemins relatifs, comptage |
| TP06 | Compute — dossier source absent |
| TP07 | Verify — bon répertoire de travail, OK |
| TP08 | Verify — corruption détectée |
| TP09 | Verify — base .b3 absente |
| TP10 | Compare — fichiers de résultats produits |
| TP11 | Compare — base_a absente |
| TP12 | Pipeline complet compute + verify + compare |

---

## Prérequis globaux

```bash
# run_tests.sh
apt install b3sum shellcheck   # shellcheck optionnel

# run_tests_pipeline.sh
apt install b3sum jq
```

Les deux suites sont indépendantes et peuvent être lancées séparément.

--- Fichier : docs/hash_tool-docker-documentation.docx ---
[Fichier binaire ou illisible, contenu ignoré]

--- Fichier : docs/hash_tool-docker-documentation.pdf ---
[Fichier binaire ou illisible, contenu ignoré]

--- Fichier : docs/hash_tool-positionnement-open-source.docx ---
[Fichier binaire ou illisible, contenu ignoré]

--- Fichier : docs/hash_tool-positionnement-open-source.pdf ---
[Fichier binaire ou illisible, contenu ignoré]

--- Fichier : docs/hash_tool-presentation.docx ---
[Fichier binaire ou illisible, contenu ignoré]

--- Fichier : docs/hash_tool-presentation.pdf ---
[Fichier binaire ou illisible, contenu ignoré]

--- Fichier : docs/manuel.md ---
# Manuel technique — Vérification d'intégrité de données

**Périmètre :** détection d'erreurs de transfert et de corruption silencieuse sur disque, sans adversaire.  
**Outils couverts :** b3sum (BLAKE3) · xxHash3 · find · diff · bash · jq

---

## Table des matières

1. [Algorithmes de hachage](#1-algorithmes-de-hachage)
2. [Structure du fichier .b3](#2-structure-du-fichier-b3)
3. [Workflow : calcul, stockage, comparaison](#3-workflow--calcul-stockage-comparaison)
4. [Explication du script integrity.sh](#4-explication-du-script-integritysh)
5. [Pipeline batch : runner.sh + pipeline.json](#5-pipeline-batch--runnersh--pipelinejson)
6. [Performances et optimisation disque](#6-performances-et-optimisation-disque)
7. [Limites et angles morts](#7-limites-et-angles-morts)
8. [Référence rapide](#8-référence-rapide)
9. [Annexe — Alternatives et extensions](#9-annexe--alternatives-et-extensions)

---

## 1. Algorithmes de hachage

### Taxonomie

Deux familles distinctes, usages mutuellement exclusifs :

| Propriété | Cryptographique (BLAKE3) | Non-cryptographique (xxHash3) |
|---|---|---|
| Résistance collision intentionnelle | Oui — infaisable calculatoirement | Non — collisions construisibles |
| Résistance préimage | Oui | Non |
| Débit CPU (1 cœur) | ~1 Go/s | ~50 Go/s |
| Débit sur HDD (150 Mo/s) | Identique — disque impose le rythme | Identique |
| Débit sur SATA SSD (500 Mo/s) | Identique | Identique |
| Détection corruption accidentelle | Oui | Oui |
| Utilisable en sécurité | Oui | Non |

### Pourquoi BLAKE3 plutôt que xxHash3

xxHash3 est techniquement suffisant pour détecter des erreurs accidentelles. BLAKE3 est recommandé pour une seule raison : **le coût marginal sur disque est nul** — les deux sont limités par l'I/O. BLAKE3 reste utilisable si le besoin évolue vers un contexte de sécurité. Headroom gratuit.

```bash
# Si xxHash3 est préféré — workflow identique à b3sum
find ./dossier -type f -print0 | sort -z | xargs -0 xxh128sum > base.xxh
```

### Limitations spécifiques à ce workflow

- Ne hache pas les métadonnées (mtime, permissions).
- Ne hache pas les dossiers vides : `find -type f` ne remonte que les fichiers réguliers.
- Sensible aux chemins : chemin absolu vs relatif → deux bases incompatibles pour la même donnée.

---

## 2. Structure du fichier .b3

b3sum produit un format texte simple, une ligne par fichier :

```
# Format : <hash>  <chemin>
# Deux espaces séparent le hash du chemin (convention b3sum/sha256sum)

a1b2c3d4e5f6a7b8c9d0e1f2a3b4c5d6e7f8a9b0c1d2e3f4a5b6c7d8e9f0a1b2  ./dossier/fichier.txt
e5f6a7b8c9d0e1f2a3b4c5d6e7f8a9b0c1d2e3f4a5b6c7d8e9f0a1b2c3d4e5f6  ./dossier/sous/autre.bin
```

| Nombre de fichiers | Taille approximative |
|---|---|
| 10 000 | ~2 Mo |
| 100 000 | ~20 Mo |
| 1 000 000 | ~200 Mo |

> **Règle absolue : chemins relatifs.** Toujours `find ./dossier`, jamais `find /chemin/absolu`. Un chemin absolu rend la base inutilisable après déplacement ou remontage.

---

## 3. Workflow : calcul, stockage, comparaison

### Calcul et enregistrement de la base

```bash
find ./mon_dossier -type f -print0 \
  | sort -z \
  | xargs -0 b3sum \
  > hashes_2024-01-15.b3

wc -l hashes_2024-01-15.b3
```

**`sort -z`** : `find` ne garantit pas un ordre déterministe. Sans tri, `diff` entre deux bases est inutilisable.

**`-print0` / `-0`** : robuste aux noms de fichiers avec espaces ou caractères spéciaux.

### Vérification directe

```bash
b3sum --check hashes_2024-01-15.b3

# Sortie OK :
# ./mon_dossier/fichier.txt: OK

# Sortie ECHEC :
# ./mon_dossier/sous/corrompu.bin: FAILED
# b3sum: WARNING: 1 computed checksum did NOT match

b3sum --check hashes_2024-01-15.b3 2>&1 | grep FAILED
```

> **Contrainte critique : répertoire de travail.** `b3sum --check` résout les chemins relatifs depuis `pwd`. Toujours exécuter depuis le répertoire où `compute` a été lancé.

### Comparaison de deux bases .b3

```bash
diff <(sort hashes_2024-01-15.b3) <(sort hashes_2024-02-01.b3)
```

`run_compare()` dans `integrity.sh` automatise cette comparaison avec `join`, `comm`, et un rapport structuré.

---

## 4. Explication du script integrity.sh

### En-tête et mode strict

```bash
#!/usr/bin/env bash
set -euo pipefail
```

- `-e` : arrêt sur échec de commande.
- `-u` : erreur sur variable non initialisée.
- `-o pipefail` : échec du pipeline si une commande intermédiaire échoue.

### Parsing des arguments

```bash
QUIET=0
ARGS=()
for arg in "$@"; do
  case "$arg" in
    --quiet) QUIET=1 ;;
    *)       ARGS+=("$arg") ;;
  esac
done
MODE="${ARGS[0]:-}"
ARG2="${ARGS[1]:-}"
ARG3="${ARGS[2]:-}"
```

`--quiet` filtré avant la lecture positionnelle. `:-` donne une valeur vide par défaut en mode `-u`.

### Mode compute

```bash
compute_with_progress() {
  local -a files
  mapfile -d '' files < <(find "$target" -type f -print0 | sort -z)

  for file in "${files[@]}"; do
    b3sum "$file" >> "$hashfile"
    # ETA calculé et affiché sur /dev/tty — jamais dans le pipe
    printf "\r[%d/%d] ETA : %dm %02ds   " ... > /dev/tty
  done
}
```

**`mapfile -d ''`** : charge les chemins en tableau depuis flux nul-séparé. Robuste aux espaces et caractères spéciaux.

**`> /dev/tty`** : progression écrite directement sur le terminal, ne peut pas polluer la base `.b3`.

### Mode verify

```bash
hashfile_abs=$(realpath "$ARG2")
[ -n "${ARG3:-}" ] && cd "$ARG3"
run_verify "$hashfile_abs"
```

Le chemin absolu est résolu **avant** le `cd` — un chemin relatif deviendrait invalide après changement de répertoire.

### Mode compare

`run_compare()` convertit `hash  chemin` → `chemin\thash` via `awk` (offset fixe 64 chars pour le hash), puis utilise `sort`, `join`, `comm` avec `-t $'\t'` — robuste aux chemins avec espaces.

---

## 5. Pipeline batch : runner.sh + pipeline.json

### Problème résolu

Lancer `integrity.sh` manuellement sur plusieurs dossiers depuis des partitions différentes (VeraCrypt, disques externes) est error-prone : répertoire de travail incorrect, chemins absolus dans les bases, oubli de `cd`. `runner.sh` automatise et sécurise ces étapes.

**Dépendance supplémentaire :** `jq` (`apt install jq` dans WSL).

### pipeline.json — format

```json
{
    "pipeline": [

        {
            "op":     "compute",
            "source": "/mnt/a/dossier_disque_1",
            "bases":  "/mnt/c/Users/TonNom/Desktop/bases",
            "nom":    "hashes_dossier_1.b3"
        },

        {
            "op":     "compute",
            "source": "/mnt/i/dossier_disque_2",
            "bases":  "/mnt/c/Users/TonNom/Desktop/bases",
            "nom":    "hashes_dossier_2.b3"
        },

        {
            "op":     "verify",
            "source": "/mnt/a/dossier_disque_1",
            "base":   "/mnt/c/Users/TonNom/Desktop/bases/hashes_dossier_1.b3"
        },

        {
            "op":     "compare",
            "base_a": "/mnt/c/Users/TonNom/Desktop/bases/hashes_dossier_1.b3",
            "base_b": "/mnt/c/Users/TonNom/Desktop/bases/hashes_dossier_2.b3"
        }

    ]
}
```

Champs requis par opération :

| `op` | Champs |
|---|---|
| `compute` | `source` — dossier à hacher · `bases` — dossier de destination · `nom` — nom du `.b3` |
| `verify` | `source` — répertoire de travail d'origine · `base` — chemin complet du `.b3` |
| `compare` | `base_a` — ancienne base · `base_b` — nouvelle base |

### runner.sh — comportement

**compute** : `cd "$source"` puis `integrity.sh compute . "$bases/$nom"`. Le `.` garantit des chemins relatifs dans la base.

**verify** : `cd "$source"` puis `integrity.sh verify "$base"`. Le `cd` reproduit le répertoire de travail d'origine du compute.

**compare** : appel direct sans `cd`. `base_a` et `base_b` sont des chemins absolus vers les `.b3`.

**Validation** : `jq empty` vérifie la syntaxe JSON à l'entrée. Champs manquants et opérations inconnues produisent un message `ERREUR` avec numéro de bloc, sans stacktrace `jq`.

### Lancement Windows (double-clic)

```bat
@echo off
wsl bash /mnt/c/Users/TonNom/Desktop/runner.sh
pause
```

### Chemins WSL — partitions VeraCrypt

| Windows | WSL |
|---|---|
| `A:\` | `/mnt/a/` |
| `C:\` | `/mnt/c/` |
| `H:\` | `/mnt/h/` |
| `I:\` | `/mnt/i/` |

Si VeraCrypt remonte une partition sur une lettre différente, seul le champ `source` dans `pipeline.json` est à modifier. La base `.b3` reste valide car ses chemins sont relatifs.

---

## 6. Performances et optimisation disque

Sur HDD (150 Mo/s), SSD SATA (500 Mo/s) ou SSD NVMe séquentiel, le disque est systématiquement le goulot. b3sum à 1 Go/s sur un cœur ne sera jamais le facteur limitant.

La boucle séquentielle de `compute_with_progress` est légèrement moins efficace que `xargs -P 4` sur SSD NVMe avec de nombreux petits fichiers, mais identique sur HDD — cas principal pour gros volumes. Le gain ETA justifie le choix.

Pour SSD NVMe + pas besoin d'ETA :

```bash
find ./dossier -type f -print0 | sort -z | xargs -0 -P 4 b3sum > base.b3
```

---

## 7. Limites et angles morts

| Scénario | Détecté ? | Explication |
|---|---|---|
| Fichier corrompu | **Oui** | Hash différent → FAILED ou divergence compare |
| Fichier manquant | **Oui** | FAILED (No such file) ou section DISPARUS |
| Fichier ajouté | **Oui** (compare) | Section NOUVEAUX |
| Dossier vide | **Non** | `find -type f` ignore les dossiers vides |
| Permissions/timestamps | **Non** | b3sum ne hache que le contenu binaire |
| Clone identique | **Non** | Hash identique — indétectable par définition |
| Corruption de la base .b3 | **Non** | La base n'est pas auto-protégée |

### Protéger la base

```bash
b3sum hashes_2024-01-15.b3 > hashes_2024-01-15.b3.check
b3sum --check hashes_2024-01-15.b3.check
```

Stocker la base sur un support distinct. Sur VeraCrypt : stocker les `.b3` sur `C:`, jamais sur la partition vérifiée.

### Renommages et changements de chemin

`b3sum --check` compare les chemins littéralement. Tout renommage de dossier produit des FAILED sur tous les fichiers, même si le contenu est intact.

```bash
sed 's|./ancien_nom/|./nouveau_nom/|g' base.b3 > base_corrigee.b3
b3sum --check base_corrigee.b3
```

---

## 8. Référence rapide

```bash
# Calcul
find ./dossier -type f -print0 | sort -z | xargs -0 b3sum > base.b3

# Vérification
./integrity.sh verify base.b3

# Comparaison
./integrity.sh compare ancienne.b3 nouvelle.b3

# Pipeline multi-dossiers
./runner.sh                        # lit pipeline.json dans le même dossier
./runner.sh /chemin/pipeline.json  # config explicite

# Compter les fichiers indexés
wc -l base.b3

# Fichier unique
b3sum fichier.bin

# Protéger la base
b3sum base.b3 > base.b3.check
```

| Situation | Mode | Commande |
|---|---|---|
| Première indexation | compute | `./integrity.sh compute ./dossier base.b3` |
| Multi-dossiers / VeraCrypt | runner | `./runner.sh` |
| Vérifier après transfert | verify | `./integrity.sh verify base.b3` |
| Comparer deux archives | compare | `./integrity.sh compare old.b3 new.b3` |
| Fichier unique | ad hoc | `b3sum fichier.bin` |

---

## 9. Annexe — Alternatives et extensions

### A.1 Outils FIM

| Outil | Usage | Complexité | Pertinent si… |
|---|---|---|---|
| Tripwire | Audit système local | Moyenne | Serveur Linux, conformité PCI-DSS/HIPAA |
| Samhain | FIM distribué, alertes SIEM | Élevée | Infrastructure d'entreprise |
| AIDE | Alternative open source à Tripwire | Moyenne | Remplacement direct de Tripwire |
| ZFS | Checksum natif sur chaque bloc | Faible (si migration possible) | Protection transparente |

b3sum/xxHash3 sont des **primitives**. Tripwire et Samhain sont des **systèmes** qui maintiennent un état de référence et détectent les dérives.

### A.2 Intégration automatisée

```bash
# Crontab — vérification hebdomadaire
0 2 * * 0 /opt/integrity.sh --quiet verify /var/lib/integrity/base.b3 >> /var/log/integrity.log 2>&1

# Post-transfert rsync
rsync -av source/ dest/ && b3sum --check base.b3

# Alerte email
b3sum --check base.b3 2>&1 | grep FAILED | mail -s 'Alerte intégrité' admin@example.com
```

--- Fichier : docs/progression-eta.md ---
# Progression temps réel et estimation ETA

## Le problème

Le pipeline `find | sort | xargs b3sum` est une boîte noire : `b3sum` ne remonte aucune progression. Par défaut, le mode `compute` s'exécute en silence jusqu'à complétion - aucun indicateur de durée ni d'avancement.

---

## Pourquoi l'ETA nécessite de casser le pipeline `xargs`

Intercaler `pv` dans le pipeline existant est techniquement possible mais inutilisable ici : mesurer le débit sur un flux `cat | pv | b3sum` produit un hash global du flux concaténé, pas une ligne par fichier. Le fichier `.b3` résultant est invalide pour `--check` ou `compare`.

```bash
# Cette approche est invalide - ne pas utiliser
TOTAL=$(find "$TARGET" -type f -print0 | xargs -0 du -sb | awk '{sum+=$1} END {print sum}')
find "$TARGET" -type f -print0 | sort -z \
  | xargs -0 cat \
  | pv -s "$TOTAL" \
  | b3sum \
  > "$HASHFILE"
# Produit un hash unique du flux concaténé - inutilisable
```

La seule approche compatible avec le format `.b3` : remplacer `xargs` par une boucle bash explicite, fichier par fichier. Le contrôle de progression devient trivial. Le coût en performance est négligeable - le disque est le goulot, pas le shell.

---

## Implémentation finale : `compute_with_progress`

```bash
compute_with_progress() {
  local target="$1"
  local hashfile="$2"

  local -a files
  mapfile -d '' files < <(find "$target" -type f -print0 | sort -z)

  local total_files=${#files[@]}
  local total_bytes
  total_bytes=$(du -sb "$target" | awk '{print $1}')

  local bytes_done=0
  local t_start
  t_start=$(date +%s)

  local i=0
  for file in "${files[@]}"; do
    b3sum "$file" >> "$hashfile"

    bytes_done=$(( bytes_done + $(stat -c%s "$file") ))
    i=$(( i + 1 ))

    local t_now elapsed
    t_now=$(date +%s)
    elapsed=$(( t_now - t_start ))

    if (( bytes_done > 0 && elapsed > 0 )); then
      local speed remaining
      speed=$(( bytes_done / elapsed ))
      remaining=$(( (total_bytes - bytes_done) / speed ))
      printf "\r[%d/%d] ETA : %dm %02ds   " \
        "$i" "$total_files" $(( remaining / 60 )) $(( remaining % 60 ))
    fi
  done

  printf "\r%*s\r" 40 ""  # effacer la ligne de progression
}
```

**`mapfile -d ''`** au lieu de `FILES=($(find ...))` : la substitution de commande `$(...)` découpe sur les espaces et les retours à la ligne - les noms de fichiers avec espaces seraient cassés en plusieurs éléments. `mapfile -d ''` lit le flux nul-séparé produit par `-print0` et charge chaque chemin comme un élément distinct du tableau, sans ambiguïté.

---

## Mécanique de l'estimation

L'ETA repose sur trois mesures :

- **octets traités** - cumulés après chaque fichier via `stat -c%s`
- **octets totaux** - calculés une fois avant la boucle via `du -sb`
- **débit instantané** - `octets_traités / secondes_écoulées`

```
ETA = (octets_restants) / débit_moyen
    = (total - fait) / (fait / elapsed)
```

Le débit moyen converge après ~10–20 secondes de traitement. Avant ce seuil, l'ETA est instable - comportement identique à `rsync`, `cp --progress`, ou tout outil du même type. Ce n'est pas un défaut d'implémentation, c'est une contrainte statistique inhérente à toute estimation par extrapolation linéaire sur fenêtre courte.

---

## Coût du changement de stratégie

| | Pipeline `xargs` | Boucle bash (avec progression) |
|---|---|---|
| Débit sur HDD | Optimal | Identique - I/O impose le rythme |
| Débit sur SSD séquentiel | Optimal | Identique |
| Débit sur SSD `-P 4` | +20–40 % | Non applicable - boucle séquentielle |
| Progression temps réel | Non | Oui |
| ETA | Non | Oui |

**Cas où la boucle dégrade les performances :** SSD avec `-P 4`. Le parallélisme par `xargs` n'est pas reproductible en boucle bash sans complexité significative. Sur HDD - cas le plus courant pour de gros volumes - la différence est nulle.


